@inproceedings{10.1007/978-3-319-78105-1_46,
  title = {Factors Influencing Emoji Usage in Smartphone Mediated Communications},
  booktitle = {Transforming Digital Worlds},
  author = {An, Jiaxin and Li, Tian and Teng, Yifei and Zhang, Pengyi},
  editor = {Chowdhury, Gobinda and McLeod, Julie and Gillet, Val and Willett, Peter},
  year = {2018},
  pages = {423--428},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  abstract = {Emojis have become more and more popular in text-based online communication to express emotions. This indicates a potential to utilize emojis in sentiment analysis and emotion measurements. However, many factors could affect people's emoji usage and need to be examined. Among them, age, gender, and relationship types may result in different interpretations of the same emoji due to the ambiguity of the iconic expression. In this paper, we aim to explore how these factors may affect the frequency, type, and sentiment of people's emoji usage in communications. After analyzing 6,821 Wechat chatting messages from 158 participants, we found people between 26{\textendash}35 had lowest frequency of emoji usage; younger and elder groups showed different sentiment levels for the same emojis; people chose emoji types based on relationships. These findings shed light on how people use emojis as a communication tool.},
  isbn = {978-3-319-78105-1}
}

@article{addingtonRelationshipSelectedVocal1968,
  title = {The Relationship of Selected Vocal Characteristics to Personality Perception},
  author = {Addington, David W.},
  year = {1968},
  file = {/Users/timokoch/Zotero/storage/T3TZ6JFK/Addington - 1968 - The relationship of selected vocal characteristics.pdf}
}

@misc{Affectiva2019,
  title = {Affectiva},
  year = {2019},
  urldate = {2019-03-03},
  howpublished = {https://www.affectiva.com/},
  file = {/Users/timokoch/Zotero/storage/SYZJLPYP/www.affectiva.com.html}
}

@article{alamComparativeStudySpeaker,
  title = {Comparative {{Study}} of {{Speaker Personality Traits Recognition}} in {{Conversational}} and {{Broadcast News Speech}}},
  author = {Alam, Firoj and Riccardi, G},
  pages = {5},
  abstract = {Natural human-computer interaction requires, in addition to understand what the speaker is saying, recognition of behavioral descriptors, such as speaker's personality traits (SPTs). The complexity of this problem depends on the high variability and dimensionality of the acoustic, lexical and situational context manifestations of the SPTs. In this paper, we present a comparative study of automatic speaker personality trait recognition from speech corpora that differ in the source speaking style (broadcast news vs. conversational) and experimental context. We evaluated different feature selection algorithms such as information gain, relief and ensemble classification methods to address the high dimensionality issues. We trained and evaluated ensemble methods to leverage base learners, using three different algorithms such as SMO (Sequential Minimal Optimization for Support Vector Machine), RF (Random Forest) and Adaboost. After that, we combined them using majority voting and stacking methods. Our study shows that, performance of the system greatly benefits from feature selection and ensemble methods across corpora.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/CB33DAK3/Alam und Riccardi - Comparative Study of Speaker Personality Traits Re.pdf}
}

@inproceedings{alamFusionAcousticLinguistic2014,
  title = {Fusion of Acoustic, Linguistic and Psycholinguistic Features for {{Speaker Personality Traits}} Recognition},
  booktitle = {2014 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  author = {Alam, Firoj and Riccardi, Giuseppe},
  year = {2014},
  month = may,
  pages = {955--959},
  publisher = {{IEEE}},
  address = {{Florence, Italy}},
  doi = {10.1109/ICASSP.2014.6853738},
  urldate = {2019-07-05},
  abstract = {Behavioral analytics is an emerging research area that aims at automatic understanding of human behavior. For the advancement of this research area, we are interested in the problem of learning the personality traits from spoken data. In this study, we investigated the contribution of different types of speech features to the automatic recognition of Speaker Personality Trait (SPT) across diverse speech corpora (broadcast news and spoken conversation). We have extracted acoustic, linguistic, and psycholinguistic features and modeled their combination as input to the classification task. For the classification, we used Sequential Minimal Optimization for Support Vector Machine (SMO) together with Relief feature selection. The present study shows different levels of performance for automatically selected feature sets, and overall improved performance with their combination across diverse corpora.},
  isbn = {978-1-4799-2893-4},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/TEIVWBEQ/Alam und Riccardi - 2014 - Fusion of acoustic, linguistic and psycholinguisti.pdf}
}

@article{alexanderBewareSimpleUnambiguous2015,
  title = {Beware of {{R}} 2: Simple, Unambiguous Assessment of the Prediction Accuracy of {{QSAR}} and {{QSPR}} Models},
  author = {Alexander, D. L. J. and Tropsha, A. and Winkler, David A.},
  year = {2015},
  journal = {Journal of chemical information and modeling},
  volume = {55},
  number = {7},
  pages = {1316--1322},
  issn = {1549-9596}
}

@article{allportUsePersonalDocuments1942,
  title = {The Use of Personal Documents in Psychological Science},
  author = {Allport, G. W.},
  year = {1942},
  journal = {Social Science Research Council Bulletin},
  volume = {49},
  abstract = {The psychological use of personal documents is traced from its uncritical beginnings at the turn of the century to its emergence in the last 20 years as a method in its own right. Its uses in molecular and molar research; in teaching; in suggesting new items for questionnaires; in inductive studies, often with the construction of typologies; in social psychology; etc. are examined. The place of the personal document in an idiographic rather than a nomothetic scheme is stressed: "Lawful happenings may be one-time events. Frequency is not a necessary test of validity." The forms of personal documents are presented with examples and discussion. Essentially, documents are reducible to autobiographies, questionnaire responses, verbatim recordings, diaries, letters, or expressive and projective productions. The evaluation of personal documents (65 pages) examines the case for and against their use. "It can be shown that{\ldots} critical tests of science are met by personal documents properly handled," and personal documents may be superior to actuarial methods by themselves in achieving the scientific goals of understanding, prediction, and control. Bibliography of 198 references; indices. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {/Users/timokoch/Zotero/storage/PE7683JT/1942-02314-001.html}
}

@article{altmannPermutationImportanceCorrected2010,
  title = {Permutation Importance: A Corrected Feature Importance Measure},
  shorttitle = {Permutation Importance},
  author = {Altmann, Andr{\'e} and Tolo{\c s}i, Laura and Sander, Oliver and Lengauer, Thomas},
  year = {2010},
  month = may,
  journal = {Bioinformatics},
  volume = {26},
  number = {10},
  pages = {1340--1347},
  issn = {1460-2059, 1367-4803},
  doi = {10.1093/bioinformatics/btq134},
  urldate = {2021-03-29},
  abstract = {Motivation: In life sciences, interpretability of machine learning models is as important as their prediction accuracy. Linear models are probably the most frequently used methods for assessing feature relevance, despite their relative inflexibility. However, in the past years effective estimators of feature relevance have been derived for highly complex or non-parametric models such as support vector machines and RandomForest (RF) models. Recently, it has been observed that RF models are biased in such a way that categorical variables with a large number of categories are preferred.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/WGLHVVDV/Altmann et al. - 2010 - Permutation importance a corrected feature import.pdf}
}

@inproceedings{andalibiHumanEmotionRecognition2020,
  title = {The {{Human}} in {{Emotion Recognition}} on {{Social Media}}: {{Attitudes}}, {{Outcomes}}, {{Risks}}},
  shorttitle = {The {{Human}} in {{Emotion Recognition}} on {{Social Media}}},
  booktitle = {Proceedings of the 2020 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Andalibi, Nazanin and Buss, Justin},
  year = {2020},
  month = apr,
  pages = {1--16},
  publisher = {{ACM}},
  address = {{Honolulu HI USA}},
  doi = {10.1145/3313831.3376680},
  urldate = {2022-11-08},
  abstract = {Emotion recognition algorithms recognize, infer, and harvest emotions using data sources such as social media behavior, streaming service use, voice, facial expressions, and biometrics in ways often opaque to the people providing these data. People's attitudes towards emotion recognition and the harms and outcomes they associate with it are important yet unknown. Focusing on social media, we interviewed 13 adult U.S. social media users to fill this gap. We find that people view emotions as insights to behavior, prone to manipulation, intimate, vulnerable, and complex. Many find emotion recognition invasive and scary, associating it with autonomy and control loss. We identify two categories of emotion recognition's risks: individual and societal. We discuss findings' implications for algorithmic accountability and argue for considering emotion data as sensitive. Using a Science and Technology Studies lens, we advocate that technology users should be considered as a relevant social group in emotion recognition advancements.},
  isbn = {978-1-4503-6708-0},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/YKRWJ4PY/Andalibi und Buss - 2020 - The Human in Emotion Recognition on Social Media .pdf}
}

@article{andyliawClassificationRegressionRandomForest2002,
  title = {Classification and {{Regression}} by {{randomForest}}},
  author = {Andy Liaw and Matthew Wiener},
  year = {2002},
  journal = {R News},
  volume = {2},
  number = {3},
  pages = {18--22}
}

@book{anFactorsInfluencingEmoji2018,
  title = {Factors {{Influencing Emoji Usage}} in {{Smartphone Mediated Communications}}},
  author = {An, Jiaxin and Zhang, Pengyi and {li}, Tian and Teng, Yifei},
  year = {2018},
  month = jan,
  abstract = {Emojis have become more and more popular in text-based online communi-cation to express emotions. This indicates a potential to utilize emojis in sentiment analysis and emotion measurements. However, many factors could affect people's emoji usage and need to be examined. Among them, age, gender, and relationship types may result in different interpretations of the same emoji due to the ambiguity of the iconic expression. In this paper, we aim to explore how these factors may affect the frequency, type, and sen-timent of people's emoji usage in communications. After analyzing 6,821 Wechat chatting messages from158 participants, we found people between 26-35 had lowest frequency of emoji usage; younger and elder groups showed different sentiment levels for the same emojis; people chose emoji types based on relationships. These findings shed light on how people use emojis as a communication tool.},
  file = {/Users/timokoch/Zotero/storage/FTBVZZLG/An et al. - 2018 - Factors Influencing Emoji Usage in Smartphone Medi.pdf}
}

@article{apleyVisualizingEffectsPredictor2020,
  title = {Visualizing the Effects of Predictor Variables in Black Box Supervised Learning Models},
  author = {Apley, Daniel W. and Zhu, Jingyu},
  year = {2020},
  journal = {Journal of the Royal Statistical Society Series B},
  volume = {82},
  number = {4},
  pages = {1059--1086},
  publisher = {{Royal Statistical Society}},
  urldate = {2020-10-29},
  abstract = {In many supervised learning applications, understanding and visualizing the effects of the predictor variables on the predicted response is of paramount importance. A shortcoming of black box supervised learning models (e.g. complex trees, neural networks, boosted trees, random forests, nearest neighbours, local kernel-weighted methods and support vector regression) in this regard is their lack of interpretability or transparency. Partial dependence plots, which are the most popular approach for visualizing the effects of the predictors with black box supervised learning models, can produce erroneous results if the predictors are strongly correlated, because they require extrapolation of the response at predictor values that are far outside the multivariate envelope of the training data. As an alternative to partial dependence plots, we present a new visualization approach that we term accumulated local effects plots, which do not require this unreliable extrapolation with correlated predictors. Moreover, accumulated local effects plots are far less computationally expensive than partial dependence plots. We also provide an R package ALEPlot as supplementary material to implement our proposed method.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/IYAZC8FI/Apley und Zhu - 2019 - Visualizing the Effects of Predictor Variables in .pdf;/Users/timokoch/Zotero/storage/UC9M8AN7/v82y2020i4p1059-1086.html}
}

@article{argamonAutomaticallyProfilingAuthor2009,
  title = {Automatically Profiling the Author of an Anonymous Text},
  author = {Argamon, Shlomo and Koppel, Moshe and Pennebaker, James W. and Schler, Jonathan},
  year = {2009},
  month = feb,
  journal = {Communications of the ACM},
  volume = {52},
  number = {2},
  pages = {119},
  issn = {00010782},
  doi = {10.1145/1461928.1461959},
  urldate = {2019-07-29},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/6ZSLD56L/Argamon et al. - 2009 - Automatically profiling the author of an anonymous.pdf}
}

@article{argamonAutomaticallyProfilingAuthor2009a,
  title = {Automatically Profiling the Author of an Anonymous Text},
  author = {Argamon, Shlomo and Koppel, Moshe and Pennebaker, James W. and Schler, Jonathan},
  year = {2009},
  month = feb,
  journal = {Communications of the ACM},
  volume = {52},
  number = {2},
  pages = {119},
  issn = {00010782},
  doi = {10.1145/1461928.1461959},
  urldate = {2019-07-29},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/RHLWFYBZ/Argamon et al. - 2009 - Automatically profiling the author of an anonymous.pdf}
}

@article{argamonLexicalPredictorsPersonality2005,
  title = {Lexical {{Predictors}} of {{Personality Type}}},
  author = {Argamon, Shlomo and Dhawle, Sushant and Koppel, Moshe and Pennebaker, James W},
  year = {2005},
  pages = {17},
  abstract = {We are currently pursuing methods for ``author profiling'' in which various aspects of the author's identity might be identified from a text, without necessarily having a corpus of documents from the same individual. A key component of such an identity profile is personality; this paper addresses distinguishing high from low neuroticism and extraversion in authors of informal text. We consider four different sets of lexical features for this task: a standard function word list, conjunctive phrases, modality indicators, and appraisal adjectives and modifiers. SMO, a support vector machine learner, was used to learn linear separators for the high and low classes in each of the two tasks. We find that appraisal use is the best predictor for neuroticism, and that function words work best for extraversion. Further, examination of the specifically most important features yields insight into how neuroticism and extraversion differentially affect language use.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/9CZG4SEM/Argamon et al. - LEXICAL PREDICTORS OF PERSONALITY TYPE.pdf}
}

@article{argamonMiningBlogosphereAge2007,
  title = {Mining the Blogosphere: {{Age}}, Gender and the Varieties of Self-Expression},
  author = {Argamon, Shlomo and Koppel, Moshe and Pennebaker, James W. and Schler, Jonathan},
  year = {2007},
  journal = {First Monday},
  volume = {12},
  number = {9},
  issn = {1396-0466},
  file = {/Users/timokoch/Zotero/storage/6ICTMG2Y/Mining the Blogosphere_ Age, gender and the varieties of self-expression _ Argamon _ First Monday.pdf}
}

@book{auGroupedFeatureImportance2021,
  title = {Grouped {{Feature Importance}} and {{Combined Features Effect Plot}}},
  author = {Au, Quay and Herbinger, Julia and Stachl, Clemens and Bischl, Bernd and Casalicchio, Giuseppe},
  year = {2021},
  month = apr,
  abstract = {Interpretable machine learning has become a very active area of research due to the rising popularity of machine learning algorithms and their inherently challenging interpretability. Most work in this area has been focused on the interpretation of single features in a model. However, for researchers and practitioners, it is often equally important to quantify the importance or visualize the effect of feature groups. To address this research gap, we provide a comprehensive overview of how existing model-agnostic techniques can be defined for feature groups to assess the grouped feature importance, focusing on permutation-based, refitting, and Shapley-based methods. We also introduce an importance-based sequential procedure that identifies a stable and well-performing combination of features in the grouped feature space. Furthermore, we introduce the combined features effect plot, which is a technique to visualize the effect of a group of features based on a sparse, interpretable linear combination of features. We used simulation studies and a real data example from computational psychology to analyze, compare, and discuss these methods.},
  file = {/Users/timokoch/Zotero/storage/CXH25GH7/Au et al. - 2021 - Grouped Feature Importance and Combined Features E.pdf}
}

@article{auGroupedFeatureImportance2022,
  title = {Grouped Feature Importance and Combined Features Effect Plot},
  author = {Au, Quay and Herbinger, Julia and Stachl, Clemens and Bischl, Bernd and Casalicchio, Giuseppe},
  year = {2022},
  month = jul,
  journal = {Data Mining and Knowledge Discovery},
  volume = {36},
  number = {4},
  pages = {1401--1450},
  issn = {1573-756X},
  doi = {10.1007/s10618-022-00840-5},
  urldate = {2022-07-31},
  abstract = {Interpretable machine learning has become a very active area of research due to the rising popularity of machine learning algorithms and their inherently challenging interpretability. Most work in this area has been focused on the interpretation of single features in a model. However, for researchers and practitioners, it is often equally important to quantify the importance or visualize the effect of feature groups. To address this research gap, we provide a comprehensive overview of how existing model-agnostic techniques can be defined for feature groups to assess the grouped feature importance, focusing on permutation-based, refitting, and Shapley-based methods. We also introduce an importance-based sequential procedure that identifies a stable and well-performing combination of features in the grouped feature space. Furthermore, we introduce the combined features effect plot, which is a technique to visualize the effect of a group of features based on a sparse, interpretable linear combination of features. We used simulation studies and real data examples to analyze, compare, and discuss these methods.},
  langid = {english},
  keywords = {Combined features effects,Dimension reduction,Grouped feature importance,Interpretable machine learning},
  file = {/Users/timokoch/Zotero/storage/JSR343C7/Au et al. - 2022 - Grouped feature importance and combined features e.pdf}
}

@article{azucarPredictingBigPersonality2018,
  title = {Predicting the {{Big}} 5 Personality Traits from Digital Footprints on Social Media: {{A}} Meta-Analysis},
  author = {Azucar, Danny and Marengo, Davide and Settanni, Michele},
  year = {2018},
  journal = {Personality and Individual Differences},
  volume = {124},
  pages = {150--159},
  issn = {01918869},
  doi = {10.1016/j.paid.2017.12.018}
}

@article{backEmotionalTimelineSeptember2010,
  title = {The {{Emotional Timeline}} of {{September}} 11, 2001},
  author = {Back, Mitja D. and K{\"u}fner, Albrecht C.P. and Egloff, Boris},
  year = {2010},
  month = oct,
  journal = {Psychological Science},
  volume = {21},
  number = {10},
  pages = {1417--1419},
  publisher = {{SAGE Publications Inc}},
  issn = {0956-7976},
  doi = {10.1177/0956797610382124},
  urldate = {2022-05-09},
  file = {/Users/timokoch/Zotero/storage/2P3FYNDU/Back et al. - 2010 - The Emotional Timeline of September 11, 2001.pdf}
}

@article{backFacebookProfilesReflect2010,
  title = {Facebook Profiles Reflect Actual Personality, Not Self-Idealization},
  author = {Back, M. D. and Stopfer, J. M. and Vazire, S. and Gaddis, S. and Schmukle, S. C. and Egloff, B. and Gosling, S. D.},
  year = {2010},
  month = mar,
  journal = {Psychol Sci},
  volume = {21},
  number = {3},
  pages = {372--4},
  issn = {1467-9280 (Electronic) 0956-7976 (Linking)},
  doi = {10.1177/0956797609360756},
  keywords = {*Communication,*Internet,*Personality,*Self Concept,*Self Disclosure,*Social Behavior,*Social Support,*Truth Disclosure,Adolescent,{Feedback, Psychological},Female,Friends/psychology,Germany,Humans,Male,Motivation,United States,Young Adult}
}

@article{backFacebookProfilesReflect2010a,
  title = {Facebook {{Profiles Reflect Actual Personality}}, {{Not Self-Idealization}}},
  author = {Back, Mitja D. and Stopfer, Juliane M. and Vazire, Simine and Gaddis, Sam and Schmukle, Stefan C. and Egloff, Boris and Gosling, Samuel D.},
  year = {2010},
  month = mar,
  journal = {Psychological Science},
  volume = {21},
  number = {3},
  pages = {372--374},
  issn = {0956-7976, 1467-9280},
  doi = {10.1177/0956797609360756},
  urldate = {2020-03-18},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/2ZDBWGDL/Back et al. - 2010 - Facebook Profiles Reflect Actual Personality, Not .pdf}
}

@article{baiSystematicReviewEmoji2019,
  title = {A {{Systematic Review}} of {{Emoji}}: {{Current Research}} and {{Future Perspectives}}},
  shorttitle = {A {{Systematic Review}} of {{Emoji}}},
  author = {Bai, Qiyu and Dan, Qi and Mu, Zhe and Yang, Maokun},
  year = {2019},
  month = oct,
  journal = {Frontiers in Psychology},
  volume = {10},
  pages = {2221},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2019.02221},
  urldate = {2019-12-19},
  abstract = {A growing body of research explores emoji, which are visual symbols in computer mediated communication (CMC). In the 20 years since the first set of emoji was released, research on it has been on the increase, albeit in a variety of directions. We reviewed the extant body of research on emoji and noted the development, usage, function, and application of emoji. In this review article, we provide a systematic review of the extant body of work on emoji, reviewing how they have developed, how they are used differently, what functions they have and what research has been conducted on them in different domains. Furthermore, we summarize directions for future research on this topic.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/LSP65372/Bai et al. - 2019 - A Systematic Review of Emoji Current Research and.pdf}
}

@article{bammanGenderIdentityLexical2014,
  title = {Gender Identity and Lexical Variation in Social Media},
  author = {Bamman, David and Eisenstein, Jacob and Schnoebelen, Tyler},
  year = {2014},
  month = apr,
  journal = {Journal of Sociolinguistics},
  volume = {18},
  number = {2},
  pages = {135--160},
  issn = {13606441},
  doi = {10.1111/josl.12080},
  urldate = {2020-03-30},
  abstract = {We present a study of the relationship between gender, linguistic style, and social networks, using a novel corpus of 14,000 Twitter users. Prior quantitative work on gender often treats this social variable as a female/ male binary; we argue for a more nuanced approach. By clustering Twitter users, we find a natural decomposition of the dataset into various styles and topical interests. Many clusters have strong gender orientations, but their use of linguistic resources sometimes directly conflicts with the populationlevel language statistics. We view these clusters as a more accurate reflection of the multifaceted nature of gendered language styles. Previous corpus-based work has also had little to say about individuals whose linguistic styles defy population-level gender patterns. To identify such individuals, we train a statistical classifier, and measure the classifier confidence for each individual in the dataset. Examining individuals whose language does not match the classifier's model for their gender, we find that they have social networks that include significantly fewer same-gender social connections and that, in general, social network homophily is correlated with the use of same-gender language markers. Pairing computational methods and social theory thus offers a new perspective on how gender emerges as individuals position themselves relative to audiences, topics, and mainstream gender norms.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/Q3BS8LL4/Bamman et al. - 2014 - Gender identity and lexical variation in social me.pdf}
}

@article{banseAcousticProfilesVocal1996,
  title = {Acoustic Profiles in Vocal Emotion Expression},
  author = {Banse, Rainer and Scherer, Klaus R.},
  year = {1996},
  journal = {Journal of Personality and Social Psychology},
  volume = {70},
  number = {3},
  pages = {614--636},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1315},
  doi = {10.1037/0022-3514.70.3.614},
  abstract = {Professional actors' portrayals of 14 emotions varying in intensity and valence were presented to judges. The results on decoding replicated earlier findings on the ability of judges to infer vocally expressed emotions with much-better-than-chance accuracy, including consistently found differences in the recognizability of different emotions. A total of 224 portrayals were subjected to digital acoustical analysis to obtain profiles of vocal parameters for different emotions. The data suggest that vocal parameters not only index the degree of intensity typical for different emotions but also differentiate valence or quality aspects. The data are also used to test theoretical predictions on vocal patterning based on the component process of model of emotion (K. R. Scherer, see record 1986-16849-001). Although most hypotheses are supported, some need to be revised on the basis of the empirical evidence. Discriminant analysis and jackknifing show remarkably high hit rates and patterns of confusion that closely mirror those found for listener-judges. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Emotional States,Inference,Oral Communication,Speech Characteristics,Speech Perception},
  file = {/Users/timokoch/Zotero/storage/VFDXX3QK/banse1996.pdf;/Users/timokoch/Zotero/storage/WQ56WD26/Banse und Scherer - 1996 - Acoustic profiles in vocal emotion expression.pdf;/Users/timokoch/Zotero/storage/LKG3C3H8/1996-03014-015.html}
}

@article{banzigerIntroducingGenevaMultimodal2012,
  title = {Introducing the {{Geneva Multimodal}} Expression Corpus for Experimental Research on Emotion Perception},
  author = {B{\"a}nziger, Tanja and Mortillaro, Marcello and Scherer, Klaus R.},
  year = {2012},
  month = oct,
  journal = {Emotion (Washington, D.C.)},
  volume = {12},
  number = {5},
  pages = {1161--1179},
  issn = {1931-1516},
  doi = {10.1037/a0025827},
  abstract = {Research on the perception of emotional expressions in faces and voices is exploding in psychology, the neurosciences, and affective computing. This article provides an overview of some of the major emotion expression (EE) corpora currently available for empirical research and introduces a new, dynamic, multimodal corpus of emotion expressions, the Geneva Multimodal Emotion Portrayals Core Set (GEMEP-CS). The design features of the corpus are outlined and justified, and detailed validation data for the core set selection are presented and discussed. Finally, an associated database with microcoded facial, vocal, and body action elements, as well as observer ratings, is introduced.},
  langid = {english},
  pmid = {22081890},
  keywords = {Emotions,Facial Expression,Humans,Research,Voice}
}

@article{banzigerPathModelsVocal2015,
  title = {Path {{Models}} of {{Vocal Emotion Communication}}},
  author = {B{\"a}nziger, Tanja and Hosoya, Georg and Scherer, Klaus R.},
  year = {2015},
  month = jan,
  journal = {PLOS ONE},
  volume = {10},
  number = {9},
  pages = {e0136675},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0136675},
  urldate = {2022-11-03},
  abstract = {We propose to use a comprehensive path model of vocal emotion communication, encompassing encoding, transmission, and decoding processes, to empirically model data sets on emotion expression and recognition. The utility of the approach is demonstrated for two data sets from two different cultures and languages, based on corpora of vocal emotion enactment by professional actors and emotion inference by na{\"i}ve listeners. Lens model equations, hierarchical regression, and multivariate path analysis are used to compare the relative contributions of objectively measured acoustic cues in the enacted expressions and subjective voice cues as perceived by listeners to the variance in emotion inference from vocal expressions for four emotion families (fear, anger, happiness, and sadness). While the results confirm the central role of arousal in vocal emotion communication, the utility of applying an extended path modeling framework is demonstrated by the identification of unique combinations of distal cues and proximal percepts carrying information about specific emotion families, independent of arousal. The statistical models generated show that more sophisticated acoustic parameters need to be developed to explain the distal underpinnings of subjective voice quality percepts that account for much of the variance in emotion inference, in particular voice instability and roughness. The general approach advocated here, as well as the specific results, open up new research strategies for work in psychology (specifically emotion and social perception research) and engineering and computer science (specifically research and development in the domain of affective computing, particularly on automatic emotion detection and synthetic emotion expression in avatars).},
  langid = {english},
  keywords = {Acoustics,Bioacoustics,Emotions,Facial expressions,Fear,Happiness,Perception,Speech},
  file = {/Users/timokoch/Zotero/storage/ABZ6Y3N2/Bänziger et al. - 2015 - Path Models of Vocal Emotion Communication.pdf;/Users/timokoch/Zotero/storage/37TWMRVL/article.html}
}

@incollection{barrettChapterAffectPsychological2009,
  title = {Chapter 4 {{Affect}} as a {{Psychological Primitive}}},
  booktitle = {Advances in {{Experimental Social Psychology}}},
  author = {Barrett, Lisa Feldman and Bliss-Moreau, Eliza},
  year = {2009},
  month = jan,
  volume = {41},
  pages = {167--218},
  publisher = {{Academic Press}},
  doi = {10.1016/S0065-2601(08)00404-8},
  urldate = {2022-11-05},
  abstract = {In this article, we discuss the hypothesis that affect is a fundamental, psychologically irreducible property of the human mind. We begin by presenting historical perspectives on the nature of affect. Next, we proceed with a more contemporary discussion of core affect as a basic property of the mind that is realized within a broadly distributed neuronal workspace. We then present the affective circumplex, a mathematical formalization for representing core affective states, and show that this model can be used to represent individual differences in core affective feelings that are linked to meaningful variation in emotional experience. Finally, we conclude by suggesting that core affect has psychological consequences that reach beyond the boundaries of emotion, to influence learning and consciousness.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/SLU46AH6/Barrett und Bliss‐Moreau - 2009 - Chapter 4 Affect as a Psychological Primitive.pdf;/Users/timokoch/Zotero/storage/8N46WCIL/S0065260108004048.html}
}

@misc{barrettDarwinWasWrong2022,
  title = {Darwin {{Was Wrong}}: {{Your Facial Expressions Do Not Reveal Your Emotions}}},
  shorttitle = {Darwin {{Was Wrong}}},
  author = {Barrett, Lisa Feldman},
  year = {2022},
  month = apr,
  journal = {Scientific American},
  urldate = {2022-04-28},
  abstract = {The emotion AI industry, courts and child educators are unknowingly relying on a misunderstanding of Darwin\&rsquo;s ideas},
  howpublished = {https://www.scientificamerican.com/article/darwin-was-wrong-your-facial-expressions-do-not-reveal-your-emotions/},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/P3K5D9H8/darwin-was-wrong-your-facial-expressions-do-not-reveal-your-emotions.html}
}

@article{barrettEmotionalExpressionsReconsidered2019,
  title = {Emotional {{Expressions Reconsidered}}: {{Challenges}} to {{Inferring Emotion From Human Facial Movements}}},
  shorttitle = {Emotional {{Expressions Reconsidered}}},
  author = {Barrett, Lisa Feldman and Adolphs, Ralph and Marsella, Stacy and Martinez, Aleix M. and Pollak, Seth D.},
  year = {2019},
  month = jul,
  journal = {Psychological Science in the Public Interest},
  volume = {20},
  number = {1},
  pages = {1--68},
  publisher = {{SAGE Publications Inc}},
  issn = {1529-1006},
  doi = {10.1177/1529100619832930},
  urldate = {2022-07-18},
  abstract = {It is commonly assumed that a person's emotional state can be readily inferred from his or her facial movements, typically called emotional expressions or facial expressions. This assumption influences legal judgments, policy decisions, national security protocols, and educational practices; guides the diagnosis and treatment of psychiatric illness, as well as the development of commercial applications; and pervades everyday social interactions as well as research in other scientific fields such as artificial intelligence, neuroscience, and computer vision. In this article, we survey examples of this widespread assumption, which we refer to as the common view, and we then examine the scientific evidence that tests this view, focusing on the six most popular emotion categories used by consumers of emotion research: anger, disgust, fear, happiness, sadness, and surprise. The available scientific evidence suggests that people do sometimes smile when happy, frown when sad, scowl when angry, and so on, as proposed by the common view, more than what would be expected by chance. Yet how people communicate anger, disgust, fear, happiness, sadness, and surprise varies substantially across cultures, situations, and even across people within a single situation. Furthermore, similar configurations of facial movements variably express instances of more than one emotion category. In fact, a given configuration of facial movements, such as a scowl, often communicates something other than an emotional state. Scientists agree that facial movements convey a range of information and are important for social communication, emotional or otherwise. But our review suggests an urgent need for research that examines how people actually move their faces to express emotions and other social information in the variety of contexts that make up everyday life, as well as careful study of the mechanisms by which people perceive instances of emotion in one another. We make specific research recommendations that will yield a more valid picture of how people move their faces to express emotions and how they infer emotional meaning from facial movements in situations of everyday life. This research is crucial to provide consumers of emotion research with the translational information they require.},
  langid = {english},
  keywords = {emotion perception,emotion recognition,emotional expression},
  file = {/Users/timokoch/Zotero/storage/GM75IMQ7/Barrett et al. - 2019 - Emotional Expressions Reconsidered Challenges to .pdf}
}

@article{barrettEmotionalExpressionsReconsidered2019a,
  title = {Emotional {{Expressions Reconsidered}}: {{Challenges}} to {{Inferring Emotion From Human Facial Movements}}},
  shorttitle = {Emotional {{Expressions Reconsidered}}},
  author = {Barrett, Lisa Feldman and Adolphs, Ralph and Marsella, Stacy and Martinez, Aleix M. and Pollak, Seth D.},
  year = {2019},
  month = jul,
  journal = {Psychological Science in the Public Interest},
  volume = {20},
  number = {1},
  pages = {1--68},
  publisher = {{SAGE Publications Inc}},
  issn = {1529-1006},
  doi = {10.1177/1529100619832930},
  urldate = {2021-12-14},
  abstract = {It is commonly assumed that a person's emotional state can be readily inferred from his or her facial movements, typically called emotional expressions or facial expressions. This assumption influences legal judgments, policy decisions, national security protocols, and educational practices; guides the diagnosis and treatment of psychiatric illness, as well as the development of commercial applications; and pervades everyday social interactions as well as research in other scientific fields such as artificial intelligence, neuroscience, and computer vision. In this article, we survey examples of this widespread assumption, which we refer to as the common view, and we then examine the scientific evidence that tests this view, focusing on the six most popular emotion categories used by consumers of emotion research: anger, disgust, fear, happiness, sadness, and surprise. The available scientific evidence suggests that people do sometimes smile when happy, frown when sad, scowl when angry, and so on, as proposed by the common view, more than what would be expected by chance. Yet how people communicate anger, disgust, fear, happiness, sadness, and surprise varies substantially across cultures, situations, and even across people within a single situation. Furthermore, similar configurations of facial movements variably express instances of more than one emotion category. In fact, a given configuration of facial movements, such as a scowl, often communicates something other than an emotional state. Scientists agree that facial movements convey a range of information and are important for social communication, emotional or otherwise. But our review suggests an urgent need for research that examines how people actually move their faces to express emotions and other social information in the variety of contexts that make up everyday life, as well as careful study of the mechanisms by which people perceive instances of emotion in one another. We make specific research recommendations that will yield a more valid picture of how people move their faces to express emotions and how they infer emotional meaning from facial movements in situations of everyday life. This research is crucial to provide consumers of emotion research with the translational information they require.},
  langid = {english},
  keywords = {emotion perception,emotion recognition,emotional expression},
  file = {/Users/timokoch/Zotero/storage/38BVLXEK/Barrett et al. - 2019 - Emotional Expressions Reconsidered Challenges to .pdf}
}

@article{barrettEmotionalExpressionsReconsidered2019b,
  title = {Emotional {{Expressions Reconsidered}}: {{Challenges}} to {{Inferring Emotion From Human Facial Movements}}},
  shorttitle = {Emotional {{Expressions Reconsidered}}},
  author = {Barrett, Lisa Feldman and Adolphs, Ralph and Marsella, Stacy and Martinez, Aleix M. and Pollak, Seth D.},
  year = {2019},
  month = jul,
  journal = {Psychological Science in the Public Interest},
  volume = {20},
  number = {1},
  pages = {1--68},
  publisher = {{SAGE Publications Inc}},
  issn = {1529-1006},
  doi = {10.1177/1529100619832930},
  urldate = {2022-12-02},
  abstract = {It is commonly assumed that a person?s emotional state can be readily inferred from his or her facial movements, typically called emotional expressions or facial expressions. This assumption influences legal judgments, policy decisions, national security protocols, and educational practices; guides the diagnosis and treatment of psychiatric illness, as well as the development of commercial applications; and pervades everyday social interactions as well as research in other scientific fields such as artificial intelligence, neuroscience, and computer vision. In this article, we survey examples of this widespread assumption, which we refer to as the common view, and we then examine the scientific evidence that tests this view, focusing on the six most popular emotion categories used by consumers of emotion research: anger, disgust, fear, happiness, sadness, and surprise. The available scientific evidence suggests that people do sometimes smile when happy, frown when sad, scowl when angry, and so on, as proposed by the common view, more than what would be expected by chance. Yet how people communicate anger, disgust, fear, happiness, sadness, and surprise varies substantially across cultures, situations, and even across people within a single situation. Furthermore, similar configurations of facial movements variably express instances of more than one emotion category. In fact, a given configuration of facial movements, such as a scowl, often communicates something other than an emotional state. Scientists agree that facial movements convey a range of information and are important for social communication, emotional or otherwise. But our review suggests an urgent need for research that examines how people actually move their faces to express emotions and other social information in the variety of contexts that make up everyday life, as well as careful study of the mechanisms by which people perceive instances of emotion in one another. We make specific research recommendations that will yield a more valid picture of how people move their faces to express emotions and how they infer emotional meaning from facial movements in situations of everyday life. This research is crucial to provide consumers of emotion research with the translational information they require.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/9MJ6AKHF/Barrett et al. - 2019 - Emotional Expressions Reconsidered Challenges to .pdf}
}

@misc{barrettFacialExpressionsNot2022,
  title = {Facial {{Expressions Do Not Reveal Emotions}}},
  author = {Barrett, Lisa Feldman},
  year = {2022},
  month = apr,
  journal = {Scientific American},
  urldate = {2022-11-03},
  abstract = {The emotion AI industry, courts and child educators are unknowingly relying on a misunderstanding of Darwin\&rsquo;s ideas},
  howpublished = {https://www.scientificamerican.com/article/darwin-was-wrong-your-facial-expressions-do-not-reveal-your-emotions/},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/6XS4QL4J/darwin-was-wrong-your-facial-expressions-do-not-reveal-your-emotions.html}
}

@incollection{barrettFeelingPerceivingCore2005,
  title = {Feeling {{Is Perceiving}}: {{Core Affect}} and {{Conceptualization}} in the {{Experience}} of {{Emotion}}},
  shorttitle = {Feeling {{Is Perceiving}}},
  booktitle = {Emotion and Consciousness},
  author = {Barrett, Lisa Feldman},
  year = {2005},
  pages = {255--284},
  publisher = {{The Guilford Press}},
  address = {{New York, NY, US}},
  doi = {10.1016/j.tics.2007.01.005},
  abstract = {What is the experience of emotion? This question fascinates friends and family members, novelists and poets, psychologists and philosophers alike. In this chapter I challenge the view that emotions are entities causing experience, and offer an equally plausible model to account for the experience of emotion. This account involves the recently defined scientific concept of core affect (i.e., the affective state that results from the process of evaluation), ideas and evidence from the social-psychological literature on "person perception," and work on embodied conceptual knowledge in cognitive science. Specifically, I pursue the idea that we experience an emotion when we categorize an instance of core affective feeling. From this perspective, the experience of emotion is a perceptual act, guided by conceptual knowledge about emotion. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
  isbn = {978-1-59385-188-0},
  keywords = {Emotional States,Emotions,Experiences (Events),Perception},
  file = {/Users/timokoch/Zotero/storage/T5Q76ZD7/Barrett - 2005 - Feeling Is Perceiving Core Affect and Conceptuali.pdf;/Users/timokoch/Zotero/storage/YUU57FVQ/2005-08637-011.html}
}

@article{barrettStructureCurrentAffect1999,
  title = {The {{Structure}} of {{Current Affect}}: {{Controversies}} and {{Emerging Consensus}}},
  shorttitle = {The {{Structure}} of {{Current Affect}}},
  author = {Barrett, Lisa Feldman and Russell, James A.},
  year = {1999},
  month = feb,
  journal = {Current Directions in Psychological Science},
  volume = {8},
  number = {1},
  pages = {10--14},
  publisher = {{SAGE Publications Inc}},
  issn = {0963-7214},
  doi = {10.1111/1467-8721.00003},
  urldate = {2022-11-05},
  abstract = {For some years now, emotion researchers have debated a series of issues related to the structure of consciously experienced affective states. The present article reviews evidence that current affective experience can be summarized by a structure that is anchored by two bipolar but independent dimensions of experience, pleasure and activation. Four issues have presented themselves as central to the nature of this structure: the number of dimensions necessary to describe the space, the bipolarity of the dimensions, whether the structure displays a circumplex shape, and the definition of the activation dimension. Points of consensus and the remaining controversies regarding each issue are presented.},
  file = {/Users/timokoch/Zotero/storage/7X2MDZEU/Barrett und Russell - 1999 - The Structure of Current Affect Controversies and.pdf}
}

@inproceedings{basuReviewEmotionRecognition2017,
  title = {A Review on Emotion Recognition Using Speech},
  booktitle = {2017 {{International Conference}} on {{Inventive Communication}} and {{Computational Technologies}} ({{ICICCT}})},
  author = {Basu, Saikat and Chakraborty, Jaybrata and Bag, Arnab and Aftabuddin, {\relax Md}.},
  year = {2017},
  month = mar,
  pages = {109--114},
  publisher = {{IEEE}},
  address = {{Coimbatore, India}},
  doi = {10.1109/ICICCT.2017.7975169},
  urldate = {2019-07-09},
  abstract = {Emotion recognition or affect detection from speech is an old and challenging problem in the field of artificial intelligence. Many significant research works have been done on emotion recognition. In this paper, the recent works on affect detection using speech and different issues related to affect detection has been presented. The primary challenges of emotion recognition are choosing the emotion recognition corpora (speech database), identification of different features related to speech and an appropriate choice of a classification model. Different types of methods to collect emotional speech data and issues related to them are covered by this presentation along with the previous works review. Literature survey on different features used for recognizing emotion from human speech has been discussed. The significance of various classification models has been presented along with some recent research works review. A detailed description of a prime feature extraction technique named Mel Frequency Cepstral Coefficient (MFCC) and brief description of the working principle of some classification models are also discussed here . In this paper terms like affect detection and emotion recognition are used interchangeably.},
  isbn = {978-1-5090-5297-4},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/YIR4MXQM/Basu et al. - 2017 - A review on emotion recognition using speech.pdf}
}

@incollection{batlinerAutomaticRecognitionEmotions2011,
  title = {The {{Automatic Recognition}} of {{Emotions}} in {{Speech}}},
  booktitle = {Cognitive {{Technologies}}},
  author = {Batliner, Anton and Schuller, Bj{\"o}rn and Seppi, Dino and Steidl, Stefan and Devillers, Laurence and Vidrascu, Laurence and Vogt, Thurid and Aharonson, Vered and Amir, Noam},
  year = {2011},
  month = jan,
  pages = {71--99},
  doi = {10.1007/978-3-642-15184-2_6},
  abstract = {In this chapter, we focus on the automatic recognition of emotional states using acoustic and linguistic parameters as features and classifiers as tools to predict the `correct' emotional states. We first sketch history and state of the art in this field; then we describe the process of `corpus engineering', i.e. the design and the recording of databases, the annotation of emotional states, and further processing such as manual or automatic segmentation. Next, we present an overview of acoustic and linguistic features that are extracted automatically or manually. In the section on classifiers, we deal with topics such as the curse of dimensionality and the sparse data problem, classifiers, and evaluation. At the end of each section, we point out important aspects that should be taken into account for the planning or the assessment of studies. The subject area of this chapter is not emotions in some narrow sense but in a wider sense encompassing emotion-related states such as moods, attitudes, or interpersonal stances as well. We do not aim at an in-depth treatise of some specific aspects or algorithms but at an overview of approaches and strategies that have been used or should be used.},
  file = {/Users/timokoch/Zotero/storage/KEK8VWQJ/Batliner et al. - 2011 - The Automatic Recognition of Emotions in Speech.pdf}
}

@inproceedings{batlinerYouStupidTin2004,
  title = {``{{You Stupid Tin Box}}'' - {{Children Interacting}} with the {{AIBO Robot}}: {{A Cross-linguistic Emotional Speech Corpus}}},
  shorttitle = {``{{You Stupid Tin Box}}'' - {{Children Interacting}} with the {{AIBO Robot}}},
  booktitle = {Proceedings of the {{Fourth International Conference}} on {{Language Resources}} and {{Evaluation}} ({{LREC}}'04)},
  author = {Batliner, Anton and Hacker, C. and Steidl, S. and N{\"o}th, E. and D'Arcy, S. and Russell, M. and Wong, M.},
  year = {2004},
  month = may,
  publisher = {{European Language Resources Association (ELRA)}},
  address = {{Lisbon, Portugal}},
  urldate = {2023-01-02},
  abstract = {This paper deals with databases that combine different aspects: children's speech, emotional speech, human-robot communication, cross-linguistics, and read vs. spontaneous speech: in a Wizard-of-Oz scenario, German and English children had to instruct Sony's AIBO robot to fulfil specific tasks. In one experimental condition, strictly parallel for German and English, the AIBO behaved `disobedient' by following it's own script irrespective of the child's commands. By that, reactions of different children to the same sequence of AIBO's actions could be obtained. In addition, both the German and the English children were recorded reading texts. The data are transliterated orthographically; emotional user states and some other phenomena will be annotated. We report preliminary word recognition rates and classification results.},
  file = {/Users/timokoch/Zotero/storage/LV96D4JY/Batliner et al. - 2004 - “You Stupid Tin Box” - Children Interacting with t.pdf}
}

@article{bauerleIncreasedGeneralizedAnxiety2020,
  title = {Increased Generalized Anxiety, Depression and Distress during the {{COVID-19}} Pandemic: A Cross-Sectional Study in {{Germany}}},
  shorttitle = {Increased Generalized Anxiety, Depression and Distress during the {{COVID-19}} Pandemic},
  author = {B{\"a}uerle, Alexander and Teufel, Martin and Musche, Venja and Weism{\"u}ller, Benjamin and Kohler, Hannah and Hetkamp, Madeleine and D{\"o}rrie, Nora and Schweda, Adam and Skoda, Eva-Maria},
  year = {2020},
  month = nov,
  journal = {Journal of Public Health},
  volume = {42},
  number = {4},
  pages = {672--678},
  issn = {1741-3842},
  doi = {10.1093/pubmed/fdaa106},
  urldate = {2023-02-21},
  abstract = {Since the first cases of the novel coronavirus disease SARS-CoV-2 were reported in December 2019 in China, the virus has spread in most countries. The aim of the present study was to assess initial data on the mental health burden of the German public during the COVID-19 pandemic.A cross-sectional study was conducted in Germany and collected complete datasets from 15~704 German residents aged 18~years and over. Besides demographics, generalized anxiety (GAD-7), depression (PHQ-2) and psychological distress (DT) were assessed. Furthermore, COVID-19-related fear, trust in governmental actions to face COVID-19 and the subjective level of information regarding COVID-19 were covered.Significantly increased symptoms were highly prevalent in all dimensions: generalized anxiety (44.9\%), depression (14.3\%), psychological distress (65.2\%) and COVID-19-related fear (59\%). Females and younger people reported higher mental burden. Trust in governmental actions to face COVID-19 and the subjective level of information regarding COVID-19 are negatively associated with mental health burden. However, the subjective level of information regarding COVID-19 is positively associated with increased COVID-19-related fear.The provision of appropriate psychological interventions for those in need and the provision of transparency and comprehensible information are crucial during the current pandemic.},
  file = {/Users/timokoch/Zotero/storage/ZNFXNN7W/Bäuerle et al. - 2020 - Increased generalized anxiety, depression and dist.pdf;/Users/timokoch/Zotero/storage/IIC7GXE2/5869903.html}
}

@article{bazarovaManagingImpressionsRelationships2013,
  title = {Managing {{Impressions}} and {{Relationships}} on {{Facebook}}: {{Self-Presentational}} and {{Relational Concerns Revealed Through}} the {{Analysis}} of {{Language Style}}},
  shorttitle = {Managing {{Impressions}} and {{Relationships}} on {{Facebook}}},
  author = {Bazarova, Natalya N. and Taft, Jessie G. and Choi, Yoon Hyung and Cosley, Dan},
  year = {2013},
  month = jun,
  journal = {Journal of Language and Social Psychology},
  volume = {32},
  number = {2},
  pages = {121--141},
  issn = {0261-927X, 1552-6526},
  doi = {10.1177/0261927X12456384},
  urldate = {2020-09-10},
  abstract = {The merging of audiences in social media and the variety of participation structures they present, including different audience sizes and interaction targets, pose questions about how people respond to these new communication situations. This research examined self-presentational and relational concerns through the analysis of language styles on Facebook. The authors collected a corpus of status updates, wall posts, and private messages from 79 participants.These messages varied in certain characteristics of language style, revealing differences in underlying self-presentational and relational concerns based on the publicness and directedness of the interaction. Positive emotion words correlated with self-reported self-presentational concerns in status updates, suggesting a strategic use of sharing positive emotions in public and nondirected communication via status updates.Verbal immediacy correlated with partner familiarity in wall posts but not in private messages, suggesting that verbal immediacy cues serve as markers to differentiate between more and less familiar partners in public wall posts.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/5AWNTMPA/Bazarova et al. - 2013 - Managing Impressions and Relationships on Facebook.pdf}
}

@article{bazarovaPublicIntimacyDisclosure2012,
  title = {Public {{Intimacy}}: {{Disclosure Interpretation}} and {{Social Judgments}} on {{Facebook}}: {{Public Intimacy}}},
  shorttitle = {Public {{Intimacy}}},
  author = {Bazarova, Natalya N.},
  year = {2012},
  month = oct,
  journal = {Journal of Communication},
  volume = {62},
  number = {5},
  pages = {815--832},
  issn = {00219916},
  doi = {10.1111/j.1460-2466.2012.01664.x},
  urldate = {2020-09-10},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/DD2QNUGF/Bazarova - 2012 - Public Intimacy Disclosure Interpretation and Soc.pdf}
}

@article{bazarovaSelfDisclosureSocialMedia2014,
  title = {Self-{{Disclosure}} in {{Social Media}}: {{Extending}} the {{Functional Approach}} to {{Disclosure Motivations}} and {{Characteristics}} on {{Social Network Sites}}},
  shorttitle = {Self-{{Disclosure}} in {{Social Media}}},
  author = {Bazarova, Natalya N. and Choi, Yoon Hyung},
  year = {2014},
  month = aug,
  journal = {Journal of Communication},
  volume = {64},
  number = {4},
  pages = {635--657},
  issn = {00219916},
  doi = {10.1111/jcom.12106},
  urldate = {2020-07-03},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/IWS5ECF6/Bazarova und Choi - 2014 - Self-Disclosure in Social Media Extending the Fun.pdf}
}

@article{bazarovaSocialSharingEmotions2015,
  title = {Social {{Sharing}} of {{Emotions}} on {{Facebook}}: {{Channel Differences}}, {{Satisfaction}}, and {{Replies}}},
  author = {Bazarova, Natalya N. and Choi, Yoon Hyung and Sosik, Victoria Schwanda and Cosley, Dan and Whitlock, Janis},
  year = {2015},
  pages = {11},
  abstract = {People often share emotions with others in order to manage their emotional experiences. We investigate how social media properties such as visibility and directedness affect how people share emotions in Facebook, and their satisfaction after doing so. 141 participants rated 1,628 of their own recent status updates, posts they made on others' timelines, and private messages they sent for intensity, valence, personal relevance, and overall satisfaction felt after sharing each message. For network-visible channels{\textemdash}status updates and posts on others' timelines{\textemdash}they also rated their satisfaction with replies they received. People shared differently between channels, with more intense and negative emotions in private messages. People felt more satisfied after sharing more positive emotions in all channels and after sharing more personally relevant emotions in network-visible channels. Finally, people's overall satisfaction after sharing emotions in networkvisible channels is strongly tied to their reply satisfaction. Quality of replies, not just quantity, matters, suggesting the need for designs that help people receive valuable responses to their shared emotions.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/TPHKBZL2/Bazarova et al. - 2015 - Social Sharing of Emotions on Facebook Channel Di.pdf}
}

@inproceedings{beasleyEmotionalStatesVs2015,
  title = {Emotional {{States}} vs. {{Emotional Words}} in {{Social Media}}},
  booktitle = {Proceedings of the {{ACM Web Science Conference}} on {{ZZZ}} - {{WebSci}} '15},
  author = {Beasley, Asaf and Mason, Winter},
  year = {2015},
  pages = {1--10},
  publisher = {{ACM Press}},
  address = {{Oxford, United Kingdom}},
  doi = {10.1145/2786451.2786473},
  urldate = {2020-11-30},
  abstract = {A number of social media studies have equated people's emotional states with the frequency with which they use affectively positive and negative words in their posts. We explore how such word frequencies relate to a ground truth measure of both positive and negative emotion for 515 Facebook users and 448 Twitter users. We find statistically significant but very weak ({$\rho$} in the 0.1 to 0.2 range) correlations between positive and negative emotion-related words from the Linguistic Inquiry Word Count (LIWC) dictionary and a wellvalidated scale of trait emotionality called the Positive and Negative Affect Schedule (PANAS). We test this for tweets and Facebook status updates, focus on different time slices around the completion of the survey, and consider participants who report expressing emotions frequently on social media. With rare exception, this pattern of low correlation persists, suggesting that for the typical user, dictionarybased sentiment analysis tools may not be sufficient to infer how they truly feel.},
  isbn = {978-1-4503-3672-7},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/JZVAXFR8/Beasley und Mason - 2015 - Emotional States vs. Emotional Words in Social Med.pdf}
}

@article{beckDetectingIdiographicPersonality2022,
  title = {Detecting {{Idiographic Personality Change}}},
  author = {Beck, Emorie D. and Jackson, Joshua J.},
  year = {2022},
  month = jul,
  journal = {Journal of Personality Assessment},
  volume = {104},
  number = {4},
  pages = {467--483},
  publisher = {{Routledge}},
  issn = {0022-3891},
  doi = {10.1080/00223891.2021.1984246},
  urldate = {2022-11-07},
  abstract = {Personality changes across the lifespan, but strong evidence regarding the mechanisms responsible for personality change remains elusive. Studies of personality change and life events, for example, suggest that personality is difficult to change. But there are two key issues with assessing personality change. First, most change models optimize population-level, not individual-level, effects, which ignores heterogeneity in patterns of change. Second, optimizing change as mean-levels of self-reports fails to incorporate methods for assessing personality dynamics, such as using changes in variances of and correlations in multivariate time series data that often proceed changes in mean-levels, making variance change detection a promising technique for the study of change. Using a sample of N = 388 participants (total N = 21,790) assessed weekly over 60 weeks, we test a permutation-based approach for detecting individual-level personality changes in multivariate time series and compare the results to event-based methods for assessing change. We find that a non-trivial number of participants show change over the course of the year but that there was little association between these change points and life events they experienced. We conclude by highlighting the importance in idiographic and dynamic investigations of change.},
  pmid = {34678086},
  file = {/Users/timokoch/Zotero/storage/SJFNN9IU/Beck und Jackson - 2022 - Detecting Idiographic Personality Change.pdf}
}

@article{beckPersonalizedPredictionBehaviors2022,
  title = {Personalized {{Prediction}} of {{Behaviors}} and {{Experiences}}: {{An Idiographic Person}}{\textendash}{{Situation Test}}},
  shorttitle = {Personalized {{Prediction}} of {{Behaviors}} and {{Experiences}}},
  author = {Beck, Emorie D. and Jackson, Joshua J.},
  year = {2022},
  month = oct,
  journal = {Psychological Science},
  volume = {33},
  number = {10},
  pages = {1767--1782},
  issn = {0956-7976, 1467-9280},
  doi = {10.1177/09567976221093307},
  urldate = {2022-11-07},
  abstract = {A longstanding goal of psychology is to predict the things that people do and feel, but tools to accurately predict future behaviors and experiences remain elusive. In the present study, we used intensive longitudinal data (N = 104 college-age adults at a midwestern university; total assessments = 5,971) and three machine-learning approaches to investigate the degree to which three future behaviors and experiences{\textemdash}loneliness, procrastination, and studying{\textemdash}could be predicted from past psychological (i.e., personality and affective states), situational (i.e., objective situations and psychological situation cues), and time (i.e., trends, diurnal cycles, time of day, and day of the week) phenomena from an idiographic, person-specific perspective. Rather than pitting persons against situations, such an approach allows psychological phenomena, situations, and time to jointly predict future behaviors and experiences. We found (a) a striking degree of prediction accuracy across participants, (b) that a majority of participants' future behaviors are predicted by both person and situation features, and (c) that the most important features vary greatly across people.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/K6I3Z4UX/Beck und Jackson - 2022 - Personalized Prediction of Behaviors and Experienc.pdf}
}

@article{beedieDistinctionsEmotionMood2005,
  title = {Distinctions between Emotion and Mood},
  author = {Beedie, Christopher and Terry, Peter and Lane, Andrew},
  year = {2005},
  month = sep,
  journal = {Cognition \& Emotion},
  volume = {19},
  number = {6},
  pages = {847--878},
  issn = {0269-9931, 1464-0600},
  doi = {10.1080/02699930541000057},
  urldate = {2019-02-08},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/7T3BB933/Beedie et al. - 2005 - Distinctions between emotion and mood.pdf}
}

@misc{belbachirAutomaticDetectionGender2013,
  title = {Automatic Detection of Gender on the Blogs},
  author = {Belbachir, Faiza and Henni, Khadidja and Zaoui, Lynda},
  year = {2013}
}

@inproceedings{belbachirAutomaticDetectionGender2013a,
  title = {Automatic Detection of Gender on the Blogs},
  author = {Belbachir, Faiza and Henni, Khadidja and Zaoui, Lynda},
  year = {2013},
  month = may,
  pages = {1--4},
  doi = {10.1109/AICCSA.2013.6616510},
  abstract = {In this paper, we are interested in defining the gender of blogger while using only texts written from bloggers. For that purpose, we offer a number of features based on specific words, which were categorized into classes. For each blog, a score is calculated based on these characteristics, thereby determining the gender of its author. The evaluation was made on a corpus of 681,288 Blogs (140 million words) tagged as men or women. In our work, this collection will be taken as a reference. The obtained results show gender detection over 82\% compared to the referenced collection.},
  file = {/Users/timokoch/Zotero/storage/LIL45X6S/Belbachir et al. - 2013 - Automatic detection of gender on the blogs.pdf}
}

@article{bellUsingLIWCCohMetrix2011,
  title = {{Using LIWC and Coh-Metrix to investigate gender differences in linguistic styles}},
  author = {Bell, Courtney M. and McCarthy, Philip M. and McNamara, Danielle},
  year = {2011},
  journal = {Applied Natural Language Processing: Identification, Investigation and Resolution},
  pages = {545--556},
  doi = {10.4018/978-1-60960-741-8.ch032},
  urldate = {2019-07-29},
  langid = {English (US)},
  file = {/Users/timokoch/Zotero/storage/LUHRZNIV/using-liwc-and-coh-metrix-to-investigate-gender-differences-in-li.html}
}

@inproceedings{bellUsingLIWCCohMetrix2012,
  title = {Using {{LIWC}} and {{Coh-Metrix}} to {{Investigate Gender Differences}} in {{Linguistic Styles}}},
  author = {Bell, Courtney M. and McCarthy, Philip M. and McNamara, Danielle S.},
  year = {2012},
  doi = {10.4018/978-1-60960-741-8.ch032},
  abstract = {We use computational linguistic tools to investigate gender differences in language use within the context of marital conflict. Using the Language Inquiry and Word Count tool (LIWC), differences between genders were significant for the use of self references, but not for the use of social words and positive and negative emotion words. Using Coh-Metrix, differences were significant for the use of syntactic complexity, global argument overlap, and density of logical connectors but not for the use of word frequency, frequency of causal verbs and particles, global Latent Semantic Analysis (LSA), local argument overlap, and local LSA. These results confirmed some expectations but failed to confirm the majority of the expectations based on the biological theory of gender, which defines gender in terms of biological sex resulting in polarized and static language differences based on the speaker's gender.},
  file = {/Users/timokoch/Zotero/storage/PP627ANS/Bell et al. - 2012 - Using LIWC and Coh-Metrix to Investigate Gender Di.pdf}
}

@article{bemmannLanguageLoggerMobileKeyboard2020,
  title = {{{LanguageLogger}}: {{A Mobile Keyboard Application}} for {{Studying Language Use}} in {{Everyday Text Communication}} in the {{Wild}}},
  shorttitle = {{{LanguageLogger}}},
  author = {Bemmann, Florian and Buschek, Daniel},
  year = {2020},
  month = jun,
  journal = {Proceedings of the ACM on Human-Computer Interaction},
  volume = {4},
  number = {EICS},
  pages = {1--24},
  issn = {2573-0142, 2573-0142},
  doi = {10.1145/3397872},
  urldate = {2020-11-30},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/YZKI3Q7L/Bemmann und Buschek - 2020 - LanguageLogger A Mobile Keyboard Application for .pdf}
}

@article{ben-davidLinguisticEmotionalvalenceCharacteristics2016,
  title = {Linguistic and Emotional-Valence Characteristics of Reading Passages for Clinical Use and Research},
  author = {{Ben-David}, Boaz M. and Moral, Maroof I. and Namasivayam, Aravind K. and Erel, Hadas and {van Lieshout}, Pascal H. H. M.},
  year = {2016},
  month = sep,
  journal = {Journal of Fluency Disorders},
  volume = {49},
  pages = {1--12},
  issn = {0094-730X},
  doi = {10.1016/j.jfludis.2016.06.003},
  urldate = {2019-05-15},
  abstract = {Purpose Fluency assessment in people who stutter (PWS) includes reading aloud passages. There is little information on properties of these passages that may affect reading performance: emotional valance, arousal, word familiarity and frequency and passage-readability. Our first goal was to present an extensive examination of these factors in three commonly used (``traditional'') passages. The second goal was to compare a traditional passage to a new passage, designed to minimize the impact of these properties. Methods Content words were rated (129 participants) on arousal, valence and familiarity. Other linguistic features were analyzed based on available datasets. This information was used to assess traditional passages, and to construct a new well-balanced passage, made of neutral, low-arousal and highly-familiar words. Readability for all passages was tested using formula-based and CLOZE tests (31 participants). Finally, 26 PWS were evaluated on fluency comparing the commonly used ``Rainbow'' passage with the novel one. Results The three traditional passages contain a share of emotionally valenced (22-34\%), high arousal (15-18\%), lower familiarity (6-8\%) and polysyllabic (5-9\%) content words. Readability was highest for the novel passage (on formula-based scales). Average disfluencies percent for the Rainbow and our novel passage were not significantly different. Yet half of the individuals in this sample showed a large difference between the two passages. Conclusion We provide detailed information on potential sources of variance using the traditional passages. Knowledge about these characteristics can inform clinical practice (and research). We suggest a combined procedure, using more than one passage to assess stuttering in individual cases.},
  keywords = {Arousal,Emotion,Fluency disorders,Lexical characteristics,Phonetic properties,Readability,Reading passage,Threat,Word familiarity},
  file = {/Users/timokoch/Zotero/storage/9QX5NADI/S0094730X16300377.html}
}

@article{ben-davidProsodySemanticsAre2016,
  title = {Prosody and {{Semantics Are Separate}} but {{Not Separable Channels}} in the {{Perception}} of {{Emotional Speech}}: {{Test}} for {{Rating}} of {{Emotions}} in {{Speech}}},
  shorttitle = {Prosody and {{Semantics Are Separate}} but {{Not Separable Channels}} in the {{Perception}} of {{Emotional Speech}}},
  author = {{Ben-David}, Boaz M. and Multani, Namita and Shakuf, Vered and Rudzicz, Frank and {van Lieshout}, Pascal H. H. M.},
  year = {2016},
  month = feb,
  journal = {Journal of Speech, Language, and Hearing Research},
  volume = {59},
  number = {1},
  pages = {72--89},
  publisher = {{American Speech-Language-Hearing Association}},
  doi = {10.1044/2015_JSLHR-H-14-0323},
  urldate = {2020-11-20},
  abstract = {Purpose       Our aim is to explore the complex interplay of prosody (tone of speech) and semantics          (verbal content) in the perception of discrete emotions in speech.              Method       We implement a novel tool, the Test for Rating of Emotions in Speech. Eighty native          English speakers were presented with spoken sentences made of different combinations          of 5 discrete emotions (anger, fear, happiness, sadness, and neutral) presented in          prosody and semantics. Listeners were asked to rate the sentence as a whole, integrating          both speech channels, or to focus on one channel only (prosody or semantics).              Results       We observed supremacy of congruency, failure of selective attention, and prosodic          dominance. Supremacy of congruency means that a sentence that presents the same emotion          in both speech channels was rated highest; failure of selective attention means that          listeners were unable to selectively attend to one channel when instructed; and prosodic          dominance means that prosodic information plays a larger role than semantics in processing          emotional speech.              Conclusions       Emotional prosody and semantics are separate but not separable channels, and it is          difficult to perceive one without the influence of the other. Our findings indicate          that the Test for Rating of Emotions in Speech can reveal specific aspects in the          processing of emotional speech and may in the future prove useful for understanding          emotion-processing deficits in individuals with pathologies.},
  file = {/Users/timokoch/Zotero/storage/S2RNDXPL/Ben-David Boaz M. et al. - 2016 - Prosody and Semantics Are Separate but Not Separab.pdf;/Users/timokoch/Zotero/storage/VILZX44P/2015_JSLHR-H-14-0323.html}
}

@article{ben-davidProsodySemanticsAre2016a,
  title = {Prosody and {{Semantics Are Separate}} but {{Not Separable Channels}} in the {{Perception}} of {{Emotional Speech}}: {{Test}} for {{Rating}} of {{Emotions}} in {{Speech}}},
  shorttitle = {Prosody and {{Semantics Are Separate}} but {{Not Separable Channels}} in the {{Perception}} of {{Emotional Speech}}},
  author = {{Ben-David}, Boaz M. and Multani, Namita and Shakuf, Vered and Rudzicz, Frank and {van Lieshout}, Pascal H. H. M.},
  year = {2016},
  month = feb,
  journal = {Journal of Speech, Language, and Hearing Research},
  volume = {59},
  number = {1},
  pages = {72--89},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/2015_JSLHR-H-14-0323},
  urldate = {2019-05-15},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/XNMRKFRW/Ben-David et al. - 2016 - Prosody and Semantics Are Separate but Not Separab.pdf}
}

@article{ben-davidResourceValidatedAffective2011,
  title = {A Resource of Validated Affective and Neutral Sentences to Assess Identification of Emotion in Spoken Language after a Brain Injury},
  author = {{Ben-David}, Boaz M. and {van Lieshout}, Pascal H. H. M. and Leszcz, Talia},
  year = {2011},
  month = feb,
  journal = {Brain Injury},
  volume = {25},
  number = {2},
  pages = {206--220},
  issn = {0269-9052, 1362-301X},
  doi = {10.3109/02699052.2010.536197},
  urldate = {2019-05-15},
  abstract = {Primary objective: The ability to identify emotions in spoken language is an essential component of communication and could be disrupted in persons with brain injury. Current tools to assess this function show important shortcomings. The aim is to present a set of validated and linguistically equated lexical sentences that can be used to separate the impact of lexical content and prosody on the processing of emotion in speech in persons with brain injury.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/ZSEUKCZT/Ben-David et al. - 2011 - A resource of validated affective and neutral sent.pdf}
}

@article{bennettPredictingClinicallyRelevant2022,
  title = {Predicting Clinically Relevant Changes in Bipolar Disorder Outside the Clinic Walls Based on Pervasive Technology Interactions via Smartphone Typing Dynamics},
  author = {Bennett, Casey C. and Ross, Mindy K. and Baek, EuGene and Kim, Dohyeon and Leow, Alex D.},
  year = {2022},
  month = jul,
  journal = {Pervasive and Mobile Computing},
  volume = {83},
  pages = {101598},
  issn = {1574-1192},
  doi = {10.1016/j.pmcj.2022.101598},
  urldate = {2023-01-16},
  abstract = {Modeling smartphone keyboard dynamics as the foundation of an early warning system (EWS) for mood instability holds potential to expand the reach of healthcare beyond the traditional clinic wall's, which may lead to better ongoing care for chronic mental illnesses such as bipolar disorder. Here, we investigate the feasibility of such a system using a real-world open-science dataset. In particular, we are interested in whether passive technology interaction patterns in real-world datasets reflect findings from more controlled research trials, and the implications for clinical care. Data from 328 people who downloaded an open-science app was analyzed using a variety of machine learning methods, including different modeling methods (random forests, gradient boosting, neural networks), different types of class rebalancing, and pre-processing techniques. The aim was to predict fluctuations in PHQ scores in the weeks before the fluctuation occurred. Various feature selection methods were also employed to identify the top features driving the predictive patterns (out of total 54 starting features). Results showed predictive accuracy around {$\sim$}90\%, similar to controlled research trials, while revealing a number of interesting features (e.g. PTSD and mood instability) that suggest future research avenues. The findings from our analysis appear to indicate that real-world interaction data from smartphones can be utilized as an EWS monitoring tool for mood disorders like bipolar. We also discuss the broader applicability of ecological momentary assessment (EMA) approaches to connected systems combining different forms of pervasive technology interaction (smartphones, wearables, social robots) to track everyday health status.},
  langid = {english},
  keywords = {Ecological momentary assessment,Human{\textendash}computer interaction,Machine learning,Mental health,mHealth,Smartphones},
  file = {/Users/timokoch/Zotero/storage/A6SF36PH/Bennett et al. - 2022 - Predicting clinically relevant changes in bipolar .pdf;/Users/timokoch/Zotero/storage/SBCF9DWB/S1574119222000396.html}
}

@article{bennettSmartphoneAccelerometerData2022,
  title = {Smartphone Accelerometer Data as a Proxy for Clinical Data in Modeling of Bipolar Disorder Symptom Trajectory},
  author = {Bennett, Casey C. and Ross, Mindy K. and Baek, EuGene and Kim, Dohyeon and Leow, Alex D.},
  year = {2022},
  month = dec,
  journal = {npj Digital Medicine},
  volume = {5},
  number = {1},
  pages = {1--10},
  publisher = {{Nature Publishing Group}},
  issn = {2398-6352},
  doi = {10.1038/s41746-022-00741-3},
  urldate = {2022-12-15},
  abstract = {Being able to track and predict fluctuations in symptoms of mental health disorders such as bipolar disorder outside the clinic walls is critical for expanding access to care for the global population. To that end, we analyze a dataset of 291 individuals from a smartphone app targeted at bipolar disorder, which contains rich details about their smartphone interactions (including typing dynamics and accelerometer motion) collected everyday over several months, along with more traditional clinical features. The aim is to evaluate whether smartphone accelerometer data could serve as a proxy for traditional clinical data, either by itself or in combination with typing dynamics. Results show that accelerometer data improves the predictive performance of machine learning models by nearly 5\% over those previously reported in the literature based only on clinical data and typing dynamics. This suggests it is possible to elicit essentially the same ``information'' about bipolar symptomology using different data sources, in a variety of settings.},
  copyright = {2022 The Author(s)},
  langid = {english},
  keywords = {Bipolar disorder,Computational science,Machine learning,Predictive markers},
  file = {/Users/timokoch/Zotero/storage/MTTSKMKQ/Bennett et al. - 2022 - Smartphone accelerometer data as a proxy for clini.pdf}
}

@article{benoitQuantedaPackageQuantitative2018,
  title = {Quanteda: {{An R}} Package for the Quantitative Analysis of Textual Data},
  shorttitle = {Quanteda},
  author = {Benoit, Kenneth and Watanabe, Kohei and Wang, Haiyan and Nulty, Paul and Obeng, Adam and M{\"u}ller, Stefan and Matsuo, Akitaka},
  year = {2018},
  month = oct,
  journal = {Journal of Open Source Software},
  volume = {3},
  number = {30},
  pages = {774},
  issn = {2475-9066},
  doi = {10.21105/joss.00774},
  urldate = {2021-04-20},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/NM4JQ2CV/Benoit et al. - 2018 - quanteda An R package for the quantitative analys.pdf}
}

@article{berinskyRumorsHealthCare2017,
  title = {Rumors and {{Health Care Reform}}: {{Experiments}} in {{Political Misinformation}}},
  shorttitle = {Rumors and {{Health Care Reform}}},
  author = {Berinsky, Adam J.},
  year = {2017},
  month = apr,
  journal = {British Journal of Political Science},
  volume = {47},
  number = {2},
  pages = {241--262},
  issn = {0007-1234, 1469-2112},
  doi = {10.1017/S0007123415000186},
  urldate = {2019-05-23},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/HVBR6DJ5/Berinsky - 2017 - Rumors and Health Care Reform Experiments in Poli.pdf}
}

@article{bernardDepressionLanguageAffect2016,
  title = {Depression, {{Language}}, and {{Affect}}: {{An Examination}} of the {{Influence}} of {{Baseline Depression}} and {{Affect Induction}} on {{Language}}},
  shorttitle = {Depression, {{Language}}, and {{Affect}}},
  author = {Bernard, Jared D. and Baddeley, Jenna L. and Rodriguez, Benjamin F. and Burke, Philip A.},
  year = {2016},
  month = jun,
  journal = {Journal of Language and Social Psychology},
  volume = {35},
  number = {3},
  pages = {317--326},
  publisher = {{SAGE Publications Inc}},
  issn = {0261-927X},
  doi = {10.1177/0261927X15589186},
  urldate = {2022-12-22},
  abstract = {Literature suggests that depression influences how individuals communicate. However, no studies examine the impact of affective state on language. The current study examined the influence of depression and affective state on linguistic style. Findings suggest that depression and temporary negative moods both affect pronoun use, but depression influences use of first-person pronouns, whereas negative affect influences use of third-person pronouns.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/BLIBBN3D/Bernard et al. - 2016 - Depression, Language, and Affect An Examination o.pdf}
}

@inproceedings{bertonCompoundWordsLargevocabulary1996,
  title = {Compound Words in Large-Vocabulary {{German}} Speech Recognition Systems},
  booktitle = {Spoken {{Language}}, 1996. {{ICSLP}} 96. {{Proceedings}}., {{Fourth International Conference}} On},
  author = {Berton, Andre and Fetter, Pablo and {Regel-Brietzmann}, Peter},
  year = {1996},
  volume = {2},
  pages = {1165--1168},
  publisher = {{IEEE}},
  isbn = {0-7803-3555-4}
}

@article{beukeboomHowMoodTurns2006,
  title = {How Mood Turns on Language},
  author = {Beukeboom, Camiel J. and Semin, G{\"u}n R.},
  year = {2006},
  month = sep,
  journal = {Journal of Experimental Social Psychology},
  volume = {42},
  number = {5},
  pages = {553--566},
  issn = {00221031},
  doi = {10.1016/j.jesp.2005.09.005},
  urldate = {2019-01-29},
  abstract = {Four studies examined the hypothesis that positive mood induces a global processing style and gives rise to the use of more abstract linguistic expressions in the description of social events. In contrast, negative mood induces a detail-oriented analytic processing style, resulting in more concrete descriptions. This hypothesis received support in the case of describing autobiographical events (Studies 1 and 2) and a Wlm scene (Studies 3 and 4), whereby mood was induced either by Wlm clips, or a self-induced mood technique (Study 3). Moreover, Study 4 showed that these systematic diVerences in linguistic expression disappear when the source of mood is made salient to participants, in line with the aVect-as-information (Schwarz \& Clore, 1983) and mood-and-general-knowledge approach (Bless, 2000). Implications for interpersonal communication are discussed.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/Y9DAF69E/Beukeboom und Semin - 2006 - How mood turns on language.pdf}
}

@article{biecekDALEXExplainersComplex,
  title = {{{DALEX}}: {{Explainers}} for {{Complex Predictive Models}} in {{R}}},
  author = {Biecek, Przemyslaw},
  pages = {5},
  abstract = {Predictive modeling is invaded by elastic, yet complex methods such as neural networks or ensembles (model stacking, boosting or bagging). Such methods are usually described by a large number of parameters or hyper parameters - a price that one needs to pay for elasticity. The very number of parameters makes models hard to understand.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/ETKTCJHX/Biecek - DALEX Explainers for Complex Predictive Models in.pdf}
}

@article{biecekDALEXExplainersComplex2018,
  title = {{{DALEX}}: {{Explainers}} for {{Complex Predictive Models}} in {{R}}},
  shorttitle = {{{DALEX}}},
  author = {Biecek, Przemyslaw},
  year = {2018},
  journal = {Journal of Machine Learning Research},
  volume = {19},
  number = {84},
  pages = {1--5},
  issn = {1533-7928},
  urldate = {2020-12-04},
  file = {/Users/timokoch/Zotero/storage/KYJGBMFE/Biecek - 2018 - DALEX Explainers for Complex Predictive Models in.pdf;/Users/timokoch/Zotero/storage/BUG4TDSD/18-416.html;/Users/timokoch/Zotero/storage/QQ5BTZ2V/18-416.html}
}

@article{biecekDALEXExplainersComplexa,
  title = {{{DALEX}}: {{Explainers}} for {{Complex Predictive Models}} in {{R}}},
  author = {Biecek, Przemyslaw},
  pages = {5},
  abstract = {Predictive modeling is invaded by elastic, yet complex methods such as neural networks or ensembles (model stacking, boosting or bagging). Such methods are usually described by a large number of parameters or hyper parameters - a price that one needs to pay for elasticity. The very number of parameters makes models hard to understand.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/J9URFPAR/Biecek - DALEX Explainers for Complex Predictive Models in.pdf}
}

@misc{binderMlrCPOComposablePreprocessing2020,
  title = {{{mlrCPO}}: {{Composable Preprocessing Operators}} and {{Pipelines}} for {{Machine Learning}}},
  shorttitle = {{{mlrCPO}}},
  author = {Binder, Martin and Bischl, Bernd and Lang, Michel and Kotthoff, Lars},
  year = {2020},
  month = apr,
  urldate = {2020-06-25},
  abstract = {Toolset that enriches 'mlr' with a diverse set of preprocessing operators. Composable Preprocessing Operators ("CPO"s) are first-class R objects that can be applied to data.frames and 'mlr' "Task"s to modify data, can be attached to 'mlr' "Learner"s to add preprocessing to machine learning algorithms, and can be composed to form preprocessing pipelines.},
  copyright = {BSD\_2\_clause + file LICENSE}
}

@article{bischlMlrMachineLearning2016,
  title = {Mlr: {{Machine Learning}} in {{R}}},
  author = {Bischl, Bernd and Lang, Michel and Kotthoff, Lars and Schiffner, Julia and Richter, Jakob and Studerus, Erich and Casalicchio, Giuseppe and Jones, Zachary M.},
  year = {2016},
  journal = {The Journal of Machine Learning Research},
  volume = {17},
  number = {170},
  pages = {1--5},
  issn = {1532-4435}
}

@article{bischlResamplingMethodsMetaModel2012,
  title = {Resampling {{Methods}} for {{Meta-Model Validation}} with {{Recommendations}} for {{Evolutionary Computation}}},
  author = {Bischl, B. and Mersmann, O. and Trautmann, H. and Weihs, C.},
  year = {2012},
  month = jun,
  journal = {Evolutionary Computation},
  volume = {20},
  number = {2},
  pages = {249--275},
  issn = {1063-6560, 1530-9304},
  doi = {10.1162/EVCO_a_00069},
  urldate = {2019-09-18},
  abstract = {Meta-modeling has become a crucial tool in solving expensive optimization problems. Much of the work in the past has focused on finding a good regression method to model the fitness function. Examples include classical linear regression, splines, neural networks, Kriging and support vector regression. This paper specifically draws attention to the fact that assessing model accuracy is a crucial aspect in the meta-modeling framework. Resampling strategies such as cross-validation, subsampling, bootstrapping, and nested resampling are prominent methods for model validation and are systematically discussed with respect to possible pitfalls, shortcomings, and specific features. A survey of meta-modeling techniques within evolutionary optimization is provided. In addition, practical examples illustrating some of the pitfalls associated with model selection and performance assessment are presented. Finally, recommendations are given for choosing a model validation technique for a particular setting.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/4GUF3X9P/Bischl et al. - 2012 - Resampling Methods for Meta-Model Validation with .pdf}
}

@article{blagusSMOTEHighdimensionalClassimbalanced2013,
  title = {{{SMOTE}} for High-Dimensional Class-Imbalanced Data},
  author = {Blagus, Rok and Lusa, Lara},
  year = {2013},
  month = mar,
  journal = {BMC Bioinformatics},
  volume = {14},
  number = {1},
  pages = {106},
  issn = {1471-2105},
  doi = {10.1186/1471-2105-14-106},
  urldate = {2021-06-19},
  abstract = {Classification using class-imbalanced data is biased in favor of the majority class. The bias is even larger for high-dimensional data, where the number of variables greatly exceeds the number of samples. The problem can be attenuated by undersampling or oversampling, which produce class-balanced data. Generally undersampling is helpful, while random oversampling is not. Synthetic Minority Oversampling TEchnique (SMOTE) is a very popular oversampling method that was proposed to improve random oversampling but its behavior on high-dimensional data has not been thoroughly investigated. In this paper we investigate the properties of SMOTE from a theoretical and empirical point of view, using simulated and real high-dimensional data.},
  keywords = {Alternative Case,Minority Class,Null Case,Smite,Variable Selection},
  file = {/Users/timokoch/Zotero/storage/C42CANUZ/Blagus und Lusa - 2013 - SMOTE for high-dimensional class-imbalanced data.pdf;/Users/timokoch/Zotero/storage/39ATNSDS/1471-2105-14-106.html}
}

@article{bleiLatentDirichletAllocation2003,
  title = {Latent Dirichlet Allocation},
  author = {Blei, David M. and Ng, Andrew Y. and Jordan, Michael I.},
  year = {2003},
  journal = {Journal of machine Learning research},
  volume = {3},
  number = {Jan},
  pages = {993--1022}
}

@article{bojahrSchatzBischHaessig,
  title = {{{\guillemotleft}Schatz bisch h{\"a}ssig? Schriibsch so kei smiley{\ldots}{\guillemotright} Zu Emoji und Gender auf WhatsApp}},
  author = {Bojahr, Tamara},
  pages = {42},
  langid = {ngerman},
  file = {/Users/timokoch/Zotero/storage/VBMHS48S/Bojahr - «Schatz bisch hässig Schriibsch so kei smiley…» Z.pdf}
}

@book{bolgerIntensiveLongitudinalMethods2013,
  title = {Intensive Longitudinal Methods: {{An}} Introduction to Diary and Experience Sampling Research},
  shorttitle = {Intensive Longitudinal Methods},
  author = {Bolger, Niall and Laurenceau, Jean-Philippe},
  year = {2013},
  series = {Intensive Longitudinal Methods: {{An}} Introduction to Diary and Experience Sampling Research},
  pages = {xv, 256},
  publisher = {{Guilford Press}},
  address = {{New York, NY, US}},
  abstract = {A complete, practical guide to planning and executing an intensive longitudinal study, this book provides the tools for understanding within-subject social, psychological, and physiological processes in everyday contexts. Intensive longitudinal studies involve many repeated measurements taken on individuals, dyads, or groups, and include diary and experience sampling studies. A range of engaging, worked-through research examples with datasets are featured. Coverage includes how to: select the best intensive longitudinal design for a particular research question, model within-subject change processes for continuous and categorical outcomes, distinguish within-subject from between-subjects effects, assess the reliability of within-subject changes, assure sufficient statistical power, and more. Several end-of-chapter write-ups illustrate effective ways to present study findings for publication. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  isbn = {978-1-4625-0678-1 978-1-4625-0692-7},
  keywords = {Longitudinal Studies,Measurement,Methodology,Psychophysiology,Social Processes},
  file = {/Users/timokoch/Zotero/storage/6R7PBUNY/2012-17340-000.html}
}

@article{bommertBenchmarkFilterMethods2020,
  title = {Benchmark for Filter Methods for Feature Selection in High-Dimensional Classification Data},
  author = {Bommert, Andrea and Sun, Xudong and Bischl, Bernd and Rahnenf{\"u}hrer, J{\"o}rg and Lang, Michel},
  year = {2020},
  month = mar,
  journal = {Computational Statistics \& Data Analysis},
  volume = {143},
  pages = {106839},
  issn = {01679473},
  doi = {10.1016/j.csda.2019.106839},
  urldate = {2021-04-20},
  abstract = {Feature selection is one of the most fundamental problems in machine learning and has drawn increasing attention due to high-dimensional data sets emerging from different fields like bioinformatics. For feature selection, filter methods play an important role, since they can be combined with any machine learning model and can heavily reduce run time of machine learning algorithms. The aim of the analyses is to review how different filter methods work, to compare their performance with respect to both run time and predictive accuracy, and to provide guidance for applications. Based on 16 high-dimensional classification data sets, 22 filter methods are analyzed with respect to run time and accuracy when combined with a classification method. It is concluded that there is no group of filter methods that always outperforms all other methods, but recommendations on filter methods that perform well on many of the data sets are made. Also, groups of filters that are similar with respect to the order in which they rank the features are found. For the analyses, the R machine learning package mlr is used. It provides a uniform programming API and therefore is a convenient tool to conduct feature selection using filter methods.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/BYEEHW7U/Bommert et al. - 2020 - Benchmark for filter methods for feature selection.pdf}
}

@incollection{bontempiMachineLearningStrategies2013,
  title = {Machine {{Learning Strategies}} for {{Time Series Forecasting}}},
  booktitle = {Business {{Intelligence}}},
  author = {Bontempi, Gianluca and Ben Taieb, Souhaib and Le Borgne, Yann-A{\"e}l},
  editor = {{van der Aalst}, Wil and Mylopoulos, John and Rosemann, Michael and Shaw, Michael J. and Szyperski, Clemens and Aufaure, Marie-Aude and Zim{\'a}nyi, Esteban},
  year = {2013},
  volume = {138},
  pages = {62--77},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-36318-4_3},
  urldate = {2020-11-17},
  abstract = {The increasing availability of large amounts of historical data and the need of performing accurate forecasting of future behavior in several scientific and applied domains demands the definition of robust and efficient techniques able to infer from observations the stochastic dependency between past and future. The forecasting domain has been influenced, from the 1960s on, by linear statistical methods such as ARIMA models. More recently, machine learning models have drawn attention and have established themselves as serious contenders to classical statistical models in the forecasting community. This chapter presents an overview of machine learning techniques in time series forecasting by focusing on three aspects: the formalization of one-step forecasting problems as supervised learning tasks, the discussion of local learning techniques as an effective tool for dealing with temporal data and the role of the forecasting strategy when we move from one-step to multiple-step forecasting.},
  isbn = {978-3-642-36317-7 978-3-642-36318-4},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/AXIASWUE/Bontempi et al. - 2013 - Machine Learning Strategies for Time Series Foreca.pdf}
}

@article{boutetEmojisInfluenceEmotional2021,
  title = {Emojis Influence Emotional Communication, Social Attributions, and Information Processing},
  author = {Boutet, Isabelle and LeBlanc, Megan and Chamberland, Justin and Collin, Charles},
  year = {2021},
  month = feb,
  journal = {Computers in Human Behavior},
  pages = {106722},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2021.106722},
  urldate = {2021-02-12},
  abstract = {Many emojis symbolize nonverbal cues that are used during face-to-face communication. Despite their popularity, few studies have examined how emojis influence digital interactions. The present study addresses this gap by measuring the impact of emojis on emotion interpretation, social attributions, and information processing. Participants read messages that are typical of social exchanges in instant text messaging (IM) accompanied by emojis that mimic negative, positive and neutral facial expressions. Sentence valence and emoji valence were paired in a fully crossed design such that verbal and nonverbal messages were either congruent or incongruent. Perceived emotional state of the sender, perceived warmth, and patterns of eye movements that reflect information processing were measured. A negativity effect was observed whereby the sender's mood was perceived as negative when a negative emoji and/or a negative sentence were presented. Moreover, the presence of a negative emoji intensified the perceived negativity of negative sentences. Adding a positive emoji to a message increased the perceived warmth of the sender. Finally, processing speed and understanding of verbal messages was enhanced by the presence of congruent emojis. Our results therefore support the use of emojis, and in particular positive emojis, to improve communication, express feelings, and make a positive impression during socially-driven digital interactions.},
  langid = {english},
  keywords = {digital communication,Emojis,emotions,first impressions,information processing,nonverbal},
  file = {/Users/timokoch/Zotero/storage/UAHJPLUR/S0747563221000443.html}
}

@article{boydDevelopmentPsychometricProperties2022,
  title = {The Development and Psychometric Properties of {{LIWC-22}}},
  author = {Boyd, Ryan L. and Ashokkumar, Ashwini and Seraj, Sarah and Pennebaker, James W.},
  year = {2022},
  journal = {Austin, TX: University of Texas at Austin}
}

@article{boydNaturalLanguageAnalysis2021,
  title = {Natural {{Language Analysis}} and the {{Psychology}} of {{Verbal Behavior}}: {{The Past}}, {{Present}}, and {{Future States}} of the {{Field}}},
  shorttitle = {Natural {{Language Analysis}} and the {{Psychology}} of {{Verbal Behavior}}},
  author = {Boyd, Ryan L. and Schwartz, H.},
  year = {2021},
  month = jan,
  journal = {Journal of Language and Social Psychology},
  volume = {40},
  doi = {10.1177/0261927X20967028},
  abstract = {Throughout history, scholars and laypeople alike have believed that our words contain subtle clues about what we are like as people, psychologically speaking. However, the ways in which language has been used to infer psychological processes has seen dramatic shifts over time and, with modern computational technologies and digital data sources, we are on the verge of a massive revolution in language analysis research. In this article, we discuss the past and current states of research at the intersection of language analysis and psychology, summarizing the central successes and shortcomings of psychological text analysis to date. We additionally outline and discuss a critical need for language analysis practitioners in the social sciences to expand their view of verbal behavior. Lastly, we discuss the trajectory of interdisciplinary research on language and the challenges of integrating analysis methods across paradigms, recommending promising future directions for the field along the way.},
  file = {/Users/timokoch/Zotero/storage/B4VGAXIT/Boyd und Schwartz - 2021 - Natural Language Analysis and the Psychology of Ve.pdf}
}

@article{boydPersonalityPanoramaConceptualizing2020,
  title = {The {{Personality Panorama}}: {{Conceptualizing Personality}} through {{Big Behavioural Data}}},
  shorttitle = {The {{Personality Panorama}}},
  author = {Boyd, Ryan L. and Pasca, Paola and Lanning, Kevin},
  year = {2020},
  month = sep,
  journal = {European Journal of Personality},
  volume = {34},
  number = {5},
  pages = {599--612},
  publisher = {{SAGE Publications Ltd}},
  issn = {0890-2070},
  doi = {10.1002/per.2254},
  urldate = {2022-12-16},
  abstract = {Personality psychology has long been grounded in data typologies, particularly in the delineation of behavioural, life outcome, informant?report, and self?report sources of data from one another. Such data typologies are becoming obsolete in the face of new methods, technologies, and data philosophies. In this article, we discuss personality psychology's historical thinking about data, modern data theory's place in personality psychology, and several qualities of big data that urge a rethinking of personality itself. We call for a move away from self?report questionnaires and a reprioritization of the study of behaviour within personality science. With big data and behavioural assessment, we have the potential to witness the confluence of situated, seamlessly interacting psychological processes, forming an inclusive, dynamic, multiangle view of personality. However, big behavioural data come hand in hand with important ethical considerations, and our emerging ability to create a ?personality panopticon? requires careful and thoughtful navigation. For our research to improve and thrive in partnership with new technologies, we must not only wield our new tools thoughtfully, but humanely. Through discourse and collaboration with other disciplines and the general public, we can foster mutual growth and ensure that humanity's burgeoning technological capabilities serve, rather than control, the public interest. ? 2020 European Association of Personality Psychology},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/4BWW25YI/Boyd et al. - 2020 - The Personality Panorama Conceptualizing Personal.pdf}
}

@article{breilIncrementalValidityAverage2021,
  title = {The {{Incremental Validity}} of {{Average States}}: {{A Replication}} and {{Extension}} of {{Finnigan}} and {{Vazire}} (2018)},
  shorttitle = {The {{Incremental Validity}} of {{Average States}}},
  author = {Breil, Simon and Schweppe, Paula and Geukes, Katharina and Biesanz, Jeremy and Wagner, Jenny and Wrzus, Cornelia and Nestler, Steffen and Back, Mitja},
  year = {2021},
  month = nov,
  journal = {Journal of Personality and Social Psychology},
  doi = {10.1037/pspp0000408},
  abstract = {States refer to our momentary thoughts, feelings, and behaviors. Average states (aggregates across multiple time points) are discussed as a more accurate and objective measure of personality compared to global self-reports since they do not only rely on people's general beliefs about themselves. Specifically, Finnigan and Vazire (2018) argued that, if average states better capture what a person is actually like, this should be reflected in their unique association with informant-reports of personality, and tested this idea based on two experience-sampling studies. Their results showed, however, that average self-reported states did not predict global informant-reported personality above and beyond global self-reports. In this research, we aimed at replicating and extending these results. We used data of five studies (total N = 806) that involved global self- and informant-reports and employed a variety of different experience-sampling methods (time-based with different sampling schedules, event-based). Across all studies, the original results (i.e., no incremental effects of average self-reported states) were replicated. Furthermore, as an extension to the original study, we found that average other-reported states (provided by peers, results based on one study) did indeed predict global informant-reports above and beyond global self-reports. These findings highlight the importance of differentiating between method effects (global reports vs. average states) from source of information effects (self vs. other). We discuss these results, focusing on the suitability of using informant-reports as a criterion variable and conceptual differences between assessment methods.},
  file = {/Users/timokoch/Zotero/storage/3GPLU6G9/Breil et al. - 2021 - The Incremental Validity of Average States A Repl.pdf}
}

@article{breimanRandomForests2001,
  title = {Random Forests},
  author = {Breiman, Leo},
  year = {2001},
  journal = {Machine learning},
  volume = {45},
  number = {1},
  pages = {5--32},
  issn = {0885-6125}
}

@article{breyerDeutscheVersionPositive2016,
  title = {{Deutsche Version der Positive and Negative Affect Schedule PANAS (GESIS Panel)}},
  author = {Breyer, B. and Bluemke, M.},
  year = {2016},
  journal = {Zusammenstellung sozialwissenschaftlicher Items und Skalen (ZIS)},
  publisher = {{ZIS - GESIS Leibniz Institute for the Social Sciences}},
  doi = {10.6102/ZIS242},
  urldate = {2023-01-13},
  abstract = {Die Deutsche Version der Positive and Negative Affect Schedule (PANAS) wurde aus dem weit verbreiteten englischsprachigen Instrument zur Erfassung der emotionalen Befindlichkeit PANAS von Watson, Clark und Tellegen (1988) adaptiert. Der Fragebogen besteht aus 20 Adjektiven, die unterschiedliche Empfindungen und Gef{\"u}hle beschreiben. Jeweils 10 Adjektive erfassen die Dimensionen Positiver Affekt und Negativer Affekt. Die Skala kann f{\"u}r unterschiedliche Untersuchungsziele eingesetzt werden. Je nach Instruktion k{\"o}nnen sowohl aktuelle, zeitlich begrenzte Affekte als auch {\"u}berdauernde, habituelle Affektivit{\"a}tsmerkmale gemessen werden. Die Items wurden in der zweiten Welle des GESIS Panel (2014) verwendet.},
  copyright = {Nutzungsbedingungen: Alle in ZIS dokumentierten Erhebungsinstrumente d{\"u}rfen kostenfrei f{\"u}r nicht-kommerzielle Forschungszwecke verwendet werden.Bei einem Einsatz f{\"u}r andere Zwecke oder in einer anderen als der hier dokumentierten Form ist das Einverst{\"a}ndnis der Autoren bzw. Autorinnen einzuholen. In allen resultierenden Arbeiten und Publikationen ist die ZIS-Dokumentation als Quelle anzugeben., Terms of use: All survey instruments documented in ZIS may be used free of charge for non-commercial research purposes. In the case of use for other purposes or in a form other than those documented here, the consent of the authors must be obtained. In all resulting works and publications, the ZIS documentation must be cited as the source.},
  langid = {ngerman},
  keywords = {Affektivit{\"a}t,Emotion,Gef{\"u}hl,Wohlbefinden},
  file = {/Users/timokoch/Zotero/storage/UXTEQPI3/Breyer und Bluemke - 2016 - Deutsche Version der Positive and Negative Affect .pdf}
}

@article{brinbergIdiosyncrasiesEverydayDigital2021,
  title = {The Idiosyncrasies of Everyday Digital Lives: {{Using}} the {{Human Screenome Project}} to Study User Behavior on Smartphones},
  shorttitle = {The Idiosyncrasies of Everyday Digital Lives},
  author = {Brinberg, Miriam and Ram, Nilam and Yang, Xiao and Cho, Mu-Jung and Sundar, S. Shyam and Robinson, Thomas N. and Reeves, Byron},
  year = {2021},
  month = jan,
  journal = {Computers in Human Behavior},
  volume = {114},
  pages = {106570},
  issn = {07475632},
  doi = {10.1016/j.chb.2020.106570},
  urldate = {2021-11-30},
  abstract = {Most methods used to make theory-relevant observations of technology use rely on self-report or application logging data where individuals' digital experiences are purposively summarized into aggregates meant to describe how the average individual engages with broadly defined segments of content. This aggregation and averaging masks heterogeneity in how and when individuals actually engage with their technology. In this study, we use screenshots (N {$>$} 6 million) collected every 5five seconds that were sequenced and processed using text and image extraction tools into content-, context-, and temporally-informative ``screenomes'' from 132 smart\- phone users over several weeks to examine individuals' digital experiences. Analyses of screenomes highlight extreme between-person and within-person heterogeneity in how individuals switch among and titrate their engagement with different content. Our simple quantifications of textual and graphical content and flow throughout the day illustrate the value screenomes have for the study of individuals' smartphone use and the cognitive and psychological processes that drive use. We demonstrate how temporal, textual, graphical, and topical features of people's smartphone screens can lay the foundation for expanding the Human Screenome Project with full-scale mining that will inform researchers' knowledge of digital life.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/PX4VSTKK/Brinberg et al. - 2021 - The idiosyncrasies of everyday digital lives Usin.pdf}
}

@article{brooksDeepLearningReveals2023,
  title = {Deep Learning Reveals What Vocal Bursts Express in Different Cultures},
  author = {Brooks, Jeffrey A. and Tzirakis, Panagiotis and Baird, Alice and Kim, Lauren and Opara, Michael and Fang, Xia and Keltner, Dacher and Monroy, Maria and Corona, Rebecca and Metrick, Jacob and Cowen, Alan S.},
  year = {2023},
  month = feb,
  journal = {Nature Human Behaviour},
  volume = {7},
  number = {2},
  pages = {240--250},
  publisher = {{Nature Publishing Group}},
  issn = {2397-3374},
  doi = {10.1038/s41562-022-01489-2},
  urldate = {2023-03-01},
  abstract = {Human social life is rich with sighs, chuckles, shrieks and other emotional vocalizations, called `vocal bursts'. Nevertheless, the meaning of vocal bursts across cultures is only beginning to be understood. Here, we combined large-scale experimental data collection with deep learning to reveal the shared and culture-specific meanings of vocal bursts. A total of n\,=\,4,031 participants in China, India, South Africa, the USA and Venezuela mimicked vocal bursts drawn from 2,756 seed recordings. Participants also judged the emotional meaning of each vocal burst. A deep neural network tasked with predicting the culture-specific meanings people attributed to vocal bursts while disregarding context and speaker identity discovered 24 acoustic dimensions, or kinds, of vocal expression with distinct emotion-related meanings. The meanings attributed to these complex vocal modulations were 79\% preserved across the five countries and three languages. These results reveal the underlying dimensions of human emotional vocalization in remarkable detail.},
  copyright = {2022 The Author(s), under exclusive licence to Springer Nature Limited},
  langid = {english},
  keywords = {Emotion,Human behaviour}
}

@article{brownClassbasedNgramModels1992,
  title = {Class-Based n-Gram Models of Natural Language},
  author = {Brown, Peter F. and Desouza, Peter V. and Mercer, Robert L. and Pietra, Vincent J. Della and Lai, Jenifer C.},
  year = {1992},
  journal = {Computational linguistics},
  volume = {18},
  number = {4},
  pages = {467--479}
}

@book{brunswikPerceptionRepresentativeDesign1956,
  title = {Perception and the Representative Design of Psychological Experiments},
  author = {Brunswik, Egon},
  year = {1956},
  publisher = {{Univ of California Press}}
}

@article{buhlmannDiscussionSignificanceTest2014,
  title = {Discussion: "{{A}} Significance Test for the Lasso"},
  shorttitle = {Discussion},
  author = {B{\"u}hlmann, Peter and Meier, Lukas and {van de Geer}, Sara},
  year = {2014},
  month = apr,
  journal = {The Annals of Statistics},
  volume = {42},
  number = {2},
  eprint = {1405.6792},
  issn = {0090-5364},
  doi = {10.1214/13-AOS1175A},
  urldate = {2021-03-29},
  abstract = {Discussion of "A significance test for the lasso" by Richard Lockhart, Jonathan Taylor, Ryan J. Tibshirani, Robert Tibshirani [arXiv:1301.7161].},
  archiveprefix = {arxiv},
  keywords = {Mathematics - Statistics Theory},
  file = {/Users/timokoch/Zotero/storage/V62IF8RR/Bühlmann et al. - 2014 - Discussion A significance test for the lasso.pdf;/Users/timokoch/Zotero/storage/FP2C8T44/1405.html}
}

@inproceedings{burgerDiscriminatingGenderTwitter2011,
  title = {Discriminating {{Gender}} on {{Twitter}}},
  booktitle = {Proceedings of the 2011 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Burger, John D and Henderson, John and Kim, George and Zarrella, Guido},
  year = {2011},
  pages = {1301--1309},
  address = {{Edinburgh}},
  abstract = {Accurate prediction of demographic attributes from social media and other informal online content is valuable for marketing, personalization, and legal investigation. This paper describes the construction of a large, multilingual dataset labeled with gender, and investigates statistical models for determining the gender of uncharacterized Twitter users. We explore several different classifier types on this dataset. We show the degree to which classifier accuracy varies based on tweet volumes as well as when various kinds of profile metadata are included in the models. We also perform a large-scale human assessment using Amazon Mechanical Turk. Our methods significantly out-perform both baseline models and almost all humans on the same task.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/T5JTRG3Y/Burger et al. - Discriminating Gender on Twitter.pdf}
}

@inproceedings{burkhardtDatabaseGermanEmotional2005,
  title = {A Database of {{German}} Emotional Speech.},
  booktitle = {Interspeech},
  author = {Burkhardt, Felix and Paeschke, Astrid and Rolfes, Miriam and Sendlmeier, Walter F. and Weiss, Benjamin},
  year = {2005},
  volume = {5},
  pages = {1517--1520}
}

@article{burkhardtDatabaseGermanEmotional2005a,
  title = {A {{Database}} of {{German Emotional Speech}}},
  author = {Burkhardt, Felix and Paeschke, A and Rolfes, M and Sendlmeier, W and Weiss, B},
  year = {2005},
  pages = {4},
  abstract = {The article describes a database of emotional speech. Ten actors (5 female and 5 male) simulated the emotions, producing 10 German utterances (5 short and 5 longer sentences) which could be used in everyday communication and are interpretable in all applied emotions.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/3XGHLXT8/Burkhardt et al. - 2005 - A Database of German Emotional Speech.pdf}
}

@inproceedings{buschekResearchIMEMobileKeyboard2018,
  title = {{{ResearchIME}}: {{A Mobile Keyboard Application}} for {{Studying Free Typing Behaviour}} in the {{Wild}}},
  shorttitle = {{{ResearchIME}}},
  booktitle = {Proceedings of the 2018 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}  - {{CHI}} '18},
  author = {Buschek, Daniel and Bisinger, Benjamin and Alt, Florian},
  year = {2018},
  pages = {1--14},
  publisher = {{ACM Press}},
  address = {{Montreal QC, Canada}},
  doi = {10.1145/3173574.3173829},
  urldate = {2019-06-12},
  abstract = {We present a data logging concept, tool, and analyses to facilitate studies of everyday mobile touch keyboard use and free typing behaviour: 1) We propose a filtering concept to log typing without recording readable text and assess reactions to filters with a survey (N=349). 2) We release an Android keyboard app and backend that implement this concept. 3) Based on a three-week field study (N=30), we present the first analyses of keyboard use and typing biometrics on such free text typing data in the wild, including speed, postures, apps, auto correction, and word suggestions. We conclude that research on mobile keyboards benefits from observing free typing beyond the lab and discuss ideas for further studies.},
  isbn = {978-1-4503-5620-6},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/U4N9QMKM/Buschek et al. - 2018 - ResearchIME A Mobile Keyboard Application for Stu.pdf}
}

@article{buskForecastingMoodBipolar2020,
  title = {Forecasting {{Mood}} in {{Bipolar Disorder From Smartphone Self-assessments}}: {{Hierarchical Bayesian Approach}}},
  shorttitle = {Forecasting {{Mood}} in {{Bipolar Disorder From Smartphone Self-assessments}}},
  author = {Busk, Jonas and {Faurholt-Jepsen}, Maria and Frost, Mads and Bardram, Jakob E. and Kessing, Lars Vedel and Winther, Ole},
  year = {2020},
  month = apr,
  journal = {JMIR mHealth and uHealth},
  volume = {8},
  number = {4},
  pages = {e15028},
  publisher = {{JMIR Publications Inc., Toronto, Canada}},
  doi = {10.2196/15028},
  urldate = {2022-12-16},
  abstract = {Background: Bipolar disorder is a prevalent mental health condition that is imposing significant burden on society. Accurate forecasting of symptom scores can be used to improve disease monitoring, enable early intervention, and eventually help prevent costly hospitalizations. Although several studies have examined the use of smartphone data to detect mood, only few studies deal with forecasting mood for one or more days. Objective: This study aimed to examine the feasibility of forecasting daily subjective mood scores based on daily self-assessments collected from patients with bipolar disorder via a smartphone-based system in a randomized clinical trial. Methods: We applied hierarchical Bayesian regression models, a multi-task learning method, to account for individual differences and forecast mood for up to seven days based on 15,975 smartphone self-assessments from 84 patients with bipolar disorder participating in a randomized clinical trial. We reported the results of two time-series cross-validation 1-day forecast experiments corresponding to two different real-world scenarios and compared the outcomes with commonly used baseline methods. We then applied the best model to evaluate a 7-day forecast. Results: The best performing model used a history of 4 days of self-assessment to predict future mood scores with historical mood being the most important predictor variable. The proposed hierarchical Bayesian regression model outperformed pooled and separate models in a 1-day forecast time-series cross-validation experiment and achieved the predicted metrics, R2=0.51 and root mean squared error of 0.32, for mood scores on a scale of -3 to 3. When increasing the forecast horizon, forecast errors also increased and the forecast regressed toward the mean of data distribution. Conclusions: Our proposed method can forecast mood for several days with low error compared with common baseline methods. The applicability of a mood forecast in the clinical treatment of bipolar disorder has also been discussed.},
  copyright = {Unless stated otherwise, all articles are open-access distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work ("first published in JMIR mHealth and uHealth...") is properly cited with original URL and bibliographic citation information. The complete bibliographic information, a link to the original publication on http://mhealth.jmir.org/, as well as this copyright and license information must be included.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/SV479QA3/Busk et al. - 2020 - Forecasting Mood in Bipolar Disorder From Smartpho.pdf;/Users/timokoch/Zotero/storage/XV32UR9Q/PDF.pdf;/Users/timokoch/Zotero/storage/P9EYQZYU/e15028.html}
}

@article{butterworthSenderGenderInfluences2019,
  title = {Sender {{Gender Influences Emoji Interpretation}} in {{Text Messages}}},
  author = {Butterworth, Sarah E. and Giuliano, Traci A. and White, Justin and Cantu, Lizette and Fraser, Kyle C.},
  year = {2019},
  month = apr,
  journal = {Frontiers in Psychology},
  volume = {10},
  pages = {784},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2019.00784},
  urldate = {2019-11-25},
  abstract = {With the rise in social media use, emojis have become a popular addition to textbased communication. The sudden increase in the number and variety of emojis used raises questions about how individuals interpret messages containing emojis. To explore perceptions of emoji usage, we conducted a 2 (Sender Gender: Female or Male) {\texttimes} 2 (Emoji Type: Affectionate or Friendly) between-groups experiment to examine the appropriateness and likability of each of four hypothetical text messages sent to a woman from either a male or female coworker. In general, we predicted that text messages containing affectionate emojis (i.e., kissing-face and heart emoji) would be perceived as more appropriate and likable when they came from female than from male senders, whereas messages containing less overtly affectionate (but still friendly) emojis (i.e., smiling-face emoji) would be considered equally appropriate and likable whether it came from female or male senders. As predicted, the results confirmed that texts with affectionate emojis were judged as more appropriate and likable when they came from women than from men. However, texts with less affectionate but friendly emojis were judged as equally appropriate{\textendash}but more likable{\textendash}when they came from men than when they came from women. Taken together, our results indicate that gender and emoji choice influence perceptions, and therefore people should consider how emoji choice could impact the reception of their message.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/EFP26BTD/Butterworth et al. - 2019 - Sender Gender Influences Emoji Interpretation in T.pdf}
}

@article{bzdokStatisticsMachineLearning2018,
  title = {Statistics versus Machine Learning},
  author = {Bzdok, Danilo and Altman, Naomi and Krzywinski, Martin},
  year = {2018},
  month = apr,
  journal = {Nature Methods},
  volume = {15},
  number = {4},
  pages = {233--234},
  publisher = {{Nature Publishing Group}},
  issn = {1548-7105},
  doi = {10.1038/nmeth.4642},
  urldate = {2020-06-19},
  abstract = {Statistics draws population inferences from a sample, and machine learning finds generalizable predictive patterns.},
  copyright = {2018 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/FQGDZW8Y/Bzdok et al. - 2018 - Statistics versus machine learning.pdf;/Users/timokoch/Zotero/storage/3GNQQBZZ/nmeth.html}
}

@article{caiStateAffectRecognition2018,
  title = {State {{Affect Recognition Using Smartphone Sensing Data}}},
  author = {Cai, Lihua},
  year = {2018},
  pages = {6},
  abstract = {Momentary experiences of positive and negative emotionality{\textemdash}also referred to as state affect{\textemdash}are core components of well-being and performance. The ability to unobtrusively monitor state affect could raise individuals' awareness of their mental health status and enable healthcare providers to deliver targeted, just-in-time mental health interventions. In this work, we investigate whether passively sensed smartphone data can be used to recognize individuals' state affect. Our exploratory analysis uses data generated from 220 participants in a two-week study, and our results indicate that fluctuations in participants' negative state affect are associated with various aspects of context including current physical state, geographic location, and time. We also test algorithms that predict participants' negative state affect given contextual features, comparing the impact of historical contextual features on prediction performance.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/SUBUYHLG/Cai - 2018 - State Affect Recognition Using Smartphone Sensing .pdf}
}

@inproceedings{caiStateAffectRecognition2020,
  title = {State Affect Recognition Using Smartphone Sensing Data},
  booktitle = {Proceedings of the 2018 {{IEEE}}/{{ACM International Conference}} on {{Connected Health}}: {{Applications}}, {{Systems}} and {{Engineering Technologies}}},
  author = {Cai, Lihua and Boukhechba, Mehdi and Wu, Congyu and Chow, Philip I. and Teachman, Bethany A. and Barnes, Laura E. and Gerber, Matthew S.},
  year = {2020},
  month = jan,
  series = {{{CHASE}} '18},
  pages = {120--125},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3278576.3284386},
  urldate = {2022-11-08},
  abstract = {Momentary experiences of positive and negative emotionality--- also referred to as state affect---are core components of well-being and performance. The ability to unobtrusively monitor state affect could raise individuals' awareness of their mental health status and enable healthcare providers to deliver targeted, just-in-time mental health interventions. In this work, we investigate whether passively sensed smartphone data can be used to recognize individuals' state affect. Our exploratory analysis uses data generated from 220 participants in a two-week study, and our results indicate that fluctuations in participants' negative state affect are associated with various aspects of context including current physical state, geographic location, and time. We also test algorithms that predict participants' negative state affect given contextual features, comparing the impact of historical contextual features on prediction performance.},
  isbn = {978-1-4503-5958-0},
  keywords = {affect recognition,machine learning,mental health,mobile EMA,mobile sensing},
  file = {/Users/timokoch/Zotero/storage/BQ4BMPGC/Cai et al. - 2020 - State affect recognition using smartphone sensing .pdf}
}

@article{cambriaAffectiveComputingSentiment2016,
  title = {Affective {{Computing}} and {{Sentiment Analysis}}},
  author = {Cambria, E.},
  year = {2016},
  month = mar,
  journal = {IEEE Intelligent Systems},
  volume = {31},
  number = {2},
  pages = {102--107},
  issn = {1941-1294},
  doi = {10.1109/MIS.2016.31},
  abstract = {Understanding emotions is an important aspect of personal development and growth, and as such it is a key tile for the emulation of human intelligence. Besides being important for the advancement of AI, emotion processing is also important for the closely related task of polarity detection. The opportunity to automatically capture the general public's sentiments about social events, political movements, marketing campaigns, and product preferences has raised interest in both the scientific community, for the exciting open challenges, and the business world, for the remarkable fallouts in marketing and financial market prediction. This has led to the emerging fields of affective computing and sentiment analysis, which leverage human-computer interaction, information retrieval, and multimodal signal processing for distilling people's sentiments from the ever-growing amount of online social data.},
  keywords = {affective computing,Affective computing,affective reasoning,emotion,emotion processing,emotion understanding,financial market prediction,human computer interaction,human intelligence emulation,human-computer interaction,information retrieval,intelligent systems,Knowledge based systems,marketing campaigns,multimodal signal processing,online social data,polarity detection,political movements,Pragmatics,public sentiments,scientific community,Semantics,sentiment analysis,Sentiment analysis,social events,social networking (online),Statistical analysis,Videos},
  file = {/Users/timokoch/Zotero/storage/6FEQAB26/Cambria - 2016 - Affective Computing and Sentiment Analysis.pdf;/Users/timokoch/Zotero/storage/5DEW42CE/7435182.html}
}

@inproceedings{canalesEmotionDetectionText2014,
  title = {Emotion {{Detection}} from Text: {{A Survey}}},
  shorttitle = {Emotion {{Detection}} from Text},
  booktitle = {Proceedings of the {{Workshop}} on {{Natural Language Processing}} in the 5th {{Information Systems Research Working Days}} ({{JISIC}})},
  author = {Canales, Lea and {Mart{\'i}nez-Barco}, Patricio},
  year = {2014},
  pages = {37--43},
  publisher = {{Association for Computational Linguistics}},
  address = {{Quito, Ecuador}},
  doi = {10.3115/v1/W14-6905},
  urldate = {2019-07-09},
  abstract = {This survey describes recent works in the field of Emotion Detection from text, being a part of the broader area of Affective Computing. This survey has been inspired on the well-known fact that, despite there is a lot of work on emotional detection systems, a lot of work is expected to be done yet. The increment of these systems is due to the large amount of emotional data available in Social Web. Detecting emotions from text have attracted the attention of many researchers in computational linguistics because it has a wide range of applications, such as suicide prevention or measuring well-being of a community. This paper mainly collects works based on lexical and machine learning approaches and these works are classificated in accordance with the emotional model and the approach used.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/NTDVYEMV/Canales und Martínez-Barco - 2014 - Emotion Detection from text A Survey.pdf}
}

@inproceedings{caoDeepMoodModelingMobile2017,
  title = {{{DeepMood}}: {{Modeling Mobile Phone Typing Dynamics}} for {{Mood Detection}}},
  shorttitle = {{{DeepMood}}},
  booktitle = {Proceedings of the 23rd {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Cao, Bokai and Zheng, Lei and Zhang, Chenwei and Yu, Philip S. and Piscitello, Andrea and Zulueta, John and Ajilore, Olu and Ryan, Kelly and Leow, Alex D.},
  year = {2017},
  month = aug,
  pages = {747--755},
  publisher = {{ACM}},
  address = {{Halifax NS Canada}},
  doi = {10.1145/3097983.3098086},
  urldate = {2021-02-01},
  abstract = {The increasing use of electronic forms of communication presents new opportunities in the study of mental health, including the ability to investigate the manifestations of psychiatric diseases unobtrusively and in the setting of patients' daily lives. A pilot study to explore the possible connections between bipolar affective disorder and mobile phone usage was conducted. In this study, participants were provided a mobile phone to use as their primary phone. This phone was loaded with a custom keyboard that collected metadata consisting of keypress entry time and accelerometer movement. Individual character data with the exceptions of the backspace key and space bar were not collected due to privacy concerns. We propose an end-to-end deep architecture based on late fusion, named DeepMood, to model the multi-view metadata for the prediction of mood scores. Experimental results show that 90.31\% prediction accuracy on the depression score can be achieved based on sessionlevel mobile phone typing dynamics which is typically less than one minute. It demonstrates the feasibility of using mobile phone metadata to infer mood disturbance and severity.},
  isbn = {978-1-4503-4887-4},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/ZH5T62SU/Cao et al. - 2017 - DeepMood Modeling Mobile Phone Typing Dynamics fo.pdf}
}

@article{carlierSearchStateTrait2022,
  title = {In {{Search}} of {{State}} and {{Trait Emotion Markers}} in {{Mobile-Sensed Language}}: {{Field Study}}},
  shorttitle = {In {{Search}} of {{State}} and {{Trait Emotion Markers}} in {{Mobile-Sensed Language}}},
  author = {Carlier, Chiara and Niemeijer, Koen and Mestdagh, Merijn and Bauwens, Michael and Vanbrabant, Peter and Geurts, Luc and van Waterschoot, Toon and Kuppens, Peter},
  year = {2022},
  month = feb,
  journal = {JMIR Mental Health},
  volume = {9},
  number = {2},
  pages = {e31724},
  publisher = {{JMIR Publications Inc., Toronto, Canada}},
  doi = {10.2196/31724},
  urldate = {2022-07-23},
  abstract = {Background: Emotions and mood are important for overall well-being. Therefore, the search for continuous, effortless emotion prediction methods is an important field of study. Mobile sensing provides a promising tool and can capture one of the most telling signs of emotion: language. Objective: The aim of this study is to examine the separate and combined predictive value of mobile-sensed language data sources for detecting both momentary emotional experience as well as global individual differences in emotional traits and depression. Methods: In a 2-week experience sampling method study, we collected self-reported emotion ratings and voice recordings 10 times a day, continuous keyboard activity, and trait depression severity. We correlated state and trait emotions and depression and language, distinguishing between speech content (spoken words), speech form (voice acoustics), writing content (written words), and writing form (typing dynamics). We also investigated how well these features predicted state and trait emotions using cross-validation to select features and a hold-out set for validation. Results: Overall, the reported emotions and mobile-sensed language demonstrated weak correlations. The most significant correlations were found between speech content and state emotions and between speech form and state emotions, ranging up to 0.25. Speech content provided the best predictions for state emotions. None of the trait emotion{\textendash}language correlations remained significant after correction. Among the emotions studied, valence and happiness displayed the most significant correlations and the highest predictive performance. Conclusions: Although using mobile-sensed language as an emotion marker shows some promise, correlations and predictive R2 values are low.},
  copyright = {Unless stated otherwise, all articles are open-access distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/2.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work ("first published in the Journal of Medical Internet Research...") is properly cited with original URL and bibliographic citation information. The complete bibliographic information, a link to the original publication on http://www.jmir.org/, as well as this copyright and license information must be included.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/99P5654U/Carlier et al. - 2022 - In Search of State and Trait Emotion Markers in Mo.pdf;/Users/timokoch/Zotero/storage/QKH5DPFA/e31724.html}
}

@misc{centerforhistoryandnewmediaSchnelleinstieg,
  title = {Schnelleinstieg},
  author = {{Center for History and New Media}},
  howpublished = {http://zotero.org/support/quick\_start\_guide}
}

@article{chairunnisaAnalysisEmojiEmoticon2017,
  title = {Analysis of {{Emoji}} and {{Emoticon Usage}} in {{Interpersonal Communication}} of {{Blackberry Messenger}} and {{WhatsApp Application User}}},
  author = {Chairunnisa, Sabrina and A.S., Benedictus},
  year = {2017},
  month = apr,
  journal = {International Journal of Social Sciences and Management},
  volume = {4},
  number = {2},
  pages = {120--126},
  issn = {2091-2986},
  doi = {10.3126/ijssm.v4i2.17173},
  urldate = {2019-07-29},
  abstract = {The aims of this research are: 1) to know the display of emoji and emoticon in Blackberry Messenger and WhatsApp application, 2) to know the usage of emoji and emoticon in Blackberry Messenger and WhatsApp application on interpersonal communication, and 3) to know the role of emoji and emoticon usage on interpersonal communication. In this research, the method used was qualitative research method. This research was based on media richness theory. Through the communication channel, the message will have high noise level so that it could be conveyed perfectly. Research results showed that emoji and emoticon have very important role in interpersonal communication. In media richness theory, Blackberry Messenger and WhatsApp media had fulfilled the criteria. 1) Ability of communication channel in conveying message signals such as facial expression, body movement, and vocal inflection; 2) Feedbacks are directly given by the message receiver as response to every chats, 3) Variety of language such as the presence of symbols and foreign language, and 4) Ability of communication channel in conveying personality such as showing personal emotion. This research concluded that emoji and emoticon have important role in interpersonal communication to enhance the text message's meaning.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/4SB2WXJ4/Chairunnisa und A.S. - 2017 - Analysis of Emoji and Emoticon Usage in Interperso.pdf}
}

@article{chawlaSMOTESyntheticMinority2002,
  title = {{{SMOTE}}: {{Synthetic Minority Over-sampling Technique}}},
  shorttitle = {{{SMOTE}}},
  author = {Chawla, N. V. and Bowyer, K. W. and Hall, L. O. and Kegelmeyer, W. P.},
  year = {2002},
  month = jun,
  journal = {Journal of Artificial Intelligence Research},
  volume = {16},
  pages = {321--357},
  issn = {1076-9757},
  doi = {10.1613/jair.953},
  urldate = {2020-02-10},
  abstract = {An approach to the construction of classifiers from imbalanced datasets is described. A dataset is imbalanced if the classification categories are not approximately equally represented. Often real-world data sets are predominately composed of ``normal'' examples with only a small percentage of ``abnormal'' or ``interesting'' examples. It is also the case that the cost of misclassifying an abnormal (interesting) example as a normal example is often much higher than the cost of the reverse error. Under-sampling of the majority (normal) class has been proposed as a good means of increasing the sensitivity of a classifier to the minority class. This paper shows that a combination of our method of over-sampling the minority (abnormal) class and under-sampling the majority (normal) class can achieve better classifier performance (in ROC space) than only under-sampling the majority class. This paper also shows that a combination of our method of over-sampling the minority class and under-sampling the majority class can achieve better classifier performance (in ROC space) than varying the loss ratios in Ripper or class priors in Naive Bayes. Our method of over-sampling the minority class involves creating synthetic minority class examples. Experiments are performed using C4.5, Ripper and a Naive Bayes classifier. The method is evaluated using the area under the Receiver Operating Characteristic curve (AUC) and the ROC convex hull strategy.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/Y5ME5IPL/Chawla et al. - 2002 - SMOTE Synthetic Minority Over-sampling Technique.pdf}
}

@article{chenEffectUserPsychology2020,
  title = {The {{Effect}} of {{User Psychology}} on the {{Content}} of {{Social Media Posts}}: {{Originality}} and {{Transitions Matter}}},
  shorttitle = {The {{Effect}} of {{User Psychology}} on the {{Content}} of {{Social Media Posts}}},
  author = {Chen, Lucia Lushi and Magdy, Walid and Wolters, Maria K.},
  year = {2020},
  journal = {Frontiers in Psychology},
  volume = {11},
  pages = {526},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2020.00526},
  urldate = {2021-10-06},
  abstract = {Multiple studies suggest that frequencies of affective words in social media text are associated with the user's personality and mental health. In this study, we re-examine these associations by looking at the transition patterns of affect. We analyzed the content originality and affect polarity of 4,086 posts from 70 adult Facebook users contributed over 2 months. We studied posting behavior, including silent periods when the user does not post any content. Our results show that more extroverted participants tend to post positive content continuously and that more agreeable participants tend to avoid posting negative content. We also observe that participants with stronger depression symptoms posted more non-original content. We recommend that transitions of affect pattern derived from social media text and content originality should be considered in further studies on mental health, personality, and social media.},
  file = {/Users/timokoch/Zotero/storage/37423UED/Chen et al. - 2020 - The Effect of User Psychology on the Content of So.pdf}
}

@article{chenGenderLensEmpirical2017,
  title = {Through a Gender Lens: {{An}} Empirical Study of Emoji Usage over Large-Scale Android Users},
  author = {Chen, Zhenpeng and Lu, Xuan and Shen, Sheng and Ai, Wei and Liu, Xuanzhe and Mei, Qiaozhu},
  year = {2017},
  journal = {arXiv preprint arXiv:1705.05546},
  eprint = {1705.05546},
  archiveprefix = {arxiv},
  file = {/Users/timokoch/Zotero/storage/LRMKLM9B/1705.05546.pdf}
}

@inproceedings{chenGenderLensLearning2018,
  title = {Through a Gender Lens: Learning Usage Patterns of Emojis from Large-Scale Android Users},
  booktitle = {Proceedings of the 2018 {{World Wide Web Conference}}},
  author = {Chen, Zhenpeng and Lu, Xuan and Ai, Wei and Li, Huoran and Mei, Qiaozhu and Liu, Xuanzhe},
  year = {2018},
  pages = {763--772}
}

@patent{chenPredictingPersonalityTraits2018,
  title = {Predicting Personality Traits Based on Text-Speech Hybrid Data},
  author = {Chen, Yue and Luo, Lin and Shi, Qin and Su, Zhong and SUN, Changhua and Xu, Enliang and Zhao, Shiwan},
  year = {2018},
  month = may,
  number = {US20180137432A1},
  urldate = {2019-02-10},
  assignee = {International Business Machines Corp},
  nationality = {US},
  keywords = {computer,data,device,speech,text},
  file = {/Users/timokoch/Zotero/storage/YPYCTR43/Chen et al. - 2018 - Predicting personality traits based on text-speech.pdf}
}

@article{cherbonnierRecognitionEmotionsFacial2021,
  title = {The Recognition of Emotions beyond Facial Expressions: {{Comparing}} Emoticons Specifically Designed to Convey Basic Emotions with Other Modes of Expression},
  shorttitle = {The Recognition of Emotions beyond Facial Expressions},
  author = {Cherbonnier, Anthony and Michinov, Nicolas},
  year = {2021},
  month = may,
  journal = {Computers in Human Behavior},
  volume = {118},
  pages = {106689},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2021.106689},
  urldate = {2021-01-25},
  abstract = {The development of information and communication technologies has provided a new non-verbal channel to convey emotions using emoticons. Although a great diversity of emoticons is widely used today in text-based communications, little is known about the way emotions are recognized when using emoticons compared to other modes of expression. In a pretest and three studies (N~=~1203), `new' emoticons specifically designed to represent the six basic emotions were proposed to participants who had to recognized the emotions conveyed by each. The quality of recognition was compared to other modes of emotional expression, including facial expressions. In using a between-subject design, the first two studies revealed that the emotions conveyed by `new' emoticons were recognized more effectively than other modes of expression, including facial expressions. Using a within-subject design, a third study confirmed the more successful recognition of `new' emoticons than other modes of expression, and with a greater intensity. For all the studies, this effect was mainly due to the negative emotions of disgust (Study 1, 2, and 3) and sadness (Study 2 and 3). These findings suggest the need to use specific emoticons to convey easily recognized basic emotions for communication technologies, and implement them in social media.},
  langid = {english},
  keywords = {Basic emotions,Emoticons,Facial expressions},
  file = {/Users/timokoch/Zotero/storage/F6HN52BE/S074756322100011X.html}
}

@book{chiconferenceCHI20Extended2020,
  title = {{{CHI}}'20: Extended Abstracts of the 2020 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}} : {{April}} 25-30, 2020, {{Honolulu}}, {{HI}}, {{USA}}},
  shorttitle = {{{CHI}}'20},
  author = {CHI Conference, Regina, Bernhaupt and Mueller, Florian and {SIGCHI (Group : U.S.)} and {Association for Computing Machinery}},
  year = {2020},
  urldate = {2022-04-28},
  langid = {english},
  annotation = {OCLC: 1175624697},
  file = {/Users/timokoch/Zotero/storage/H8Z73B6C/CHI Conference et al. - 2020 - CHI'20 extended abstracts of the 2020 CHI Confere.pdf}
}

@misc{Chomsky1975Reflections,
  title = {Chomsky, {{N}}. (1975) {{Reflections}} on {{Language}}. {{Pantheon Books}}, {{New York}}. - {{References}} - {{Scientific Research Publishing}}},
  urldate = {2018-12-06},
  howpublished = {https://www.scirp.org/(S(i43dyn45teexjx455qlt3d2q))/reference/ReferencesPapers.aspx?ReferenceID=1218503},
  file = {/Users/timokoch/Zotero/storage/9XQF5FEG/ReferencesPapers.html}
}

@book{chomskyReflectionsLanguage1975,
  title = {Reflections on Language},
  author = {Chomsky, Noam},
  year = {1975},
  publisher = {{Pantheon Books}},
  abstract = {Presents observations on and analyses of the purposes, methods, and implications of linguistic studies, the concerns and findings of recent work, and current problems and controversies},
  googlebooks = {R78kAQAAMAAJ},
  isbn = {978-0-394-73123-0},
  langid = {english},
  keywords = {Education / General,Language and languages,Language Arts \& Disciplines / Linguistics / General}
}

@article{chungCountingLittleWords,
  title = {Counting {{Little Words}} in {{Big Data}}:},
  author = {Chung, Cindy K and Pennebaker, James W},
  pages = {31},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/EWEXUILD/Chung und Pennebaker - Counting Little Words in Big Data.pdf}
}

@article{chungCountingLittleWords2014,
  title = {Counting Little Words in Big Data: {{The}} Psychology of Communities, Culture, and History},
  author = {Chung, Cindy K. and Pennebaker, James W.},
  year = {2014},
  journal = {Social Cognition and Communication. Psychology Press, New York, New York, USA},
  pages = {25--42},
  file = {/Users/timokoch/Zotero/storage/H6JU9FHI/Chung und Pennebaker - Counting Little Words in Big Data.pdf}
}

@techreport{chungInvestigatingWithinPersonStructure2021,
  type = {Preprint},
  title = {Investigating the {{Within-Person Structure}} and {{Correlates}} of {{Emotional Experiences}} in {{Everyday Life Using}} an {{Emotion Family Approach}}},
  author = {Chung, Joanne M. and Harari, Gabriella M. and Denissen, Jaap J. A.},
  year = {2021},
  month = feb,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/hdrq9},
  urldate = {2022-07-21},
  abstract = {We examined self-reported emotional experiences in 3 short-term intensive longitudinal studies of Mechanical Turk workers in the United States (Ns = 55; 107; 229). We used an emotion family approach based on lexical studies of emotion knowledge to investigate the within-person structure and correlates of everyday emotional experiences, and took steps towards developing the Facets of Emotional Experiences in Everyday Life Scale. We conducted factor analyses on the within-person level using 6 emotion families to guide our approach (Nobservations = 1,375; 6,582; 11,029). We observed that responses to a range of emotion terms ``in the past hour'' could be summarized into 26 factors, 19 of which showed evidence of replication. Some factors included descriptors corresponding to discrete emotions (e.g., content, serene, calm, peaceful comprised a Contentment factor), and some included clusters of related emotions (e.g., compassionate, adoring, caring, loving comprised a Love factor). Facets of emotional experiences were associated with momentary self-views and situational characteristics. For example, Authentic Pride and Gratitude experiences were both characterized by greater momentary self-esteem, but Authentic Pride was associated with being in situations involving productivity, thinking deeply, and being with weak ties, while Gratitude was linked to acting sociably and being around close others. The assessment of facets of emotional experience expands our view of emotional experience and shows promise for better understanding personality dynamics in everyday life. Research is needed to examine the generalizability of results to other samples and to further assess measurement properties in studies of daily life.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/CATUUTCH/Chung et al. - 2021 - Investigating the Within-Person Structure and Corr.pdf}
}

@article{churchWordAssociationNorms1990,
  title = {Word {{Association Norms}}, {{Mutual Information}}, and {{Lexicography}}},
  author = {Church, Kenneth Ward and Hanks, Patrick},
  year = {1990},
  journal = {Computational Linguistics},
  volume = {16},
  number = {1},
  pages = {22--29},
  urldate = {2021-06-16},
  file = {/Users/timokoch/Zotero/storage/XJQ2IZAZ/Church und Hanks - 1990 - Word Association Norms, Mutual Information, and Le.pdf}
}

@article{cohenClarifyingLinguisticSignature2008,
  title = {Clarifying the {{Linguistic Signature}}: {{Measuring Personality From Natural Speech}}},
  shorttitle = {Clarifying the {{Linguistic Signature}}},
  author = {Cohen, Alex S. and Minor, Kyle S. and Baillie, Lauren E. and Dahir, Amanda M.},
  year = {2008},
  month = oct,
  journal = {Journal of Personality Assessment},
  volume = {90},
  number = {6},
  pages = {559--563},
  issn = {0022-3891, 1532-7752},
  doi = {10.1080/00223890802388459},
  urldate = {2022-07-23},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/A63LLG8X/Cohen et al. - 2008 - Clarifying the Linguistic Signature Measuring Per.pdf}
}

@misc{cohenStatisticalPowerAnalysis1988,
  title = {Statistical Power Analysis for the Behavioral Sciences. 2nd},
  author = {Cohen, Jacob},
  year = {1988},
  publisher = {{Hillsdale, NJ: erlbaum}}
}

@article{cohnLinguisticMarkersPsychological2004,
  title = {Linguistic {{Markers}} of {{Psychological Change Surrounding September}} 11, 2001},
  author = {Cohn, M. A. and Mehl, Matthias R. and Pennebaker, J. W.},
  year = {2004},
  month = oct,
  journal = {Psychological Science},
  volume = {15},
  number = {10},
  pages = {687--693},
  issn = {0956-7976},
  doi = {10.1111/j.0956-7976.2004.00741.x},
  urldate = {2019-08-09},
  abstract = {The diaries of 1,084 U.S. users of an on-line journaling service were downloaded for a period of 4 months spanning the 2 months prior to and after the September 11 attacks. Linguistic analyses of the journal entries revealed pronounced psychological changes in response to the attacks. In the short term, participants expressed more negative emotions, were more cognitively and socially engaged, and wrote with greater psychological distance. After 2 weeks, their moods and social referencing returned to baseline, and their use of cognitive-analytic words dropped below baseline. Over the next 6 weeks, social referencing decreased, and psychological distancing remained elevated relative to baseline. Although the effects were generally stronger for individuals highly preoccupied with September 11, even participants who hardly wrote about the events showed comparable language changes. This study bypasses many of the methodological obstacles of trauma research and provides a finegrained analysis of the time line of human coping with upheaval.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/E5U5ZPII/Cohn et al. - 2004 - Linguistic Markers of Psychological Change Surroun.pdf}
}

@article{cohnLinguisticMarkersPsychological2004a,
  title = {Linguistic {{Markers}} of {{Psychological Change Surrounding September}} 11, 2001},
  author = {Cohn, Michael A. and Mehl, Matthias R. and Pennebaker, James W.},
  year = {2004},
  month = oct,
  journal = {Psychological Science},
  volume = {15},
  number = {10},
  pages = {687--693},
  publisher = {{SAGE Publications Inc}},
  issn = {0956-7976},
  doi = {10.1111/j.0956-7976.2004.00741.x},
  urldate = {2022-05-09},
  abstract = {The diaries of 1,084 U.S. users of an on-line journaling service were downloaded for a period of 4 months spanning the 2 months prior to and after the September 11 attacks. Linguistic analyses of the journal entries revealed pronounced psychological changes in response to the attacks. In the short term, participants expressed more negative emotions, were more cognitively and socially engaged, and wrote with greater psychological distance. After 2 weeks, their moods and social referencing returned to baseline, and their use of cognitive-analytic words dropped below baseline. Over the next 6 weeks, social referencing decreased, and psychological distancing remained elevated relative to baseline. Although the effects were generally stronger for individuals highly preoccupied with September 11, even participants who hardly wrote about the events showed comparable language changes. This study bypasses many of the methodological obstacles of trauma research and provides a finegrained analysis of the time line of human coping with upheaval.},
  file = {/Users/timokoch/Zotero/storage/H3EZ2RMW/Cohn et al. - 2004 - Linguistic Markers of Psychological Change Surroun.pdf}
}

@article{connerExperienceSamplingMethods2009,
  title = {Experience {{Sampling Methods}}: {{A Modern Idiographic Approach}} to {{Personality Research}}},
  shorttitle = {Experience {{Sampling Methods}}},
  author = {Conner, Tamlin S. and Tennen, Howard and Fleeson, William and Barrett, Lisa Feldman},
  year = {2009},
  journal = {Social and Personality Psychology Compass},
  volume = {3},
  number = {3},
  pages = {292--313},
  issn = {1751-9004},
  doi = {10.1111/j.1751-9004.2009.00170.x},
  urldate = {2022-12-14},
  abstract = {Experience sampling methods are essential tools for building a modern idiographic approach to understanding personality. These methods yield multiple snapshots of people's experiences over time in daily life and allow researchers to identify patterns of behavior within a given individual, rather than strictly identify patterns of behavior across individuals, as with standard nomothetic approaches. In this article, we discuss the origin and evolution of idiographic methods in the field of personality and explain how experience sampling methods function as modern day idiographic methods in this field. We then review four primary ways in which experience sampling methods have been used to foster idiographic approaches in personality research. Specifically, we highlight approaches that examine individual differences in temporal and behavioral distributions, situation{\textendash}behavior contingencies, daily processes, and the structure of daily experience. Following a brief methodology primer, we end by discussing future directions for idiographic experience sampling approaches in personality psychology and beyond.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/2TA93KPF/Conner et al. - 2009 - Experience Sampling Methods A Modern Idiographic .pdf;/Users/timokoch/Zotero/storage/S3Z38YPM/j.1751-9004.2009.00170.html}
}

@inproceedings{coppersmithQuantifyingMentalHealth2014,
  title = {Quantifying Mental Health Signals in Twitter},
  booktitle = {Proceedings of the {{Workshop}} on {{Computational Linguistics}} and {{Clinical Psychology}}: {{From Linguistic Signal}} to {{Clinical Reality}}},
  author = {Coppersmith, Glen and Dredze, Mark and Harman, Craig},
  year = {2014},
  pages = {51--60}
}

@article{correaWhoInteractsWeb2010,
  title = {Who Interacts on the {{Web}}?: {{The}} Intersection of Users' Personality and Social Media Use},
  shorttitle = {Who Interacts on the {{Web}}?},
  author = {Correa, Teresa and Hinsley, Amber Willard and {de Z{\'u}{\~n}iga}, Homero Gil},
  year = {2010},
  month = mar,
  journal = {Computers in Human Behavior},
  volume = {26},
  number = {2},
  pages = {247--253},
  issn = {07475632},
  doi = {10.1016/j.chb.2009.09.003},
  urldate = {2019-05-27},
  abstract = {In the increasingly user-generated Web, users' personality traits may be crucial factors leading them to engage in this participatory media. The literature suggests factors such as extraversion, emotional stability and openness to experience are related to uses of social applications on the Internet. Using a national sample of US adults, this study investigated the relationship between these three dimensions of the BigFive model and social media use (defined as use of social networking sites and instant messages). It also examined whether gender and age played a role in that dynamic. Results revealed that while extraversion and openness to experiences were positively related to social media use, emotional stability was a negative predictor, controlling for socio-demographics and life satisfaction. These findings differed by gender and age. While extraverted men and women were both likely to be more frequent users of social media tools, only the men with greater degrees of emotional instability were more regular users. The relationship between extraversion and social media use was particularly important among the young adult cohort. Conversely, being open to new experiences emerged as an important personality predictor of social media use for the more mature segment of the sample.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/JZMKG7HK/Correa et al. - 2010 - Who interacts on the Web The intersection of use.pdf}
}

@article{cowenMapping24Emotions2019,
  title = {Mapping 24 Emotions Conveyed by Brief Human Vocalization},
  author = {Cowen, Alan S. and Elfenbein, Hillary Anger and Laukka, Petri and Keltner, Dacher},
  year = {2019},
  month = sep,
  journal = {The American Psychologist},
  volume = {74},
  number = {6},
  pages = {698--712},
  issn = {1935-990X},
  doi = {10.1037/amp0000399},
  abstract = {Emotional vocalizations are central to human social life. Recent studies have documented that people recognize at least 13 emotions in brief vocalizations. This capacity emerges early in development, is preserved in some form across cultures, and informs how people respond emotionally to music. What is poorly understood is how emotion recognition from vocalization is structured within what we call a semantic space, the study of which addresses questions critical to the field: How many distinct kinds of emotions can be expressed? Do expressions convey emotion categories or affective appraisals (e.g., valence, arousal)? Is the recognition of emotion expressions discrete or continuous? Guided by a new theoretical approach to emotion taxonomies, we apply large-scale data collection and analysis techniques to judgments of 2,032 emotional vocal bursts produced in laboratory settings (Study 1) and 48 found in the real world (Study 2) by U.S. English speakers (N = 1,105). We find that vocal bursts convey at least 24 distinct kinds of emotion. Emotion categories (sympathy, awe), more so than affective appraisals (including valence and arousal), organize emotion recognition. In contrast to discrete emotion theories, the emotion categories conveyed by vocal bursts are bridged by smooth gradients with continuously varying meaning. We visualize the complex, high-dimensional space of emotion conveyed by brief human vocalization within an online interactive map. (PsycINFO Database Record (c) 2019 APA, all rights reserved).},
  langid = {english},
  pmcid = {PMC6586540},
  pmid = {30570267},
  keywords = {Adolescent,Adult,Aged,Communication,Emotions,Female,Humans,Male,Middle Aged,{Recognition, Psychology},Semantics,Social Perception,Voice,Young Adult},
  file = {/Users/timokoch/Zotero/storage/6ZDLDV7P/Cowen et al. - 2019 - Mapping 24 emotions conveyed by brief human vocali.pdf}
}

@article{critchleyInteroceptionEmotion2017,
  title = {Interoception and Emotion},
  author = {Critchley, Hugo D and Garfinkel, Sarah N},
  year = {2017},
  month = oct,
  journal = {Current Opinion in Psychology},
  series = {Emotion},
  volume = {17},
  pages = {7--14},
  issn = {2352-250X},
  doi = {10.1016/j.copsyc.2017.04.020},
  urldate = {2022-12-16},
  abstract = {Influential theories suggest emotional feeling states arise from physiological changes from within the body. Interoception describes the afferent signalling, central processing, and neural and mental representation of internal bodily signals. Recent progress is made in conceptualizing interoception and its neural underpinnings. These developments are supported by empirical data concerning interoceptive mechanisms and their contribution to emotion. Fresh insights include description of short-term interoceptive effects on neural and mental processes (including fear-specific cardiac effects), the recognition of dissociable psychological dimensions of interoception, and models of interoceptive predictive coding that explain emotions and selfhood (reinforced by structural anatomical models and brain and experimental findings). This growing grasp of interoception is enriching our understanding of emotion and its disorders.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/4DKERYPQ/Critchley und Garfinkel - 2017 - Interoception and emotion.pdf}
}

@incollection{csikszentmihalyiValidityReliabilityExperienceSampling2014,
  title = {Validity and {{Reliability}} of the {{Experience-Sampling Method}}},
  booktitle = {Flow and the {{Foundations}} of {{Positive Psychology}}: {{The Collected Works}} of {{Mihaly Csikszentmihalyi}}},
  author = {Csikszentmihalyi, Mihaly and Larson, Reed},
  editor = {Csikszentmihalyi, Mihaly},
  year = {2014},
  pages = {35--54},
  publisher = {{Springer Netherlands}},
  address = {{Dordrecht}},
  doi = {10.1007/978-94-017-9088-8_3},
  urldate = {2022-05-10},
  abstract = {To understand the dynamics of mental health, it is essential to develop measures for the frequency and the patterning of mental processes in every-day-life situations. The Experience-Sampling Method (ESM) is an attempt to provide a valid instrument to describe variations in self-reports of mental processes. It can be used to obtain empirical data on the following types of variables: (a) frequency and patterning of daily activity, social interaction, and changes in location; (b) frequency, intensity, and patterning of psychological states, i.e., emotional, cognitive, and conative dimensions of experience; (c) frequency and patterning of thoughts, including quality and intensity of thought disturbance. The article reviews practical and methodological issues of the ESM and presents evidence for its short-and long-term reliability when used as an instrument for assessing the variables outlined above.},
  isbn = {978-94-017-9088-8},
  langid = {english},
  keywords = {Binge Eating,Person File,Psychological State,Signaling Device,Time Budget Activity},
  file = {/Users/timokoch/Zotero/storage/Z6F8WN4X/Csikszentmihalyi und Larson - 2014 - Validity and Reliability of the Experience-Samplin.pdf}
}

@article{cullenGenerationHighQuality,
  title = {Generation of {{High Quality Audio Natural Emotional Speech Corpus}} Using {{Task Based Mood Induction}}},
  author = {Cullen, C and Vaughan, B and Kousidis, S and Yi, Wang and McDonnell, C and Campbell, D},
  pages = {7},
  abstract = {Detecting emotional dimensions [1] in speech is an area of great research interest, notably as a means of improving human computer interaction in areas such as speech synthesis [2]. In this paper, a method of obtaining high quality emotional audio speech assets is proposed. The methods of obtaining emotional content are subject to considerable debate, with distinctions between acted [3] and natural [4] speech being made based on the grounds of authenticity. Mood Induction Procedures (MIP's) [5] are often employed to stimulate emotional dimensions in a controlled environment. This paper details experimental procedures based around MIP 4, using performance related tasks to engender activation and evaluation responses from the participant. Tasks are specified involving two participants, who must co-operate in order to complete a given task [6] within the allotted time. Experiments designed in this manner also allow for the specification of high quality audio assets (notably 24bit/192Khz [7]), within an acoustically controlled environment [8], thus providing means of reducing unwanted acoustic factors within the recorded speech signal. Once suitable assets are obtained, they will be assessed for the purposes of segregation into differing emotional dimensions. The most statistically robust method of evaluation involves the use of listening tests to determine the perceived emotional dimensions within an audio clip. In this experiment, the FeelTrace [9] rating tool is employed within user listening tests to specify the categories of emotional dimensions for each audio clip.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/4UHTP7EH/Cullen et al. - Generation of High Quality Audio Natural Emotional.pdf}
}

@inproceedings{dannerDeutscheVersionBig2016,
  title = {Die Deutsche {{Version}} Des {{Big Five Inventory}} 2 ({{BFI-2}})},
  booktitle = {Zusammenstellung Sozialwissenschaftlicher {{Items}} Und {{Skalen}}},
  author = {Danner, Daniel and Rammstedt, Beatrice and Bluemke, Matthias and Treiber, Lisa and Berres, Sabrina and Soto, Christopher and John, Oliver},
  year = {2016}
}

@book{darwinExpressionEmotionsMan1886,
  title = {The {{Expression}} of the {{Emotions}} in {{Man}} and {{Animals}}},
  author = {Darwin, Charles},
  year = {1886},
  publisher = {{D. Appleton}},
  googlebooks = {KGNHAAAAIAAJ},
  langid = {english}
}

@article{dasHowHasCoronavirus2021,
  title = {How Has the Coronavirus ({{COVID-19}}) Pandemic Affected Global Emoji Usage?},
  author = {Das, Anwesha},
  year = {2021},
  month = may,
  journal = {Journal of Human Behavior in the Social Environment},
  volume = {31},
  number = {1-4},
  pages = {425--434},
  issn = {1091-1359, 1540-3556},
  doi = {10.1080/10911359.2020.1838383},
  urldate = {2023-03-01},
  abstract = {Over the past few decades, emojis have emerged as a popular form of non-linguistic expression in computer-mediated communication. Various factors have been known to affect emoji usage patterns (such as age, gender, platform diversity etc.). The aim of the current study is to explore if the onset of the coronavirus pandemic (2019{\textendash}20) has affected emoji usage patterns across various countries. The pre\- sent study was conducted on two sets of tweets, collected before (July, 2019) and during the pandemic (March, 2020). The results suggest that although the usage of specific emojis has not changed noticeably (that is, the popular emojis mostly remained the same), the emoji density (average number of emojis per tweet) and the relative popularity of specific emojis have changed. This could potentially point toward a sense of insufficiency of emojis to express the sentiments associated with the pandemic.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/7HG6ICKF/Das - 2021 - How has the coronavirus (COVID-19) pandemic affect.pdf}
}

@inproceedings{dechoudhuryNarcoEmotionsAffect2014,
  title = {"{{Narco}}" Emotions: Affect and Desensitization in Social Media during the Mexican Drug War},
  shorttitle = {"{{Narco}}" Emotions},
  booktitle = {Proceedings of the {{SIGCHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {De Choudhury, Munmun and {Monroy-Hern{\'a}ndez}, Andr{\'e}s and Mark, Gloria},
  year = {2014},
  month = apr,
  pages = {3563--3572},
  publisher = {{ACM}},
  address = {{Toronto Ontario Canada}},
  doi = {10.1145/2556288.2557197},
  urldate = {2022-05-09},
  abstract = {Social media platforms have emerged as prominent information sharing ecosystems in the context of a variety of recent crises, ranging from mass emergencies, to wars and political conflicts. We study affective responses in social media and how they might indicate desensitization to violence experienced in communities embroiled in an armed conflict. Specifically, we examine three established affect measures: negative affect, activation, and dominance as observed on Twitter in relation to a number of statistics on protracted violence in four major cities afflicted by the Mexican Drug War. During a two year period (Aug 2010Dec 2012), while violence was on the rise in these regions, our findings show a decline in negative emotional expression as well as a rise in emotional arousal and dominance in Twitter posts: aspects known to be psychological markers of desensitization. We discuss the implications of our work for behavioral health, facilitating rehabilitation efforts in communities enmeshed in an acute and persistent urban warfare, and the impact on civic engagement.},
  isbn = {978-1-4503-2473-1},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/I96S39XH/De Choudhury et al. - 2014 - Narco emotions affect and desensitization in so.pdf}
}

@inproceedings{dechoudhurySocialMediaMeasurement2013,
  title = {Social Media as a Measurement Tool of Depression in Populations},
  booktitle = {Proceedings of the 5th {{Annual ACM Web Science Conference}} on - {{WebSci}} '13},
  author = {De Choudhury, Munmun and Counts, Scott and Horvitz, Eric},
  year = {2013},
  pages = {47--56},
  publisher = {{ACM Press}},
  address = {{Paris, France}},
  doi = {10.1145/2464464.2464480},
  urldate = {2022-05-09},
  abstract = {Depression is a serious and widespread public health challenge. We examine the potential for leveraging social media postings as a new type of lens in understanding depression in populations. Information gleaned from social media bears potential to complement traditional survey techniques in its ability to provide finer grained measurements over time while radically expanding population sample sizes. We present work on using a crowdsourcing methodology to build a large corpus of postings on Twitter that have been shared by individuals diagnosed with clinical depression. Next, we develop a probabilistic model trained on this corpus to determine if posts could indicate depression. The model leverages signals of social activity, emotion, and language manifested on Twitter. Using the model, we introduce a social media depression index that may serve to characterize levels of depression in populations. Geographical, demographic and seasonal patterns of depression given by the measure confirm psychiatric findings and correlate highly with depression statistics reported by the Centers for Disease Control and Prevention (CDC).},
  isbn = {978-1-4503-1889-1},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/VM3D5QRZ/De Choudhury et al. - 2013 - Social media as a measurement tool of depression i.pdf}
}

@inproceedings{defrenEmotionalSpeechPerception2018,
  title = {Emotional {{Speech Perception}}: {{A}} Set of Semantically Validated {{German}} Neutral and Emotionally Affective Sentences},
  shorttitle = {Emotional {{Speech Perception}}},
  booktitle = {9th {{International Conference}} on {{Speech Prosody}} 2018},
  author = {Defren, Sabrina and {de Brito Castilho Wesseling}, Patricia and Allen, Shanley and Shakuf, Vered and {Ben-David}, Boaz and Lachmann, Thomas},
  year = {2018},
  month = jun,
  pages = {714--718},
  publisher = {{ISCA}},
  doi = {10.21437/SpeechProsody.2018-145},
  urldate = {2020-03-19},
  abstract = {In order to address the complex interplay of prosody and semantics, a set of sentences were generated, suitable for investigating emotional speech perception in German. Fortyseven German native speakers rated the emotional content of sentences on a 6-point Likert scale. From a set of 54 sentences, 10-11 each could reliably be associated with one of four distinct emotions. The remaining 11 were assessed as neutral (expressing no emotion). The unambiguous assignment of semantic (emotional) content enables the study of prosody as an independent factor. Moreover, the sentences were balanced regarding average word frequency, average phonological neighborhood density, and number of syllables per sentence. This linguistic balance enables an unbiased evaluation of the roles of semantic content and prosody in emotional speech.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/ULCJFZWM/Defren et al. - 2018 - Emotional Speech Perception A set of semantically.pdf}
}

@article{dejonckheereAssessingReliabilitySingleitem2022,
  title = {Assessing the Reliability of Single-Item Momentary Affective Measurements in Experience Sampling.},
  author = {Dejonckheere, Egon and Demeyer, Febe and Geusens, Birte and Piot, Maarten and Tuerlinckx, Francis and Verdonck, Stijn and Mestdagh, Merijn},
  year = {2022},
  month = dec,
  journal = {Psychological Assessment},
  volume = {34},
  number = {12},
  pages = {1138--1154},
  issn = {1939-134X, 1040-3590},
  doi = {10.1037/pas0001178},
  urldate = {2023-01-24},
  abstract = {In research on emotions in daily life, measurement error is often ignored because emotions are assessed with a single item to reduce participant burden. We introduce two retests procedures to determine how reliable such emotion ratings are and show that measurement error variance is too substantial to simply disregard.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/9CELVXKV/Dejonckheere et al. - 2022 - Assessing the reliability of single-item momentary.pdf}
}

@incollection{demetriouSelfReportQuestionnaires2015,
  title = {Self-{{Report Questionnaires}}},
  booktitle = {The {{Encyclopedia}} of {{Clinical Psychology}}},
  author = {Demetriou, Constantina and Ozer, Bilge Uzun and Essau, Cecilia A.},
  editor = {Cautin, Robin L. and Lilienfeld, Scott O.},
  year = {2015},
  month = jan,
  pages = {1--6},
  publisher = {{John Wiley \& Sons, Inc.}},
  address = {{Hoboken, NJ, USA}},
  doi = {10.1002/9781118625392.wbecp507},
  urldate = {2019-03-07},
  isbn = {978-1-118-62539-2},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/W8KFWEP4/Demetriou et al. - 2015 - Self-Report Questionnaires.pdf}
}

@incollection{demetriouSelfReportQuestionnaires2015a,
  title = {Self-{{Report Questionnaires}}},
  author = {Demetriou, Constantina and {\"O}zer, Bilge and Essau, Cecilia},
  year = {2015},
  month = jan,
  doi = {10.1002/9781118625392.wbecp507},
  abstract = {The self-report questionnaire is one of the most widely used assessment strategies in clinical psychology. It consists of a set of written questions used for describing certain qualities or characteristics of the test subject. In this entry a brief overview of the main characteristics of self-report questionnaires is presented along with advantages and disadvantages to be used in the field of clinical psychology, both in research and practice, the crucial steps to develop self-report questionnaires, and description of the reliability and validity of self-report questionnaires. Keywords: assessment; cognitive development; cultural adaptation; reliability; self-report questionnaires; validity; assessment; cultural adaptation},
  file = {/Users/timokoch/Zotero/storage/J4XFS62Z/Demetriou et al. - 2015 - Self‐Report Questionnaires.pdf}
}

@article{dengInterpretingTreeEnsembles2014,
  title = {Interpreting {{Tree Ensembles}} with {{inTrees}}},
  author = {Deng, Houtao},
  year = {2014},
  month = aug,
  journal = {arXiv:1408.5456 [cs, stat]},
  eprint = {1408.5456},
  primaryclass = {cs, stat},
  urldate = {2021-06-18},
  abstract = {Tree ensembles such as random forests and boosted trees are accurate but difficult to understand, debug and deploy. In this work, we provide the inTrees (interpretable trees) framework that extracts, measures, prunes and selects rules from a tree ensemble, and calculates frequent variable interactions. An rule-based learner, referred to as the simplified tree ensemble learner (STEL), can also be formed and used for future prediction. The inTrees framework can applied to both classification and regression problems, and is applicable to many types of tree ensembles, e.g., random forests, regularized random forests, and boosted trees. We implemented the inTrees algorithms in the "inTrees" R package.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/timokoch/Zotero/storage/MD2JAATI/Deng - 2014 - Interpreting Tree Ensembles with inTrees.pdf;/Users/timokoch/Zotero/storage/ZEEIL9AG/1408.html}
}

@misc{DepressionPredictionsGPSbased,
  title = {Depression Predictions from {{GPS-based}} Mobility Do Not Generalize Well to Large Demographically Heterogeneous Samples | {{Scientific Reports}}},
  urldate = {2022-11-08},
  howpublished = {https://www.nature.com/articles/s41598-021-93087-x},
  file = {/Users/timokoch/Zotero/storage/8ZEKSY7Z/s41598-021-93087-x.html}
}

@misc{DeutscheVersionBig,
  title = {(6) {{Die}} Deutsche {{Version}} Des {{Big Five Inventory}} 2 ({{BFI-2}}) [{{Download}} via {{http://doi.org/10.6102/zis247]}} | {{Request PDF}}},
  shorttitle = {(6) {{Die}} Deutsche {{Version}} Des {{Big Five Inventory}} 2 ({{BFI-2}}) [{{Download}} via Http},
  journal = {ResearchGate},
  urldate = {2018-11-26},
  abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
  howpublished = {https://www.researchgate.net/publication/309210665\_Die\_deutsche\_Version\_des\_Big\_Five\_Inventory\_2\_BFI-2\_Download\_via\_httpdoiorg106102zis247},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/Y3YHXX4T/309210665_Die_deutsche_Version_des_Big_Five_Inventory_2_BFI-2_Download_via_httpdoiorg106102zis2.html}
}

@article{dharSurveyOnDeviceMachine2021,
  title = {A {{Survey}} of {{On-Device Machine Learning}}: {{An Algorithms}} and {{Learning Theory Perspective}}},
  shorttitle = {A {{Survey}} of {{On-Device Machine Learning}}},
  author = {Dhar, Sauptik and Guo, Junyao and Liu, Jiayi (Jason) and Tripathi, Samarth and Kurup, Unmesh and Shah, Mohak},
  year = {2021},
  month = aug,
  journal = {ACM Transactions on Internet of Things},
  volume = {2},
  number = {3},
  pages = {1--49},
  issn = {2691-1914, 2577-6207},
  doi = {10.1145/3450494},
  urldate = {2023-01-26},
  abstract = {The predominant paradigm for using machine learning models on a device is to train a model in the cloud and perform inference using the trained model on the device. However, with increasing numbers of smart devices and improved hardware, there is interest in performing model training on the device. Given this surge in interest, a comprehensive survey of the field from a device-agnostic perspective sets the stage for both understanding the state of the art and for identifying open challenges and future avenues of research. However, on-device learning is an expansive field with connections to a large number of related topics in AI and machine learning (including online learning, model adaptation, one/few-shot learning, etc.). Hence, covering such a large number of topics in a single survey is impractical. This survey finds a middle ground by reformulating the problem of on-device learning as resource constrained learning where the resources are compute and memory. This reformulation allows tools, techniques, and algorithms from a wide variety of research areas to be compared equitably. In addition to summarizing the state of the art, the survey also identifies a number of challenges and next steps for both the algorithmic and theoretical aspects of on-device learning.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/4ADMJXS4/Dhar et al. - 2021 - A Survey of On-Device Machine Learning An Algorit.pdf}
}

@inproceedings{dubeyBigEARInferringAmbient2016,
  title = {{{BigEAR}}: {{Inferring}} the {{Ambient}} and {{Emotional Correlates}} from {{Smartphone-Based Acoustic Big Data}}},
  shorttitle = {{{BigEAR}}},
  booktitle = {2016 {{IEEE First International Conference}} on {{Connected Health}}: {{Applications}}, {{Systems}} and {{Engineering Technologies}} ({{CHASE}})},
  author = {Dubey, Harishchandra and Mehl, Matthias R. and Mankodiya, Kunal},
  year = {2016},
  month = jun,
  pages = {78--83},
  doi = {10.1109/CHASE.2016.46},
  abstract = {This paper presents a novel BigEAR big data framework that employs psychological audio processing chain (PAPC) to process smartphone-based acoustic big data collected when the user performs social conversations in naturalistic scenarios. The overarching goal of BigEAR is to identify moods of the wearer from various activities such as laughing, singing, crying, arguing, and sighing. These annotations are based on ground truth relevant for psychologists who intend to monitor/infer the social context of individuals coping with breast cancer. We pursued a case study on couples coping with breast cancer to know how the conversations affect emotional and social well being. In the state-of-the-art methods, psychologists and their team have to hear the audio recordings for making these inferences by subjective evaluations that not only are time-consuming and costly, but also demand manual data coding for thousands of audio files. The BigEAR framework automates the audio analysis. We computed the accuracy of BigEAR with respect to the ground truth obtained from a human rater. Our approach yielded overall average accuracy of 88.76\% on real-world data from couples coping with breast cancer.},
  keywords = {Acoustics,Big data,Breast cancer,Feature extraction,Mood,Speech},
  file = {/Users/timokoch/Zotero/storage/X6EE5EE9/Dubey et al. - 2016 - BigEAR Inferring the Ambient and Emotional Correl.pdf;/Users/timokoch/Zotero/storage/GKFD6KJD/7545817.html}
}

@article{dudauPerformingMultilingualAnalysis2021,
  title = {Performing {{Multilingual Analysis With Linguistic Inquiry}} and {{Word Count}} 2015 ({{LIWC2015}}). {{An Equivalence Study}} of {{Four Languages}}},
  author = {Dud{\u a}u, Diana and Sava, Florin},
  year = {2021},
  month = jul,
  journal = {Frontiers in Psychology},
  volume = {12},
  pages = {570568},
  doi = {10.3389/fpsyg.2021.570568},
  abstract = {Today, there is a range of computer-aided techniques to convert text into data. However, they convey not only strengths but also vulnerabilities compared to traditional content analysis. One of the challenges that have gained increasing attention is performing automatic language analysis to make sound inferences in a multilingual assessment setting. The current study is the first to test the equivalence of multiple versions of one of the most appealing and widely used lexicon-based tools worldwide, Linguistic Inquiry and Word Count 2015 (LIWC2015). For this purpose, we employed supervised learning in a classification problem and computed Pearson's correlations and intraclass correlation coefficients on a large corpus of parallel texts in English, Dutch, Brazilian Portuguese, and Romanian. Our findings suggested that LIWC2015 is a valuable tool for multilingual analysis, but within-language standardization is needed when the aim is to analyze texts sourced from different languages.},
  file = {/Users/timokoch/Zotero/storage/7TECP6UE/Dudău und Sava - 2021 - Performing Multilingual Analysis With Linguistic I.pdf}
}

@article{dukesRiseAffectivism2021,
  title = {The Rise of Affectivism},
  author = {Dukes, Daniel and Abrams, Kathryn and Adolphs, Ralph and Ahmed, Mohammed E. and Beatty, Andrew and Berridge, Kent C. and Broomhall, Susan and Brosch, Tobias and Campos, Joseph J. and Clay, Zanna and Cl{\'e}ment, Fabrice and Cunningham, William A. and Damasio, Antonio and Damasio, Hanna and D'Arms, Justin and Davidson, Jane W. and de Gelder, Beatrice and Deonna, Julien and de Sousa, Ronnie and Ekman, Paul and Ellsworth, Phoebe C. and Fehr, Ernst and Fischer, Agneta and Foolen, Ad and Frevert, Ute and Grandjean, Didier and Gratch, Jonathan and Greenberg, Leslie and Greenspan, Patricia and Gross, James J. and Halperin, Eran and Kappas, Arvid and Keltner, Dacher and Knutson, Brian and Konstan, David and Kret, Mariska E. and LeDoux, Joseph E. and Lerner, Jennifer S. and Levenson, Robert W. and Loewenstein, George and Manstead, Antony S. R. and Maroney, Terry A. and Moors, Agnes and Niedenthal, Paula and Parkinson, Brian and Pavlidis, Ioannis and Pelachaud, Catherine and Pollak, Seth D. and Pourtois, Gilles and {Roettger-Roessler}, Birgitt and Russell, James A. and Sauter, Disa and Scarantino, Andrea and Scherer, Klaus R. and Stearns, Peter and Stets, Jan E. and Tappolet, Christine and Teroni, Fabrice and Tsai, Jeanne and Turner, Jonathan and Reekum, Carien Van and Vuilleumier, Patrik and Wharton, Tim and Sander, David},
  year = {2021},
  month = jun,
  journal = {Nature Human Behaviour},
  pages = {1--5},
  publisher = {{Nature Publishing Group}},
  issn = {2397-3374},
  doi = {10.1038/s41562-021-01130-8},
  urldate = {2021-06-15},
  abstract = {Research over the past decades has demonstrated the explanatory power of emotions, feelings, motivations, moods, and other affective processes when trying to understand and predict how we think and behave. In this consensus article, we ask: has the increasingly recognized impact of affective phenomena ushered in a new era, the era of affectivism?},
  copyright = {2021 Springer Nature Limited},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/URGR3PCU/Dukes et al. - 2021 - The rise of affectivism.pdf;/Users/timokoch/Zotero/storage/VX4IKLRE/s41562-021-01130-8.html}
}

@article{dukesRiseAffectivism2021a,
  title = {The Rise of Affectivism},
  author = {Dukes, Daniel and Abrams, Kathryn and Adolphs, Ralph and Ahmed, Mohammed E. and Beatty, Andrew and Berridge, Kent C. and Broomhall, Susan and Brosch, Tobias and Campos, Joseph J. and Clay, Zanna and Cl{\'e}ment, Fabrice and Cunningham, William A. and Damasio, Antonio and Damasio, Hanna and D'Arms, Justin and Davidson, Jane W. and de Gelder, Beatrice and Deonna, Julien and de Sousa, Ronnie and Ekman, Paul and Ellsworth, Phoebe C. and Fehr, Ernst and Fischer, Agneta and Foolen, Ad and Frevert, Ute and Grandjean, Didier and Gratch, Jonathan and Greenberg, Leslie and Greenspan, Patricia and Gross, James J. and Halperin, Eran and Kappas, Arvid and Keltner, Dacher and Knutson, Brian and Konstan, David and Kret, Mariska E. and LeDoux, Joseph E. and Lerner, Jennifer S. and Levenson, Robert W. and Loewenstein, George and Manstead, Antony S. R. and Maroney, Terry A. and Moors, Agnes and Niedenthal, Paula and Parkinson, Brian and Pavlidis, Ioannis and Pelachaud, Catherine and Pollak, Seth D. and Pourtois, Gilles and {Roettger-Roessler}, Birgitt and Russell, James A. and Sauter, Disa and Scarantino, Andrea and Scherer, Klaus R. and Stearns, Peter and Stets, Jan E. and Tappolet, Christine and Teroni, Fabrice and Tsai, Jeanne and Turner, Jonathan and Reekum, Carien Van and Vuilleumier, Patrik and Wharton, Tim and Sander, David},
  year = {2021},
  month = jun,
  journal = {Nature Human Behaviour},
  pages = {1--5},
  publisher = {{Nature Publishing Group}},
  issn = {2397-3374},
  doi = {10.1038/s41562-021-01130-8},
  urldate = {2021-06-15},
  abstract = {Research over the past decades has demonstrated the explanatory power of emotions, feelings, motivations, moods, and other affective processes when trying to understand and predict how we think and behave. In this consensus article, we ask: has the increasingly recognized impact of affective phenomena ushered in a new era, the era of affectivism?},
  copyright = {2021 Springer Nature Limited},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/BAJKF3QA/Dukes et al. - 2021 - The rise of affectivism.pdf;/Users/timokoch/Zotero/storage/JK9W5NFH/s41562-021-01130-8.html}
}

@article{dunnMultipleComparisonsMeans1961,
  title = {Multiple Comparisons among Means},
  author = {Dunn, Olive Jean},
  year = {1961},
  journal = {Journal of the American Statistical Association},
  volume = {56},
  number = {293},
  pages = {52--64},
  issn = {0162-1459}
}

@article{eichstaedtClosedOpenvocabularyApproaches2021,
  title = {Closed- and Open-Vocabulary Approaches to Text Analysis: {{A}} Review, Quantitative Comparison, and Recommendations.},
  shorttitle = {Closed- and Open-Vocabulary Approaches to Text Analysis},
  author = {Eichstaedt, Johannes C. and Kern, Margaret L. and Yaden, David B. and Schwartz, H. A. and Giorgi, Salvatore and Park, Gregory and Hagan, Courtney A. and Tobolsky, Victoria A. and Smith, Laura K. and Buffone, Anneke and Iwry, Jonathan and Seligman, Martin E. P. and Ungar, Lyle H.},
  year = {2021},
  month = aug,
  journal = {Psychological Methods},
  volume = {26},
  number = {4},
  pages = {398--427},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/met0000349},
  urldate = {2021-12-08},
  abstract = {Technology now makes it possible to understand efficiently and at large scale how people use language to reveal their everyday thoughts, behaviors, and emotions. Written text has been analyzed through both theory-based, closed-vocabulary methods from the social sciences as well as datadriven, open-vocabulary methods from computer science, but these approaches have not been comprehensively compared. To provide guidance on best practices for automatically analyzing written text, this narrative review and quantitative synthesis compares five predominant closed- and open-vocabulary methods: Linguistic Inquiry and Word Count (LIWC), the General Inquirer, DICTION, Latent Dirichlet Allocation, and Differential Language Analysis. We compare the linguistic features associated with gender, age, and personality across the five methods using an existing dataset of Facebook status updates and self-reported survey data from 65,896 users. Results are fairly consistent across methods. The closed-vocabulary approaches efficiently summarize concepts and are helpful for understanding how people think, with LIWC2015 yielding the strongest, most parsimonious results. Open-vocabulary approaches reveal more specific and concrete patterns across a broad range of content domains, better address ambiguous word senses, and are less prone to misinterpretation, suggesting that they are well-suited for capturing the nuances of everyday psychological processes. We detail several errors that can occur in closed-vocabulary analyses, the impact of sample size, number of words per user and number of topics included in open-vocabulary analyses, and implications of different analytical decisions. We conclude with recommendations for researchers, advocating for a complementary approach that combines closed- and open-vocabulary methods.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/7U2J389E/Eichstaedt et al. - 2021 - Closed- and open-vocabulary approaches to text ana.pdf}
}

@article{eichstaedtClosedOpenVocabularyApproachesinpress,
  title = {Closed- and {{Open-Vocabulary Approaches}} to {{Text Analysis}}: {{A Review}}, {{Quantitative Comparison}}, and {{Recommendations}}},
  author = {Eichstaedt, J. C. and Kern, M. L. and Yaden, D. B. and Schwartz, H. A. and Giorgi, S. and Park, G. and Hagan, C. A. and Tobolsky, V. and Smith, Laura K. and Buffone, A. and Iwry, J. and Seligman, M. E. and Ungar, L. H.},
  year = {in press},
  journal = {Psychological Methods},
  urldate = {2020-10-16},
  annotation = {In Press},
  file = {/Users/timokoch/Zotero/storage/5VYMNME8/psych-methods-2020.pdf}
}

@article{eichstaedtEmotionalMentalHealth2021,
  title = {The Emotional and Mental Health Impact of the Murder of {{George Floyd}} on the {{US}} Population},
  author = {Eichstaedt, Johannes C. and Sherman, Garrick T. and Giorgi, Salvatore and Roberts, Steven O. and Reynolds, Megan E. and Ungar, Lyle H. and Guntuku, Sharath Chandra},
  year = {2021},
  month = sep,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {118},
  number = {39},
  pages = {e2109139118},
  publisher = {{Proceedings of the National Academy of Sciences}},
  doi = {10.1073/pnas.2109139118},
  urldate = {2022-11-11},
  abstract = {On May 25, 2020, George Floyd, an unarmed Black American male, was killed by a White police officer. Footage of the murder was widely shared. We examined the psychological impact of Floyd's death using two population surveys that collected data before and after his death; one from Gallup (117,568 responses from n = 47,355) and one from the US Census (409,652 responses from n = 319,471). According to the Gallup data, in the week following Floyd's death, anger and sadness increased to unprecedented levels in the US population. During this period, more than a third of the US population reported these emotions. These increases were more pronounced for Black Americans, nearly half of whom reported these emotions. According to the US Census Household Pulse data, in the week following Floyd's death, depression and anxiety severity increased among Black Americans at significantly higher rates than that of White Americans. Our estimates suggest that this increase corresponds to an additional 900,000 Black Americans who would have screened positive for depression, associated with a burden of roughly 2.7 million to 6.3 million mentally unhealthy days.},
  file = {/Users/timokoch/Zotero/storage/HRXWYA25/Eichstaedt et al. - 2021 - The emotional and mental health impact of the murd.pdf}
}

@article{eichstaedtFacebookLanguagePredicts2018,
  title = {Facebook Language Predicts Depression in Medical Records},
  author = {Eichstaedt, Johannes C. and Smith, Robert J. and Merchant, Raina M. and Ungar, Lyle H. and Crutchley, Patrick and {Preo{\c t}iuc-Pietro}, Daniel and Asch, David A. and Schwartz, H. Andrew},
  year = {2018},
  month = oct,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {115},
  number = {44},
  pages = {11203--11208},
  publisher = {{Proceedings of the National Academy of Sciences}},
  doi = {10.1073/pnas.1802331115},
  urldate = {2022-05-09},
  file = {/Users/timokoch/Zotero/storage/6XZZCNK3/Eichstaedt et al. - 2018 - Facebook language predicts depression in medical r.pdf}
}

@article{eichstaedtTrackingFluctuationsPsychological2020,
  title = {Tracking {{Fluctuations}} in {{Psychological States Using Social Media Language}}: {{A Case Study}} of {{Weekly Emotion}}},
  shorttitle = {Tracking {{Fluctuations}} in {{Psychological States Using Social Media Language}}},
  author = {Eichstaedt, Johannes C. and Weidman, Aaron C.},
  editor = {Rauthmann, John},
  year = {2020},
  month = sep,
  journal = {European Journal of Personality},
  volume = {34},
  number = {5},
  pages = {845--858},
  issn = {0890-2070, 1099-0984},
  doi = {10.1002/per.2261},
  urldate = {2020-11-06},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/AK2VWLBL/Eichstaedt und Weidman - 2020 - Tracking Fluctuations in Psychological States Usin.pdf}
}

@article{ekmanArgumentBasicEmotions1992,
  title = {An Argument for Basic Emotions},
  author = {Ekman, Paul},
  year = {1992},
  month = may,
  journal = {Cognition and Emotion},
  volume = {6},
  number = {3-4},
  pages = {169--200},
  publisher = {{Routledge}},
  issn = {0269-9931},
  doi = {10.1080/02699939208411068},
  urldate = {2021-11-24},
  abstract = {Emotions are viewed as having evolved through their adaptive value in dealing with fundamental life-tasks. Each emotion has unique features: signal, physiology, and antecedent events. Each emotion also has characteristics in common with other emotions: rapid onset, short duration, unbidden occurrence, automatic appraisal, and coherence among responses. These shared and unique characteristics are the product of our evolution, and distinguish emotions from other affective phenomena.},
  file = {/Users/timokoch/Zotero/storage/F8ZQ6L9S/02699939208411068.html}
}

@article{ekmanArgumentBasicEmotions1992a,
  title = {An Argument for Basic Emotions},
  author = {Ekman, Paul},
  year = {1992},
  month = may,
  journal = {Cognition and Emotion},
  volume = {6},
  number = {3-4},
  pages = {169--200},
  publisher = {{Routledge}},
  issn = {0269-9931},
  doi = {10.1080/02699939208411068},
  urldate = {2021-11-24},
  abstract = {Emotions are viewed as having evolved through their adaptive value in dealing with fundamental life-tasks. Each emotion has unique features: signal, physiology, and antecedent events. Each emotion also has characteristics in common with other emotions: rapid onset, short duration, unbidden occurrence, automatic appraisal, and coherence among responses. These shared and unique characteristics are the product of our evolution, and distinguish emotions from other affective phenomena.},
  file = {/Users/timokoch/Zotero/storage/SVRRXKTP/02699939208411068.html}
}

@article{elhaiCompatibilityTheoreticalFrameworks2020,
  title = {The Compatibility of Theoretical Frameworks with Machine Learning Analyses in Psychological Research},
  author = {Elhai, Jon D and Montag, Christian},
  year = {2020},
  month = dec,
  journal = {Current Opinion in Psychology},
  series = {Cyberpsychology},
  volume = {36},
  pages = {83--88},
  issn = {2352-250X},
  doi = {10.1016/j.copsyc.2020.05.002},
  urldate = {2022-11-08},
  abstract = {Supervised machine learning has been increasingly used in psychology and psychiatry research. Machine learning offers an important advantage over traditional statistical analyses: statistical model training in example data to enhance predictions in external test data. Additional advantages include advanced, improved statistical algorithms, and empirical methods to select a smaller set of predictor variables. Yet machine learning researchers often use large numbers of predictor variables, without using theory to guide variable selection. Such approach leads to Type I error, spurious findings, and decreased generalizability. We discuss the importance of theory to the psychology field. We offer suggestions for using theory to drive variable selection and data analyses using machine learning in psychological research, including an example from the cyberpsychology field.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/AKT8BDYY/Elhai und Montag - 2020 - The compatibility of theoretical frameworks with m.pdf;/Users/timokoch/Zotero/storage/KN5ILW9K/S2352250X20300804.html}
}

@misc{emojipediaUnicodeVersion2018,
  title = {Unicode {{Version}} 7.0},
  author = {Emojipedia},
  year = {2018}
}

@misc{EmojisToolsEmotion,
  title = {Emojis as {{Tools}} for {{Emotion Work}}: {{Communicating Affect}} in {{Text Messages}} - {{Monica A}}. {{Riordan}}, 2017},
  urldate = {2020-11-23},
  howpublished = {https://journals.sagepub.com/doi/abs/10.1177/0261927X17704238},
  file = {/Users/timokoch/Zotero/storage/XRMLP4L5/0261927X17704238.html}
}

@misc{EmotionAIResearchers,
  title = {Emotion {{AI}} Researchers Say Overblown Claims Give Their Work a Bad Name},
  journal = {MIT Technology Review},
  urldate = {2022-12-02},
  abstract = {A lack of government regulation isn't just bad for consumers. It's bad for the field, too.},
  howpublished = {https://www.technologyreview.com/2020/02/14/844765/ai-emotion-recognition-affective-computing-hirevue-regulation-ethics/},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/K7J7AI5D/ai-emotion-recognition-affective-computing-hirevue-regulation-ethics.html}
}

@article{EmotionRecognitionCan2021,
  title = {Emotion Recognition: Can {{AI}} Detect Human Feelings from a Face?},
  shorttitle = {Emotion Recognition},
  year = {2021},
  month = may,
  journal = {Financial Times}
}

@article{enosFrameworkElicitingEmotional2008,
  title = {A {{Framework}} for {{Eliciting Emotional Speech}}: {{Capitalizing}} on the {{Actor}}'s {{Process}}},
  shorttitle = {A {{Framework}} for {{Eliciting Emotional Speech}}},
  author = {Enos, Frank and Hirschberg, Julia},
  year = {2008},
  month = dec,
  abstract = {This paper offers an approach and a theoretical framework for eliciting emotional speech using actors. The framework is developed by connecting the goal-based model of emo- tion proposed by Abelson (1), the work of appraisal theo- rists, and an approach to the actor's technical process widely used in the professional theater and taught in modern con- servatories. In doing so, we hope to address some of the difficulties currently encountered in the use of acted speech in emotion research. Author Keywords Emotion, elicitation, acting, appraisal theory.},
  file = {/Users/timokoch/Zotero/storage/BQ83R9MI/Enos und Hirschberg - 2008 - A Framework for Eliciting Emotional Speech Capita.pdf}
}

@inproceedings{estivalAuthorProfilingEnglish2007,
  title = {Author Profiling for {{English}} Emails},
  booktitle = {In {{Proceedings}} of the 10th {{Conference}} of the {{Pacific Association}} for {{Computational Linguistics}}},
  author = {Estival, Dominique and Gaustad, Tanja and Hutchinson, Ben and Pham, Son Bao and Radford, Will},
  year = {2007},
  pages = {263--272},
  abstract = {This paper reports on some aspects of a project aimed at automating the analysis of texts for the purpose of author profiling and identification. The complete analysis provides probabilities for the author's basic demographic traits (gender, age, geographic origin, level of education and native language) as well as for five psychometric traits. We describe the email data which was collected for the project, the ways this data is processed and analysed, and the experimental setup used for classification with the Text Attribution Tool (TAT) before presenting our results for the demographic and psychometric traits using English email. Results are very promising for all ten traits examined. 1},
  file = {/Users/timokoch/Zotero/storage/HUEBC6RJ/Estival et al. - 2007 - Author profiling for English emails.pdf;/Users/timokoch/Zotero/storage/ZZGW282G/Estival et al. - Author Proﬁling for English Emails.pdf;/Users/timokoch/Zotero/storage/WMYG3AIQ/summary.html}
}

@inproceedings{estivalAuthorProfilingEnglish2007a,
  title = {Author {{Profiling}} for {{English Emails}}},
  author = {Estival, Dominique and Gaustad, Tanja and Hutchinson, Ben and Pham, Son and Radford, Will},
  year = {2007},
  pages = {10},
  abstract = {This paper reports on some aspects of a project aimed at automating the analysis of texts for the purpose of author profiling and identification. The complete analysis provides probabilities for the author's basic demographic traits (gender, age, geographic origin, level of education and native language) as well as for five psychometric traits. We describe the email data which was collected for the project, the ways this data is processed and analysed, and the experimental setup used for classification with the Text Attribution Tool (TAT) before presenting our results for the demographic and psychometric traits using English email. Results are very promising for all ten traits examined.},
  langid = {english}
}

@misc{evansWhyUSGovernment2020,
  title = {Why the {{US}} Government Is Questioning {{WhatsApp}}'s Encryption},
  author = {Evans, Dain},
  year = {2020},
  month = feb,
  journal = {CNBC},
  urldate = {2020-07-01},
  abstract = {Encryption takes data like a text message or email, and converts it into code to prevent people, who are not the desired recipient, from seeing the data online. Encryption has gotten companies like Apple and WhatsApp in hot water with the U.S. government for prohibiting it from accessing private user data.},
  chapter = {Technology},
  howpublished = {https://www.cnbc.com/2020/02/21/whatsapp-encryption-under-scrutiny-by-us-government.html},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/88AILH64/whatsapp-encryption-under-scrutiny-by-us-government.html}
}

@article{eybenGenevaMinimalisticAcoustic2016,
  title = {The {{Geneva Minimalistic Acoustic Parameter Set}} ({{GeMAPS}}) for {{Voice Research}} and {{Affective Computing}}},
  author = {Eyben, Florian and Scherer, Klaus R. and Schuller, Bjorn W. and Sundberg, Johan and Andre, Elisabeth and Busso, Carlos and Devillers, Laurence Y. and Epps, Julien and Laukka, Petri and Narayanan, Shrikanth S. and Truong, Khiet P.},
  year = {2016},
  month = apr,
  journal = {IEEE Transactions on Affective Computing},
  volume = {7},
  number = {2},
  pages = {190--202},
  issn = {1949-3045},
  doi = {10.1109/TAFFC.2015.2457417},
  urldate = {2019-02-20},
  abstract = {Work on voice sciences over recent decades has led to a proliferation of acoustic parameters that are used quite selectively and are not always extracted in a similar fashion. With many independent teams working in different research areas, shared standards become an essential safeguard to ensure compliance with state-of-the-art methods allowing appropriate comparison of results across studies and potential integration and combination of extraction and recognition systems. In this paper we propose a basic standard acoustic parameter set for various areas of automatic voice analysis, such as paralinguistic or clinical speech analysis. In contrast to a large brute-force parameter set, we present a minimalistic set of voice parameters here. These were selected based on a) their potential to index affective physiological changes in voice production, b) their proven value in former studies as well as their automatic extractability, and c) their theoretical significance. The set is intended to provide a common baseline for evaluation of future research and eliminate differences caused by varying parameter sets or even different implementations of the same parameters. Our implementation is publicly available with the openSMILE toolkit. Comparative evaluations of the proposed feature set and large baseline feature sets of INTERSPEECH challenges show a high performance of the proposed set in relation to its size.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/U5GKGSVA/Eyben et al. - 2016 - The Geneva Minimalistic Acoustic Parameter Set (Ge.pdf}
}

@article{eybenGenevaMinimalisticAcoustic2016a,
  title = {The {{Geneva Minimalistic Acoustic Parameter Set}} ({{GeMAPS}}) for {{Voice Research}} and {{Affective Computing}}},
  author = {Eyben, Florian and Scherer, Klaus R. and Schuller, Bjorn W. and Sundberg, Johan and Andre, Elisabeth and Busso, Carlos and Devillers, Laurence Y. and Epps, Julien and Laukka, Petri and Narayanan, Shrikanth S. and Truong, Khiet P.},
  year = {2016},
  month = apr,
  journal = {IEEE Transactions on Affective Computing},
  volume = {7},
  number = {2},
  pages = {190--202},
  issn = {1949-3045},
  doi = {10.1109/TAFFC.2015.2457417},
  urldate = {2020-11-20},
  abstract = {Work on voice sciences over recent decades has led to a proliferation of acoustic parameters that are used quite selectively and are not always extracted in a similar fashion. With many independent teams working in different research areas, shared standards become an essential safeguard to ensure compliance with state-of-the-art methods allowing appropriate comparison of results across studies and potential integration and combination of extraction and recognition systems. In this paper we propose a basic standard acoustic parameter set for various areas of automatic voice analysis, such as paralinguistic or clinical speech analysis. In contrast to a large brute-force parameter set, we present a minimalistic set of voice parameters here. These were selected based on a) their potential to index affective physiological changes in voice production, b) their proven value in former studies as well as their automatic extractability, and c) their theoretical significance. The set is intended to provide a common baseline for evaluation of future research and eliminate differences caused by varying parameter sets or even different implementations of the same parameters. Our implementation is publicly available with the openSMILE toolkit. Comparative evaluations of the proposed feature set and large baseline feature sets of INTERSPEECH challenges show a high performance of the proposed set in relation to its size.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/GGMQPBKY/Eyben et al. - 2016 - The Geneva Minimalistic Acoustic Parameter Set (Ge.pdf}
}

@inproceedings{eybenOpensmileMunichVersatile2010,
  title = {Opensmile: The Munich Versatile and Fast Open-Source Audio Feature Extractor},
  shorttitle = {Opensmile},
  booktitle = {Proceedings of the International Conference on {{Multimedia}} - {{MM}} '10},
  author = {Eyben, Florian and W{\"o}llmer, Martin and Schuller, Bj{\"o}rn},
  year = {2010},
  pages = {1459},
  publisher = {{ACM Press}},
  address = {{Firenze, Italy}},
  doi = {10.1145/1873951.1874246},
  urldate = {2021-11-09},
  abstract = {We introduce the openSMILE feature extraction toolkit, which unites feature extraction algorithms from the speech processing and the Music Information Retrieval communities. Audio low-level descriptors such as CHROMA and CENS features, loudness, Mel-frequency cepstral coefficients, perceptual linear predictive cepstral coefficients, linear predictive coefficients, line spectral frequencies, fundamental frequency, and formant frequencies are supported. Delta regression and various statistical functionals can be applied to the low-level descriptors. openSMILE is implemented in C++ with no third-party dependencies for the core functionality. It is fast, runs on Unix and Windows platforms, and has a modular, component based architecture which makes extensions via plug-ins easy. It supports on-line incremental processing for all implemented features as well as off-line and batch processing. Numeric compatibility with future versions is ensured by means of unit tests. openSMILE can be downloaded from http://opensmile.sourceforge.net/.},
  isbn = {978-1-60558-933-6},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/NINCC86M/Eyben et al. - 2010 - Opensmile the munich versatile and fast open-sour.pdf}
}

@inproceedings{eybenRecentDevelopmentsOpenSMILE2013,
  title = {Recent {{Developments}} in {{openSMILE}}, the {{Munich Open-source Multimedia Feature Extractor}}},
  booktitle = {Proceedings of the 21st {{ACM International Conference}} on {{Multimedia}}},
  author = {Eyben, Florian and Weninger, Felix and Gross, Florian and Schuller, Bj{\"o}rn},
  year = {2013},
  series = {{{MM}} '13},
  pages = {835--838},
  publisher = {{ACM}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2502081.2502224},
  urldate = {2018-11-21},
  abstract = {We present recent developments in the openSMILE feature extraction toolkit. Version 2.0 now unites feature extraction paradigms from speech, music, and general sound events with basic video features for multi-modal processing. Descriptors from audio and video can be processed jointly in a single framework allowing for time synchronization of parameters, on-line incremental processing as well as off-line and batch processing, and the extraction of statistical functionals (feature summaries), such as moments, peaks, regression parameters, etc. Postprocessing of the features includes statistical classifiers such as support vector machine models or file export for popular toolkits such as Weka or HTK. Available low-level descriptors include popular speech, music and video features including Mel-frequency and similar cepstral and spectral coefficients, Chroma, CENS, auditory model based loudness, voice quality, local binary pattern, color, and optical flow histograms. Besides, voice activity detection, pitch tracking and face detection are supported. openSMILE is implemented in C++, using standard open source libraries for on-line audio and video input. It is fast, runs on Unix and Windows platforms, and has a modular, component based architecture which makes extensions via plug-ins easy. openSMILE 2.0 is distributed under a research license and can be downloaded from http://opensmile.sourceforge.net/.},
  isbn = {978-1-4503-2404-5},
  keywords = {acoustic features,affect recognition,affective computing,audio features,computational paralinguistics,feature extraction,machine learning,multimedia analysis,openSMILE,video features,visual features},
  file = {/Users/timokoch/Zotero/storage/LZFKTXVL/Eyben et al. - 2013 - Recent Developments in openSMILE, the Munich Open-.pdf}
}

@article{fabesGenderAgeStereotypes1991,
  title = {Gender and Age Stereotypes of Emotionality},
  author = {Fabes, Richard A. and Martin, Carol Lynn},
  year = {1991},
  journal = {Personality and social psychology bulletin},
  volume = {17},
  number = {5},
  pages = {532--540},
  issn = {0146-1672}
}

@article{fairbanksExperimentalStudyPitch1939,
  title = {An Experimental Study of the Pitch Characteristics of the Voice during the Expression of Emotions},
  author = {Fairbanks, G. and Pronovost, W.},
  year = {1939},
  journal = {Speech Monographs},
  volume = {6},
  pages = {87--104},
  publisher = {{Taylor \& Francis}},
  address = {{United Kingdom}},
  issn = {0038-7169},
  doi = {10.1080/03637753909374863},
  abstract = {The pitch characteristics of simulated emotions were investigated to determine their distinguishing characteristics. Six actors read for recording selections whose content facilitated the expression of anger, contempt, fear, grief, and indifference. All selections contained the same brief test section. Although not itself having a single inherent affective meaning, this recorded test section, when separated from the main selection, was accurately identified by high percentages of a group of 64 observers, averaging 84\% for contempt, 78\% for anger, 66\% for fear, 78\% for grief, and 88\% for indifference. The most accurately identified example for each emotion was analyzed. These five were all identified by 94\% or more of the subjects. Tables and graphs are presented to demonstrate that measurable pitch characteristics distinguish these expressions of emotion from each other. Variations in pitch level, inflections, shifts, and frequency of pitch changes are described. (PsycINFO Database Record (c) 2017 APA, all rights reserved)},
  file = {/Users/timokoch/Zotero/storage/S4CQE8EH/1940-02497-001.html}
}

@inproceedings{fanAutomaticEmotionVariation2014,
  title = {Automatic {{Emotion Variation Detection}} in Continuous Speech},
  booktitle = {Signal and {{Information Processing Association Annual Summit}} and {{Conference}} ({{APSIPA}}), 2014 {{Asia-Pacific}}},
  author = {Fan, Yuchao and Xu, Mingxing and Wu, Zhiyong and Cai, Lianhong},
  year = {2014},
  month = dec,
  pages = {1--5},
  publisher = {{IEEE}},
  address = {{Chiang Mai, Thailand}},
  doi = {10.1109/APSIPA.2014.7041592},
  urldate = {2019-06-13},
  abstract = {Though emotion speech recognition has gained increasing interest in the field of Human Computer Interaction, it is still a challenge to automatically determine the emotion state type and the boundaries of each emotionally salient segment in continuous speech, which is named as Automatic Emotion Variation Detection (AEVD). In this task, the input utterances are not pre-segmented and may contain emotion variations. This paper proposes a Multi-timescaled Sliding Window based AEVD (MSW-AEVD). Firstly, a sliding window with fixed-length is employed to segment continuous speech for classic emotion recognition. An emotion type is assigned to each window-shift according to the recognition results of all the sliding windows containing that window-shift. Then this basic procedure is extended to multitimescaled sliding window, in which several different features are utilized for different scales. Finally, a post-processing is employed to refine the final outputs. In this work, we focus on angerneutral and happiness-neutral cases, which are mostly dominant in recent studies of AEVD. Performance evaluation is carried out across two databases, including German database EMO-DB and Chinese database TH1309-DB. Experimental results show that the proposed method outperforms HMM-based baseline significantly.},
  isbn = {978-616-361-823-8},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/AKP4DR82/Fan et al. - 2014 - Automatic Emotion Variation Detection in continuou.pdf}
}

@article{fanHowWellCan2023,
  title = {How Well Can an {{AI}} Chatbot Infer Personality? {{Examining}} Psychometric Properties of Machine-Inferred Personality Scores},
  shorttitle = {How Well Can an {{AI}} Chatbot Infer Personality?},
  author = {Fan, Jinyan and Sun, Tianjun and Liu, Jiayi and Zhao, Teng and Zhang, Bo and Chen, Zheng and Glorioso, Melissa and Hack, Elissa},
  year = {2023},
  journal = {Journal of Applied Psychology},
  pages = {No Pagination Specified-No Pagination Specified},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1854},
  doi = {10.1037/apl0001082},
  abstract = {The present study explores the plausibility of measuring personality indirectly through an artificial intelligence (AI) chatbot. This chatbot mines various textual features from users' free text responses collected during an online conversation/interview and then uses machine learning algorithms to infer personality scores. We comprehensively examine the psychometric properties of the machine-inferred personality scores, including reliability (internal consistency, split-half, and test{\textendash}retest), factorial validity, convergent and discriminant validity, and criterion-related validity. Participants were undergraduate students (n = 1,444) enrolled in a large southeastern public university in the United States who completed a self-report Big Five personality measure (IPIP-300) and engaged with an AI chatbot for approximately 20{\textendash}30 min. In a subsample (n = 407), we obtained participants' cumulative grade point averages from the University Registrar and had their peers rate their college adjustment. In an additional sample (n = 61), we obtained test{\textendash}retest data. Results indicated that machine-inferred personality scores (a) had overall acceptable reliability at both the domain and facet levels, (b) yielded a comparable factor structure to self-reported questionnaire-derived personality scores, (c) displayed good convergent validity but relatively poor discriminant validity (averaged convergent correlations = .48 vs. averaged machine-score correlations = .35 in the test sample), (d) showed low criterion-related validity, and (e) exhibited incremental validity over self-reported questionnaire-derived personality scores in some analyses. In addition, there was strong evidence for cross-sample generalizability of psychometric properties of machine scores. Theoretical implications, future research directions, and practical considerations are discussed. (PsycInfo Database Record (c) 2023 APA, all rights reserved)},
  keywords = {Artificial Intelligence,Convergent Validity,Conversational Agents,Criterion Validity,Discriminant Validity,Factorial Validity,Internal Consistency,Machine Learning,Personality,Split-Half Reliability,Test Reliability,Test Scores,Test Validity,Test-Retest Reliability},
  file = {/Users/timokoch/Zotero/storage/E6ZJ3HMY/2023-43379-001.html}
}

@article{farnadiComputationalPersonalityRecognition2016,
  title = {Computational Personality Recognition in Social Media},
  author = {Farnadi, Golnoosh and Sitaraman, Geetha and Sushmita, Shanu and Celli, Fabio and Kosinski, Michal and Stillwell, David and Davalos, Sergio and Moens, Marie-Francine and De Cock, Martine},
  year = {2016},
  journal = {User Modeling and User-Adapted Interaction},
  volume = {26},
  number = {2-3},
  pages = {109--142},
  issn = {0924-1868 1573-1391},
  doi = {10.1007/s11257-016-9171-0}
}

@article{faurholt-jepsenVoiceAnalysisObjective2016,
  title = {Voice Analysis as an Objective State Marker in Bipolar Disorder},
  author = {{Faurholt-Jepsen}, M. and Busk, J. and Frost, M. and Vinberg, M. and Christensen, E. M. and Winther, O. and Bardram, J. E. and Kessing, L. V.},
  year = {2016},
  month = jul,
  journal = {Translational Psychiatry},
  volume = {6},
  number = {7},
  pages = {e856-e856},
  publisher = {{Nature Publishing Group}},
  issn = {2158-3188},
  doi = {10.1038/tp.2016.123},
  urldate = {2022-11-15},
  abstract = {Changes in speech have been suggested as sensitive and valid measures of depression and mania in bipolar disorder. The present study aimed at investigating (1) voice features collected during phone calls as objective markers of affective states in bipolar disorder and (2) if combining voice features with automatically generated objective smartphone data on behavioral activities (for example, number of text messages and phone calls per day) and electronic self-monitored data (mood) on illness activity would increase the accuracy as a marker of affective states. Using smartphones, voice features, automatically generated objective smartphone data on behavioral activities and electronic self-monitored data were collected from 28 outpatients with bipolar disorder in naturalistic settings on a daily basis during a period of 12 weeks. Depressive and manic symptoms were assessed using the Hamilton Depression Rating Scale 17-item and the Young Mania Rating Scale, respectively, by a researcher blinded to smartphone data. Data were analyzed using random forest algorithms. Affective states were classified using voice features extracted during everyday life phone calls. Voice features were found to be more accurate, sensitive and specific in the classification of manic or mixed states with an area under the curve (AUC)=0.89 compared with an AUC=0.78 for the classification of depressive states. Combining voice features with automatically generated objective smartphone data on behavioral activities and electronic self-monitored data increased the accuracy, sensitivity and specificity of classification of affective states slightly. Voice features collected in naturalistic settings using smartphones may be used as objective state markers in patients with bipolar disorder.},
  copyright = {2016 The Author(s)},
  langid = {english},
  keywords = {Bipolar disorder,Predictive markers},
  file = {/Users/timokoch/Zotero/storage/NTRNU33J/Faurholt-Jepsen et al. - 2016 - Voice analysis as an objective state marker in bip.pdf}
}

@article{feinererTextMiningInfrastructure2008,
  title = {Text {{Mining Infrastructure}} in {{R}}},
  author = {Feinerer, Ingo and Hornik, Kurt and Meyer, David},
  year = {2008},
  journal = {Journal of Statistical Software},
  volume = {25},
  number = {5},
  issn = {1548-7660},
  doi = {10.18637/jss.v025.i05},
  urldate = {2021-04-20},
  abstract = {During the last decade text mining has become a widely used discipline utilizing statistical and machine learning methods. We present the tm package which provides a framework for text mining applications within R. We give a survey on text mining facilities in R and explain how typical application tasks can be carried out using our framework. We present techniques for count-based analysis methods, text clustering, text classification and string kernels.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/VN7QNTK9/Feinerer et al. - 2008 - Text Mining Infrastructure in R.pdf}
}

@book{fernandezgallardoHumanAutomaticSpeaker2016,
  title = {Human and {{Automatic Speaker Recognition}} over {{Telecommunication Channels}}},
  author = {Fern{\'a}ndez Gallardo, Laura},
  year = {2016},
  series = {T-{{Labs Series}} in {{Telecommunication Services}}},
  publisher = {{Springer Singapore}},
  address = {{Singapore}},
  doi = {10.1007/978-981-287-727-7},
  urldate = {2019-07-05},
  isbn = {978-981-287-726-0 978-981-287-727-7},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/XHAFNM2H/Fernández Gallardo - 2016 - Human and Automatic Speaker Recognition over Telec.pdf}
}

@article{fernandezSMOTELearningImbalanced2018,
  title = {{{SMOTE}} for {{Learning}} from {{Imbalanced Data}}: {{Progress}} and {{Challenges}}, {{Marking}} the 15-Year {{Anniversary}}},
  shorttitle = {{{SMOTE}} for {{Learning}} from {{Imbalanced Data}}},
  author = {Fernandez, Alberto and Garcia, Salvador and Herrera, Francisco and Chawla, Nitesh V.},
  year = {2018},
  month = apr,
  journal = {Journal of Artificial Intelligence Research},
  volume = {61},
  pages = {863--905},
  issn = {1076-9757},
  doi = {10.1613/jair.1.11192},
  urldate = {2020-09-06},
  abstract = {The Synthetic Minority Oversampling Technique (SMOTE) preprocessing algorithm is considered ``de facto'' standard in the framework of learning from imbalanced data. This is due to its simplicity in the design of the procedure, as well as its robustness when applied to different type of problems. Since its publication in 2002, SMOTE has proven successful in a variety of applications from several different domains. SMOTE has also inspired several approaches to counter the issue of class imbalance, and has also significantly contributed to new supervised learning paradigms, including multilabel classification, incremental learning, semi-supervised learning, multi-instance learning, among others. It is standard benchmark for learning from imbalanced data. It is also featured in a number of different software packages {\textemdash} from open source to commercial. In this paper, marking the fifteen year anniversary of SMOTE, we reflect on the SMOTE journey, discuss the current state of affairs with SMOTE, its applications, and also identify the next set of challenges to extend SMOTE for Big Data problems.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/CWPIP9NU/Fernandez et al. - 2018 - SMOTE for Learning from Imbalanced Data Progress .pdf}
}

@article{ferreiraAWAREMobileContext2015,
  title = {{{AWARE}}: {{Mobile Context Instrumentation Framework}}},
  shorttitle = {{{AWARE}}},
  author = {Ferreira, Denzil and Kostakos, Vassilis and Dey, Anind K.},
  year = {2015},
  journal = {Frontiers in ICT},
  volume = {2},
  pages = {6},
  issn = {2297-198X},
  doi = {10.3389/fict.2015.00006},
  urldate = {2021-12-08},
  abstract = {We present a mobile instrumentation toolkit, AWARE, an open-source effort to develop an extensible and reusable platform for capturing, inferring, and generating context on mobile devices. Mobile phones are sensor-rich but resource-constrained, and therefore several considerations need to be addressed when creating a research tool that ensures problem-free context collection. We demonstrate how AWARE can mitigate researchers' effort when building mobile data-logging tools and context-aware applications, with minimal battery impact. By encapsulating implementation details of sensor data retrieval and exposing the sensed context as higher-level abstractions, AWARE shifts the focus from software development to data analysis, both quantitative and qualitative. We have evaluated AWARE in several case studies and discuss its use, power consumption, and scalability.},
  file = {/Users/timokoch/Zotero/storage/N7H95DAM/Ferreira et al. - 2015 - AWARE Mobile Context Instrumentation Framework.pdf}
}

@article{fesslerNegativelyBiasedCredulityCultural2014,
  title = {Negatively-{{Biased Credulity}} and the {{Cultural Evolution}} of {{Beliefs}}},
  author = {Fessler, Daniel M. T. and Pisor, Anne C. and Navarrete, Carlos David},
  editor = {Mesoudi, Alex},
  year = {2014},
  month = apr,
  journal = {PLoS ONE},
  volume = {9},
  number = {4},
  pages = {e95167},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0095167},
  urldate = {2019-05-23},
  abstract = {The functions of cultural beliefs are often opaque to those who hold them. Accordingly, to benefit from cultural evolution's ability to solve complex adaptive problems, learners must be credulous. However, credulity entails costs, including susceptibility to exploitation, and effort wasted due to false beliefs. One determinant of the optimal level of credulity is the ratio between the costs of two types of errors: erroneous incredulity (failing to believe information that is true) and erroneous credulity (believing information that is false). This ratio can be expected to be asymmetric when information concerns hazards, as the costs of erroneous incredulity will, on average, exceed the costs of erroneous credulity; no equivalent asymmetry characterizes information concerning benefits. Natural selection can therefore be expected to have crafted learners' minds so as to be more credulous toward information concerning hazards. This negatively-biased credulity extends general negativity bias, the adaptive tendency for negative events to be more salient than positive events. Together, these biases constitute attractors that should shape cultural evolution via the aggregated effects of learners' differential retention and transmission of information. In two studies in the U.S., we demonstrate the existence of negatively-biased credulity, and show that it is most pronounced in those who believe the world to be dangerous, individuals who may constitute important nodes in cultural transmission networks. We then document the predicted imbalance in cultural content using a sample of urban legends collected from the Internet and a sample of supernatural beliefs obtained from ethnographies of a representative collection of the world's cultures, showing that beliefs about hazards predominate in both.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/7LBSMDKY/Fessler et al. - 2014 - Negatively-Biased Credulity and the Cultural Evolu.PDF}
}

@article{fischerEmojiAffectiveSymbols2021,
  title = {Emoji as {{Affective Symbols}}: {{Affective Judgments}} of {{Emoji}}, {{Emoticons}}, and {{Human Faces Varying}} in {{Emotional Content}}},
  shorttitle = {Emoji as {{Affective Symbols}}},
  author = {Fischer, Brigitte and Herbert, Cornelia},
  year = {2021},
  journal = {Frontiers in Psychology},
  volume = {12},
  issn = {1664-1078},
  urldate = {2023-02-07},
  abstract = {An important function of emoji as communicative symbols is to convey emotional content from sender to receiver in computer-mediated communication, e. g., WhatsApp. However, compared with real faces, pictures or words, many emoji are ambiguous because they do not symbolize a discrete emotion or feeling state. Thus, their meaning relies on the context of the message in which they are embedded. Previous studies investigated affective judgments of pictures, faces, and words suggesting that these stimuli show a typical distribution along the big two emotion dimensions of valence and arousal. Also, emoji and emoticons have been investigated recently for their affective significance. The present study extends previous research by investigating affective ratings of emoji, emoticons and human faces and by direct comparison between them. In total, 60 stimuli have been rated by 83 participants (eight males, age: 18{\textendash}49 years), using the non-verbal Self-Assessment Manikin Scales for valence and arousal. The emotionality of the stimuli was measured on a 9-point Likert scale. The results show significant main effects of the factors ``stimulus category'' and ``discrete emotion'' including emotionality, valence and arousal. Also, the interaction between these two main factors was significant. Emoji elicited highest arousal, whereas stimuli related to happiness were rated highest in valence across stimulus categories. Angry emoji were rated highest in emotionality. Also, the discrete emotion was best recognized in emoji, followed by human face stimuli and lastly emoticons.},
  file = {/Users/timokoch/Zotero/storage/9LZ7C57X/Fischer und Herbert - 2021 - Emoji as Affective Symbols Affective Judgments of.pdf}
}

@article{fisherExploringIdiographicDynamics2017,
  title = {Exploring the Idiographic Dynamics of Mood and Anxiety via Network Analysis},
  author = {Fisher, Aaron J. and Reeves, Jonathan W. and Lawyer, Glenn and Medaglia, John D. and Rubel, Julian A.},
  year = {2017},
  journal = {Journal of Abnormal Psychology},
  volume = {126},
  pages = {1044--1056},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1846},
  doi = {10.1037/abn0000311},
  abstract = {Individual variation is increasingly recognized as important to psychopathology research. Concurrently, new methods of analysis based on network models are bringing new perspectives on mental (dys)function. This current work analyzed idiographic multivariate time series data using a novel network methodology that incorporates contemporaneous and lagged associations in mood and anxiety symptomatology. Data were taken from 40 individuals with generalized anxiety disorder (GAD), major depressive disorder (MDD), or comorbid GAD and MDD, who answered questions about 21 descriptors of mood and anxiety symptomatology 4 times a day over a period of approximately 30 days. The model provided an excellent fit to the intraindividual symptom dynamics of all 40 individuals. The most central symptoms in contemporaneous systems were those related to positive and negative mood. The temporal networks highlighted the importance of anger to symptomatology, while also finding that depressed mood and worry{\textemdash}the principal diagnostic criteria for GAD and MDD{\textemdash}were the least influential nodes across the sample. The method's potential for analysis of individual symptom patterns is demonstrated by 3 exemplar participants. Idiographic network-based analysis may fundamentally alter the way psychopathology is assessed, classified, and treated, allowing researchers and clinicians to better understand individual symptom dynamics. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  keywords = {Anxiety,Comorbidity,Emotional States,Models,Psychological Assessment,Psychopathology,Symptoms},
  file = {/Users/timokoch/Zotero/storage/2H9TJCLL/Fisher et al. - 2017 - Exploring the idiographic dynamics of mood and anx.pdf;/Users/timokoch/Zotero/storage/QLBZPXSV/doiLanding.html}
}

@article{flynnNatureOriginsMisperceptions2017,
  title = {The {{Nature}} and {{Origins}} of {{Misperceptions}}: {{Understanding False}} and {{Unsupported Beliefs About Politics}}: {{Nature}} and {{Origins}} of {{Misperceptions}}},
  shorttitle = {The {{Nature}} and {{Origins}} of {{Misperceptions}}},
  author = {Flynn, D.J. and Nyhan, Brendan and Reifler, Jason},
  year = {2017},
  month = feb,
  journal = {Political Psychology},
  volume = {38},
  pages = {127--150},
  issn = {0162895X},
  doi = {10.1111/pops.12394},
  urldate = {2019-05-23},
  abstract = {Political misperceptions can distort public debate and undermine people's ability to form meaningful opinions. Why do people often hold these false or unsupported beliefs and why is it sometimes so di cult to convince them otherwise? We argue that political misperceptions are typically rooted in directionally motivated reasoning, which limits the e{$\carriagereturn$}ectiveness of corrective information about controversial issues and political figures. We discuss factors known to a{$\carriagereturn$}ect the prevalence of directionally motivated reasoning and assess strategies for accurately measuring misperceptions in surveys. Finally, we address the normative implications of misperceptions for democracy and suggest important topics for future research.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/TBVA45TB/Flynn et al. - 2017 - The Nature and Origins of Misperceptions Understa.pdf}
}

@article{fragaleEvolvingInformationalCredentials2004,
  title = {Evolving {{Informational Credentials}}: {{The}} ({{Mis}}){{Attribution}} of {{Believable Facts}} to {{Credible Sources}}},
  shorttitle = {Evolving {{Informational Credentials}}},
  author = {Fragale, Alison R. and Heath, Chip},
  year = {2004},
  month = feb,
  journal = {Personality and Social Psychology Bulletin},
  volume = {30},
  number = {2},
  pages = {225--236},
  issn = {0146-1672, 1552-7433},
  doi = {10.1177/0146167203259933},
  urldate = {2019-05-23},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/8HXCA7MJ/Fragale und Heath - 2004 - Evolving Informational Credentials The (Mis)Attri.pdf}
}

@article{franceAcousticalPropertiesSpeech2000,
  title = {Acoustical Properties of Speech as Indicators of Depression and Suicidal Risk},
  author = {France, Daniel Joseph and Shiavi, Richard G. and Silverman, Stephen and Silverman, Marilyn and Wilkes, M.},
  year = {2000},
  journal = {IEEE transactions on Biomedical Engineering},
  volume = {47},
  number = {7},
  pages = {829--837}
}

@article{freudPsychopathologyEverydayLife1901,
  title = {The Psychopathology of Everyday Life. {{The Standard Edition}} of the Complete Psychological Works of {{Sigmund Freud}}},
  author = {Freud, Sigmund and Strachey, James},
  year = {1901},
  journal = {Trans. James Strachey},
  volume = {24},
  pages = {1953--74}
}

@article{freudPsychopathologyEverydayLife1914,
  title = {Psychopathology of Everyday Life ({{AA Brill}}, {{Trans}}.)},
  author = {Freud, Sigmund},
  year = {1914},
  journal = {New York: Macmillan. doi},
  volume = {10},
  pages = {10012--000}
}

@article{freudPsychopathologyEverydayLife1938,
  title = {Psychopathology of Everyday Life},
  author = {Freud, Sigmund},
  year = {1938}
}

@misc{freudPsychopathologyEverydayLife1938a,
  title = {Psychopathology of {{Everyday Life}} (1914). {{AA Brill}}, Trs},
  author = {Freud, Sigmund},
  year = {1938},
  publisher = {{Harmondsworth: Penguin}}
}

@book{freyPsychologieRitualeUnd2018,
  title = {{Psychologie der Rituale und Br{\"a}uche: 30 Riten und Gebr{\"a}uche wissenschaftlich analysiert und erkl{\"a}rt}},
  shorttitle = {{Psychologie der Rituale und Br{\"a}uche}},
  author = {Frey, Dieter},
  year = {2018},
  month = apr,
  publisher = {{Springer-Verlag}},
  abstract = {Dieses Buch betrachtet bekannte Rituale, Sitten und Br{\"a}uche des menschlichen Lebens aus psychologischer Perspektive: Welche neuen Erkenntnisse bietet die moderne Wissenschaft zu den teils uralten Ritualen unseres individuellen oder gesellschaftlichen Lebens, die uns Menschen bis heute beeinflussen? {\textendash} Dazu stellen die Autoren den historischen Hintergr{\"u}nden neue, psychologische Erkl{\"a}rungen gegen{\"u}ber und erweitern so unser Wissen dar{\"u}ber, warum es gewisse Br{\"a}uche gibt, welche Funktion sie f{\"u}r unser (Zusammen-)Leben erf{\"u}llen und warum sich manche Rituale nach wie vor erhalten haben oder im Laufe der Zeit aufgegeben oder modifiziert wurden. Dar{\"u}ber hinaus bietet das Buch erstaunliche Erkenntnisse {\"u}ber das Urteilen, Denken und Verhalten von Menschen und gibt ganz konkrete Tipps f{\"u}r unser Handeln {\textendash} z.B. in der Erziehung in Kinderg{\"a}rten und Schulen, F{\"u}hrung in Unternehmen und der Politik oder unserem allt{\"a}glichen Leben.},
  googlebooks = {r5JUDwAAQBAJ},
  isbn = {978-3-662-56219-2},
  langid = {ngerman},
  keywords = {Psychology / General,Psychology / Personality,Psychology / Reference,Self-Help / Personal Growth / General}
}

@article{frickCommunicatingEmotionRole,
  title = {Communicating {{Emotion}}: {{The Role}} of {{Prosodic Features}}},
  author = {Frick, Robert W},
  pages = {18},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/GNCFGNN2/Frick - Communicating Emotion The Role of Prosodic Featur.pdf}
}

@article{friedmanGreedyFunctionApproximation2001,
  title = {Greedy Function Approximation: A Gradient Boosting Machine},
  author = {Friedman, Jerome},
  year = {2001},
  journal = {Annals of statistics},
  pages = {1189--1232},
  issn = {0090-5364}
}

@article{friedmanRegularizationPathsGeneralized2010,
  title = {Regularization Paths for Generalized Linear Models via Coordinate Descent},
  author = {Friedman, Jerome and Hastie, Trevor and Tibshirani, Rob},
  year = {2010},
  journal = {Journal of statistical software},
  volume = {33},
  number = {1},
  pages = {1}
}

@misc{FrontiersMoodDetection,
  title = {Frontiers | {{Mood Detection}} in {{Ambiguous Messages}}: {{The Interaction Between Text}} and {{Emoticons}}},
  urldate = {2023-02-07},
  howpublished = {https://www.frontiersin.org/articles/10.3389/fpsyg.2018.00423/full}
}

@article{fruhholzOxfordHandbookVoice2019,
  title = {The {{Oxford}} Handbook of Voice Perception},
  author = {Fr{\"u}hholz, Sascha and Belin, Pascal},
  year = {2019},
  month = jan
}

@article{fullwoodEmoticonConvergenceInternet2013,
  title = {Emoticon Convergence in {{Internet}} Chat Rooms},
  author = {Fullwood, Chris and Orchard, Lisa J. and Floyd, Sarah A.},
  year = {2013},
  month = nov,
  journal = {Social Semiotics},
  volume = {23},
  number = {5},
  pages = {648--662},
  issn = {1035-0330},
  doi = {10.1080/10350330.2012.739000},
  urldate = {2019-07-29},
  abstract = {The present study examines sex and age differences in the use of emoticons (graphic representations of facial expressions) in Internet chat rooms. Data were collected from four Noesis chat rooms (``18+'', ``30-something'', ``40-something'' and ``50+''). Although women were more likely than men to use emoticons, there was no difference between the sexes in the range of emoticons used. The fact that men expressed a similar range of emoticons to women implies a general convergence towards female expression in mixed-sex communication contexts. Chat room users without a profile picture were also more likely to use winking emoticons. This may be because these types of emoticons are more flirtatious in intent, and it is easier for chatters to engage in risky communications when they are less identifiable. Furthermore, age had little bearing on the uptake of emoticons as well as the types of emoticons expressed. We draw upon Communication Accommodation Theory to help explain why emotional expression may converge in the chat room context.},
  keywords = {age differences,chat rooms,convergence,emoticons,sex differences},
  file = {/Users/timokoch/Zotero/storage/FJ893QG5/Fullwood et al. - 2013 - Emoticon convergence in Internet chat rooms.pdf;/Users/timokoch/Zotero/storage/Z7EBQY5S/10350330.2012.html}
}

@inproceedings{gaoInvestigatingReliabilitySelfreport2021,
  title = {Investigating the {{Reliability}} of {{Self-report Data}} in the {{Wild}}: {{The Quest}} for {{Ground Truth}}},
  shorttitle = {Investigating the {{Reliability}} of {{Self-report Data}} in the {{Wild}}},
  booktitle = {Adjunct {{Proceedings}} of the 2021 {{ACM International Joint Conference}} on {{Pervasive}} and {{Ubiquitous Computing}} and {{Proceedings}} of the 2021 {{ACM International Symposium}} on {{Wearable Computers}}},
  author = {Gao, Nan and Saiedur Rahaman, Mohammad and Shao, Wei and Salim, Flora D},
  year = {2021},
  month = sep,
  series = {{{UbiComp}} '21},
  pages = {237--242},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3460418.3479338},
  urldate = {2022-12-16},
  abstract = {Inferring human mental state (e.g., emotion, depression, engagement) with sensing technology is one of the most valuable challenges in the affective computing area, which has a profound impact in all industries interacting with humans. Self-report is the most common way to quantify how people think, but prone to subjectivity and various responses bias. It is usually used as the ground truth for human mental state prediction. In recent years, many data-driven machine learning models are built based on self-report annotations as the target value. In this research, we investigate the reliability of self-report data in the wild by studying the confidence level of responses and survey completion time. We conduct a case study (i.e., student engagement inference) by recruiting 23 students in a high school setting over a period of 4 weeks. Overall, our participants volunteered 488 self-reported responses and sensing data from smart wristbands. We find that the physiologically measured student engagement and perceived student engagement are not always consistent. The findings from this research have great potential to benefit future studies in predicting engagement, depression, stress, and other emotion-related states in the field of affective computing and sensing technologies.},
  isbn = {978-1-4503-8461-2},
  keywords = {Ecological Momentary Assessment,Emotion Prediction,Field Study,Ground Truth,Physiological Signals,Reliability,Self-report Measures},
  file = {/Users/timokoch/Zotero/storage/I9L9IM4C/Gao et al. - 2021 - Investigating the Reliability of Self-report Data .pdf;/Users/timokoch/Zotero/storage/QMVG5NZV/Gao et al. - 2021 - Investigating the Reliability of Self-report Data .pdf}
}

@book{gaoInvestigatingReliabilitySelfreport2021a,
  title = {Investigating the {{Reliability}} of {{Self-report Data}} in the {{Wild}}: {{The Quest}} for {{Ground Truth}}},
  shorttitle = {Investigating the {{Reliability}} of {{Self-report Data}} in the {{Wild}}},
  author = {Gao, Nan and Rahaman, Mohammad and Shao, Wei and Salim, Flora},
  year = {2021},
  month = sep,
  pages = {242},
  doi = {10.1145/3460418.3479338},
  file = {/Users/timokoch/Zotero/storage/KI2GNC6Q/Gao et al. - 2021 - Investigating the Reliability of Self-report Data .pdf}
}

@misc{gaoInvestigatingReliabilitySelfreport2021b,
  title = {Investigating the {{Reliability}} of {{Self-report Data}} in the {{Wild}}: {{The Quest}} for {{Ground Truth}}},
  shorttitle = {Investigating the {{Reliability}} of {{Self-report Data}} in the {{Wild}}},
  author = {Gao, Nan and Rahaman, Mohammad Saiedur and Shao, Wei and Salim, Flora D.},
  year = {2021},
  month = nov,
  number = {arXiv:2107.00389},
  eprint = {2107.00389},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2022-11-08},
  abstract = {Inferring human mental state (e.g., emotion, depression, engagement) with sensing technology is one of the most valuable challenges in the affective computing area, which has a profound impact in all industries interacting with humans. The self-report survey is the most common way to quantify how people think, but prone to subjectivity and various responses bias. It is usually used as the ground truth for human mental state prediction. In recent years, many data-driven machine learning models are built based on self-report annotations as the target value. In this research, we investigate the reliability of self-report surveys in the wild by studying the confidence level of responses and survey completion time. We conduct a case study (i.e., student engagement inference) by recruiting 23 students in a high school setting over a period of 4 weeks. Our participants volunteered 488 self-reported responses and data from their wearable sensors. We also find the physiologically measured student engagement and perceived student engagement are not always consistent. The findings from this research have great potential to benefit future studies in predicting engagement, depression, stress, and other emotion-related states in the field of affective computing and sensing technologies.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Human-Computer Interaction},
  file = {/Users/timokoch/Zotero/storage/GX5KNZCI/2107.html}
}

@article{garciaSocialMediaEmotion2021,
  title = {Social Media Emotion Macroscopes Reflect Emotional Experiences in Society at Large},
  author = {Garcia, David and Pellert, Max and Lasser, Jana and Metzler, Hannah},
  year = {2021},
  month = jul,
  journal = {arXiv:2107.13236 [cs]},
  eprint = {2107.13236},
  primaryclass = {cs},
  urldate = {2021-10-14},
  abstract = {Social media generate data on human behaviour at large scales and over long periods of time, posing a complementary approach to traditional methods in the social sciences. Millions of texts from social media can be processed with computational methods to study emotions over time and across regions. However, recent research has shown weak correlations between social media emotions and affect questionnaires at the individual level and between static regional aggregates of social media emotion and subjective well-being at the population level, questioning the validity of social media data to study emotions. Yet, to date, no research has tested the validity of social media emotion macroscopes to track the temporal evolution of emotions at the level of a whole society. Here we present a pre-registered prediction study that shows how gender-rescaled time series of Twitter emotional expression at the national level substantially correlate with aggregates of self-reported emotions in a weekly representative survey in the United Kingdom. A follow-up exploratory analysis shows a high prevalence of third-person references in emotionally-charged tweets, indicating that social media data provide a way of social sensing the emotions of others rather than just the emotional experiences of users. These results show that, despite the issues that social media have in terms of representativeness and algorithmic confounding, the combination of advanced text analysis methods with user demographic information in social media emotion macroscopes can provide measures that are informative of the general population beyond social media users.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computers and Society,Computer Science - Social and Information Networks},
  file = {/Users/timokoch/Zotero/storage/ZD7VU8XK/Garcia et al. - 2021 - Social media emotion macroscopes reflect emotional.pdf;/Users/timokoch/Zotero/storage/42X8GSCF/2107.html}
}

@article{gehrigTTISIStyle,
  title = {{{TTI SI Style InsightsR}} v {{Big}} 5 {{Personality Inventory}}: {{University Students Validation Study}}},
  author = {Gehrig, Eric and Bonnstetter, Ron},
  pages = {5},
  abstract = {Establishing concurrent or construct validity is a process, not an individual study. One way to establish different forms of validity it so run comparison studies against known, established psychometric assessments. In this study, the TTI Success Insights Style Insights R behavior assessment is compare with the Big Five Personality Inventory on a population of US university students. There are some differences noted in the levels of correlations between certain scales and a similar study conducted earlier on a different population. These differences are not of a magnitude that diminishes the argument of evidence of validity based on comparison with a well-known psychometric assessment.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/NQZA534Z/Gehrig und Bonnstetter - TTI SI Style InsightsR v Big 5 Personality Invento.pdf}
}

@article{geldhofReliabilityEstimationMultilevel2014,
  title = {Reliability Estimation in a Multilevel Confirmatory Factor Analysis Framework.},
  author = {Geldhof, G. John and Preacher, Kristopher J. and Zyphur, Michael J.},
  year = {2014},
  month = mar,
  journal = {Psychological Methods},
  volume = {19},
  number = {1},
  pages = {72--91},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/a0032138},
  urldate = {2021-11-26},
  abstract = {Scales with varying degrees of measurement reliability are often used in the context of multistage sampling, where variance exists at multiple levels of analysis (e.g., individual and group). Because methodological guidance on assessing and reporting reliability at multiple levels of analysis is currently lacking, we discuss the importance of examining level-specific reliability. We present a simulation study and an applied example showing different methods for estimating multilevel reliability using multilevel confirmatory factor analysis and provide supporting Mplus program code. We conclude that (a) single-level estimates will not reflect a scale's actual reliability unless reliability is identical at each level of analysis, (b) 2-level alpha and composite reliability (omega) perform relatively well in most settings, (c) estimates of maximal reliability (H) were more biased when estimated using multilevel data than either alpha or omega, and (d) small cluster size can lead to overestimates of reliability at the between level of analysis. We also show that Monte Carlo confidence intervals and Bayesian credible intervals closely reflect the sampling distribution of reliability estimates under most conditions. We discuss the estimation of credible intervals using Mplus and provide R code for computing Monte Carlo confidence intervals.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/E952A23H/Geldhof et al. - 2014 - Reliability estimation in a multilevel confirmator.pdf}
}

@article{gendronEmotionPerceptionHadza2020,
  title = {Emotion {{Perception}} in {{Hadza Hunter-Gatherers}}},
  author = {Gendron, Maria and Hoemann, Katie and Crittenden, Alyssa N. and Mangola, Shani Msafiri and Ruark, Gregory A. and Barrett, Lisa Feldman},
  year = {2020},
  month = mar,
  journal = {Scientific Reports},
  volume = {10},
  number = {1},
  pages = {3867},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  doi = {10.1038/s41598-020-60257-2},
  urldate = {2022-11-03},
  abstract = {It has long been claimed that certain configurations of facial movements are universally recognized as emotional expressions because they evolved to signal emotional information in situations that posed fitness challenges for our hunting and gathering hominin ancestors. Experiments from the last decade have called this particular evolutionary hypothesis into doubt by studying emotion perception in a wider sample of small-scale societies with discovery-based research methods. We replicate these newer findings in the Hadza of Northern Tanzania; the Hadza are semi-nomadic hunters and gatherers who live in tight-knit social units and collect wild foods for a large portion of their diet, making them a particularly relevant population for testing evolutionary hypotheses about emotion. Across two studies, we found little evidence of universal emotion perception. Rather, our findings are consistent with the hypothesis that people infer emotional meaning in facial movements using emotion knowledge embrained by cultural learning.},
  copyright = {2020 The Author(s)},
  langid = {english},
  keywords = {Evolution,Human behaviour},
  file = {/Users/timokoch/Zotero/storage/VDGV64UW/Gendron et al. - 2020 - Emotion Perception in Hadza Hunter-Gatherers.pdf;/Users/timokoch/Zotero/storage/YCHSFV2N/s41598-020-60257-2.html}
}

@article{geukesTraitPersonalityState2017,
  title = {Trait Personality and State Variability: {{Predicting}} Individual Differences in within- and Cross-Context Fluctuations in Affect, Self-Evaluations, and Behavior in Everyday Life},
  shorttitle = {Trait Personality and State Variability},
  author = {Geukes, Katharina and Nestler, Steffen and Hutteman, Roos and K{\"u}fner, Albrecht C. P. and Back, Mitja D.},
  year = {2017},
  month = aug,
  journal = {Journal of Research in Personality},
  series = {Within-{{Person Variability}} in {{Personality}}},
  volume = {69},
  pages = {124--138},
  issn = {0092-6566},
  doi = {10.1016/j.jrp.2016.06.003},
  urldate = {2019-02-11},
  abstract = {Prior research on the effects of personality on the variability of states has either not assessed states in real-life contexts or not incorporated meaningful contextual information when analyzing state variability. Providing an integrated contextualized approach, we introduce the Within and Across Context (WAC) Variability framework that disentangles real-life within-person fluctuations occurring within and across real-life contexts. To illustrate the utility of this framework, we investigated effects of Big Five personality traits on the level and the within- and cross-context variability of experience-sampled states (affect, self-esteem, behavior) of psychology freshmen (N=118). Results provide initial empirical support for the meaningful separation of within- and cross-context variability and their distinct relations to personality.},
  keywords = {Behavioral consistency,Cross-context variability,Cross-role variability,Self-esteem fragility,State fluctuations,Within-person variability},
  file = {/Users/timokoch/Zotero/storage/WYRLF2JA/Geukes et al. - 2017 - Trait personality and state variability Predictin.pdf;/Users/timokoch/Zotero/storage/VZXUHKQ3/S0092656616300514.html}
}

@article{ghoshEmotionDetectionTouch2019,
  title = {Emotion Detection from Touch Interactions during Text Entry on Smartphones},
  author = {Ghosh, Surjya and Hiware, Kaustubh and Ganguly, Niloy and Mitra, Bivas and De, Pradipta},
  year = {2019},
  month = oct,
  journal = {International Journal of Human-Computer Studies},
  volume = {130},
  pages = {47--57},
  issn = {10715819},
  doi = {10.1016/j.ijhcs.2019.04.005},
  urldate = {2022-07-15},
  abstract = {There are different modes of interaction with a software keyboard on a smartphone, such as typing and swyping. Patterns of such touch interactions on a keyboard may reflect emotions of a user. Since users may switch between different touch modalities while using a keyboard, therefore, automatic detection of emotion from touch patterns must consider both modalities in combination to detect the pattern. In this paper, we focus on identifying different features of touch interactions with a smartphone keyboard that lead to a personalized model for inferring user emotion. Since distinguishing typing and swyping activity is important to record the correct features, we designed a technique to correctly identify the modality. The ground truth labels for user emotion are collected directly from the user by periodically collecting self-reports. We jointly model typing and swyping features and correlate them with user provided self-reports to build a personalized machine learning model, which detects four emotion states (happy, sad, stressed, relaxed). We combine these design choices into an Android application TouchSense and evaluate the same in a 3-week in-the-wild study involving 22 participants. Our key evaluation results and post-study participant assessment demonstrate that it is possible to predict these emotion states with an average accuracy (AUCROC) of 73\% (std dev. 6\%, maximum 87\%) combining these two touch interactions only.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/3XW3LKBI/Ghosh et al. - 2019 - Emotion detection from touch interactions during t.pdf}
}

@inproceedings{ghoshEvaluatingEffectivenessSmartphone2017,
  title = {Evaluating Effectiveness of Smartphone Typing as an Indicator of User Emotion},
  booktitle = {2017 {{Seventh International Conference}} on {{Affective Computing}} and {{Intelligent Interaction}} ({{ACII}})},
  author = {Ghosh, Surjya and Ganguly, Niloy and Mitra, Bivas and De, Pradipta},
  year = {2017},
  month = oct,
  pages = {146--151},
  issn = {2156-8111},
  doi = {10.1109/ACII.2017.8273592},
  abstract = {In Affective Computing, different modalities, such as speech, facial expressions, physiological properties, smart-phone usage patterns, and their combinations, are applied to detect the affective states of a user. Keystroke analysis i.e. study of the typing behavior in desktop computer is found to be an effective modality for emotion detection because of its reliability, non-intrusiveness and low resource overhead. As smartphones proliferate, typing behavior on smartphone presents an equally powerful modality for emotion detection. It has the added advantage to run in-situ experiments with better coverage than the experiments using desktop computer keyboards. This work explores the efficacy of smartphone typing to detect multiple affective states. We use a qualitative and experimental approach to answer the question. We conduct an online survey among 120 participants to understand the typing habits in smartphones and collect feedback on multiple measurable parameters that affect their emotion while typing. The findings lead us to design and implement an Android based emotion detection system, TapSense, which can identify four different emotion states (happy, sad, stressed, relaxed) with an average accuracy (AUCROC) of 73\% (maximum of 94\%) based on typing features only. The analysis also reveals that among different features, typing speed is the most discriminative one.},
  keywords = {Affective computing,Feature extraction,Keyboards,Physiology,Probes,Reliability,Servers},
  file = {/Users/timokoch/Zotero/storage/BHMGPSFU/Ghosh et al. - 2017 - Evaluating effectiveness of smartphone typing as a.pdf;/Users/timokoch/Zotero/storage/GLCU29UY/8273592.html}
}

@article{gideonMOODSTATEPREDICTION2016,
  title = {{{MOOD STATE PREDICTION FROM SPEECH OF VARYING ACOUSTIC QUALITY FOR INDIVIDUALS WITH BIPOLAR DISORDER}}},
  author = {Gideon, John and Provost, Emily Mower and McInnis, Melvin},
  year = {2016},
  month = mar,
  journal = {Proceedings of the ... IEEE International Conference on Acoustics, Speech, and Signal Processing / sponsored by the Institute of Electrical and Electronics Engineers Signal Processing Society. ICASSP (Conference)},
  volume = {2016},
  pages = {2359--2363},
  issn = {1520-6149},
  doi = {10.1109/ICASSP.2016.7472099},
  urldate = {2019-02-08},
  abstract = {Speech contains patterns that can be altered by the mood of an individual. There is an increasing focus on automated and distributed methods to collect and monitor speech from large groups of patients suffering from mental health disorders. However, as the scope of these collections increases, the variability in the data also increases. This variability is due in part to the range in the quality of the devices, which in turn affects the quality of the recorded data, negatively impacting the accuracy of automatic assessment. It is necessary to mitigate variability effects in order to expand the impact of these technologies. This paper explores speech collected from phone recordings for analysis of mood in individuals with bipolar disorder. Two different phones with varying amounts of clipping, loudness, and noise are employed. We describe methodologies for use during preprocessing, feature extraction, and data modeling to correct these differences and make the devices more comparable. The results demonstrate that these pipeline modifications result in statistically significantly higher performance, which highlights the potential of distributed mental health systems.},
  pmcid = {PMC4995442},
  pmid = {27570493},
  file = {/Users/timokoch/Zotero/storage/RG4Q82FN/Gideon et al. - 2016 - MOOD STATE PREDICTION FROM SPEECH OF VARYING ACOUS.pdf}
}

@article{gil-lopezOneSizeFits2018,
  title = {One {{Size Fits All}}: {{Context Collapse}}, {{Self-Presentation Strategies}} and {{Language Styles}} on {{Facebook}}},
  shorttitle = {One {{Size Fits All}}},
  author = {{Gil-Lopez}, Teresa and Shen, Cuihua and Benefield, Grace A and Palomares, Nicholas A and Kosinski, Michal and Stillwell, David},
  year = {2018},
  month = may,
  journal = {Journal of Computer-Mediated Communication},
  volume = {23},
  number = {3},
  pages = {127--145},
  issn = {1083-6101},
  doi = {10.1093/jcmc/zmy006},
  urldate = {2018-11-05},
  abstract = {This study empirically examines context collapse on Facebook by examining audience influences on content and language in self-disclosures. Context collapse is the process of disparate audiences being conjoined into one. Using a public longitudinal behavioral data set of 6,378 Facebook users, the study found that the size and heterogeneity of people's networks were positively associated with the number of text status updates they posted, but negatively associated with language style variability of these updates during 12 months. Results suggest that people manage their online self-presentation in ways that are consistent with lowest common denominator, imagined audience, and accommodation propositions. Network size was positively associated with the proportion of positive emotional language and negatively with negative emotional language, whereas heterogeneity had the opposite effect.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/ZYSJDWHF/Gil-Lopez et al. - 2018 - One Size Fits All Context Collapse, Self-Presenta.pdf}
}

@article{gillLanguagePersonalityComputerMediated2006,
  title = {Language and {{Personality}} in {{Computer-Mediated Communication}}: {{A}} Cross-Genre Comparison},
  author = {Gill, Alastair J. and Nowson, Scott and Oberlander, Jon},
  year = {2006},
  journal = {Journal of Computer Mediated Communication, submitted}
}

@inproceedings{gilpinPerceptionSpeakerPersonality2018,
  title = {Perception of {{Speaker Personality Traits Using Speech Signals}}},
  booktitle = {Extended {{Abstracts}} of the 2018 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}  - {{CHI}} '18},
  author = {Gilpin, Leilani H. and Olson, Danielle M. and Alrashed, Tarfah},
  year = {2018},
  pages = {1--6},
  publisher = {{ACM Press}},
  address = {{Montreal QC, Canada}},
  doi = {10.1145/3170427.3188557},
  urldate = {2019-02-10},
  isbn = {978-1-4503-5621-3},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/V89AVSWH/Gilpin et al. - 2018 - Perception of Speaker Personality Traits Using Spe.pdf}
}

@article{giordanoRepresentationalDynamicsPerceived2021,
  title = {The Representational Dynamics of Perceived Voice Emotions Evolve from Categories to Dimensions},
  author = {Giordano, Bruno L. and Whiting, Caroline and Kriegeskorte, Nikolaus and Kotz, Sonja A. and Gross, Joachim and Belin, Pascal},
  year = {2021},
  month = sep,
  journal = {Nature Human Behaviour},
  volume = {5},
  number = {9},
  pages = {1203--1213},
  publisher = {{Nature Publishing Group}},
  issn = {2397-3374},
  doi = {10.1038/s41562-021-01073-0},
  urldate = {2021-11-23},
  abstract = {Long-standing affective science theories conceive the perception of emotional stimuli either as discrete categories (for example, an angry voice) or continuous dimensional attributes (for example, an intense and negative vocal emotion). Which position provides a better account is still widely debated. Here we contrast the positions to account for acoustics-independent perceptual and cerebral representational geometry of perceived voice emotions. We combined multimodal imaging of the cerebral response to heard vocal stimuli (using functional magnetic resonance imaging and magneto-encephalography) with post-scanning behavioural assessment of voice emotion perception. By using representational similarity analysis, we find that categories prevail in perceptual and early (less than 200\,ms) frontotemporal cerebral representational geometries and that dimensions impinge predominantly on a later limbic{\textendash}temporal network (at 240\,ms and after 500\,ms). These results reconcile the two opposing views by reframing the perception of emotions as the interplay of cerebral networks with different representational dynamics that emphasize either categories or dimensions.},
  copyright = {2021 The Author(s), under exclusive licence to Springer Nature Limited},
  langid = {english},
  keywords = {Human behaviour,Limbic system},
  annotation = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Human behaviour;Limbic system Subject\_term\_id: human-behaviour;limbic-system},
  file = {/Users/timokoch/Zotero/storage/ANKKUA8E/Giordano et al. - 2021 - The representational dynamics of perceived voice e.pdf;/Users/timokoch/Zotero/storage/KH9BXBUZ/s41562-021-01073-0.html}
}

@inproceedings{golbeckFakeNewsVs2018,
  title = {Fake {{News}} vs {{Satire}}: {{A Dataset}} and {{Analysis}}},
  shorttitle = {Fake {{News}} vs {{Satire}}},
  booktitle = {Proceedings of the 10th {{ACM Conference}} on {{Web Science}}  - {{WebSci}} '18},
  author = {Golbeck, Jennifer and Everett, Jennine B. and Falak, Waleed and Gieringer, Carl and Graney, Jack and Hoffman, Kelly M. and Huth, Lindsay and Ma, Zhenya and Jha, Mayanka and Khan, Misbah and Kori, Varsha and Mauriello, Matthew and Lewis, Elo and Mirano, George and Mohn IV, William T. and Mussenden, Sean and Nelson, Tammie M. and Mcwillie, Sean and Pant, Akshat and Shetye, Priya and Shrestha, Rusha and Steinheimer, Alexandra and Auxier, Brooke and Subramanian, Aditya and Visnansky, Gina and Bhanushali, Keval H. and Bonk, Christopher and Bouzaghrane, Mohamed Amine and Buntain, Cody and Chanduka, Riya and Cheakalos, Paul},
  year = {2018},
  pages = {17--21},
  publisher = {{ACM Press}},
  address = {{Amsterdam, Netherlands}},
  doi = {10.1145/3201064.3201100},
  urldate = {2019-05-29},
  abstract = {Fake news has become a major societal issue and a technical challenge for social media companies to identify. This content is difficult to identify because the term "fake news" covers intentionally false, deceptive stories as well as factual errors, satire, and sometimes, stories that a person just does not like. Addressing the problem requires clear definitions and examples. In this work, we present a dataset of fake news and satire stories that are hand coded, verified, and, in the case of fake news, include rebutting stories. We also include a thematic content analysis of the articles, identifying major themes that include hyperbolic support or condemnation of a figure, conspiracy theories, racist themes, and discrediting of reliable sources. In addition to releasing this dataset for research use, we analyze it and show results based on language that are promising for classification purposes. Overall, our contribution of a dataset and initial analysis are designed to support future work by fake news researchers.},
  isbn = {978-1-4503-5563-6},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/VV5LUQ3T/Golbeck et al. - 2018 - Fake News vs Satire A Dataset and Analysis.pdf}
}

@inproceedings{golbeckPredictingPersonalitySocial2011,
  title = {Predicting Personality with Social Media},
  booktitle = {{{CHI}}'11 Extended Abstracts on Human Factors in Computing Systems},
  author = {Golbeck, Jennifer and Robles, Cristina and Turner, Karen},
  year = {2011},
  pages = {253--262},
  publisher = {{ACM}},
  isbn = {1-4503-0268-8}
}

@article{golbeckPredictingPersonalitySocial2016,
  title = {Predicting Personality from Social Media Text},
  author = {Golbeck, Jennifer},
  year = {2016},
  journal = {AIS Transactions on Replication Research},
  volume = {2},
  number = {1},
  pages = {2},
  issn = {2473-3458}
}

@inproceedings{golbeckPredictingPersonalityTwitter2011,
  title = {Predicting Personality from Twitter},
  booktitle = {Privacy, {{Security}}, {{Risk}} and {{Trust}} ({{PASSAT}}) and 2011 {{IEEE Third Inernational Conference}} on {{Social Computing}} ({{SocialCom}}), 2011 {{IEEE Third International Conference}} On},
  author = {Golbeck, Jennifer and Robles, Cristina and Edmondson, Michon and Turner, Karen},
  year = {2011},
  pages = {149--156},
  publisher = {{IEEE}},
  isbn = {1-4577-1931-2}
}

@article{goldbergStructurePhenotypicPersonality1993,
  title = {The {{Structure}} of {{Phenotypic Personality Traits}}},
  author = {Goldberg, Lewis R},
  year = {1993},
  journal = {American Psychologist},
  pages = {9},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/TPTPCUDK/Goldberg - 1993 - The Structure of Phenotypic Personality Traits.pdf}
}

@article{golderDiurnalSeasonalMood2011,
  title = {Diurnal and {{Seasonal Mood Vary}} with {{Work}}, {{Sleep}}, and {{Daylength Across Diverse Cultures}}},
  author = {Golder, Scott A. and Macy, Michael W.},
  year = {2011},
  month = sep,
  journal = {Science},
  volume = {333},
  number = {6051},
  pages = {1878--1881},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1202775},
  urldate = {2022-05-09},
  abstract = {Across the world the collective mood heightens at breakfast time and during the weekend.           ,              We identified individual-level diurnal and seasonal mood rhythms in cultures across the globe, using data from millions of public Twitter messages. We found that individuals awaken in a good mood that deteriorates as the day progresses{\textemdash}which is consistent with the effects of sleep and circadian rhythm{\textemdash}and that seasonal change in baseline positive affect varies with change in daylength. People are happier on weekends, but the morning peak in positive affect is delayed by 2 hours, which suggests that people awaken later on weekends.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/82JHZ3WS/Golder und Macy - 2011 - Diurnal and Seasonal Mood Vary with Work, Sleep, a.pdf}
}

@article{gongEmotionAnalysisTelephone2015,
  title = {Emotion {{Analysis}} of {{Telephone Complaints}} from {{Customer Based}} on {{Affective Computing}}},
  author = {Gong, Shuangping and Dai, Yonghui and Ji, Jun and Wang, Jinzhao and Sun, Hai},
  year = {2015},
  journal = {Computational Intelligence and Neuroscience},
  volume = {2015},
  issn = {1687-5265},
  doi = {10.1155/2015/506905},
  urldate = {2019-02-12},
  abstract = {Customer complaint has been the important feedback for modern enterprises to improve their product and service quality as well as the customer's loyalty. As one of the commonly used manners in customer complaint, telephone communication carries rich emotional information of speeches, which provides valuable resources for perceiving the customer's satisfaction and studying the complaint handling skills. This paper studies the characteristics of telephone complaint speeches and proposes an analysis method based on affective computing technology, which can recognize the dynamic changes of customer emotions from the conversations between the service staff and the customer. The recognition process includes speaker recognition, emotional feature parameter extraction, and dynamic emotion recognition. Experimental results show that this method is effective and can reach high recognition rates of happy and angry states. It has been successfully applied to the operation quality and service administration in telecom and Internet service company.},
  pmcid = {PMC4655047},
  pmid = {26633967},
  file = {/Users/timokoch/Zotero/storage/R8BVJWHV/Gong et al. - 2015 - Emotion Analysis of Telephone Complaints from Cust.pdf}
}

@misc{goodePrivateMessagesAre2019,
  title = {Private {{Messages Are}} the {{New}} ({{Old}}) {{Social Network}} | {{WIRED}}},
  author = {Goode, Lauren},
  year = {2019},
  journal = {wired.com},
  urldate = {2020-09-10},
  howpublished = {https://www.wired.com/story/private-messages-new-social-networks/},
  file = {/Users/timokoch/Zotero/storage/PCFZKDMH/private-messages-new-social-networks.html}
}

@misc{goodinWhatsAppGivesUsers2021,
  title = {{{WhatsApp}} Gives Users an Ultimatum: {{Share}} Data with {{Facebook}} or Stop Using the App},
  author = {Goodin, Dan},
  year = {2021},
  urldate = {2021-04-28},
  howpublished = {https://arstechnica.com/tech-policy/2021/01/whatsapp-users-must-share-their-data-with-facebook-or-stop-using-the-app/},
  file = {/Users/timokoch/Zotero/storage/S38GGIXR/whatsapp-users-must-share-their-data-with-facebook-or-stop-using-the-app.html}
}

@article{goslingManifestationsPersonalityOnline2011,
  title = {Manifestations of Personality in {{Online Social Networks}}: Self-Reported {{Facebook-related}} Behaviors and Observable Profile Information},
  author = {Gosling, S. D. and Augustine, A. A. and Vazire, S. and Holtzman, N. and Gaddis, S.},
  year = {2011},
  month = sep,
  journal = {Cyberpsychol Behav Soc Netw},
  volume = {14},
  number = {9},
  pages = {483--8},
  issn = {2152-2723 (Electronic) 2152-2715 (Linking)},
  doi = {10.1089/cyber.2010.0087},
  abstract = {Despite the enormous popularity of Online Social Networking sites (OSNs; e.g., Facebook and Myspace), little research in psychology has been done on them. Two studies examining how personality is reflected in OSNs revealed several connections between the Big Five personality traits and self-reported Facebook-related behaviors and observable profile information. For example, extraversion predicted not only frequency of Facebook usage (Study 1), but also engagement in the site, with extraverts (vs. introverts) showing traces of higher levels of Facebook activity (Study 2). As in offline contexts, extraverts seek out virtual social engagement, which leaves behind a behavioral residue in the form of friends lists and picture postings. Results suggest that, rather than escaping from or compensating for their offline personality, OSN users appear to extend their offline personalities into the domains of OSNs.},
  pmcid = {PMC3180765},
  keywords = {*Personality,*Self Disclosure,*Social Media,*Social Networking,Adolescent,Female,Friends/psychology,Humans,Interpersonal Relations,Male,Social Behavior,Young Adult}
}

@misc{gotzeGermanStopwords2016,
  title = {German {{Stopwords}}},
  author = {G{\"o}tze, Marco and Geyer, Steffen},
  year = {2016}
}

@article{gotzUsersMainSmartphone2017,
  title = {Users of the Main Smartphone Operating Systems ({{iOS}}, {{Android}}) Differ Only Little in Personality},
  author = {G{\"o}tz, Friedrich M. and Stieger, Stefan and Reips, Ulf-Dietrich},
  year = {2017},
  month = mar,
  journal = {PLOS ONE},
  volume = {12},
  number = {5},
  pages = {e0176921},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0176921},
  urldate = {2023-02-21},
  abstract = {The increasingly widespread use of mobile phone applications (apps) as research tools and cost-effective means of vast data collection raises new methodological challenges. In recent years, it has become a common practice for scientists to design apps that run only on a single operating system, thereby excluding large numbers of users who use a different operating system. However, empirical evidence investigating any selection biases that might result thereof is scarce. Henceforth, we conducted two studies drawing from a large multi-national (Study 1; N = 1,081) and a German-speaking sample (Study 2; N = 2,438). As such Study 1 compared iOS and Android users across an array of key personality traits (i.e., well-being, self-esteem, willingness to take risks, optimism, pessimism, Dark Triad, and the Big Five). Focusing on Big Five personality traits in a broader scope, in addition to smartphone users, Study 2 also examined users of the main computer operating systems (i.e., Mac OS, Windows). In both studies, very few significant differences were found, all of which were of small or even tiny effect size mostly disappearing after sociodemographics had been controlled for. Taken together, minor differences in personality seem to exist, but they are of small to negligible effect size (ranging from OR = 0.919 to 1.344 (Study 1), {$\eta$}p2 = .005 to .036 (Study 2), respectively) and may reflect differences in sociodemographic composition, rather than operating system of smartphone users.},
  langid = {english},
  keywords = {Apps,Cell phones,Educational attainment,Operating systems,Personality,Personality traits,Psychology,Questionnaires},
  file = {/Users/timokoch/Zotero/storage/8C24KFU9/Götz et al. - 2017 - Users of the main smartphone operating systems (iO.pdf}
}

@incollection{goutteProbabilisticInterpretationPrecision2005,
  title = {A {{Probabilistic Interpretation}} of {{Precision}}, {{Recall}} and {{F-Score}}, with {{Implication}} for {{Evaluation}}},
  booktitle = {Advances in {{Information Retrieval}}},
  author = {Goutte, Cyril and Gaussier, Eric},
  editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and Losada, David E. and {Fern{\'a}ndez-Luna}, Juan M.},
  year = {2005},
  volume = {3408},
  pages = {345--359},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-540-31865-1_25},
  urldate = {2020-04-01},
  abstract = {We address the problems of 1/ assessing the confidence of the standard point estimates, precision, recall and F -score, and 2/ comparing the results, in terms of precision, recall and F -score, obtained using two different methods. To do so, we use a probabilistic setting which allows us to obtain posterior distributions on these performance indicators, rather than point estimates. This framework is applied to the case where different methods are run on different datasets from the same source, as well as the standard situation where competing results are obtained on the same data.},
  isbn = {978-3-540-25295-5 978-3-540-31865-1},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/UQQMEGKE/Goutte und Gaussier - 2005 - A Probabilistic Interpretation of Precision, Recal.pdf}
}

@article{greenwaldThereNothingTheoretical2012,
  title = {There {{Is Nothing So Theoretical}} as a {{Good Method}}},
  author = {Greenwald, Anthony G.},
  year = {2012},
  month = mar,
  journal = {Perspectives on Psychological Science},
  volume = {7},
  number = {2},
  pages = {99--108},
  publisher = {{SAGE Publications Inc}},
  issn = {1745-6916},
  doi = {10.1177/1745691611434210},
  urldate = {2022-11-28},
  abstract = {This article documents two facts that are provocative in juxtaposition. First: There is multidecade durability of theory controversies in psychology, demonstrated here in the subdisciplines of cognitive and social psychology. Second: There is a much greater frequency of Nobel science awards for contributions to method than for contributions to theory, shown here in an analysis of the last two decades of Nobel awards in physics, chemistry, and medicine. The available documentation of Nobel awards reveals two forms of method?theory synergy: (a) existing theories were often essential in enabling development of awarded methods, and (b) award-receiving methods often generated previously inconceivable data, which in turn inspired previously inconceivable theories. It is easy to find illustrations of these same synergies also in psychology. Perhaps greater recognition of the value of method in advancing theory can help to achieve resolutions of psychology?s persistent theory controversies.},
  langid = {english}
}

@inproceedings{grimmVeraAmMittag2008,
  title = {The {{Vera}} Am {{Mittag German}} Audio-Visual Emotional Speech Database},
  booktitle = {2008 {{IEEE International Conference}} on {{Multimedia}} and {{Expo}}},
  author = {Grimm, Michael and Kroschel, Kristian and Narayanan, Shrikanth},
  year = {2008},
  month = jun,
  pages = {865--868},
  issn = {1945-788X},
  doi = {10.1109/ICME.2008.4607572},
  abstract = {The lack of publicly available annotated databases is one of the major barriers to research advances on emotional information processing. In this contribution we present a recently collected database of spontaneous emotional speech in German which is being made available to the research community. The database consists of 12 hours of audio-visual recordings of the German TV talk show ldquoVera am Mittagrdquo, segmented into broadcasts, dialogue acts and utterances. This corpus contains spontaneous and very emotional speech recorded from unscripted, authentic discussions between the guests of the talk show. In addition to the audio-visual data and the segmented utterances we provide emotion labels for a great part of the data. The emotion labels are given on a continuous valued scale for three emotion primitives: valence, activation and dominance, using a large number of human evaluators. Such data is of great interest to all research groups working on spontaneous speech analysis, emotion recognition in both speech and facial expression, natural language understanding, and robust speech recognition.},
  keywords = {Data acquisition,Databases,Emotion recognition,Histograms,Speech,Speech analysis,Speech processing,Speech recognition,TV,Video signal processing},
  file = {/Users/timokoch/Zotero/storage/CE8SMSI9/4607572.html}
}

@article{grossDissociationEmotionExpression2000,
  title = {The {{Dissociation}} of {{Emotion Expression}} from {{Emotion Experience}}: {{A Personality Perspective}}},
  shorttitle = {The {{Dissociation}} of {{Emotion Expression}} from {{Emotion Experience}}},
  author = {Gross, James J. and John, Oliver P. and Richards, Jane M.},
  year = {2000},
  month = aug,
  journal = {Personality and Social Psychology Bulletin},
  volume = {26},
  number = {6},
  pages = {712--726},
  issn = {0146-1672, 1552-7433},
  doi = {10.1177/0146167200268006},
  urldate = {2021-11-23},
  abstract = {When we want to know what others are feeling, we look to the face for clues. However, individual differences matter: Some faces are more expressive than others. Do both emotion experience and dispositional expressivity predict emotion expression? Based on an analysis of display rules, the authors hypothesized that expressivity would moderate the relation between experience and expression for negative, but not for positive, emotion. Study 1 examined the relation between habitual emotion experience and peer-rated expressive behavior and showed the predicted moderator effect for negative emotion: Experience was related to expression only for dispositionally high-expressivity participants, not for low-expressivity participants. For positive emotion, however, experience was related to expression for both groups. Study 2 replicated these findings using momentary emotion experience and objectively coded expressive behavior during films that elicited amusement and sadness. Results are interpreted in terms of low-expressivity individuals' propensity to dynamically regulate negative emotion-expressive behavior.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/QKTWNC69/Gross et al. - 2000 - The Dissociation of Emotion Expression from Emotio.pdf}
}

@article{grossDissociationEmotionExpression2000a,
  title = {The {{Dissociation}} of {{Emotion Expression}} from {{Emotion Experience}}: {{A Personality Perspective}}},
  shorttitle = {The {{Dissociation}} of {{Emotion Expression}} from {{Emotion Experience}}},
  author = {Gross, James J. and John, Oliver P. and Richards, Jane M.},
  year = {2000},
  month = aug,
  journal = {Personality and Social Psychology Bulletin},
  volume = {26},
  number = {6},
  pages = {712--726},
  issn = {0146-1672, 1552-7433},
  doi = {10.1177/0146167200268006},
  urldate = {2021-11-23},
  abstract = {When we want to know what others are feeling, we look to the face for clues. However, individual differences matter: Some faces are more expressive than others. Do both emotion experience and dispositional expressivity predict emotion expression? Based on an analysis of display rules, the authors hypothesized that expressivity would moderate the relation between experience and expression for negative, but not for positive, emotion. Study 1 examined the relation between habitual emotion experience and peer-rated expressive behavior and showed the predicted moderator effect for negative emotion: Experience was related to expression only for dispositionally high-expressivity participants, not for low-expressivity participants. For positive emotion, however, experience was related to expression for both groups. Study 2 replicated these findings using momentary emotion experience and objectively coded expressive behavior during films that elicited amusement and sadness. Results are interpreted in terms of low-expressivity individuals' propensity to dynamically regulate negative emotion-expressive behavior.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/GIHB8QJW/Gross et al. - 2000 - The Dissociation of Emotion Expression from Emotio.pdf}
}

@article{grossRevealingFeelingsFacets1997,
  title = {Revealing Feelings: {{Facets}} of Emotional Expressivity in Self-Reports, Peer Ratings, and Expressive Behavior},
  shorttitle = {Revealing Feelings},
  author = {Gross, James J. and John, Oliver P.},
  year = {1997},
  journal = {Journal of Personality and Social Psychology},
  pages = {434--447},
  abstract = {Drawing on an explicit model of emotion, we propose amultifaceted approach to emotional expressiv-ity, defined as the behavioral (e.g., facial, postural) changes associated with emotion. Study 1 shows that self-reported expressivity has 3 facets (Impulse Strength, Negative Expressivity, Positive Expressivity). Study 2 shows that the same 3 facets emerge in peer ratings and that there are robust relations between self- and peer-rated expressivity. In Study 3, emotion-expressive behavior was videotaped and related to expressivity self-reports obtained several months earlier. As expected, Negative Expressivity predicted behavioral expressions of sadness (but not amusement), whereas Positive Expressivity predicted amusement (but not sadness). These relations remained even when subjective motional experience and physiological response were controlled. These studies demon-strate the importance of a multifaceted approach to emotional expressivity and have implications for the understanding of personality and emotion. Emotions help us respond adaptively to environmental chal-lenges and opportunities (Frijda, 1988; Levenson, 1994; Plut-chik, 1980). Unlike other biologically based response tenden-cies, such as reflexes, however, emotions only incline us to act in certain ways; they do not compel us to do so. This means that we may deny expression to some emotional impulses while freely expressing others. Striking individual differences in ex-pressivity suggest that people differ in their response tendencies and in how they express these impulses as they arise. Because emotions influence such a wide range of intra- and interpersonal},
  file = {/Users/timokoch/Zotero/storage/4SYF8M3P/Gross und John - 1997 - Revealing feelings Facets of emotional expressivi.pdf;/Users/timokoch/Zotero/storage/SXEEJACG/summary.html}
}

@article{grunTopicmodelsPackageFitting2011,
  title = {Topicmodels: {{An R Package}} for {{Fitting Topic Models}}},
  author = {Gr{\"u}n, Bettina and Hornik, Kurt},
  year = {2011},
  journal = {Journal of Statistical Software},
  volume = {40},
  number = {13},
  abstract = {Topic models allow the probabilistic modeling of term frequency occurrences in documents. The fitted model can be used to estimate the similarity between documents as well as between a set of specified keywords using an additional layer of latent variables which are referred to as topics. The R package topicmodels provides basic infrastructure for fitting topic models based on data structures from the text mining package tm. The package includes interfaces to two algorithms for fitting topic models: the variational expectation-maximization algorithm provided by David M. Blei and co-authors and an algorithm using Gibbs sampling by Xuan-Hieu Phan and co-authors.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/G9V36S8X/Grün und Hornik - topicmodels An R Package for Fitting Topic Models.pdf}
}

@article{guibonEmojiUsageCategorical,
  title = {From {{Emoji Usage}} to {{Categorical Emoji Prediction}}},
  author = {Guibon, Ga{\"e}l and Ochs, Magalie and Bellot, Patrice},
  pages = {11},
  abstract = {Emoji usage drastically increased recently, they are becoming some of the most common ways to convey emotions and sentiments in social messaging applications. Several research works automatically recommend emojis, so users do not have to go through a library of thousands of emojis. In order to improve emoji recommendation, we present and distribute two useful resources: an emoji embedding model from real usage, and emoji clustering based on these embeddings to automatically identify groups of emojis. Assuming that emojis are part of written natural language and can be considered as words, we only used unsupervised learning methods to extract patterns and knowledge from real emoji usage in tweets. Thereby, emotion categories of face emojis were obtained directly from text in a fully reproductible way. These resources and methodology have multiple usages; for example, they could be used to improve our understanding of emojis or enhance emoji recommendation.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/6XMJ4DR3/Guibon et al. - From Emoji Usage to Categorical Emoji Prediction.pdf}
}

@article{haberStabilityOnlineLanguage,
  title = {On the {{Stability}} of {{Online Language Features}}: {{How Much Text}} Do You {{Need}} to Know a {{Person}}?},
  author = {Haber, Eben M},
  pages = {4},
  abstract = {In recent years, numerous studies have inferred personality and other traits from people's online writing. While these studies are encouraging, more information is needed in order to use these techniques with confidence. How do linguistic features vary across different online media, and how much text is required to have a representative sample for a person? In this paper, we examine several large sets of online, user-generated text, drawn from Twitter, email, blogs, and online discussion forums. We examine and compare population-wide results for the linguistic measure LIWC, and the inferred traits of Big5 Personality and Basic Human Values. We also empirically measure the stability of these traits across different sized samples for each individual. Our results highlight the importance of tuning models to each online medium, and include guidelines for the minimum amount of text required for a representative result.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/TP96UX3U/Haber - On the Stability of Online Language Features How .pdf}
}

@article{halderInfluencePersonalityTraits,
  title = {The Influence of Personality Traits on Information Seeking Behaviour of Students},
  author = {Halder, Santoshi and Roy, Anjali and Chakraborty, P K},
  pages = {13},
  abstract = {The present study was undertaken with the objective to explore the influence of the five personality dimensions on the information seeking behaviour of the students in higher educational institutions. Information seeking behaviour is defined as the sum total of all those activities that are usually undertaken by the students of higher education to collect, utilize and process any kind of information needed for their studies. Data has been collected from 600 university students of the three broad disciplines of studies from the Universities of Eastern part of India (West Bengal). The tools used for the study were General Information schedule (GIS), Information Seeking Behaviour Inventory (ISBI) and NEO-FFI Personality Inventory. Product moment correlation has been worked out between the scores in ISBI and those in NEO-FFI Personality Inventory. The findings indicated that the five personality traits are significantly correlated to all the dimensions of information seeking behaviour of the university students.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/IA7URZ98/Halder et al. - The influence of personality traits on information.pdf}
}

@misc{hallinanInformationProvisionInformed2022,
  title = {Information {{Provision}} for {{Informed Consent Procedures}} in {{Psychological Research}} under the {{GDPR}}: {{A Practical Guide}}},
  shorttitle = {Information {{Provision}} for {{Informed Consent Procedures}} in {{Psychological Research}} under the {{GDPR}}},
  author = {Hallinan, Dara and Boehm, Franziska and K{\"u}lpmann, Annika Iris and Elson, Malte},
  year = {2022},
  month = may,
  publisher = {{PsyArXiv}},
  doi = {10.31234/osf.io/znb9m},
  urldate = {2023-01-23},
  abstract = {Psychological research often involves the collection and processing of personal data from human research participants, and there is a norm that informed consent should be obtained before such research can go ahead. The European General Data Protection Regulation (GDPR) applies, in principle, to psychological research. It elaborates a range of conditions concerning the forms of information which should be communicated to research participants whenever personal data are collected from them, in order that they might be considered to be `informed'. There is reason to believe, however, that the information required by the GDPR may not always be provided in consent materials. This may {\textendash} at least in part {\textendash} be due to the fact that psychological researchers are not aware of the exact requirements. This tutorial thus aims to provide general practical guidance to psychological researchers allowing them to understand which forms of information must be provided to research subjects in consent materials according to the GDPR.},
  langid = {american},
  keywords = {data protection,GDPR,informed consent,other,privacy,Psychology,research ethics,Social and Behavioral Sciences},
  file = {/Users/timokoch/Zotero/storage/QCJ33TBN/Hallinan et al. - 2022 - Information Provision for Informed Consent Procedu.pdf}
}

@article{hanelStudentSamplesProvide2016,
  title = {Do {{Student Samples Provide}} an {{Accurate Estimate}} of the {{General Public}}?},
  author = {Hanel, Paul H. P. and Vione, Katia C.},
  year = {2016},
  month = dec,
  journal = {PLoS ONE},
  volume = {11},
  number = {12},
  pages = {e0168354},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0168354},
  urldate = {2023-02-15},
  abstract = {Most psychological studies rely on student samples. Students are usually considered as more homogenous than representative samples both within and across countries. However, little is known about the nature of the differences between student and representative samples. This is an important gap, also because knowledge about the degree of difference between student and representative samples may allow to infer from the former to the latter group. Across 59 countries and 12 personality (Big-5) and attitudinal variables we found that differences between students and general public were partly substantial, incoherent, and contradicted previous findings. Two often used cultural variables, embeddedness and intellectual autonomy, failed to explain the differences between both groups across countries. We further found that students vary as much as the general population both between and within countries. In summary, our results indicate that generalizing from students to the general public can be problematic when personal and attitudinal variables are used, as students vary mostly randomly from the general public. Findings are also discussed in terms of the replication crisis within psychology.},
  pmcid = {PMC5176168},
  pmid = {28002494},
  file = {/Users/timokoch/Zotero/storage/CQAFX7HF/Hanel und Vione - 2016 - Do Student Samples Provide an Accurate Estimate of.pdf}
}

@article{hanSpeechEmotionRecognition,
  title = {Speech {{Emotion Recognition Using Deep Neural Network}} and {{Extreme Learning Machine}}},
  author = {Han, Kun and Yu, Dong and Tashev, Ivan},
  pages = {5},
  abstract = {Speech emotion recognition is a challenging problem partly because it is unclear what features are effective for the task. In this paper we propose to utilize deep neural networks (DNNs) to extract high level features from raw data and show that they are effective for speech emotion recognition. We first produce an emotion state probability distribution for each speech segment using DNNs. We then construct utterance-level features from segment-level probability distributions. These utterancelevel features are then fed into an extreme learning machine (ELM), a special simple and efficient single-hidden-layer neural network, to identify utterance-level emotions. The experimental results demonstrate that the proposed approach effectively learns emotional information from low-level features and leads to 20\% relative accuracy improvement compared to the stateof-the-art approaches.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/U9XCI33Z/Han et al. - Speech Emotion Recognition Using Deep Neural Netwo.pdf}
}

@inbook{harariNaturalisticAssessmentSituations2018,
  title = {Naturalistic {{Assessment}} of {{Situations Using Mobile Sensing Methods}}},
  booktitle = {The {{Oxford Handbook}} of {{Psychological Situations}}},
  author = {Harari, Gabriella M. and M{\"u}ller, Sandrine R. and Gosling, Samuel D.},
  year = {2018},
  month = jun,
  publisher = {{Oxford University Press}},
  doi = {10.1093/oxfordhb/9780190263348.013.14},
  urldate = {2019-02-11},
  abstract = {The assessment of psychological situations in everyday life presents a number of methodological challenges, largely stemming from the need to assess situations as they occur in their natural context. Digital media devices (e.g., smartphones, wearables, smart home appliances) that come equipped with a wide array of sensors address these challenges by making it possible to measure objective information about situations, many times, with great fidelity, over long periods of time, in a way that is both unobtrusive and ecologically valid. This chapter provides an overview of mobile sensing methods (MSMs) and describes how they can be used to capture objective information about situational cues (e.g., social interactions, objects, activities, locations, time). It then describes opportunities for psychological research using MSMs to provide insights into everyday situational cues, characteristics, and classes. It concludes by discussing some of the practical considerations and challenges associated with using MSMs to assess situations.},
  collaborator = {Harari, Gabriella M. and M{\"u}ller, Sandrine R. and Gosling, Samuel D.},
  isbn = {978-0-19-026334-8},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/RKREXAHI/Harari et al. - 2018 - Naturalistic Assessment of Situations Using Mobile.pdf}
}

@article{harariPersonalitySensingTheory2020,
  title = {Personality {{Sensing}} for {{Theory Development}} and {{Assessment}} in the {{Digital Age}}},
  author = {Harari, Gabriella M. and Vaid, Sumer S. and M{\"u}ller, Sandrine R. and Stachl, Clemens and Marrero, Zachariah and Schoedel, Ramona and B{\"u}hner, Markus and Gosling, Samuel D.},
  year = {2020},
  journal = {European Journal of Personality},
  volume = {34},
  number = {5},
  pages = {649--669},
  issn = {1099-0984},
  doi = {10.1002/per.2273},
  urldate = {2022-11-08},
  abstract = {People around the world own digital media devices that mediate and are in close proximity to their daily behaviours and situational contexts. These devices can be harnessed as sensing technologies to collect information from sensor and metadata logs that provide fine-grained records of everyday personality expression. In this paper, we present a conceptual framework and empirical illustration for personality sensing research, which leverages sensing technologies for personality theory development and assessment. To further empirical knowledge about the degree to which personality-relevant information is revealed via such data, we outline an agenda for three research domains that focus on the description, explanation, and prediction of personality. To illustrate the value of the personality sensing research agenda, we present findings from a large smartphone-based sensing study (N = 633) characterizing individual differences in sensed behavioural patterns (physical activity, social behaviour, and smartphone use) and mapping sensed behaviours to the Big Five dimensions. For example, the findings show associations between behavioural tendencies and personality traits and daily behaviours and personality states. We conclude with a discussion of best practices and provide our outlook on how personality sensing will transform our understanding of personality and the way we conduct assessment in the years to come. {\textcopyright} 2020 European Association of Personality Psychology},
  langid = {english},
  keywords = {behaviour,mobile sensing,naturalistic observation,personality,situational contexts},
  file = {/Users/timokoch/Zotero/storage/L9CR579B/Harari et al. - 2020 - Personality Sensing for Theory Development and Ass.pdf;/Users/timokoch/Zotero/storage/TKHTYXMI/per.html}
}

@article{harariProcessorientedApproachRespecting2020,
  title = {A Process-Oriented Approach to Respecting Privacy in the Context of Mobile Phone Tracking},
  author = {Harari, Gabriella M.},
  year = {2020},
  month = feb,
  journal = {Current Opinion in Psychology},
  series = {Privacy and {{Disclosure}}, {{Online}} and in {{Social Interactions}}},
  volume = {31},
  pages = {141--147},
  issn = {2352-250X},
  doi = {10.1016/j.copsyc.2019.09.007},
  urldate = {2022-11-07},
  abstract = {Mobile phone tracking poses challenges to individual privacy because a phone's sensor data and metadata logs can reveal behavioral, contextual, and psychological information about the individual who uses the phone. Here, I argue for a process-oriented approach to respecting individual privacy in the context of mobile phone tracking by treating informed consent as a process, not a mouse click. This process-oriented approach allows individuals to exercise their privacy preferences and requires the design of self-tracking systems that facilitate transparency, opt-in default settings, and individual control over personal data, especially with regard to: (1) what kinds of personal data are being collected and (2) how the data are being used and shared. In sum, I argue for the development of self-tracking systems that put individual user privacy and control at their core, while enabling people to harness their personal data for self-insight and behavior change. This approach to mobile phone privacy is a radical departure from current standard data practices and has implications for a wide range of stakeholders, including individual users, researchers, and corporations.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/XNAH4L8X/Harari - 2020 - A process-oriented approach to respecting privacy .pdf;/Users/timokoch/Zotero/storage/FJHA5NA4/S2352250X19301642.html}
}

@article{harariUsingSmartphonesCollect2016,
  title = {Using {{Smartphones}} to {{Collect Behavioral Data}} in {{Psychological Science}}: {{Opportunities}}, {{Practical Considerations}}, and {{Challenges}}},
  shorttitle = {Using {{Smartphones}} to {{Collect Behavioral Data}} in {{Psychological Science}}},
  author = {Harari, Gabriella M. and Lane, Nicholas D. and Wang, Rui and Crosier, Benjamin S. and Campbell, Andrew T. and Gosling, Samuel D.},
  year = {2016},
  month = nov,
  journal = {Perspectives on psychological science : a journal of the Association for Psychological Science},
  volume = {11},
  number = {6},
  pages = {838--854},
  issn = {1745-6916},
  doi = {10.1177/1745691616650285},
  urldate = {2021-06-30},
  abstract = {Smartphones now offer the promise of collecting behavioral data unobtrusively, in situ, as it unfolds in the course of daily life. Data can be collected from the onboard sensors and other phone logs embedded in today's off-the-shelf smartphone devices. These data permit fine-grained, continuous collection of people's social interactions (e.g., speaking rates in conversation, size of social groups, calls, and text messages), daily activities (e.g., physical activity and sleep), and mobility patterns (e.g., frequency and duration of time spent at various locations). In this article, we have drawn on the lessons from the first wave of smartphone-sensing research to highlight areas of opportunity for psychological research, present practical considerations for designing smartphone studies, and discuss the ongoing methodological and ethical challenges associated with research in this domain. It is our hope that these practical guidelines will facilitate the use of smartphones as a behavioral observation tool in psychological science.},
  pmcid = {PMC5572675},
  pmid = {27899727},
  file = {/Users/timokoch/Zotero/storage/7FRUPIIX/Harari et al. - 2016 - Using Smartphones to Collect Behavioral Data in Ps.pdf}
}

@article{heavenWhyFacesDon2020,
  title = {Why Faces Don't Always Tell the Truth about Feelings},
  author = {Heaven, Douglas},
  year = {2020},
  month = feb,
  journal = {Nature},
  volume = {578},
  number = {7796},
  pages = {502--504},
  publisher = {{Nature Publishing Group}},
  doi = {10.1038/d41586-020-00507-5},
  urldate = {2021-12-14},
  abstract = {Although AI companies market software for recognizing emotions in faces, psychologists debate whether expressions can be read so easily.},
  copyright = {2021 Nature},
  langid = {english},
  keywords = {Computer science,Psychology,Society},
  annotation = {Bandiera\_abtest: a Cg\_type: News Feature Subject\_term: Psychology, Society, Computer science},
  file = {/Users/timokoch/Zotero/storage/TLPNH29I/Heaven - 2020 - Why faces don’t always tell the truth about feelin.pdf}
}

@article{heinstromFastSurfersBroad2003,
  title = {Fast Surfers, Broad Scanners and Deep Divers as Users of Information Technology{\textendash}{{Relating}} Information Preferences to Personality Traits},
  author = {Heinstr{\"o}m, Jannica},
  year = {2003},
  journal = {Proceedings of the American Society for information science and technology},
  volume = {40},
  number = {1},
  pages = {247--254}
}

@book{heinstromFearFlowPersonality2010,
  title = {From Fear to Flow: Personality and Information Interaction},
  author = {Heinstr{\"o}m, Jannica},
  year = {2010},
  publisher = {{Elsevier}},
  isbn = {1-78063-036-0}
}

@article{heinstromFivePersonalityDimensions,
  title = {Five Personality Dimensions and Their Influence on Information Behaviour},
  author = {Heinstr{\"o}m, Jannica},
  pages = {24},
  abstract = {This article emphasize the importance of considering psychological mechanisms for a thorough understanding of users of information services. The focal point is the relation between personality and information seeking which is explored through a quantitative analysis of 305 university students' personality traits and information habits. It is shown that information behaviour could be connected to all the personality dimensions tested in the study - neuroticism, extraversion, openness to experience, competitiveness and conscientiousness. Possible explanations for these relations are discussed. It is concluded that inner traits interact with contextual factors in their final impact on information behaviour.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/2B4U3D6I/Wood - Five personality dimensions and their influence on.pdf}
}

@inproceedings{hernandezGuidelinesAssessingMinimizing2021,
  title = {Guidelines for {{Assessing}} and {{Minimizing Risks}} of {{Emotion Recognition Applications}}},
  booktitle = {2021 9th {{International Conference}} on {{Affective Computing}} and {{Intelligent Interaction}} ({{ACII}})},
  author = {Hernandez, Javier and Lovejoy, Josh and McDuff, Daniel and Suh, Jina and O'Brien, Tim and Sethumadhavan, Arathi and Greene, Gretchen and Picard, Rosalind and Czerwinski, Mary},
  year = {2021},
  month = sep,
  pages = {1--8},
  issn = {2156-8111},
  doi = {10.1109/ACII52823.2021.9597452},
  abstract = {Society has witnessed a rapid increase in the adoption of commercial uses of emotion recognition. Tools that were traditionally used by domain experts are now being used by individuals who are often unaware of the technology's limitations and may use them in potentially harmful settings. The change in scale and agency, paired with gaps in regulation, urge the research community to rethink how we design, position, implement and ultimately deploy emotion recognition to anticipate and minimize potential risks. To help understand the current ecosystem of applied emotion recognition, this work provides an overview of some of the most frequent commercial applications and identifies some of the potential sources of harm. Informed by these, we then propose 12 guidelines for systematically assessing and reducing the risks presented by emotion recognition applications. These guidelines can help identify potential misuses and inform future deployments of emotion recognition.},
  keywords = {Affective computing,Ecosystems,emotion recognition,Emotion recognition,ethics,Ethics,guidelines,Regulation,risk,Technological innovation,Tools},
  file = {/Users/timokoch/Zotero/storage/JWPELSP6/Hernandez et al. - 2021 - Guidelines for Assessing and Minimizing Risks of E.pdf;/Users/timokoch/Zotero/storage/UDPG59R9/9597452.html}
}

@article{herringComputermediatedDiscourse2015,
  title = {Computer-Mediated Discourse 2.0},
  author = {Herring, Susan C. and Androutsopoulos, Jannis},
  year = {2015},
  journal = {The handbook of discourse analysis},
  volume = {2},
  pages = {127--151}
}

@article{herringGenderAgeInfluences2020,
  title = {Gender and {{Age Influences}} on {{Interpretation}} of {{Emoji Functions}}},
  author = {Herring, Susan C. and Dainas, Ashley R.},
  year = {2020},
  month = may,
  journal = {ACM Transactions on Social Computing},
  volume = {3},
  number = {2},
  pages = {1--26},
  issn = {2469-7818, 2469-7826},
  doi = {10.1145/3375629},
  urldate = {2021-02-25},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/DR5MYJCZ/Herring und Dainas - 2020 - Gender and Age Influences on Interpretation of Emo.pdf}
}

@article{hildebrandVoiceAnalyticsBusiness2020,
  title = {Voice Analytics in Business Research: {{Conceptual}} Foundations, Acoustic Feature Extraction, and Applications},
  shorttitle = {Voice Analytics in Business Research},
  author = {Hildebrand, Christian and Efthymiou, Fotis and Busquet, Francesc and Hampton, William H. and Hoffman, Donna L. and Novak, Thomas P.},
  year = {2020},
  month = dec,
  journal = {Journal of Business Research},
  volume = {121},
  pages = {364--374},
  issn = {0148-2963},
  doi = {10.1016/j.jbusres.2020.09.020},
  urldate = {2021-11-16},
  abstract = {Recent advances in artificial intelligence and natural language processing are gradually transforming how humans search, shop, and express their preferences. Leveraging the new affordances and modalities of human{\textendash}machine interaction through voice-controlled interfaces will require a nuanced understanding of the physics and psychology of speech formation as well as the systematic extraction and analysis of vocal features from the human voice. In this paper, we first develop a conceptual framework linking vocal features in the human voice to experiential outcomes and emotional states. We then illustrate the effective processing, editing, analysis, and visualization of voice data based on an Amazon Alexa user interaction, utilizing state-of-the-art signal-processing packages in R. Finally, we offer novel insight into the ways in which business research might employ voice and sound analytics moving forward, including a discussion of the ethical implications of building multi-modal databases for business and society.},
  langid = {english},
  keywords = {Acoustic markers of emotion,Emotion detection,Natural language processing,Voice Analytics,Voice-controlled interfaces},
  file = {/Users/timokoch/Zotero/storage/EHLC4HVS/Hildebrand et al. - 2020 - Voice analytics in business research Conceptual f.pdf}
}

@article{hillMicrosoftPlansEliminate2022,
  title = {Microsoft {{Plans}} to {{Eliminate Face Analysis Tools}} in {{Push}} for `{{Responsible A}}.{{I}}.'},
  author = {Hill, Kashmir},
  year = {2022},
  month = jun,
  journal = {The New York Times},
  issn = {0362-4331},
  urldate = {2022-11-30},
  abstract = {The technology giant will stop offering automated tools that predict a person's gender, age and emotional state and will restrict the use of its facial recognition tool.},
  chapter = {Technology},
  langid = {american},
  keywords = {Artificial Intelligence,Computers and the Internet,Corporate Social Responsibility,emergingtech,Facial Recognition Software,Gender,Microsoft Corp,Race and Ethnicity},
  file = {/Users/timokoch/Zotero/storage/6CSWYHBY/microsoft-facial-recognition.html}
}

@inproceedings{hilteModelingNonstandardLanguage2017,
  title = {Modeling Non-Standard Language Use in Adolescents' {{CMC}}: The Impact and Interaction of Age, Gender and Education},
  booktitle = {Proceedings of the 5th {{Conference}} on {{CMC}} and {{Social Media Corpora}} for the {{Humanities}} (Cmccorpora17), 3-4 {{October}} 2017, {{Italy}}/{{Stemle}}, {{Egon W}}.[Edit.]; et Al.},
  author = {Hilte, Lisa and Vandekerckhove, Reinhild and Daelemans, Walter},
  year = {2017},
  pages = {11--15},
  file = {/Users/timokoch/Zotero/storage/CKB32GSG/Hilte et al. - 2017 - Modeling non-standard language use in adolescents'.pdf}
}

@article{hirshPersonalityLanguageUse2009,
  title = {Personality and Language Use in Self-Narratives},
  author = {Hirsh, Jacob B. and Peterson, Jordan B.},
  year = {2009},
  journal = {Journal of Research in Personality},
  volume = {43},
  number = {3},
  pages = {524--527},
  issn = {00926566},
  doi = {10.1016/j.jrp.2009.01.006}
}

@article{hoemannContextawareExperienceSampling2020,
  title = {Context-Aware Experience Sampling Reveals the Scale of Variation in Affective Experience},
  author = {Hoemann, Katie and Khan, Zulqarnain and Feldman, Mallory J. and Nielson, Catie and Devlin, Madeleine and Dy, Jennifer and Barrett, Lisa Feldman and Wormwood, Jolie B. and Quigley, Karen S.},
  year = {2020},
  month = jul,
  journal = {Scientific Reports},
  volume = {10},
  pages = {12459},
  issn = {2045-2322},
  doi = {10.1038/s41598-020-69180-y},
  urldate = {2022-01-25},
  abstract = {Emotion research typically searches for consistency and specificity in physiological activity across instances of an emotion category, such as anger or fear, yet studies to date have observed more variation than expected. In the present study, we adopt an alternative approach, searching inductively for structure within variation, both within and across participants. Following a novel, physiologically-triggered experience sampling procedure, participants' self-reports and peripheral physiological activity were recorded when substantial changes in cardiac activity occurred in the absence of movement. Unsupervised clustering analyses revealed variability in the number and nature of patterns of physiological activity that recurred within individuals, as well as in the affect ratings and emotion labels associated with each pattern. There were also broad patterns that recurred across individuals. These findings support a constructionist account of emotion which, drawing on Darwin, proposes that emotion categories are populations of variable instances tied to situation-specific needs.},
  pmcid = {PMC7385108},
  pmid = {32719368},
  file = {/Users/timokoch/Zotero/storage/ASK9EFET/Hoemann et al. - 2020 - Context-aware experience sampling reveals the scal.pdf}
}

@article{hoemannContextawareExperienceSampling2020a,
  title = {Context-Aware Experience Sampling Reveals the Scale of Variation in Affective Experience},
  author = {Hoemann, Katie and Khan, Zulqarnain and Feldman, Mallory J. and Nielson, Catie and Devlin, Madeleine and Dy, Jennifer and Barrett, Lisa Feldman and Wormwood, Jolie B. and Quigley, Karen S.},
  year = {2020},
  month = jul,
  journal = {Scientific Reports},
  volume = {10},
  pages = {12459},
  issn = {2045-2322},
  doi = {10.1038/s41598-020-69180-y},
  urldate = {2022-01-25},
  abstract = {Emotion research typically searches for consistency and specificity in physiological activity across instances of an emotion category, such as anger or fear, yet studies to date have observed more variation than expected. In the present study, we adopt an alternative approach, searching inductively for structure within variation, both within and across participants. Following a novel, physiologically-triggered experience sampling procedure, participants' self-reports and peripheral physiological activity were recorded when substantial changes in cardiac activity occurred in the absence of movement. Unsupervised clustering analyses revealed variability in the number and nature of patterns of physiological activity that recurred within individuals, as well as in the affect ratings and emotion labels associated with each pattern. There were also broad patterns that recurred across individuals. These findings support a constructionist account of emotion which, drawing on Darwin, proposes that emotion categories are populations of variable instances tied to situation-specific needs.},
  pmcid = {PMC7385108},
  pmid = {32719368},
  file = {/Users/timokoch/Zotero/storage/PF5FPV6C/Hoemann et al. - 2020 - Context-aware experience sampling reveals the scal.pdf}
}

@article{hoganPresentationSelfAge2010,
  title = {The {{Presentation}} of {{Self}} in the {{Age}} of {{Social Media}}: {{Distinguishing Performances}} and {{Exhibitions Online}}},
  shorttitle = {The {{Presentation}} of {{Self}} in the {{Age}} of {{Social Media}}},
  author = {Hogan, Bernie},
  year = {2010},
  month = dec,
  journal = {Bulletin of Science, Technology \& Society},
  volume = {30},
  number = {6},
  pages = {377--386},
  issn = {0270-4676, 1552-4183},
  doi = {10.1177/0270467610385893},
  urldate = {2020-03-18},
  abstract = {Presentation of self (via Goffman) is becoming increasingly popular as a means for explaining differences in meaning and activity of online participation. This article argues that self-presentation can be split into performances, which take place in synchronous ``situations,'' and artifacts, which take place in asynchronous ``exhibitions.'' Goffman's dramaturgical approach (including the notions of front and back stage) focuses on situations. Social media, on the other hand, frequently employs exhibitions, such as lists of status updates and sets of photos, alongside situational activities, such as chatting. A key difference in exhibitions is the virtual ``curator'' that manages and redistributes this digital content. This article introduces the exhibitional approach and the curator and suggests ways in which this approach can extend present work concerning online presentation of self. It introduces a theory of ``lowest common denominator'' culture employing the exhibitional approach.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/N4K4LHCY/Hogan - 2010 - The Presentation of Self in the Age of Social Medi.pdf}
}

@inproceedings{hogenboomExploitingEmoticonsSentiment2013,
  title = {Exploiting Emoticons in Sentiment Analysis},
  booktitle = {Proceedings of the 28th {{Annual ACM Symposium}} on {{Applied Computing}} - {{SAC}} '13},
  author = {Hogenboom, Alexander and Bal, Daniella and Frasincar, Flavius and Bal, Malissa and {de Jong}, Franciska and Kaymak, Uzay},
  year = {2013},
  pages = {703},
  publisher = {{ACM Press}},
  address = {{Coimbra, Portugal}},
  doi = {10.1145/2480362.2480498},
  urldate = {2019-07-29},
  abstract = {As people increasingly use emoticons in text in order to express, stress, or disambiguate their sentiment, it is crucial for automated sentiment analysis tools to correctly account for such graphical cues for sentiment. We analyze how emoticons typically convey sentiment and demonstrate how we can exploit this by using a novel, manually created emoticon sentiment lexicon in order to improve a state-of-the-art lexicon-based sentiment classification method. We evaluate our approach on 2,080 Dutch tweets and forum messages, which all contain emoticons and have been manually annotated for sentiment. On this corpus, paragraph-level accounting for sentiment implied by emoticons significantly improves sentiment classification accuracy. This indicates that whenever emoticons are used, their associated sentiment dominates the sentiment conveyed by textual cues and forms a good proxy for intended sentiment.},
  isbn = {978-1-4503-1656-9},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/A39I87NP/Hogenboom et al. - 2013 - Exploiting emoticons in sentiment analysis}
}

@misc{holtAmazonAlexaGet,
  title = {Amazon's {{Alexa Is About To Get More Emotional}}},
  author = {Holt, Kris},
  journal = {Forbes},
  urldate = {2021-06-30},
  abstract = {Developers can tap into Alexa's new excited and disappointed voice tones.},
  chapter = {Consumer Tech},
  howpublished = {https://www.forbes.com/sites/krisholt/2019/11/27/amazons-alexa-is-about-to-get-more-emotional/},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/W64HGRC6/amazons-alexa-is-about-to-get-more-emotional.html}
}

@article{holtgravesTextMessagingPersonality2011,
  title = {Text Messaging, Personality, and the Social Context},
  author = {Holtgraves, Thomas},
  year = {2011},
  journal = {Journal of research in personality},
  volume = {45},
  number = {1},
  pages = {92--99}
}

@incollection{hornikDerivingConsensusRankings2007,
  title = {Deriving {{Consensus Rankings}} from {{Benchmarking Experiments}}},
  booktitle = {Advances in {{Data Analysis}}},
  author = {Hornik, Kurt and Meyer, David},
  editor = {Decker, Reinhold and Lenz, Hans -J.},
  year = {2007},
  pages = {163--170},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-540-70981-7_19},
  urldate = {2020-03-12},
  abstract = {Whereas benchmarking experiments are very frequently used to investigate the performance of statistical or machine learning algorithms for supervised and unsupervised learning tasks, overall analyses of such experiments are typically only carried out on a heuristic basis, if at all. We suggest to determine winners, and more generally, to derive a consensus ranking of the algorithms, as the linear order on the algorithms which minimizes average symmetric distance (Kemeny-Snell distance) to the performance relations on the individual benchmark data sets. This leads to binary programming problems which can typically be solved reasonably efficiently. We apply the approach to a medium-scale benchmarking experiment to assess the performance of Support Vector Machines in regression and classification problems, and compare the obtained consensus ranking with rankings obtained by simple scoring and Bradley-Terry modeling.},
  isbn = {978-3-540-70980-0 978-3-540-70981-7},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/QMSR67QQ/Hornik und Meyer - 2007 - Deriving Consensus Rankings from Benchmarking Expe.pdf}
}

@article{hosanagarWeNeedTransparency2018,
  title = {We {{Need Transparency}} in {{Algorithms}}, {{But Too Much Can Backfire}}},
  author = {Hosanagar, Kartik and Jair, Vivian},
  year = {2018},
  month = jul,
  journal = {Harvard Business Review},
  issn = {0017-8012},
  urldate = {2019-01-15},
  abstract = {Consumers should have some idea how machines make decisions.},
  keywords = {Technology,Transparency},
  file = {/Users/timokoch/Zotero/storage/IMH8378L/we-need-transparency-in-algorithms-but-too-much-can-backfire.html}
}

@article{HttpWwwNytimes,
  title = {{{http://www.nytimes.com/2012/02/12/sunday-review/big-datas-impac}}},
  pages = {5},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/KU2FXKNG/httpwww.nytimes.com20120212sunday-reviewbi.pdf}
}

@article{huangPredictionEmotionChange2018,
  title = {Prediction of {{Emotion Change From Speech}}},
  author = {Huang, Zhaocheng and Epps, Julien},
  year = {2018},
  journal = {Frontiers in ICT},
  volume = {5},
  issn = {2297-198X},
  urldate = {2023-02-13},
  abstract = {The fact that emotions are dynamic in nature and evolve across time has been explored relatively less often in automatic emotion recognition systems to date. Although within-utterance information about emotion changes recently has received some attention, there remain open questions unresolved, such as how to approach delta emotion ground truth, how to predict the extent of emotion change from speech, and how well change can be predicted relative to absolute emotion ratings. In this article, we investigate speech-based automatic systems for continuous prediction of the extent of emotion changes in arousal/valence. We propose the use of regression (smoothed) deltas as ground truth for emotion change, which yielded considerably higher inter-rater reliability than first-order deltas, a commonly used approach in previous research, and represent a more appropriate approach to derive annotations for emotion change research, findings which are applicable beyond speech-based systems. In addition, the first system design for continuous emotion change prediction from speech is explored. Experimental results under the Output-Associative Relevance Vector Machine framework interestingly show that changes in emotion ratings may be better predicted than absolute emotion ratings on the RECOLA database, achieving 0.74 vs. 0.71 for arousal and 0.41 vs. 0.37 for valence in concordance correlation coefficients. However, further work is needed to achieve effective emotion change prediction performances on the SEMAINE database, due to the large number of non-change frames in the absolute emotion ratings.},
  file = {/Users/timokoch/Zotero/storage/B7KMMRJN/Huang und Epps - 2018 - Prediction of Emotion Change From Speech.pdf}
}

@article{huangPredictionEmotionChange2018a,
  title = {Prediction of {{Emotion Change From Speech}}},
  author = {Huang, Zhaocheng and Epps, Julien},
  year = {2018},
  month = jun,
  journal = {Frontiers in ICT},
  volume = {5},
  pages = {11},
  issn = {2297-198X},
  doi = {10.3389/fict.2018.00011},
  urldate = {2019-06-13},
  abstract = {The fact that emotions are dynamic in nature and evolve across time has been explored relatively less often in automatic emotion recognition systems to date. Although withinutterance information about emotion changes recently has received some attention, there remain open questions unresolved, such as how to approach delta emotion ground truth, how to predict the extent of emotion change from speech, and how well change can be predicted relative to absolute emotion ratings. In this article, we investigate speech-based automatic systems for continuous prediction of the extent of emotion changes in arousal/valence. We propose the use of regression (smoothed) deltas as ground truth for emotion change, which yielded considerably higher inter-rater reliability than first-order deltas, a commonly used approach in previous research, and represent a more appropriate approach to derive annotations for emotion change research, findings which are applicable beyond speech-based systems. In addition, the first system design for continuous emotion change prediction from speech is explored. Experimental results under the Output-Associative Relevance Vector Machine framework interestingly show that changes in emotion ratings may be better predicted than absolute emotion ratings on the RECOLA database, achieving 0.74 vs. 0.71 for arousal and 0.41 vs. 0.37 for valence in concordance correlation coefficients. However, further work is needed to achieve effective emotion change prediction performances on the SEMAINE database, due to the large number of non-change frames in the absolute emotion ratings.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/KAH6LFWR/Huang und Epps - 2018 - Prediction of Emotion Change From Speech.pdf}
}

@article{huangPredictionEmotionChange2018b,
  title = {Prediction of {{Emotion Change From Speech}}},
  author = {Huang, Zhaocheng and Epps, Julien},
  year = {2018},
  month = jun,
  journal = {Frontiers in ICT},
  volume = {5},
  issn = {2297-198X},
  doi = {10.3389/fict.2018.00011},
  urldate = {2019-06-06},
  abstract = {The fact that emotions are dynamic in nature and evolve across time has been explored relatively less often in automatic emotion recognition systems to date. Although withinutterance information about emotion changes recently has received some attention, there remain open questions unresolved, such as how to approach delta emotion ground truth, how to predict the extent of emotion change from speech, and how well change can be predicted relative to absolute emotion ratings. In this article, we investigate speech-based automatic systems for continuous prediction of the extent of emotion changes in arousal/valence. We propose the use of regression (smoothed) deltas as ground truth for emotion change, which yielded considerably higher inter-rater reliability than first-order deltas, a commonly used approach in previous research, and represent a more appropriate approach to derive annotations for emotion change research, findings which are applicable beyond speech-based systems. In addition, the first system design for continuous emotion change prediction from speech is explored. Experimental results under the Output-Associative Relevance Vector Machine framework interestingly show that changes in emotion ratings may be better predicted than absolute emotion ratings on the RECOLA database, achieving 0.74 vs. 0.71 for arousal and 0.41 vs. 0.37 for valence in concordance correlation coefficients. However, further work is needed to achieve effective emotion change prediction performances on the SEMAINE database, due to the large number of non-change frames in the absolute emotion ratings.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/ZW3IRQNQ/Huang und Epps - 2018 - Prediction of Emotion Change From Speech.pdf}
}

@inproceedings{huDemographicPredictionBased2007,
  title = {Demographic Prediction Based on User's Browsing Behavior},
  booktitle = {Proceedings of the 16th International Conference on {{World Wide Web}}  - {{WWW}} '07},
  author = {Hu, Jian and Zeng, Hua-Jun and Li, Hua and Niu, Cheng and Chen, Zheng},
  year = {2007},
  pages = {151},
  publisher = {{ACM Press}},
  address = {{Banff, Alberta, Canada}},
  doi = {10.1145/1242572.1242594},
  urldate = {2019-07-01},
  abstract = {Demographic information plays an important role in personalized web applications. However, it is usually not easy to obtain this kind of personal data such as age and gender. In this paper, we made a first approach to predict users' gender and age from their Web browsing behaviors, in which the Webpage view information is treated as a hidden variable to propagate demographic information between different users. There are three main steps in our approach: First, learning from the Webpage click-though data, Webpages are associated with users' (known) age and gender tendency through a discriminative model; Second, users' (unknown) age and gender are predicted from the demographic information of the associated Webpages through a Bayesian framework; Third, based on the fact that Webpages visited by similar users may be associated with similar demographic tendency, and users with similar demographic information would visit similar Webpages, a smoothing component is employed to overcome the data sparseness of web click-though log. Experiments are conducted on a real web clickthrough log to demonstrate the effectiveness of the proposed approach. The experimental results show that the proposed algorithm can achieve up to 30.4\% improvements on gender prediction and 50.3\% on age prediction in terms of macro F1, compared to baseline algorithms.},
  isbn = {978-1-59593-654-7},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/MT2FUSDN/Hu et al. - 2007 - Demographic prediction based on user's browsing be.pdf}
}

@article{huttoVADERParsimoniousRuleBased2014,
  title = {{{VADER}}: {{A Parsimonious Rule-Based Model}} for {{Sentiment Analysis}} of {{Social Media Text}}},
  shorttitle = {{{VADER}}},
  author = {Hutto, C. and Gilbert, Eric},
  year = {2014},
  month = may,
  journal = {Proceedings of the International AAAI Conference on Web and Social Media},
  volume = {8},
  number = {1},
  pages = {216--225},
  issn = {2334-0770, 2162-3449},
  doi = {10.1609/icwsm.v8i1.14550},
  urldate = {2023-01-16},
  abstract = {The inherent nature of social media content poses serious challenges to practical applications of sentiment analysis. We present VADER, a simple rule-based model for general sentiment analysis, and compare its effectiveness to eleven typical state-of-practice benchmarks including LIWC, ANEW, the General Inquirer, SentiWordNet, and machine learning oriented techniques relying on Naive Bayes, Maximum Entropy, and Support Vector Machine (SVM) algorithms. Using a combination of qualitative and quantitative methods, we first construct and empirically validate a goldstandard list of lexical features (along with their associated sentiment intensity measures) which are specifically attuned to sentiment in microblog-like contexts. We then combine these lexical features with consideration for five general rules that embody grammatical and syntactical conventions for expressing and emphasizing sentiment intensity. Interestingly, using our parsimonious rule-based model to assess the sentiment of tweets, we find that VADER outperforms individual human raters (F1 Classification Accuracy = 0.96 and 0.84, respectively), and generalizes more favorably across contexts than any of our benchmarks.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/DC8HE4SK/Hutto und Gilbert - 2014 - VADER A Parsimonious Rule-Based Model for Sentime.pdf}
}

@incollection{iacobelliLargeScalePersonality2011,
  title = {Large Scale Personality Classification of Bloggers},
  booktitle = {Affective Computing and Intelligent Interaction},
  author = {Iacobelli, Francisco and Gill, Alastair J. and Nowson, Scott and Oberlander, Jon},
  year = {2011},
  pages = {568--577},
  publisher = {{Springer}}
}

@misc{ianfellowsPackageWordcloud2015,
  title = {Package 'wordcloud'},
  author = {Ian Fellows},
  year = {2015}
}

@misc{IdealOrator,
  title = {On the {{Ideal Orator}}},
  urldate = {2023-03-13},
  abstract = {Read 28 reviews from the world's largest community for readers. In , ( ), Cicero, the greatest Roman orator and prosewriter of his day, gives his mature vi{\ldots}},
  howpublished = {https://www.goodreads.com/book/show/84602.On\_the\_Ideal\_Orator},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/HUE34EZX/84602.html}
}

@article{ilievAutomatedTextAnalysis2015,
  title = {Automated Text Analysis in Psychology: Methods, Applications, and Future Developments},
  shorttitle = {Automated Text Analysis in Psychology},
  author = {Iliev, Rumen and Dehghani, Morteza and Sagi, Eyal},
  year = {2015},
  month = jun,
  journal = {Language and Cognition},
  volume = {7},
  number = {02},
  pages = {265--290},
  issn = {1866-9808, 1866-9859},
  doi = {10.1017/langcog.2014.30},
  urldate = {2018-11-05},
  abstract = {Recent years have seen rapid developments in automated text analysis methods focused on measuring psychological and demographic properties. While this development has mainly been driven by computer scientists and computational linguists, such methods can be of great value for social scientists in general, and for psychologists in particular. In this paper, we review some of the most popular approaches to automated text analysis from the perspective of social scientists, and give examples of their applications in different theoretical domains. After describing some of the pros and cons of these methods, we speculate about future methodological developments, and how they might change social sciences. We conclude that, despite the fact that current methods have many disadvantages and pitfalls compared to more traditional methods of data collection, the constant increase of computational power and the wide availability of textual data will inevitably make automated text analysis a common tool for psychologists.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/S4TSDDUD/Iliev et al. - 2015 - Automated text analysis in psychology methods, ap.pdf}
}

@article{isaakUserDataPrivacy2018,
  title = {User {{Data Privacy}}: {{Facebook}}, {{Cambridge Analytica}}, and {{Privacy Protection}}},
  shorttitle = {User {{Data Privacy}}},
  author = {Isaak, Jim and Hanna, Mina J.},
  year = {2018},
  month = aug,
  journal = {Computer},
  volume = {51},
  number = {8},
  pages = {56--59},
  issn = {1558-0814},
  doi = {10.1109/MC.2018.3191268},
  abstract = {With the revelation that Facebook handed over personally identifiable information of more than 87 million users to Cambridge Analytica, it is now imperative that comprehensive privacy policy laws be developed. Technologists, researchers, and innovators should meaningfully contribute to the development of these policies.},
  keywords = {Cambridge Analytica,cybercrime,data privacy,data security,Facebook,Internet/Web technologies,online security,personally identifiable information,PII,privacy,privacy protection,security,social media,The Policy Corner,user data privacy},
  file = {/Users/timokoch/Zotero/storage/GCZQKT5N/Isaak und Hanna - 2018 - User Data Privacy Facebook, Cambridge Analytica, .pdf;/Users/timokoch/Zotero/storage/7WEI4ZQY/8436400.html}
}

@article{israelEmotionPredictionWeighted2019,
  title = {Emotion {{Prediction}} with {{Weighted Appraisal Models}} - {{Validating}} a {{Psychological Theory}} of {{Affect}}},
  author = {Israel, L. S. F. and Sch{\"o}nbrodt, F. D.},
  year = {2019},
  journal = {IEEE Transactions on Affective Computing},
  pages = {1--1},
  issn = {1949-3045},
  doi = {10.1109/TAFFC.2019.2940937},
  abstract = {Appraisal theories are a prominent approach for the explanation and prediction of emotions. According to these theories, the subjective perception of an emotion results from a series of specific event evaluations. To validate and extend one of the most known representatives of appraisal theory, the Component Process Model by Klaus Scherer, we implemented four computational appraisal models that predicted emotion labels based on prototype similarity calculations. Different weighting algorithms, mapping the models' input to a distinct emotion label, were integrated in the models. We evaluated the plausibility of the models' structure by assessing their predictive power and comparing their performance to a baseline model and a highly predictive machine learning algorithm. Model parameters were estimated from empirical data and validated out-of-sample. All models were notably better than the baseline model and able to explain part of the variance in the emotion labels. The preferred model, yielding a relatively high performance and stable parameter estimations, was able to predict a correct emotion label with an accuracy of 40.2\% and a correct emotion family with an accuracy of 76.9\%. The weighting algorithm of this favored model corresponds to the weighting complexity implied by the Component Process Model, but uses differing weighting parameters.},
  keywords = {Adaptation models,Affective computing,Appraisal,appraisal theory,Component Process Model,Computational modeling,Data models,emotion,Prediction algorithms,predictive models,Predictive models,Prototypes},
  file = {/Users/timokoch/Zotero/storage/6SV8QY9C/Israel und Schönbrodt - 2019 - Emotion Prediction with Weighted Appraisal Models .pdf;/Users/timokoch/Zotero/storage/5UP5AJQ8/8832270.html}
}

@article{israelPredictingAffectiveAppraisals2021,
  title = {Predicting Affective Appraisals from Facial Expressions and Physiology Using Machine Learning},
  author = {Israel, Laura S. F. and Sch{\"o}nbrodt, Felix D.},
  year = {2021},
  month = apr,
  journal = {Behavior Research Methods},
  volume = {53},
  number = {2},
  pages = {574--592},
  issn = {1554-3528},
  doi = {10.3758/s13428-020-01435-y},
  urldate = {2022-11-08},
  abstract = {The present study explored the interrelations between a broad set of appraisal ratings and five physiological signals, including facial EMG, electrodermal activity, and heart rate variability, that were assessed in 157 participants watching 10 emotionally charged videos. A total of 134 features were extracted from the physiological data, and a benchmark comparing different kinds of machine learning algorithms was conducted to test how well the appraisal dimensions can be predicted from these features. For 13 out of 21 appraisals, a robust positive R2 was attained, indicating that the dimensions are actually related to the considered physiological channels. The highest R2 (.407) was reached for the appraisal dimension intrinsic pleasantness. Moreover, the comparison of linear and nonlinear algorithms and the inspection of the links between the appraisals and single physiological features using accumulated local effects plots indicates that the relationship between physiology and appraisals is nonlinear. By constructing different importance measures for the assessed physiological channels, we showed that for the 13 predictable appraisals, the five channels explained different amounts of variance and that only a few blocks incrementally explained variance beyond the other physiological channels.},
  langid = {english},
  keywords = {Appraisal theory,Component process model,Machine learning,Physiology,Predictive modeling},
  file = {/Users/timokoch/Zotero/storage/TQ5L4JVM/Israel und Schönbrodt - 2021 - Predicting affective appraisals from facial expres.pdf}
}

@article{ivanovRecognitionPersonalityTraits2011,
  title = {Recognition of {{Personality Traits}} from {{Human Spoken Conversations}}},
  author = {Ivanov, A V and Riccardi, G and Sporka, A J and Franc, J},
  year = {2011},
  pages = {4},
  abstract = {We are interested in understanding human personality and its manifestations in human interactions. The automatic analysis of such personality traits in natural conversation is quite complex due to the user-profiled corpora acquisition, annotation task and multidimensional modeling. While in the experimental psychology research this topic has been addressed extensively, speech and language scientists have recently engaged in limited experiments. In this paper we describe an automated system for speaker-independent personality prediction in the context of human-human spoken conversations. The evaluation of such system is carried out on the PersIA human-human spoken dialog corpus annotated with user self-assessments of the Big-Five personality traits. The personality predictor has been trained on paralinguistic features and its evaluation on five personality traits shows encouraging results for the conscientiousness and extroversion labels.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/KUFI42F6/Ivanov et al. - Recognition of Personality Traits from Human Spoke.pdf}
}

@article{jacksonEmotionSemanticsShow2019,
  title = {Emotion Semantics Show Both Cultural Variation and Universal Structure},
  author = {Jackson, Joshua Conrad and Watts, Joseph and Henry, Teague R. and List, Johann-Mattis and Forkel, Robert and Mucha, Peter J. and Greenhill, Simon J. and Gray, Russell D. and Lindquist, Kristen A.},
  year = {2019},
  month = dec,
  journal = {Science},
  volume = {366},
  number = {6472},
  pages = {1517--1522},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/science.aaw8160},
  urldate = {2021-12-14},
  file = {/Users/timokoch/Zotero/storage/G68BDQY4/Jackson et al. - 2019 - Emotion semantics show both cultural variation and.pdf}
}

@article{jacksonTextThoughtHow2021,
  title = {From {{Text}} to {{Thought}}: {{How Analyzing Language Can Advance Psychological Science}}},
  shorttitle = {From {{Text}} to {{Thought}}},
  author = {Jackson, Joshua Conrad and Watts, Joseph and List, Johann-Mattis and Puryear, Curtis and Drabble, Ryan and Lindquist, Kristen A.},
  year = {2021},
  month = oct,
  journal = {Perspectives on Psychological Science},
  pages = {17456916211004899},
  publisher = {{SAGE Publications Inc}},
  issn = {1745-6916},
  doi = {10.1177/17456916211004899},
  urldate = {2021-10-08},
  abstract = {Humans have been using language for millennia but have only just begun to scratch the surface of what natural language can reveal about the mind. Here we propose that language offers a unique window into psychology. After briefly summarizing the legacy of language analyses in psychological science, we show how methodological advances have made these analyses more feasible and insightful than ever before. In particular, we describe how two forms of language analysis{\textemdash}natural-language processing and comparative linguistics{\textemdash}are contributing to how we understand topics as diverse as emotion, creativity, and religion and overcoming obstacles related to statistical power and culturally diverse samples. We summarize resources for learning both of these methods and highlight the best way to combine language analysis with more traditional psychological paradigms. Applying language analysis to large-scale and cross-cultural datasets promises to provide major breakthroughs in psychological science.},
  langid = {english},
  keywords = {comparative linguistics,creativity,cultural evolution,emotion,historical linguistics,natural-language processing,psycholinguistics,religion},
  file = {/Users/timokoch/Zotero/storage/4GHRWMCD/Jackson et al. - 2021 - From Text to Thought How Analyzing Language Can A.pdf}
}

@article{jacobucciMachineLearningPsychological2020,
  title = {Machine {{Learning}} and {{Psychological Research}}: {{The Unexplored Effect}} of {{Measurement}}},
  shorttitle = {Machine {{Learning}} and {{Psychological Research}}},
  author = {Jacobucci, Ross and Grimm, Kevin J.},
  year = {2020},
  month = may,
  journal = {Perspectives on Psychological Science},
  volume = {15},
  number = {3},
  pages = {809--816},
  publisher = {{SAGE Publications Inc}},
  issn = {1745-6916},
  doi = {10.1177/1745691620902467},
  urldate = {2021-11-26},
  abstract = {Machine learning (i.e., data mining, artificial intelligence, big data) has been increasingly applied in psychological science. Although some areas of research have benefited tremendously from a new set of statistical tools, most often in the use of biological or genetic variables, the hype has not been substantiated in more traditional areas of research. We argue that this phenomenon results from measurement errors that prevent machine-learning algorithms from accurately modeling nonlinear relationships, if indeed they exist. This shortcoming is showcased across a set of simulated examples, demonstrating that model selection between a machine-learning algorithm and regression depends on the measurement quality, regardless of sample size. We conclude with a set of recommendations and a discussion of ways to better integrate machine learning with statistics as traditionally practiced in psychological science.},
  langid = {english},
  keywords = {data mining,machine learning,measurement error,psychometrics,structural-equation modeling},
  file = {/Users/timokoch/Zotero/storage/NMCVF8TK/Jacobucci und Grimm - 2020 - Machine Learning and Psychological Research The U.pdf}
}

@article{jaegerEmojiQuestionnairesCan2017,
  title = {Emoji Questionnaires Can Be Used with a Range of Population Segments: {{Findings}} Relating to Age, Gender and Frequency of Emoji/Emoticon Use},
  shorttitle = {Emoji Questionnaires Can Be Used with a Range of Population Segments},
  author = {Jaeger, Sara and Xia, Yixun and Lee, Pui-Yee and Hunter, Denise and Beresford, Michelle and Ares, Gast{\'o}n},
  year = {2017},
  month = dec,
  journal = {Food Quality and Preference},
  volume = {68},
  doi = {10.1016/j.foodqual.2017.12.011},
  abstract = {The assessment of emoji questionnaires as a method in food-related consumer research is furthered by this methodological study aimed at exploring the extent to which they can be used with a range of population segments. In the first part of the paper, a web-based survey was implemented to assess differences in the interpretation of 33 facial emoji using a check-all-that-apply (CATA) question. Results showed that while emoji interpretation was not influenced by age and frequency of emoji/emoticon use in computer-mediated communications, age-related differences existed for a few emoji. In the second part of the paper, differences in the completion of emoji questionnaires used to measure product-elicited emotional associations were assessed across four studies involving the evaluation of written stimuli and tasted food samples. Gender and age did not influence consumer ability to describe and discriminate between stimuli, eliciting emoji profiles that were highly similar. Among more frequent users of emoji/emoticon, the average number of emoji used to characterise the stimuli was significant higher than among less frequent users, and there was a tendency toward greater discrimination, but the differences were small and of little concern regarding ability of the less frequent emoji/emoticon users' ability to perform the research task. The findings of this research provide preliminary evidence about the suitability of emoji surveys to measure product-related emotional associations with different consumer populations.}
}

@article{jaidkaEstimatingGeographicSubjective2020,
  title = {Estimating Geographic Subjective Well-Being from {{Twitter}}: {{A}} Comparison of Dictionary and Data-Driven Language Methods},
  shorttitle = {Estimating Geographic Subjective Well-Being from {{Twitter}}},
  author = {Jaidka, Kokil and Giorgi, Salvatore and Schwartz, H. A. and Kern, Margaret L. and Ungar, Lyle H. and Eichstaedt, Johannes C.},
  year = {2020},
  month = apr,
  journal = {Proceedings of the National Academy of Sciences},
  pages = {201906364},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1906364117},
  urldate = {2020-05-06},
  abstract = {Researchers and policy makers worldwide are interested in measuring the subjective well-being of populations. When users post on social media, they leave behind digital traces that reflect their thoughts and feelings. Aggregation of such digital traces may make it possible to monitor well-being at large scale. However, social media-based methods need to be robust to regional effects if they are to produce reliable estimates. Using a sample of 1.53 billion geotagged English tweets, we provide a systematic evaluation of word-level and data-driven methods for text analysis for generating well-being estimates for 1,208 US counties. We compared Twitter-based county-level estimates with well-being measurements provided by the Gallup-Sharecare Well-Being Index survey through 1.73 million phone surveys. We find that word-level methods (e.g., Linguistic Inquiry and Word Count [LIWC] 2015 and Language Assessment by Mechanical Turk [LabMT]) yielded inconsistent county-level well-being measurements due to regional, cultural, and socioeconomic differences in language use. However, removing as few as three of the most frequent words led to notable improvements in well-being prediction. Data-driven methods provided robust estimates, approximating the Gallup data at up to               r               = 0.64. We show that the findings generalized to county socioeconomic and health outcomes and were robust when poststratifying the samples to be more representative of the general US population. Regional well-being estimation from social media data seems to be robust when supervised data-driven methods are used.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/HKE2XA94/Jaidka et al. - 2020 - Estimating geographic subjective well-being from T.pdf}
}

@article{jaidkaEstimatingGeographicSubjective2020a,
  title = {Estimating Geographic Subjective Well-Being from {{Twitter}}: {{A}} Comparison of Dictionary and Data-Driven Language Methods},
  shorttitle = {Estimating Geographic Subjective Well-Being from {{Twitter}}},
  author = {Jaidka, Kokil and Giorgi, Salvatore and Schwartz, H. A. and Kern, Margaret L. and Ungar, Lyle H. and Eichstaedt, Johannes C.},
  year = {2020},
  month = apr,
  journal = {Proceedings of the National Academy of Sciences},
  pages = {201906364},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1906364117},
  urldate = {2020-05-06},
  abstract = {Researchers and policy makers worldwide are interested in measuring the subjective well-being of populations. When users post on social media, they leave behind digital traces that reflect their thoughts and feelings. Aggregation of such digital traces may make it possible to monitor well-being at large scale. However, social media-based methods need to be robust to regional effects if they are to produce reliable estimates. Using a sample of 1.53 billion geotagged English tweets, we provide a systematic evaluation of word-level and data-driven methods for text analysis for generating well-being estimates for 1,208 US counties. We compared Twitter-based county-level estimates with well-being measurements provided by the Gallup-Sharecare Well-Being Index survey through 1.73 million phone surveys. We find that word-level methods (e.g., Linguistic Inquiry and Word Count [LIWC] 2015 and Language Assessment by Mechanical Turk [LabMT]) yielded inconsistent county-level well-being measurements due to regional, cultural, and socioeconomic differences in language use. However, removing as few as three of the most frequent words led to notable improvements in well-being prediction. Data-driven methods provided robust estimates, approximating the Gallup data at up to               r               = 0.64. We show that the findings generalized to county socioeconomic and health outcomes and were robust when poststratifying the samples to be more representative of the general US population. Regional well-being estimation from social media data seems to be robust when supervised data-driven methods are used.},
  langid = {english}
}

@inproceedings{jaidkaFacebookTwitterCrossplatform2018,
  title = {Facebook versus {{Twitter}}: {{Cross-platform Differences}} in {{Self-Disclosure}} and {{Trait Prediction}}},
  booktitle = {Twelfth {{International AAAI Conference}} on {{Web}} and {{Social Media}}},
  author = {Jaidka, Kokil and Guntuku, Sharath Chandra and Ungar, Lyle H},
  year = {2018},
  pages = {10},
  abstract = {This study compares self-disclosure on Facebook and Twitter through the lens of demographic and psychological traits. Predictive evaluation reveals that language models trained on Facebook posts are more accurate at predicting age, gender, stress, and empathy than those trained on Twitter posts. Qualitative analyses of the underlying linguistic and demographic differences reveal that users are significantly more likely to disclose information about their family, personal concerns, and emotions and provide a more `honest' self-representation on Facebook. On the other hand, the same users significantly preferred to disclose their needs, drives, and ambitions on Twitter. The higher predictive performance of Facebook is also partly due to the greater volume of language on Facebook than Twitter {\textendash} Facebook and Twitter are equally good at predicting user traits when the same-sized language samples are used to train language models. We explore the implications of these differences in cross-platform user trait prediction.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/ATQBVIW6/Jaidka et al. - Facebook versus Twitter Cross-platform Difference.pdf}
}

@book{jamesIntroductionStatisticalLearning2013,
  title = {An Introduction to Statistical Learning},
  author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
  year = {2013},
  volume = {112},
  publisher = {{Springer}}
}

@article{jiaInferringEmotionsLargeScale2019,
  title = {Inferring {{Emotions From Large-Scale Internet Voice Data}}},
  author = {Jia, Jia and Zhou, Suping and Yin, Yufeng and Wu, Boya and Chen, Wei and Meng, Fanbo and Wang, Yanfeng},
  year = {2019},
  month = jul,
  journal = {IEEE Transactions on Multimedia},
  volume = {21},
  number = {7},
  pages = {1853--1866},
  issn = {1520-9210, 1941-0077},
  doi = {10.1109/TMM.2018.2887016},
  urldate = {2021-06-30},
  abstract = {As voice dialog applications (VDAs, e.g., Siri,1 Cortana,2 Google Now3) are increasing in popularity, inferring emotions from the large-scale internet voice data generated from VDAs can help give a more reasonable and humane response. However, the tremendous amounts of users in large-scale internet voice data lead to a great diversity of users accents and expression patterns. Therefore, the traditional speech emotion recognition methods, which mainly target acted corpora, cannot effectively handle the massive and diverse amount of internet voice data. To address this issue, we carry out a series of observations, find suitable emotion categories for large-scale internet voice data, and verify the indicators of the social attributes (query time, query topic, and users location) and emotion inferring. Based on our observations, two different strategies are employed to solve the problem. First, a deep sparse neural network model that uses acoustic information, textual information, and three indicators (a temporal indicator, descriptive indicator, and geosocial indicator) as the input is proposed. Then, to capture the contextual information, we propose a hybrid emotion inference model that includes long short-term memory to capture the acoustic features and a latent dirichlet allocation to extract text features. Experiments on 93 000 utterances collected from the Sogou Voice Assistant4 (Chinese Siri) validate the effectiveness of the proposed methodologies. Furthermore, we compare the two methodologies and give their advantages and disadvantages.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/GYGR4FZC/Jia et al. - 2019 - Inferring Emotions From Large-Scale Internet Voice.pdf}
}

@article{jibrilRelevanceEmoticonsComputerMediated2013,
  title = {Relevance of {{Emoticons}} in {{Computer-Mediated Communication Contexts}}: {{An Overview}}},
  shorttitle = {Relevance of {{Emoticons}} in {{Computer-Mediated Communication Contexts}}},
  author = {Jibril, Tanimu Ahmed and Abdullah, Mardziah Hayati},
  year = {2013},
  month = mar,
  journal = {Asian Social Science},
  volume = {9},
  number = {4},
  issn = {1911-2025, 1911-2017},
  doi = {10.5539/ass.v9n4p201},
  urldate = {2019-07-29},
  abstract = {With the constant growth in Information and Communication Technology (ICT) in the last 50 years or so, electronic communication has become part of the present day system of living. Equally, smileys or emoticons were innovated in 1982, and today the genre has attained a substantial patronage in various aspects of computer-mediated communication (CMC). Ever since written forms of electronic communication lack the face-to-face (F2F) situation attributes, emoticons are seen as socio-emotional suppliers to the CMC. This article reviews scholarly research in that field in order to compile variety of investigations on the application of emoticons in some facets of CMC, i.e. Facebook, Instant Messaging (IM), and Short Messaging Service (SMS). Key findings of the review show that emoticons do not just serve as paralanguage elements rather they are compared to word morphemes with distinctive significative functions. In other words, they are morpheme-like units and could be derivational, inflectional, or abbreviations but not unbound. The findings also indicate that emoticons could be conventionalized as well as being paralinguistic elements, therefore, they should be approached as contributory to conversation itself not mere compensatory to language.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/2CRD6DSE/Jibril und Abdullah - 2013 - Relevance of Emoticons in Computer-Mediated Commun.pdf}
}

@article{jinApplicationBlockchainPlatform2019,
  title = {Application of a {{Blockchain Platform}} to {{Manage}} and {{Secure Personal Genomic Data}}: {{A Case Study}} of {{LifeCODE}}.Ai in {{China}}},
  shorttitle = {Application of a {{Blockchain Platform}} to {{Manage}} and {{Secure Personal Genomic Data}}},
  author = {Jin, Xiao-Ling and Zhang, Miao and Zhou, Zhongyun and Yu, Xiaoyu},
  year = {2019},
  month = sep,
  journal = {Journal of Medical Internet Research},
  volume = {21},
  number = {9},
  pages = {e13587},
  publisher = {{JMIR Publications Inc., Toronto, Canada}},
  doi = {10.2196/13587},
  urldate = {2023-01-26},
  abstract = {Background: The rapid development of genetic and genomic technologies, such as next-generation sequencing and genome editing, has made disease treatment much more precise and effective. The technologies' value can only be realized by the aggregation and analysis of people's genomic and health data. However, the collection and sharing of genomic data has many obstacles, including low data quality, information islands, tampering distortions, missing records, leaking of private data, and gray data transactions. Objective: This study aimed to prove that emerging blockchain technology provides a solution for the protection and management of sensitive personal genomic data because of its decentralization, traceability, encryption algorithms, and antitampering features. Methods: This paper describes the case of a blockchain-based genomic big data platform, LifeCODE.ai, to illustrate the means by which blockchain enables the storage and management of genomic data from the perspectives of data ownership, data sharing, and data security. Results: Blockchain opens up new avenues for dealing with data ownership, data sharing, and data security issues in genomic big data platforms and realizes the psychological empowerment of individuals in the platform. Conclusions: The blockchain platform provides new possibilities for the management and security of genetic data and can help realize the psychological empowerment of individuals in the process, and consequently, the effects of data self-governance, incentive-sharing, and security improvement can be achieved. However, there are still some problems in the blockchain that have not been solved, and which require continuous in-depth research and innovation in the future.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/SQGHC6CJ/Jin et al. - 2019 - Application of a Blockchain Platform to Manage and.pdf}
}

@misc{joelleeEmoticonThirtyWhere2012,
  title = {The {{Emoticon Is Thirty}}! {{But Where Did It Come From}}? [{{Geek History}}]},
  author = {Joel Lee},
  year = {2012}
}

@book{johnHandbookPersonalityThird2008,
  title = {Handbook of {{Personality}}, {{Third Edition}}: {{Theory}} and {{Research}}},
  shorttitle = {Handbook of {{Personality}}, {{Third Edition}}},
  author = {John, Oliver P. and Robins, Richard W. and Pervin, Lawrence A.},
  year = {2008},
  month = aug,
  publisher = {{Guilford Press}},
  abstract = {This authoritative handbook is the reference of choice for researchers and students of personality. Leading authorities describe the most important theoretical approaches in personality and review the state of the science in five broad content areas: biological bases; development; self and social processes; cognitive and motivational processes; and emotion, adjustment, and health. Within each area, chapters present innovative ideas, findings, research designs, and measurement approaches. Areas of integration and consensus are discussed, as are key questions and controversies still facing the field.},
  googlebooks = {8r4KlgerjcUC},
  isbn = {978-1-60623-738-0},
  langid = {english},
  keywords = {Medical / Psychiatry / General,Psychology / Personality,Psychology / Psychotherapy / General,Psychology / Social Psychology}
}

@article{johnstoneVocalCommunicationEmotion2000,
  title = {Vocal Communication of Emotion},
  author = {Johnstone, Tom and Scherer, Klaus R.},
  year = {2000},
  journal = {Handbook of emotions},
  volume = {2},
  pages = {220--235},
  file = {/Users/timokoch/Zotero/storage/CH8ICRLU/Vocal_communication_of_emotion20161217-28878-163bacu-with-cover-page-v2.pdf}
}

@article{jonesSexDifferencesEmoji2020,
  title = {Sex Differences in Emoji Use, Familiarity, and Valence},
  author = {Jones, Lara L. and Wurm, Lee H. and Norville, Gregory A. and Mullins, Kate L.},
  year = {2020},
  month = jul,
  journal = {Computers in Human Behavior},
  volume = {108},
  pages = {106305},
  issn = {07475632},
  doi = {10.1016/j.chb.2020.106305},
  urldate = {2020-03-17},
  abstract = {Emojis (particularly smiley emojis, {$\smiley$}) are increasingly used in computer-mediated communication as well as in applied domains within marketing, healthcare, and psychology. The emotional negativity bias in the facial emotion processing literature posits that women are more sensitive to negative facial emotion than are men. Given the similarity in neural processing between human faces and smiley emojis, women may likewise view negative smiley emojis as more negative than do men. Moreover, the familiarity of the emoji and the partici\- pants' overall emoji use may increase the positivity of the emoji. To investigate these potential influences of sex, familiarity, and emoji use on the valence of smiley emojis, we assessed the familiarity and the perceived valence for 70 iOS facial emojis in a large sample (N {$\frac{1}{4}$} 299; 163 women) of United States college students (Mage {$\frac{1}{4}$} 19.66, SDage {$\frac{1}{4}$} 2.72). Results indicated higher emoji usage and familiarity ratings for women than for men. In assessing valence we found higher overall positive ratings for men than for women. Consistent with the emotional negativity bias, this sex difference was limited to the negative smiley emojis with no sex difference in valence for the positive emojis. The obtained sex differences in smiley emojis' use, familiarity, and valence are an important consideration in the selection of such stimuli in future studies.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/XMFEZ69N/Jones et al. - 2020 - Sex differences in emoji use, familiarity, and val.pdf}
}

@article{jonesTweetingNegativeEmotion2016,
  title = {Tweeting Negative Emotion: {{An}} Investigation of {{Twitter}} Data in the Aftermath of Violence on College Campuses.},
  shorttitle = {Tweeting Negative Emotion},
  author = {Jones, Nickolas M. and Wojcik, Sean P. and Sweeting, Josiah and Silver, Roxane Cohen},
  year = {2016},
  month = dec,
  journal = {Psychological Methods},
  volume = {21},
  number = {4},
  pages = {526--541},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/met0000099},
  urldate = {2022-05-09},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/4QCY5VSK/Jones et al. - 2016 - Tweeting negative emotion An investigation of Twi.pdf}
}

@article{jonnatanMobileDeviceUsage2022,
  title = {Mobile {{Device Usage}} before and during the {{COVID-19 Pandemic}} among {{Rural}} and {{Urban Adults}}},
  author = {Jonnatan, Livia and Seaton, Cherisse L. and Rush, Kathy L. and Li, Eric P. H. and Hasan, Khalad},
  year = {2022},
  month = jan,
  journal = {International Journal of Environmental Research and Public Health},
  volume = {19},
  number = {14},
  pages = {8231},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {1660-4601},
  doi = {10.3390/ijerph19148231},
  urldate = {2023-02-21},
  abstract = {Technology has played a critical role during the COVID-19 pandemic. Despite affording a safe way for people to connect with others, the potential for problematic device usage (e.g., overuse, addiction) should be considered. The goal of this study was to examine mobile device use during the COVID-19 pandemic among rural and urban people in Canada. Based on an online survey conducted in the summer of 2021 in British Columbia (n = 465), participants self-reported spending more hours per day (M = 8.35 h) using technology during the pandemic compared to prior (M = 6.02 h), with higher increases among urban participants (p {$<$} 0.001). Mobile device usage scores were highest for reasons of social connectedness and productivity, with no rural/urban differences; however, urban participants reported higher use of mobile devices for their mental well-being (p = 0.001), but also reported higher, continuous use (p {$<$} 0.001), addiction (p {$<$} 0.001), and detrimental impacts on their physical health (p {$<$} 0.001) compared to rural participants. Because urban participants were more vulnerable to mobile device overuse and addiction during the pandemic, researchers and policy makers should consider the ongoing role and positive/negative impacts of mobile device use, paying particular attention to urban populations.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {COVID-19,mobile device usage,productivity,social connection,well-being},
  file = {/Users/timokoch/Zotero/storage/2R8SWDCF/Jonnatan et al. - 2022 - Mobile Device Usage before and during the COVID-19.pdf}
}

@misc{joshcostineWhatsAppHitsBillion2018,
  title = {{{WhatsApp}} Hits 1.5 Billion Monthly Users. \${{19B}}? {{Not}} so Bad.},
  author = {Josh Costine},
  year = {2018}
}

@article{jurgensEffectActingExperience2015,
  title = {Effect of {{Acting Experience}} on {{Emotion Expression}} and {{Recognition}} in {{Voice}}: {{Non-Actors Provide Better Stimuli}} than {{Expected}}},
  shorttitle = {Effect of {{Acting Experience}} on {{Emotion Expression}} and {{Recognition}} in {{Voice}}},
  author = {J{\"u}rgens, Rebecca and Grass, Annika and Drolet, Matthis and Fischer, Julia},
  year = {2015},
  month = sep,
  journal = {Journal of Nonverbal Behavior},
  volume = {39},
  number = {3},
  pages = {195--214},
  issn = {1573-3653},
  doi = {10.1007/s10919-015-0209-5},
  urldate = {2021-11-23},
  abstract = {Both in the performative arts and in emotion research, professional actors are assumed to be capable of delivering emotions comparable to spontaneous emotional expressions. This study examines the effects of acting training on vocal emotion depiction and recognition. We predicted that professional actors express emotions in a more realistic fashion than non-professional actors. However, professional acting training may lead to a particular speech pattern; this might account for vocal expressions by actors that are less comparable to authentic samples than the ones by non-professional actors. We compared 80 emotional speech tokens from radio interviews with 80 re-enactments by professional and inexperienced actors, respectively. We analyzed recognition accuracies for emotion and authenticity ratings and compared the acoustic structure of the speech tokens. Both play-acted conditions yielded similar recognition accuracies and possessed more variable pitch contours than the spontaneous recordings. However, professional actors exhibited signs of different articulation patterns compared to non-trained speakers. Our results indicate that for emotion research, emotional expressions by professional actors are not better suited than those from non-actors.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/XLNCHXBP/Jürgens et al. - 2015 - Effect of Acting Experience on Emotion Expression .pdf}
}

@article{juslinCommunicationEmotionsVocal2003,
  title = {Communication of Emotions in Vocal Expression and Music Performance: {{Different}} Channels, Same Code?},
  shorttitle = {Communication of Emotions in Vocal Expression and Music Performance},
  author = {Juslin, Patrik N. and Laukka, Petri},
  year = {2003},
  journal = {Psychological Bulletin},
  volume = {129},
  number = {5},
  pages = {770--814},
  issn = {1939-1455, 0033-2909},
  doi = {10.1037/0033-2909.129.5.770},
  urldate = {2021-11-16},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/SKM8QC5R/Juslin und Laukka - 2003 - Communication of emotions in vocal expression and .pdf}
}

@article{juslinMirrorOurSoul2018,
  title = {The {{Mirror}} to {{Our Soul}}? {{Comparisons}} of {{Spontaneous}} and {{Posed Vocal Expression}} of {{Emotion}}},
  shorttitle = {The {{Mirror}} to {{Our Soul}}?},
  author = {Juslin, Patrik N. and Laukka, Petri and B{\"a}nziger, Tanja},
  year = {2018},
  month = mar,
  journal = {Journal of Nonverbal Behavior},
  volume = {42},
  number = {1},
  pages = {1--40},
  issn = {1573-3653},
  doi = {10.1007/s10919-017-0268-x},
  urldate = {2021-10-28},
  abstract = {It has been the subject of much debate in the study of vocal expression of emotions whether posed expressions (e.g., actor portrayals) are different from spontaneous expressions. In the present investigation, we assembled a new database consisting of 1877 voice clips from 23 datasets, and used it to systematically compare spontaneous and posed expressions across 3 experiments. Results showed that (a) spontaneous expressions were generally rated as more genuinely emotional than were posed expressions, even when controlling for differences in emotion intensity, (b) there were differences between the two stimulus types with regard to their acoustic characteristics, and (c) spontaneous expressions with a high emotion intensity conveyed discrete emotions to listeners to a similar degree as has previously been found for posed expressions, supporting a dose{\textendash}response relationship between intensity of expression and discreteness in perceived emotions. Our conclusion is that there are reliable differences between spontaneous and posed expressions, though not necessarily in the ways commonly assumed. Implications for emotion theories and the use of emotion portrayals in studies of vocal expression are discussed.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/BB27BAV8/Juslin et al. - 2018 - The Mirror to Our Soul Comparisons of Spontaneous.pdf}
}

@article{juslinSpontaneousVocalExpressions2020,
  title = {Spontaneous Vocal Expressions from Everyday Life Convey Discrete Emotions to Listeners},
  author = {Juslin, Patrik N. and Laukka, Petri and Harmat, L{\'a}szl{\'o} and Ovsiannikow, Melissa},
  year = {2020},
  journal = {Emotion},
  pages = {No Pagination Specified-No Pagination Specified},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1931-1516},
  doi = {10.1037/emo0000762},
  abstract = {Emotional expression is crucial for social interaction. Yet researchers disagree about whether nonverbal expressions truly reflect felt emotions and whether they convey discrete emotions to perceivers in everyday life. In the present study, 384 clips of vocal expression recorded in a field setting were rated by the speakers themselves and by na{\"i}ve listeners with regard to their emotional contents. Results suggested that most expressions in everyday life are reflective of felt emotions in speakers. Seventy-three percent of the voice clips involved moderate to high emotion intensity. Speaker{\textendash}listener agreement concerning expressed emotions was 5 times higher than would be expected from chance alone, and agreement was significantly higher for voice clips with high emotion intensity than for clips with low intensity. Acoustic analysis of the clips revealed emotion-specific patterns of voice cues. ``Mixed emotions'' occurred in 41\% of the clips. Such expressions were typically interpreted by listeners as conveying one or the other of the two felt emotions. Mixed emotions were rarely recognized as such. The results are discussed regarding their implications for the domain of emotional expression in general, and vocal expression in particular. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
  keywords = {Audiences,Auditory Perception,Emotionality (Personality),Emotions,Nonverbal Communication,Oral Communication,Social Interaction,Vocalization,Voice},
  file = {/Users/timokoch/Zotero/storage/K6XQDBY7/2020-69299-001.html}
}

@article{kacewiczPronounUseReflects2014,
  title = {Pronoun {{Use Reflects Standings}} in {{Social Hierarchies}}},
  author = {Kacewicz, Ewa and Pennebaker, James W. and Davis, Matthew and Jeon, Moongee and Graesser, Arthur C.},
  year = {2014},
  month = mar,
  journal = {Journal of Language and Social Psychology},
  volume = {33},
  number = {2},
  pages = {125--143},
  issn = {0261-927X, 1552-6526},
  doi = {10.1177/0261927X13502654},
  urldate = {2019-08-09},
  abstract = {Five studies explored the ways relative rank is revealed among individuals in small groups through their natural use of pronouns. In Experiment 1, four-person groups worked on a decision-making task with randomly assigned leadership status. In Studies 2 and 3, two-person groups either worked on a task or chatted informally in a get-to-know-you session. Study 4 was a naturalistic study of incoming and outgoing e-mail of 9 participants who provided information on their correspondents' relative status. The last study examined 40 letters written by soldiers in the regime of Saddam Hussein. Computerized text analyses across the five studies found that people with higher status consistently used fewer first-person singular, and more first-person plural and second-person singular pronouns. Natural language use during group interaction suggests that status is associated with attentional biases, such that higher rank is linked with other-focus whereas lower rank is linked with self-focus.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/CWFTFTZ9/Kacewicz et al. - 2014 - Pronoun Use Reflects Standings in Social Hierarchi.pdf}
}

@article{kahnMeasuringEmotionalExpression2007,
  title = {Measuring {{Emotional Expression}} with the {{Linguistic Inquiry}} and {{Word Count}}},
  author = {Kahn, Jeffrey H. and Tobin, Ren{\'e}e M. and Massey, Audra E. and Anderson, Jennifer A.},
  year = {2007},
  journal = {The American Journal of Psychology},
  volume = {120},
  number = {2},
  eprint = {20445398},
  eprinttype = {jstor},
  pages = {263--286},
  issn = {0002-9556},
  doi = {10.2307/20445398},
  urldate = {2019-02-11},
  abstract = {The Linguistic Inquiry and Word Count (LIWC) text analysis program often is used as a measure of emotion expression, yet the construct validity of its use for this purpose has not been examined. Three experimental studies assessed whether the LIWC counts of emotion processes words are sensitive to verbal expression of sadness and amusement. Experiment 1 determined that sad and amusing written autobiographical memories differed in LIWC emotion counts in expected ways. Experiment 2 revealed that reactions to emotionally provocative film clips designed to manipulate the momentary experience of sadness and amusement differed in LIWC counts. Experiment 3 replicated the findings of Experiment 2 and found generally weak relations between LIWC emotion counts and individual differences in emotional reactivity, dispositional expressivity, and personality. The LIWC therefore appears to be a valid method for measuring verbal expression of emotion.},
  file = {/Users/timokoch/Zotero/storage/3EQ3ZLK8/Kahn et al. - 2007 - Measuring Emotional Expression with the Linguistic.pdf}
}

@article{kangUnderstandingEmotionChanges2022,
  title = {Understanding {{Emotion Changes}} in {{Mobile Experience Sampling}}},
  author = {Kang, Soowon},
  year = {2022},
  pages = {14},
  abstract = {Mobile experience sampling methods (ESMs) are widely used to measure users' afective states by randomly sending self-report requests. However, this random probing can interrupt users and adversely infuence users' emotional states by inducing disturbance and stress. This work aims to understand how ESMs themselves may compromise the validity of ESM responses and what contextual factors contribute to changes in emotions when users respond to ESMs. Towards this goal, we analyze 2,227 samples of the mobile ESM data collected from 78 participants. Our results show ESM interruptions positively or negatively afected users' emotional states in at least 38\% of ESMs, and the changes in emotions are closely related to the contexts users were in prior to ESMs. Finally, we discuss the implications of using the ESM and possible considerations for mitigating the variability in emotional responses in the context of mobile data collection for afective computing.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/G3S88UFY/Kang - 2022 - Understanding Emotion Changes in Mobile Experience.pdf}
}

@inproceedings{karadoganCombiningSemanticAcoustic2012,
  title = {Combining Semantic and Acoustic Features for Valence and Arousal Recognition in Speech},
  booktitle = {2012 3rd {{International Workshop}} on {{Cognitive Information Processing}} ({{CIP}})},
  author = {Karadogan, Seliz Gulsen and Larsen, Jan},
  year = {2012},
  month = may,
  pages = {1--6},
  publisher = {{IEEE}},
  address = {{Baiona, Spain}},
  doi = {10.1109/CIP.2012.6232924},
  urldate = {2021-11-28},
  abstract = {The recognition of affect in speech has attracted a lot of interest recently; especially in the area of cognitive and computer sciences. Most of the previous studies focused on the recognition of basic emotions (such as happiness, sadness and anger) using categorical approach. Recently, the focus has been shifting towards dimensional affect recognition based on the idea that emotional states are not independent from one another but related in a systematic manner. In this paper, we design a continuous dimensional speech affect recognition model that combines acoustic and semantic features. We design our own corpus that consists of 59 short movie clips with audio and text in subtitle format, rated by human subjects in arousal and valence (A-V) dimensions. For the acoustic part, we combine many features and use correlation based feature selection and apply support vector regression. For the semantic part, we use the affective norms for English words (ANEW), that are rated also in A-V dimensions, as keywords and apply latent semantics analysis (LSA) on those words and words in the clips to estimate A-V values in the clips. Finally, the results of acoustic and semantic parts are combined. We show that combining semantic and acoustic information for dimensional speech recognition improves the results. Moreover, we show that valence is better estimated using semantic features while arousal is better estimated using acoustic features.},
  isbn = {978-1-4673-1878-5 978-1-4673-1877-8 978-1-4673-1876-1},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/68UY6C5F/Karadogan und Larsen - 2012 - Combining semantic and acoustic features for valen.pdf}
}

@article{karatzoglouKernlabS4Package2004,
  title = {Kernlab - {{An S4 Package}} for {{Kernel Methods}} in {{R}}},
  author = {Karatzoglou, Alexandros and Smola, Alex and Hornik, Kurt and Zeileis, Achim},
  year = {2004},
  journal = {Journal of Statistical Software},
  volume = {11},
  number = {9},
  issn = {1548-7660},
  doi = {10.18637/jss.v011.i09},
  urldate = {2020-03-03},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/DQ7LTQFH/Karatzoglou et al. - 2004 - bkernlabb - An iS4i Package for Kernel M.pdf}
}

@article{karatzoglouKernlabS4Package2004a,
  title = {{\textbf{Kernlab}} - {{An}} {{{\emph{S4}}}} {{Package}} for {{Kernel Methods}} in {{{\emph{R}}}}},
  author = {Karatzoglou, Alexandros and Smola, Alex and Hornik, Kurt and Zeileis, Achim},
  year = {2004},
  journal = {Journal of Statistical Software},
  volume = {11},
  number = {9},
  issn = {1548-7660},
  doi = {10.18637/jss.v011.i09},
  urldate = {2020-03-03},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/E82SJVGA/Karatzoglou et al. - 2004 - bkernlabb - An iS4i Package for Kernel M.pdf}
}

@article{kassamEffectsMeasuringEmotion2013,
  title = {The Effects of Measuring Emotion: Physiological Reactions to Emotional Situations Depend on Whether Someone Is Asking},
  shorttitle = {The Effects of Measuring Emotion},
  author = {Kassam, Karim S. and Mendes, Wendy Berry},
  year = {2013},
  journal = {PloS One},
  volume = {8},
  number = {7},
  pages = {e64959},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0064959},
  abstract = {Measurement effects exist throughout the sciences-the act of measuring often changes the properties of the observed. We suggest emotion research is no exception. The awareness and conscious assessment required by self-report of emotion may significantly alter emotional processes. In this study, participants engaged in a difficult math task designed to induce anger or shame while their cardiovascular responses were measured. Half of the participants were asked to report on their emotional states and appraise their feelings throughout the experiment, whereas the other half completed a control questionnaire. Among those in the anger condition, participants assigned to report on their emotions exhibited qualitatively different physiological responses from those who did not report. For participants in the shame condition, there were no significant differences in physiology based on the self-report manipulation. The study demonstrates that the simple act of reporting on an emotional state may have a substantial impact on the body's reaction to an emotional situation.},
  langid = {english},
  pmcid = {PMC3680163},
  pmid = {23785407},
  keywords = {Adult,Anger,Awareness,Cardiac Output,Consciousness,Female,Heart Rate,Humans,Male,Psychological Tests,Self Report,Shame,Social Behavior,Stroke Volume,Surveys and Questionnaires,Vascular Resistance},
  file = {/Users/timokoch/Zotero/storage/JYWY3CEE/Kassam und Mendes - 2013 - The effects of measuring emotion physiological re.pdf}
}

@article{kassamEffectsMeasuringEmotion2013a,
  title = {The {{Effects}} of {{Measuring Emotion}}: {{Physiological Reactions}} to {{Emotional Situations Depend}} on Whether {{Someone Is Asking}}},
  shorttitle = {The {{Effects}} of {{Measuring Emotion}}},
  author = {Kassam, Karim S. and Mendes, Wendy Berry},
  year = {2013},
  month = may,
  journal = {PLOS ONE},
  volume = {8},
  number = {6},
  pages = {e64959},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0064959},
  urldate = {2022-05-09},
  abstract = {Measurement effects exist throughout the sciences{\textendash}the act of measuring often changes the properties of the observed. We suggest emotion research is no exception. The awareness and conscious assessment required by self-report of emotion may significantly alter emotional processes. In this study, participants engaged in a difficult math task designed to induce anger or shame while their cardiovascular responses were measured. Half of the participants were asked to report on their emotional states and appraise their feelings throughout the experiment, whereas the other half completed a control questionnaire. Among those in the anger condition, participants assigned to report on their emotions exhibited qualitatively different physiological responses from those who did not report. For participants in the shame condition, there were no significant differences in physiology based on the self-report manipulation. The study demonstrates that the simple act of reporting on an emotional state may have a substantial impact on the body's reaction to an emotional situation.},
  langid = {english},
  keywords = {Blood pressure,Cardiac output,Cognition,Emotions,Fluid physiology,Heart rate,Psychometrics,Self-consciousness},
  file = {/Users/timokoch/Zotero/storage/IX2JYQHC/Kassam und Mendes - 2013 - The Effects of Measuring Emotion Physiological Re.pdf;/Users/timokoch/Zotero/storage/QVW385RQ/article.html}
}

@article{kathawallaEasingOpenScience2021,
  title = {Easing {{Into Open Science}}: {{A Guide}} for {{Graduate Students}} and {{Their Advisors}}},
  shorttitle = {Easing {{Into Open Science}}},
  author = {Kathawalla, Ummul-Kiram and Silverstein, Priya and Syed, Moin},
  year = {2021},
  month = jan,
  journal = {Collabra: Psychology},
  volume = {7},
  number = {1},
  pages = {18684},
  issn = {2474-7394},
  doi = {10.1525/collabra.18684},
  urldate = {2022-12-02},
  abstract = {This article provides a roadmap to assist graduate students and their advisors to engage in open science practices. We suggest eight open science practices that novice graduate students could begin adopting today. The topics we cover include journal clubs, project workflow, preprints, reproducible code, data sharing, transparent writing, preregistration, and registered reports. To address concerns about not knowing how to engage in open science practices, we provide a difficulty rating of each behavior (easy, medium, difficult), present them in order of suggested adoption, and follow the format of what, why, how, and worries. We give graduate students ideas on how to approach conversations with their advisors/collaborators, ideas on how to integrate open science practices within the graduate school framework, and specific resources on how to engage with each behavior. We emphasize that engaging in open science behaviors need not be an all or nothing approach, but rather graduate students can engage with any number of the behaviors outlined.},
  file = {/Users/timokoch/Zotero/storage/SGI6DSF8/Kathawalla et al. - 2021 - Easing Into Open Science A Guide for Graduate Stu.pdf;/Users/timokoch/Zotero/storage/VHWGBFXW/Easing-Into-Open-Science-A-Guide-for-Graduate.html}
}

@article{katsumataChangesUseMobile2022,
  title = {Changes in the Use of Mobile Devices during the Crisis: {{Immediate}} Response to the {{COVID-19}} Pandemic},
  shorttitle = {Changes in the Use of Mobile Devices during the Crisis},
  author = {Katsumata, Sotaro and Ichikohji, Takeyasu and Nakano, Satoshi and Yamaguchi, Shinichi and Ikuine, Fumihiko},
  year = {2022},
  month = mar,
  journal = {Computers in Human Behavior Reports},
  volume = {5},
  pages = {100168},
  issn = {2451-9588},
  doi = {10.1016/j.chbr.2022.100168},
  urldate = {2023-02-21},
  abstract = {We analyze the smartphone usage behavior of individuals against the background of the spread of the coronavirus disease (COVID-19) to classify usage behaviors and examine the factors that lead to change. Specifically, we examine the differences in smartphone usage between the first wave and the second wave of the epidemic in Japan. On average, the frequency of use increased, especially during the first wave of the epidemic. Next, we classify the changes in usage behavior and examine the differences between individuals whose smartphone usage time increased and those whose usage time decreased. Our analysis using personal characteristics as explanatory variables suggests that demographic variables may explain behavioral changes. We were able to classify the factors into three categories: positive factors that promote an increase in usage time, negative factors that promote a decrease, and variation factors that promote fluctuations.},
  langid = {english},
  keywords = {Consumer behavior,COVID-19,Disasters,Mobile apps},
  file = {/Users/timokoch/Zotero/storage/AD9JURUQ/Katsumata et al. - 2022 - Changes in the use of mobile devices during the cr.pdf}
}

@misc{kayeCompaniesAreUsing2022,
  title = {Companies Are Using {{AI}} to Monitor Your Mood during Sales Calls. {{Zoom}} Might Be Next.},
  author = {Kaye, Kate},
  year = {2022},
  month = apr,
  journal = {Protocol},
  urldate = {2022-12-02},
  abstract = {Software-makers claim that AI can help sellers not only communicate better, but detect the ``emotional state'' of a deal {\textemdash} and the people they're selling to.},
  chapter = {Enterprise},
  howpublished = {https://www.protocol.com/enterprise/emotion-ai-sales-virtual-zoom},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/P4HM3BXY/emotion-ai-sales-virtual-zoom.html}
}

@article{kayeEmojiSpatialStroop2022,
  title = {The {{Emoji Spatial Stroop Task}}: {{Exploring}} the Impact of Vertical Positioning of Emoji on Emotional Processing},
  shorttitle = {The {{Emoji Spatial Stroop Task}}},
  author = {Kaye, Linda K. and Darker, Gemma M. and {Rodriguez-Cuadrado}, Sara and Wall, Helen J. and Malone, Stephanie A.},
  year = {2022},
  month = jul,
  journal = {Computers in Human Behavior},
  volume = {132},
  pages = {107267},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2022.107267},
  urldate = {2022-03-15},
  abstract = {Despite emoji often being assumed to be a form of emotional communication, the emotional affordances of these are not yet fully established. The current study employed the Emoji Spatial Stroop Task to explore whether spatial iconicity affects semantic-relatedness judgments relating to emoji stimuli. Namely, emoji stimuli were displayed in various vertical positions and valence perceptions were measured. A 3 (emoji valence; positive, negative, neutral) x 3 (vertical position; upper, lower, central) within-participants design was used to determine the impacts on valence perceptions. Valence perceptions were obtained from ratings on how positive/negative participants perceived stimuli to be on an 11-point Likert scale (-5 negative, 0 neutral and +5 positive). Findings from 157 participants revealed that, after controlling for current mood, both emoji valence and their vertical positioning impacted significantly on valence ratings. The valence~{\texttimes}~positioning interaction effect was also significant, highlighting a congruence effect whereby positive emoji in higher vertical space were rated significantly more positively than when in central or lower space, and negative emoji were rated significantly more negatively when displayed in lower vertical space compared to central or upper space. These congruence effects suggest we may embody emoji as symbolic objects to represent abstract emotional concepts.},
  langid = {english},
  keywords = {Emoji,Emoji spatial stroop task,Spatial stroop,Valence,Vertical positioning},
  file = {/Users/timokoch/Zotero/storage/REUXC6KW/S0747563222000899.html}
}

@article{kelleyMachineLearningLanguage2022,
  title = {Machine Learning of Language Use on {{Twitter}} Reveals Weak and Non-Specific Predictions},
  author = {Kelley, Sean and Mhaonaigh, Caoimhe and Burke, Louise and Whelan, Robert and Gillan, Claire},
  year = {2022},
  month = mar,
  journal = {npj Digital Medicine},
  volume = {5},
  pages = {35},
  doi = {10.1038/s41746-022-00576-y},
  abstract = {Depressed individuals use language differently than healthy controls and it has been proposed that social media posts can be used to identify depression. Much of the evidence behind this claim relies on indirect measures of mental health and few studies have tested if these language features are specific to depression versus other aspects of mental health. We analysed the Tweets of 1006 participants who completed questionnaires assessing symptoms of depression and 8 other mental health conditions. Daily Tweets were subjected to textual analysis and the resulting linguistic features were used to train an Elastic Net model on depression severity, using nested cross-validation. We then tested performance in a held-out test set (30\%), comparing predictions of depression versus 8 other aspects of mental health. The depression trained model had modest out-of-sample predictive performance, explaining 2.5\% of variance in depression symptoms (R2 = 0.025, r = 0.16). The performance of this model was as-good or superior when used to identify other aspects of mental health: schizotypy, social anxiety, eating disorders, generalised anxiety, above chance for obsessive-compulsive disorder, apathy, but not significant for alcohol abuse or impulsivity. Machine learning analysis of social media data, when trained on well-validated clinical instruments, could not make meaningful individualised predictions regarding users' mental health. Furthermore, language use associated with depression was non-specific, having similar performance in predicting other mental health problems.},
  file = {/Users/timokoch/Zotero/storage/U42DCJLB/Kelley et al. - 2022 - Machine learning of language use on Twitter reveal.pdf}
}

@article{kelleyUsingLanguageSocial2022,
  title = {Using Language in Social Media Posts to Study the Network Dynamics of Depression Longitudinally},
  author = {Kelley, Sean and Gillan, Claire},
  year = {2022},
  month = feb,
  journal = {Nature Communications},
  volume = {13},
  doi = {10.1038/s41467-022-28513-3},
  abstract = {Network theory of mental illness posits that causal interactions between symptoms give rise to mental health disorders. Increasing evidence suggests that depression network connectivity may be a risk factor for transitioning and sustaining a depressive state. Here we analysed social media (Twitter) data from 946 participants who retrospectively self-reported the dates of any depressive episodes in the past 12 months and current depressive symptom severity. We construct personalised, within-subject, networks based on depression-related linguistic features. We show an association existed between current depression severity and 8 out of 9 text features examined. Individuals with greater depression severity had higher overall network connectivity between depression-relevant linguistic features than those with lesser severity. We observed within-subject changes in overall network connectivity associated with the dates of a self-reported depressive episode. The connectivity within personalized networks of depression-associated linguistic features may change dynamically with changes in current depression symptoms.},
  file = {/Users/timokoch/Zotero/storage/PTJK67KE/Kelley und Gillan - 2022 - Using language in social media posts to study the .pdf}
}

@article{keltnerEmotionalExpressionAdvances2019,
  title = {Emotional {{Expression}}: {{Advances}} in {{Basic Emotion Theory}}},
  shorttitle = {Emotional {{Expression}}},
  author = {Keltner, Dacher and Sauter, Disa and Tracy, Jessica and Cowen, Alan},
  year = {2019},
  month = jun,
  journal = {Journal of nonverbal behavior},
  volume = {43},
  number = {2},
  pages = {133--160},
  issn = {0191-5886},
  doi = {10.1007/s10919-019-00293-3},
  urldate = {2022-11-03},
  abstract = {In this article, we review recent developments in the study of emotional expression within a basic emotion framework. Dozens of new studies find that upwards of 20 emotions are signaled in multimodal and dynamic patterns of expressive behavior. Moving beyond word to stimulus matching paradigms, new studies are detailing the more nuanced and complex processes involved in emotion recognition and the structure of how people perceive emotional expression. Finally, we consider new studies documenting contextual influences upon emotion recognition. We conclude by extending these recent findings to questions about emotion-related physiology and the mammalian precursors of human emotion.},
  pmcid = {PMC6687086},
  pmid = {31395997},
  file = {/Users/timokoch/Zotero/storage/PVUY9T4C/Keltner et al. - 2019 - Emotional Expression Advances in Basic Emotion Th.pdf}
}

@misc{kennedyTextAnalysisPsychology2021,
  title = {Text {{Analysis}} for {{Psychology}}: {{Methods}}, {{Principles}}, and {{Practices}}},
  shorttitle = {Text {{Analysis}} for {{Psychology}}},
  author = {Kennedy, Brendan and Ashokkumar, Ashwini and Boyd, Ryan L. and Dehghani, Morteza},
  year = {2021},
  month = feb,
  publisher = {{PsyArXiv}},
  doi = {10.31234/osf.io/h2b8t},
  urldate = {2022-07-11},
  abstract = {Due to the explosion of new sources of human language data and the rapid progression of computational methods for extracting meaning from natural language, language analysis is a promising, though complicated, category of psychological research. In this chapter, we give a modern perspective on language analysis as it applies to psychology, uniting historical context, the diverse range of domains studied in psychology via language, and the methodological rigor of natural language processing (NLP) and machine learning. Top{\textendash}down methods (e.g., dictionary approaches, text annotation) are presented alongside bottom{\textendash}up methods (e.g., topic modeling, word embedding, language modeling) in order to give the reader a comprehensive grounding in the tools available and the recommended practices involved in applying them. We conclude with a view of the future of language analysis, specifically the ways in which psychology and NLP will continue to co-develop.},
  langid = {american},
  keywords = {Computational Modeling,Language,Methodology,Natural Language Processing,Quantitative Methods,Social and Behavioral Sciences,Statistical Methods,Text Analysis},
  file = {/Users/timokoch/Zotero/storage/SPCALNX8/Kennedy et al. - 2021 - Text Analysis for Psychology Methods, Principles,.pdf}
}

@article{kepuskaComparingSpeechRecognition2017,
  title = {Comparing {{Speech Recognition Systems}} ({{Microsoft API}}, {{Google API And CMU Sphinx}})},
  author = {K{\"e}puska, Veton},
  year = {2017},
  month = mar,
  journal = {International Journal of Engineering Research and Applications},
  volume = {07},
  number = {03},
  pages = {20--24},
  issn = {22489622, 22489622},
  doi = {10.9790/9622-0703022024},
  urldate = {2018-12-11},
  abstract = {The idea of this paper is to design a tool that will be used to test and compare commercial speech recognition systems, such as Microsoft Speech API and Google Speech API, with open-source speech recognition systems such as Sphinx-4. The best way to compare automatic speech recognition systems in different environments is by using some audio recordings that were selected from different sources and calculating the word error rate (WER). Although the WER of the three aforementioned systems were acceptable, it was observed that the Google API is superior.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/48BZG7AR/Këpuska - 2017 - Comparing Speech Recognition Systems (Microsoft AP.pdf}
}

@article{kernGainingInsightsSocial2016,
  title = {Gaining Insights from Social Media Language: {{Methodologies}} and Challenges.},
  shorttitle = {Gaining Insights from Social Media Language},
  author = {Kern, Margaret L. and Park, Gregory and Eichstaedt, Johannes C. and Schwartz, H. A. and Sap, Maarten and Smith, Laura K. and Ungar, Lyle H.},
  year = {2016},
  journal = {Psychological Methods},
  volume = {21},
  number = {4},
  pages = {507--525},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/met0000091},
  urldate = {2018-11-05},
  abstract = {Language data available through social media provide opportunities to study people at an unprecedented scale. However, little guidance is available to psychologists who want to enter this area of research. Drawing on tools and techniques developed in natural language processing, we first introduce psychologists to social media language research, identifying descriptive and predictive analyses that language data allow. Second, we describe how raw language data can be accessed and quantified for inclusion in subsequent analyses, exploring personality as expressed on Facebook to illustrate. Third, we highlight challenges and issues to be considered, including accessing and processing the data, interpreting effects, and ethical issues. Social media has become a valuable part of social life, and there is much we can learn by bringing together the tools of computer science with the theories and insights of psychology.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/JJS7YM3V/Kern et al. - 2016 - Gaining insights from social media language Metho.pdf}
}

@article{kernOnlineSocialSelf2014,
  title = {The Online Social Self: An Open Vocabulary Approach to Personality},
  author = {Kern, M. L. and Eichstaedt, J. C. and Schwartz, H. A. and Dziurzynski, L. and Ungar, L. H. and Stillwell, D. J. and Kosinski, Michal and Ramones, S. M. and Seligman, M. E.},
  year = {2014},
  month = apr,
  journal = {Assessment},
  volume = {21},
  number = {2},
  pages = {158--69},
  issn = {1552-3489 (Electronic) 1073-1911 (Linking)},
  doi = {10.1177/1073191113514104},
  abstract = {OBJECTIVE: We present a new open language analysis approach that identifies and visually summarizes the dominant naturally occurring words and phrases that most distinguished each Big Five personality trait. METHOD: Using millions of posts from 69,792 Facebook users, we examined the correlation of personality traits with online word usage. Our analysis method consists of feature extraction, correlational analysis, and visualization. RESULTS: The distinguishing words and phrases were face valid and provide insight into processes that underlie the Big Five traits. CONCLUSION: Open-ended data driven exploration of large datasets combined with established psychological theory and measures offers new tools to further understand the human psyche.},
  keywords = {*Personality,*Social Media,*Vocabulary,Adolescent,Adult,Age Factors,Aged,Big Five personality,computational social science,Female,Humans,interdisciplinary research,linguistic analysis,Linguistics,Male,Middle Aged,online studies,Sex Factors,Young Adult}
}

@article{keuschCoverageErrorData2020,
  title = {Coverage {{Error}} in {{Data Collection Combining Mobile Surveys With Passive Measurement Using Apps}}: {{Data From}} a {{German National Survey}}},
  shorttitle = {Coverage {{Error}} in {{Data Collection Combining Mobile Surveys With Passive Measurement Using Apps}}},
  author = {Keusch, Florian and B{\"a}hr, Sebastian and Haas, Georg-Christoph and Kreuter, Frauke and Trappmann, Mark},
  year = {2020},
  month = apr,
  journal = {Sociological Methods \& Research},
  pages = {0049124120914924},
  publisher = {{SAGE Publications Inc}},
  issn = {0049-1241},
  doi = {10.1177/0049124120914924},
  urldate = {2023-02-21},
  abstract = {Researchers are combining self-reports from mobile surveys with passive data collection using sensors and apps on smartphones increasingly more often. While smartphones are commonly used in some groups of individuals, smartphone penetration is significantly lower in other groups. In addition, different operating systems (OSs) limit how mobile data can be collected passively. These limitations cause concern about coverage error in studies targeting the general population. Based on data from the Panel Study Labour Market and Social Security (PASS), an annual probability-based mixed-mode survey on the labor market and poverty in Germany, we find that smartphone ownership and ownership of smartphones with specific OSs are correlated with a number of sociodemographic and substantive variables. The use of weighting techniques based on sociodemographic information available for both owners and nonowners reduces these differences but does not eliminate them.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/IBI9UJ3P/Keusch et al. - 2020 - Coverage Error in Data Collection Combining Mobile.pdf}
}

@misc{kikiadamsReceptivitiSampleData2016,
  title = {Receptiviti {{Sample Data Repository}}},
  author = {Kiki Adams},
  year = {2016}
}

@article{kimOnlineSelfDisclosureReview,
  title = {Online {{Self-Disclosure}}: {{A Review}} of {{Research}}},
  author = {Kim, Jinsuk and Dindia, Kathryn},
  pages = {26},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/KYIV9HNA/Kim und Dindia - Online Self-Disclosure A Review of Research.pdf}
}

@article{kintschCognitivePsychologyDiscourse1978,
  title = {Cognitive Psychology and Discourse: {{Recalling}} and Summarizing Stories},
  author = {Kintsch, Teun A. van Dijk-Walter and Van Dijk, T. A.},
  year = {1978},
  journal = {Current trends in textlinguistics},
  pages = {61}
}

@misc{kjellAIbasedLargeLanguage2023,
  title = {{{AI-based Large Language Models}} Are {{Ready}} to {{Transform Psychological Health Assessment}}},
  author = {Kjell, Oscar and Kjell, Katarina and Schwartz, H. Andrew},
  year = {2023},
  month = jan,
  publisher = {{PsyArXiv}},
  doi = {10.31234/osf.io/yfd8g},
  urldate = {2023-03-01},
  abstract = {Artificial intelligence-based (AI-based) language analysis has been undergoing a purported ``paradigm shift'' initiated by new machine learning models, large language models. These models, such as GPT3 or BERT, have led to unprecedented accuracies over most computerized language processing tasks such as web search, automatic machine translation, and question answering, while their chat-based forms like ChatGPT have captured the interest of over a million users. The success of the large language model is mostly attributed to its capability to numerically represent words in their context, long a weakness of popular language assessment techniques that use ``bag-of-words'' or word count approaches. While many potential applications, from therapy to health information education, are beginning to be studied on the heels of chatGPT's success, here we suggest these models are already ready to improve how we do psychological assessment. We present the case for AI's paradigm shift to large language models to be the missing piece for a parallel transformation in mental health assessment from the strong reliance on rating scale responses.},
  langid = {american},
  keywords = {Artificial Intelligence,Assessment,Psychiatry,Psychology,Quantitative Methods,Social and Behavioral Sciences,Statistical Methods,Transformers},
  file = {/Users/timokoch/Zotero/storage/FUTCQ2P3/Kjell et al. - 2023 - AI-based Large Language Models are Ready to Transf.pdf}
}

@article{kjellNaturalLanguageAnalyzed2022,
  title = {Natural Language Analyzed with {{AI-based}} Transformers Predict Traditional Subjective Well-Being Measures Approaching the Theoretical Upper Limits in Accuracy},
  author = {Kjell, Oscar and Sikstr{\"o}m, Sverker and Kjell, Katarina and Schwartz, H. Andrew},
  year = {2022},
  month = dec,
  journal = {Scientific Reports},
  volume = {12},
  number = {1},
  pages = {3918},
  issn = {2045-2322},
  doi = {10.1038/s41598-022-07520-w},
  urldate = {2022-03-15},
  abstract = {Abstract                            We show that using a recent break-through in artificial intelligence {\textendash}               transformers{\textendash}               , psychological assessments from text-responses can approach theoretical upper limits in accuracy, converging with standard psychological rating scales. Text-responses use people's primary form of communication {\textendash}               natural language               {\textendash} and have been suggested as a more ecologically-valid response format than closed-ended rating scales that dominate social science. However, previous language analysis techniques left a gap between how accurately they converged with standard rating scales and how well ratings scales converge with themselves {\textendash} a theoretical upper-limit in accuracy. Most recently, AI-based language analysis has gone through a transformation as nearly all of its applications, from Web search to personalized assistants (e.g., Alexa and Siri), have shown unprecedented improvement by using transformers. We evaluate transformers for estimating psychological well-being from questionnaire text- and descriptive word-responses, and find accuracies converging with rating scales that approach the theoretical upper limits (Pearson               r               \,=~0.85,               p               \,{$<$}\,0.001,               N               \,=\,608; in line with most metrics of rating scale reliability). These findings suggest an avenue for modernizing the ubiquitous questionnaire and ultimately opening doors to a greater understanding of the human condition.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/8CHAMJVF/Kjell et al. - 2022 - Natural language analyzed with AI-based transforme.pdf}
}

@misc{kjellRatingScalesLarge2023,
  title = {Beyond {{Rating Scales}}: {{Large Language Models}} Are {{Poised}} to {{Transform Psychological Health Assessment}}},
  shorttitle = {Beyond {{Rating Scales}}},
  author = {Kjell, Oscar and Kjell, Katarina and Schwartz, H. Andrew},
  year = {2023},
  month = jan,
  publisher = {{PsyArXiv}},
  doi = {10.31234/osf.io/yfd8g},
  urldate = {2023-07-06},
  abstract = {We review recent empirical evaluations of AI-based language assessments and present a case for large language models, the technology behind chatGPT and BERT, to be poised for transforming standardized psychological assessment. Artificial intelligence has been undergoing a purported ``paradigm shift'' initiated by new machine learning models, large language models. These models have led to unprecedented accuracy over most computerized language processing tasks from web search to automatic machine translation and question answering, while their dialog-based forms like ChatGPT have captured the interest of over a million users. The success of the large language model is mostly attributed to its capability to numerically represent words in their context, long a weakness of previous attempts to automate psychological assessment from language. While potential applications for automated therapy are beginning to be studied on the heels of chatGPT's success, here we suggest that AI is already poised to move mental health assessment away from rating scales and to instead utilize how people naturally communicate, in language.},
  langid = {american},
  keywords = {Artificial Intelligence,Assessment,Psychiatry,Psychology,Quantitative Methods,Social and Behavioral Sciences,Statistical Methods,Transformers},
  file = {/Users/timokoch/Zotero/storage/NH92CAA5/Kjell et al. - 2023 - Beyond Rating Scales Large Language Models are Po.pdf}
}

@misc{kjellTextRpackageAnalyzing2021,
  title = {Text: {{An R-package}} for {{Analyzing}} and {{Visualizing Human Language Using Natural Language Processing}} and {{Deep Learning}}},
  shorttitle = {Text},
  author = {Kjell, Oscar and Giorgi, Salvatore and Schwartz, H. Andrew},
  year = {2021},
  month = apr,
  publisher = {{PsyArXiv}},
  doi = {10.31234/osf.io/293kt},
  urldate = {2022-07-15},
  abstract = {The language that individuals use for expressing themselves contains rich psychological information. Recent significant advances in Natural Language Processing (NLP) and Deep Learning (DL), namely transformers, have resulted in large performance gains in tasks related to understanding natural language such as machine translation. However, these state-of-the-art methods have not yet been made easily accessible for psychology researchers, nor designed to be optimal for human-level analyses. This tutorial introduces text (www.r-text.org), a new R-package for analyzing and visualizing human language using transformers, the latest techniques from NLP and DL. The text package is both a modular solution for accessing state-of-the-art language models and an end-to-end solution catered for human-level analyses. Hence, text provides user-friendly functions tailored to test hypotheses in social sciences for both relatively small and large datasets. This tutorial describes useful methods for analyzing text, providing functions with reliable defaults that can be used off-the-shelf as well as providing a framework for the advanced users to build on for novel techniques and analysis pipelines. The reader learns about three core methods: 1) textEmbed: to transform text to traditional or modern transformer-based word embeddings (i.e., numeric representations of words); 2) textTrain and textPredict: to train predictive models with word embeddings as input, and use the models to predict from; 3) textSimilarity: to compute semantic similarity scores between texts. The reader also learns about two extended methods: 1) textSimilarityTest: to significance test the difference in meaning between two sets of texts; and 2) textProjection and textProjectionPlot: to examine and visualize text within the embedding space according to latent or specified construct dimensions (e.g., low to high rating scale scores).},
  langid = {american},
  keywords = {Computational Language Assessments,Machine Learning,Natural Language Processing,Quantitative Methods,R,r-text,Social and Behavioral Sciences,Statistical Methods},
  file = {/Users/timokoch/Zotero/storage/X6TIDPTF/Kjell et al. - 2021 - Text An R-package for Analyzing and Visualizing H.pdf}
}

@misc{knightAmazonWorkingMaking2016,
  title = {Amazon {{Working}} on {{Making Alexa Recognize Your Emotions}}},
  author = {Knight, Will},
  year = {2016},
  journal = {MIT Technology Review},
  urldate = {2019-03-03},
  abstract = {With Google and Apple preparing voice devices for the home, Amazon is teaching Alexa to listen for emotions.},
  howpublished = {https://www.technologyreview.com/s/601654/amazon-working-on-making-alexa-recognize-your-emotions/},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/ZSNBBAI4/amazon-working-on-making-alexa-recognize-your-emotions.html}
}

@misc{knightAmazonWorkingMaking2016a,
  title = {Amazon {{Working}} on {{Making Alexa Recognize Your Emotions}}},
  author = {Knight, Will},
  year = {2016},
  journal = {MIT Technology Review},
  urldate = {2021-06-30},
  abstract = {With Google and Apple preparing voice devices for the home, Amazon is teaching Alexa to listen for emotions.},
  howpublished = {https://www.technologyreview.com/2016/06/13/159665/amazon-working-on-making-alexa-recognize-your-emotions/},
  langid = {english}
}

@article{kochAffectExperienceEveryday2022,
  title = {Affect {{Experience}} in {{Everyday Language Logged}} with {{Smartphones}}},
  author = {Koch, Timo K. and Eichstaedt, Johannes C. and Stachl, Clemens},
  year = {2022},
  month = feb,
  doi = {10.23668/psycharchives.5399},
  urldate = {2023-01-30},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/UNUCAWV5/3d5a2ddc-1c49-4398-a61a-3c2fd87b4417.html}
}

@article{kochAgeGenderLanguage2022,
  title = {Age and Gender in Language, Emoji, and Emoticon Usage in Instant Messages},
  author = {Koch, Timo K. and Romero, Peter and Stachl, Clemens},
  year = {2022},
  month = jan,
  journal = {Computers in Human Behavior},
  volume = {126},
  pages = {106990},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2021.106990},
  urldate = {2022-04-19},
  abstract = {Text is one of the most prevalent types of digital data that people create as they go about their lives. Digital footprints of people's language usage in social media posts were found to allow for inferences of their age and gender. However, the even more prevalent and potentially more sensitive text from instant messaging services has remained largely uninvestigated. We analyze language variations in instant messages with regard to individual differences in age and gender by replicating and extending the methods used in prior research on social media posts. Using a dataset of 309,229 WhatsApp messages from 226 volunteers, we identify unique age- and gender-linked language variations. We use cross-validated machine learning algorithms to predict volunteers' age (MAEMd\,=\,3.95, rMd\,=\,0.81, R2Md\,=\,0.49) and gender (AccuracyMd\,=\,85.7\%, F1Md\,=\,0.67, AUCMd~= .82) significantly above baseline-levels and identify the most predictive language features. We discuss implications for psycholinguistic theory, present opportunities for application in author profiling, and suggest methodological approaches for making predictions from small text data sets. Given the recent trend towards the dominant use of private messaging and increasingly weaker user data protection, we highlight rising threats to individual privacy rights in instant messaging.},
  langid = {english},
  keywords = {Age,Author profiling,Digital footprints,Gender,Instant messages,Machine learning},
  file = {/Users/timokoch/Zotero/storage/F6XNRQFG/Koch et al. - 2022 - Age and gender in language, emoji, and emoticon us.pdf;/Users/timokoch/Zotero/storage/B2ZJK9TU/S0747563221003137.html}
}

@article{kochAgeGenderLanguage2022a,
  title = {Age and Gender in Language, Emoji, and Emoticon Usage in Instant Messages},
  author = {Koch, Timo K. and Romero, Peter and Stachl, Clemens},
  year = {2022},
  month = jan,
  journal = {Computers in Human Behavior},
  volume = {126},
  pages = {106990},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2021.106990},
  urldate = {2022-07-11},
  abstract = {Text is one of the most prevalent types of digital data that people create as they go about their lives. Digital footprints of people's language usage in social media posts were found to allow for inferences of their age and gender. However, the even more prevalent and potentially more sensitive text from instant messaging services has remained largely uninvestigated. We analyze language variations in instant messages with regard to individual differences in age and gender by replicating and extending the methods used in prior research on social media posts. Using a dataset of 309,229 WhatsApp messages from 226 volunteers, we identify unique age- and gender-linked language variations. We use cross-validated machine learning algorithms to predict volunteers' age (MAEMd\,=\,3.95, rMd\,=\,0.81, R2Md\,=\,0.49) and gender (AccuracyMd\,=\,85.7\%, F1Md\,=\,0.67, AUCMd~= .82) significantly above baseline-levels and identify the most predictive language features. We discuss implications for psycholinguistic theory, present opportunities for application in author profiling, and suggest methodological approaches for making predictions from small text data sets. Given the recent trend towards the dominant use of private messaging and increasingly weaker user data protection, we highlight rising threats to individual privacy rights in instant messaging.},
  langid = {english},
  keywords = {Age,Author profiling,Digital footprints,Gender,Instant messages,Machine learning},
  file = {/Users/timokoch/Zotero/storage/MCGFC9GN/Koch et al. - 2022 - Age and gender in language, emoji, and emoticon us.pdf}
}

@article{kochEffectsFactcheckingWarning2023,
  title = {Effects of Fact-Checking Warning Labels and Social Endorsement Cues on Climate Change Fake News Credibility and Engagement on Social Media},
  author = {Koch, Timo K. and Frischlich, Lena and Lermer, Eva},
  year = {2023},
  journal = {Journal of Applied Social Psychology},
  pages = {1--13},
  issn = {1559-1816},
  doi = {10.1111/jasp.12959},
  urldate = {2023-02-14},
  abstract = {Online fake news can have noxious consequences. Social media platforms are experimenting with different interventions to curb fake news' spread, often employing them simultaneously. However, research investigating the interaction of these interventions is limited. Here, we use the heuristic-systematic model of information processing (HSM) as a theoretical framework to jointly test two interventions against fake news that are implemented at scale by social media platforms: (1) adding warning labels from fact checkers to initiate systematic processing and (2) removing social endorsement cues (e.g., engagement counts) to reduce the influence of this heuristic cue. Moreover, we accounted for dispositions previously found to affect a person's response to fake news through motivated reasoning or cognitive style. An online experiment in Germany (N = 571) confirmed that warning labels reduced the perceived credibility of a fake news post exaggerating the consequences of climate change. Warning labels also lowered the (self-reported) likelihood to amplify fake news. Removing social endorsement cues did not have an effect. In line with research on motivated reasoning, left-leaning individuals perceived the climate fake news to be more credible and reported a higher likelihood to amplify it. Supporting research on cognitive style, participants with lower educational levels and a less analytic thinking style also reported a higher likelihood of amplification. Elaboration likelihood was associated only with age, involvement, and political leaning, but not affected by warning labels. Our findings contribute to the mounting evidence for the effectiveness of warning labels while questioning their relevance for systematic processing.},
  langid = {english},
  keywords = {fake news interventions,heuristic-systematic model,social media},
  file = {/Users/timokoch/Zotero/storage/HX9PD73Y/Koch et al. - Effects of fact-checking warning labels and social.pdf;/Users/timokoch/Zotero/storage/HRNXSRRK/jasp.html}
}

@article{kochPredictingAffectiveStates2021,
  title = {Predicting {{Affective States}} from {{Acoustic Voice Cues Collected}} with {{Smartphones}}},
  author = {Koch, Timo K. and Schoedel, Ramona},
  year = {2021},
  month = jan,
  publisher = {{PsychArchives}},
  doi = {10.23668/psycharchives.4454},
  urldate = {2021-11-23},
  abstract = {The expression and recognition of emotions (i.e., short-lived and directed representations of affective states) through the acoustic properties of speech is a unique feature of human communication (Weninger et al., 2013). Researchers have identified acoustic features, which are predictable of affective states, and emotion detecting algorithms have been developed (Schuller, 2018). However, most studies used speech data produced by actors, who had instructions to act out a given emotion, or speech samples labelled by raters, who were instructed to add affective labels to recorded utterances (e.g., from TV shows). Both, enacted and labelled speech, come with multiple downsides since these approaches assess expressed affect rather than the experience of actual affective states through voice. In this work, we want to investigate if we can predict in-situ self-reported affective states from objective voice parameters collected with smartphones in everyday life. Further, we want to explore which acoustic features are most predictive for the prediction of the experience of affective states. Finally, we want to analyze how the affective quality of instructed spoken language (e.g., a sentence with negative affective valence) translates into objective markers in the acoustic signal, which then in turn could alter the predictions in our models.},
  copyright = {CC-BY 4.0},
  langid = {english},
  annotation = {Accepted: 2021-01-07T10:19:21Z},
  file = {/Users/timokoch/Zotero/storage/XZWKESCU/Koch und Schoedel - 2021 - Predicting Affective States from Acoustic Voice Cu.pdf;/Users/timokoch/Zotero/storage/KDQMCQ83/4033.html}
}

@misc{kochPredictingUsersAge2020,
  title = {Predicting {{Users}}' {{Age}} and {{Gender}} from {{Language Use}}, {{Emoji}}, and {{Emoticon Preferences}} in {{WhatsApp Instant Messages}}},
  shorttitle = {You {{Are What You Text}}?},
  author = {Koch, Timo K. and Romero, Peter and Stachl, Clemens},
  year = {2020},
  urldate = {2019-09-18},
  howpublished = {https://osf.io/ymx26/},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/3M92IKB4/login.html}
}

@article{koelewijnEffectsLexicalContent2021,
  title = {The Effects of Lexical Content, Acoustic and Linguistic Variability, and Vocoding on Voice Cue Perception},
  author = {Koelewijn, Thomas and Gaudrain, Etienne and Tamati, Terrin and Ba{\c s}kent, Deniz},
  year = {2021},
  month = sep,
  journal = {The Journal of the Acoustical Society of America},
  volume = {150},
  number = {3},
  pages = {1620--1634},
  publisher = {{Acoustical Society of America}},
  issn = {0001-4966},
  doi = {10.1121/10.0005938},
  urldate = {2022-08-19},
  abstract = {Perceptual differences in voice cues, such as fundamental frequency (F0) and vocal tract length (VTL), can facilitate speech understanding in challenging conditions. Yet, we hypothesized that in the presence of spectrotemporal signal degradations, as imposed by cochlear implants (CIs) and vocoders, acoustic cues that overlap for voice perception and phonemic categorization could be mistaken for one another, leading to a strong interaction between linguistic and indexical (talker-specific) content. Fifteen normal-hearing participants performed an odd-one-out adaptive task measuring just-noticeable differences (JNDs) in F0 and VTL. Items used were words (lexical content) or time-reversed words (no lexical content). The use of lexical content was either promoted (by using variable items across comparison intervals) or not (fixed item). Finally, stimuli were presented without or with vocoding. Results showed that JNDs for both F0 and VTL were significantly smaller (better) for non-vocoded compared with vocoded speech and for fixed compared with variable items. Lexical content (forward vs reversed) affected VTL JNDs in the variable item condition, but F0 JNDs only in the non-vocoded, fixed condition. In conclusion, lexical content had a positive top{\textendash}down effect on VTL perception when acoustic and linguistic variability was present but not on F0 perception. Lexical advantage persisted in the most degraded conditions and vocoding even enhanced the effect of item variability, suggesting that linguistic content could support compensation for poor voice perception in CI users.},
  file = {/Users/timokoch/Zotero/storage/CM6S9MX6/Koelewijn et al. - 2021 - The effects of lexical content, acoustic and lingu.pdf}
}

@article{koolagudiEmotionRecognitionSpeech2012,
  title = {Emotion Recognition from Speech: A Review},
  shorttitle = {Emotion Recognition from Speech},
  author = {Koolagudi, Shashidhar G. and Rao, K. Sreenivasa},
  year = {2012},
  month = jun,
  journal = {International Journal of Speech Technology},
  volume = {15},
  number = {2},
  pages = {99--117},
  issn = {1381-2416, 1572-8110},
  doi = {10.1007/s10772-011-9125-1},
  urldate = {2021-11-17},
  abstract = {Emotion recognition from speech has emerged as an important research area in the recent past. In this regard, review of existing work on emotional speech processing is useful for carrying out further research. In this paper, the recent literature on speech emotion recognition has been presented considering the issues related to emotional speech corpora, different types of speech features and models used for recognition of emotions from speech. Thirty two representative speech databases are reviewed in this work from point of view of their language, number of speakers, number of emotions, and purpose of collection. The issues related to emotional speech databases used in emotional speech recognition are also briefly discussed. Literature on different features used in the task of emotion recognition from speech is presented. The importance of choosing different classification models has been discussed along with the review. The important issues to be considered for further emotion recognition research in general and in specific to the Indian context have been highlighted where ever necessary.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/9EKLUQAQ/Koolagudi und Rao - 2012 - Emotion recognition from speech a review.pdf}
}

@article{koppelAutomaticallyCategorizingWritten2002,
  title = {Automatically {{Categorizing Written Texts}} by {{Author Gender}}},
  author = {Koppel, M.},
  year = {2002},
  month = nov,
  journal = {Literary and Linguistic Computing},
  volume = {17},
  number = {4},
  pages = {401--412},
  issn = {0268-1145, 1477-4615},
  doi = {10.1093/llc/17.4.401},
  urldate = {2020-05-05},
  abstract = {The problem of automatically determining the gender of a document's author would appear to be a more subtle problem than those of categorization by topic or authorship attribution. Nevertheless, it is shown that automated text categorization techniques can exploit combinations of simple lexical and syntactic features to infer the gender of the author of an unseen formal written document with approximately 80 per cent accuracy. The same techniques can be used to determine if a document is fiction or non-fiction with approximately 98 per cent accuracy.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/29WMQFW2/Koppel - 2002 - Automatically Categorizing Written Texts by Author.pdf}
}

@article{kosinskiFacebookResearchTool2015,
  title = {Facebook as a {{Research Tool}} for the {{Social Sciences}}},
  author = {Kosinski, Michal and Matz, Sandra and Gosling, Samuel and Popov, Vesselin and Stillwell, David},
  year = {2015},
  month = sep,
  journal = {The American psychologist},
  volume = {70},
  pages = {543--556},
  doi = {10.1037/a0039210},
  abstract = {Facebook is rapidly gaining recognition as a powerful research tool for the social sciences. It constitutes a large and diverse pool of participants, who can be selectively recruited for both online and offline studies. Additionally, it facilitates data collection by storing detailed records of its users' demographic profiles, social interactions, and behaviors. With participants' consent, these data can be recorded retrospectively in a convenient, accurate, and inexpensive way. Based on our experience in designing, implementing, and maintaining multiple Facebook-based psychological studies that attracted over 10 million participants, we demonstrate how to recruit participants using Facebook, incentivize them effectively, and maximize their engagement. We also outline the most important opportunities and challenges associated with using Facebook for research, provide several practical guidelines on how to successfully implement studies on Facebook, and finally, discuss ethical considerations. (PsycINFO Database Record},
  file = {/Users/timokoch/Zotero/storage/GBE5EF62/Kosinski et al. - 2015 - Facebook as a Research Tool for the Social Science.pdf}
}

@article{kosinskiPrivateTraitsAttributes2013,
  title = {Private Traits and Attributes Are Predictable from Digital Records of Human Behavior},
  author = {Kosinski, Michal and Stillwell, D. and Graepel, T.},
  year = {2013},
  month = apr,
  journal = {Proc Natl Acad Sci U S A},
  volume = {110},
  number = {15},
  pages = {5802--5},
  issn = {1091-6490 (Electronic) 0027-8424 (Linking)},
  doi = {10.1073/pnas.1218772110},
  abstract = {We show that easily accessible digital records of behavior, Facebook Likes, can be used to automatically and accurately predict a range of highly sensitive personal attributes including: sexual orientation, ethnicity, religious and political views, personality traits, intelligence, happiness, use of addictive substances, parental separation, age, and gender. The analysis presented is based on a dataset of over 58,000 volunteers who provided their Facebook Likes, detailed demographic profiles, and the results of several psychometric tests. The proposed model uses dimensionality reduction for preprocessing the Likes data, which are then entered into logistic/linear regression to predict individual psychodemographic profiles from Likes. The model correctly discriminates between homosexual and heterosexual men in 88\% of cases, African Americans and Caucasian Americans in 95\% of cases, and between Democrat and Republican in 85\% of cases. For the personality trait "Openness," prediction accuracy is close to the test-retest accuracy of a standard personality test. We give examples of associations between attributes and Likes and discuss implications for online personalization and privacy.},
  pmcid = {PMC3625324},
  keywords = {*Behavior,*Social Support,Artificial Intelligence,Data Mining/methods,Emotions,Female,Heterosexuality,Homosexuality,Humans,Male,{Models, Theoretical},Personality,Personality Inventory,Politics,Psychometrics,Regression Analysis,Reproducibility of Results}
}

@article{kotzWhenEmotionalProsody2007,
  title = {When Emotional Prosody and Semantics Dance Cheek to Cheek: {{ERP}} Evidence},
  shorttitle = {When Emotional Prosody and Semantics Dance Cheek to Cheek},
  author = {Kotz, Sonja A. and Paulmann, Silke},
  year = {2007},
  month = jun,
  journal = {Brain Research},
  volume = {1151},
  pages = {107--118},
  issn = {00068993},
  doi = {10.1016/j.brainres.2007.03.015},
  urldate = {2021-10-29},
  abstract = {To communicate emotionally entails that a listener understands a verbal message but also the emotional prosody going along with it. So far the time course and interaction of these emotional `channels' is still poorly understood. The current set of event-related brain potential (ERP) experiments investigated both the interactive time course of emotional prosody with semantics and of emotional prosody independent of emotional semantics using a cross-splicing method. In a probe verification task (Experiment 1) prosodic expectancy violations elicited a positivity, while a combined prosodic{\textendash}semantic expectancy violation elicited a negativity. Comparable ERP results were obtained in an emotional prosodic categorization task (Experiment 2). The present data support different ERP responses with distinct time courses and topographies elicited as a function of prosodic expectancy and combined prosodic-semantic expectancy during emotional prosodic processing and combined emotional prosody/emotional semantic processing. These differences suggest that the interaction of more than one emotional channel facilitates subtle transitions in an emotional sentence context.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/F5A4EV7D/Kotz und Paulmann - 2007 - When emotional prosody and semantics dance cheek t.pdf}
}

@article{kraljnovakSentimentEmojis2015,
  title = {Sentiment of {{Emojis}}},
  author = {Kralj Novak, Petra and Smailovi{\'c}, Jasmina and Sluban, Borut and Mozeti{\v c}, Igor},
  editor = {Perc, Matjaz},
  year = {2015},
  month = dec,
  journal = {PLOS ONE},
  volume = {10},
  number = {12},
  pages = {e0144296},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0144296},
  urldate = {2019-07-29},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/2KM8VBYT/Kralj Novak et al. - 2015 - Sentiment of Emojis.PDF}
}

@inproceedings{kramerTextAnalysisTool2004,
  title = {Text Analysis as a Tool for Analyzing Conversation in Online Support Groups},
  booktitle = {{{CHI Extended Abstracts}}},
  author = {Kramer, Adam D. I. and Fussell, Susan R. and Setlock, Leslie D.},
  year = {2004},
  doi = {10.1145/985921.986096},
  abstract = {In this paper we describe a software tool that allows investigators to make comparisons across different online forums and media by analyzing word counts in user-specified categories. Using a large sample of messages from a bipolar support chatroom, we demonstrate how this tool can be used to characterize the nature of the discourse and compare it to other media, to analyze relationships among different word categories, and to characterize changes in visitors' discourse over time. Future plans for adding functionality to the software and using external data for additional validation are also discussed.},
  keywords = {Chat room,Programming tool}
}

@inproceedings{krekhovInterpolatingHappinessUnderstanding2022,
  title = {Interpolating {{Happiness}}: {{Understanding}} the {{Intensity Gradations}} of {{Face Emojis Across Cultures}}},
  shorttitle = {Interpolating {{Happiness}}},
  booktitle = {{{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Krekhov, Andrey and Emmerich, Katharina and Fuchs, Johannes and Krueger, Jens Harald},
  year = {2022},
  month = apr,
  series = {{{CHI}} '22},
  pages = {1--17},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3491102.3517661},
  urldate = {2022-05-28},
  abstract = {We frequently utilize face emojis to express emotions in digital communication. But how wholly and precisely do such pictographs sample the emotional spectrum, and are there gaps to be closed? Our research establishes emoji intensity scales for seven basic emotions: happiness, anger, disgust, sadness, shock, annoyance, and love. In our survey (N = 1195), participants worldwide assigned emotions and intensities to 68 face emojis. According to our results, certain feelings, such as happiness or shock, are visualized by manifold emojis covering a broad spectrum of intensities. Other feelings, such as anger, have limited and only very intense representative visualizations. We further emphasize that the cultural background influences emojis' perception: for instance, linear-active cultures (e.g., UK, Germany) rate the intensity of such visualizations higher than multi-active (e.g., Brazil, Russia) or reactive cultures (e.g., Indonesia, Singapore). To summarize, our manuscript promotes future research on more expressive, culture-aware emoji design.},
  isbn = {978-1-4503-9157-3},
  keywords = {cultures,emoji,emotion visualization,intensity,smiley},
  file = {/Users/timokoch/Zotero/storage/GPFSAYM5/Krekhov et al. - 2022 - Interpolating Happiness Understanding the Intensi.pdf}
}

@article{kreuterCollectingSurveySmartphone2020,
  title = {Collecting {{Survey}} and {{Smartphone Sensor Data With}} an {{App}}: {{Opportunities}} and {{Challenges Around Privacy}} and {{Informed Consent}}},
  shorttitle = {Collecting {{Survey}} and {{Smartphone Sensor Data With}} an {{App}}},
  author = {Kreuter, Frauke and Haas, Georg-Christoph and Keusch, Florian and B{\"a}hr, Sebastian and Trappmann, Mark},
  year = {2020},
  month = oct,
  journal = {Social Science Computer Review},
  volume = {38},
  number = {5},
  pages = {533--549},
  publisher = {{SAGE Publications Inc}},
  issn = {0894-4393},
  doi = {10.1177/0894439318816389},
  urldate = {2023-01-23},
  abstract = {The new European General Data Protection Regulation (GDPR) imposes enhanced requirements on digital data collection. This article reports from a 2018 German nationwide population-based probability app study in which participants were asked through a GDPR compliant consent process to share a series of digital trace data, including geolocation, accelerometer data, phone and text messaging logs, app usage, and access to their address books. With about 4,300 invitees and about 650 participants, we demonstrate (1) people were just as willing to share such extensive digital trace data as they were in studies with far more limited requests; (2) despite being provided more decision-related information, participants hardly differentiated between the different data requests made; and (3) once participants gave consent, they did not tend to revoke it. We also show (4) evidence for a widely-held belief that explanations regarding data collection and data usage are often not read carefully, at least not within the app itself, indicating the need for research and user experience improvement to adequately inform and protect participants. We close with suggestions to the field for creating a seal of approval from professional organizations to help the research community promote the safe use of data.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/T5DNJRP2/Kreuter et al. - 2020 - Collecting Survey and Smartphone Sensor Data With .pdf}
}

@article{kringSexDifferencesEmotion1998,
  title = {Sex {{Differences}} in {{Emotion}}: {{Expression}}, {{Experience}}, and {{Physiology}}},
  author = {Kring, Ann M and Gordon, Albert H},
  year = {1998},
  journal = {Journal of Personality and Social Psychology},
  pages = {18},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/ZD87MEJS/Kring und Gordon - Sex Differences in Emotion Expression, Experience.pdf}
}

@inproceedings{krogerMyPhoneListening2019,
  title = {Is {{My Phone Listening}} in? {{On}} the {{Feasibility}} and {{Detectability}} of {{Mobile Eavesdropping}}},
  shorttitle = {Is {{My Phone Listening}} In?},
  booktitle = {Data and {{Applications Security}} and {{Privacy XXXIII}}},
  author = {Kr{\"o}ger, Jacob Leon and Raschke, Philip},
  editor = {Foley, Simon N.},
  year = {2019},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {102--120},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-22479-0_6},
  abstract = {Besides various other privacy concerns with mobile devices, many people suspect their smartphones to be secretly eavesdropping on them. In particular, a large number of reports has emerged in recent years claiming that private conversations conducted in the presence of smartphones seemingly resulted in targeted online advertisements. These rumors have not only attracted media attention, but also the attention of regulatory authorities. With regard to explaining the phenomenon, opinions are divided both in public debate and in research. While one side dismisses the eavesdropping suspicions as unrealistic or even paranoid, many others are fully convinced of the allegations or at least consider them plausible. To help structure the ongoing controversy and dispel misconceptions that may have arisen, this paper provides a holistic overview of the issue, reviewing and analyzing existing arguments and explanatory approaches from both sides. Based on previous research and our own analysis, we challenge the widespread assumption that the spying fears have already been disproved. While confirming a lack of empirical evidence, we cannot rule out the possibility of sophisticated large-scale eavesdropping attacks being successful and remaining undetected. Taking into account existing access control mechanisms, detection methods, and other technical aspects, we point out remaining vulnerabilities and research gaps.},
  isbn = {978-3-030-22479-0},
  langid = {english},
  keywords = {Advertisement,Conversation,Eavesdropping,Listening,Microphone,Privacy,Smartphone,Spying},
  file = {/Users/timokoch/Zotero/storage/V66SXWB2/Kröger und Raschke - 2019 - Is My Phone Listening in On the Feasibility and D.pdf}
}

@incollection{krogerPrivacyImplicationsVoice2020,
  title = {Privacy {{Implications}} of {{Voice}} and {{Speech Analysis}} {\textendash} {{Information Disclosure}} by {{Inference}}},
  booktitle = {Privacy and {{Identity Management}}. {{Data}} for {{Better Living}}: {{AI}} and {{Privacy}}},
  author = {Kr{\"o}ger, Jacob Leon and Lutz, Otto Hans-Martin and Raschke, Philip},
  editor = {Friedewald, Michael and {\"O}nen, Melek and Lievens, Eva and Krenn, Stephan and Fricker, Samuel},
  year = {2020},
  volume = {576},
  pages = {242--258},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-42504-3_16},
  urldate = {2021-11-08},
  abstract = {Internet-connected devices, such as smartphones, smartwatches, and laptops, have become ubiquitous in modern life, reaching ever deeper into our private spheres. Among the sensors most commonly found in such devices are microphones. While various privacy concerns related to microphone-equipped devices have been raised and thoroughly discussed, the threat of unexpected inferences from audio data remains largely overlooked. Drawing from literature of diverse disciplines, this paper presents an overview of sensitive pieces of information that can, with the help of advanced data analysis methods, be derived from human speech and other acoustic elements in recorded audio. In addition to the linguistic content of speech, a speaker's voice characteristics and manner of expression may implicitly contain a rich array of personal information, including cues to a speaker's biometric identity, personality, physical traits, geographical origin, emotions, level of intoxication and sleepiness, age, gender, and health condition. Even a person's socioeconomic status can be reflected in certain speech patterns. The findings compiled in this paper demonstrate that recent advances in voice and speech processing induce a new generation of privacy threats.},
  isbn = {978-3-030-42503-6 978-3-030-42504-3},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/Y75AILIQ/Kröger et al. - 2020 - Privacy Implications of Voice and Speech Analysis .pdf}
}

@article{krohnGenerationalApproachUsing2004,
  title = {A Generational Approach to Using Emoticons as Nonverbal Communication},
  author = {Krohn, Franklin B.},
  year = {2004},
  journal = {Journal of technical writing and communication},
  volume = {34},
  number = {4},
  pages = {321--328},
  issn = {0047-2816}
}

@article{krossDoesCountingEmotion2019,
  title = {Does Counting Emotion Words on Online Social Networks Provide a Window into People's Subjective Experience of Emotion? {{A}} Case Study on {{Facebook}}.},
  shorttitle = {Does Counting Emotion Words on Online Social Networks Provide a Window into People's Subjective Experience of Emotion?},
  author = {Kross, Ethan and Verduyn, Philippe and Boyer, Margaret and Drake, Brittany and Gainsburg, Izzy and Vickers, Brian and Ybarra, Oscar and Jonides, John},
  year = {2019},
  month = feb,
  journal = {Emotion},
  volume = {19},
  number = {1},
  pages = {97--107},
  issn = {1931-1516, 1528-3542},
  doi = {10.1037/emo0000416},
  urldate = {2020-11-20},
  abstract = {Psychologists have long debated whether it is possible to assess how people subjectively feel without asking them. The recent proliferation of online social networks has recently added a fresh chapter to this discussion, with research now suggesting that it is possible to index people's subjective experience of emotion by simply counting the number of emotion words contained in their online social network posts. Whether the conclusions that emerge from this work are valid, however, rests on a critical assumption: that people's usage of emotion words in their posts accurately reflects how they feel. Although this assumption is widespread in psychological research, here we suggest that there are reasons to challenge it. We corroborate these assertions in 2 ways. First, using data from 4 experience-sampling studies of emotion in young adults, we show that people's reports of how they feel throughout the day neither predict, nor are predicted by, their use of emotion words on Facebook. Second, using simulations we show that although significant relationships emerge between the use of emotion words on Facebook and self-reported affect with increasingly large numbers of observations, the relationship between these variables was in the opposite of the theoretically expected direction 50\% of the time (i.e., 3 of 6 models that we performed simulations on). In contrast to counting emotion words, we show that judges' ratings of the emotionality of participants' Facebook posts consistently predicts how people feel across all analyses. These findings shed light on how to draw inferences about emotion using online social network data.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/XGJCM93Y/Kross et al. - 2019 - Does counting emotion words on online social netwo.pdf}
}

@article{krossDoesCountingEmotion2019a,
  title = {Does Counting Emotion Words on Online Social Networks Provide a Window into People's Subjective Experience of Emotion? {{A}} Case Study on {{Facebook}}.},
  shorttitle = {Does Counting Emotion Words on Online Social Networks Provide a Window into People's Subjective Experience of Emotion?},
  author = {Kross, Ethan and Verduyn, Philippe and Boyer, Margaret and Drake, Brittany and Gainsburg, Izzy and Vickers, Brian and Ybarra, Oscar and Jonides, John},
  year = {2019},
  month = feb,
  journal = {Emotion},
  volume = {19},
  number = {1},
  pages = {97--107},
  issn = {1931-1516, 1528-3542},
  doi = {10.1037/emo0000416},
  urldate = {2020-11-20},
  abstract = {Psychologists have long debated whether it is possible to assess how people subjectively feel without asking them. The recent proliferation of online social networks has recently added a fresh chapter to this discussion, with research now suggesting that it is possible to index people's subjective experience of emotion by simply counting the number of emotion words contained in their online social network posts. Whether the conclusions that emerge from this work are valid, however, rests on a critical assumption: that people's usage of emotion words in their posts accurately reflects how they feel. Although this assumption is widespread in psychological research, here we suggest that there are reasons to challenge it. We corroborate these assertions in 2 ways. First, using data from 4 experience-sampling studies of emotion in young adults, we show that people's reports of how they feel throughout the day neither predict, nor are predicted by, their use of emotion words on Facebook. Second, using simulations we show that although significant relationships emerge between the use of emotion words on Facebook and self-reported affect with increasingly large numbers of observations, the relationship between these variables was in the opposite of the theoretically expected direction 50\% of the time (i.e., 3 of 6 models that we performed simulations on). In contrast to counting emotion words, we show that judges' ratings of the emotionality of participants' Facebook posts consistently predicts how people feel across all analyses. These findings shed light on how to draw inferences about emotion using online social network data.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/L762HLRD/Kross et al. - 2019 - Does counting emotion words on online social netwo.pdf}
}

@incollection{kucukyilmazChatMiningGender2006,
  title = {Chat {{Mining}} for {{Gender Prediction}}},
  booktitle = {Advances in {{Information Systems}}},
  author = {Kucukyilmaz, Tayfun and Cambazoglu, B. Barla and Aykanat, Cevdet and Can, Fazli},
  editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and Yakhno, Tatyana and Neuhold, Erich J.},
  year = {2006},
  volume = {4243},
  pages = {274--283},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/11890393_29},
  urldate = {2020-05-12},
  abstract = {The aim of this paper is to investigate the feasibility of predicting the gender of a text document's author using linguistic evidence. For this purpose, term- and style-based classification techniques are evaluated over a large collection of chat messages. Prediction accuracies up to 84.2\% are achieved, illustrating the applicability of these techniques to gender prediction. Moreover, the reverse problem is exploited, and the effect of gender on the writing style is discussed.},
  isbn = {978-3-540-46291-0 978-3-540-46292-7},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/G69C2HCP/Kucukyilmaz et al. - 2006 - Chat Mining for Gender Prediction.pdf}
}

@book{kuhnAppliedPredictiveModeling2013,
  title = {Applied {{Predictive Modeling}}},
  author = {Kuhn, Max and Johnson, Kjell},
  year = {2013},
  publisher = {{Springer New York}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4614-6849-3},
  urldate = {2020-10-14},
  isbn = {978-1-4614-6848-6 978-1-4614-6849-3},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/HP58NWS7/Kuhn und Johnson - 2013 - Applied Predictive Modeling.pdf}
}

@article{kulkarniLatentHumanTraits2018,
  title = {Latent Human Traits in the Language of Social Media: {{An}} Open-Vocabulary Approach},
  shorttitle = {Latent Human Traits in the Language of Social Media},
  author = {Kulkarni, Vivek and Kern, Margaret L. and Stillwell, David and Kosinski, Michal and Matz, Sandra and Ungar, Lyle and Skiena, Steven and Schwartz, H. A.},
  editor = {Danforth, Christopher M.},
  year = {2018},
  month = nov,
  journal = {PLOS ONE},
  volume = {13},
  number = {11},
  pages = {e0201703},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0201703},
  urldate = {2020-04-12},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/3A9BA8EZ/Kulkarni et al. - 2018 - Latent human traits in the language of social medi.pdf}
}

@article{kuppensFeelingsChangeAccounting2010,
  title = {Feelings Change: Accounting for Individual Differences in the Temporal Dynamics of Affect},
  shorttitle = {Feelings Change},
  author = {Kuppens, Peter and Oravecz, Zita and Tuerlinckx, Francis},
  year = {2010},
  month = dec,
  journal = {Journal of Personality and Social Psychology},
  volume = {99},
  number = {6},
  pages = {1042--1060},
  issn = {1939-1315},
  doi = {10.1037/a0020962},
  abstract = {People display a remarkable variability in the patterns and trajectories with which their feelings change over time. In this article, we present a theoretical account for the dynamics of affect (DynAffect) that identifies the major processes underlying individual differences in the temporal dynamics of affective experiences. It is hypothesized that individuals are characterized by an affective home base, a baseline attractor state around which affect fluctuates. These fluctuations vary as the result of internal or external processes to which an individual is more or less sensitive and are regulated and tied back to the home base by the attractor strength. Individual differences in these 3 processes--affective home base, variability, and attractor strength--are proposed to underlie individual differences in affect dynamics. The DynAffect account is empirically evaluated by means of a diffusion modeling approach in 2 extensive experience-sampling studies on people's core affective experiences. The findings show that the model is capable of adequately capturing the observed dynamics in core affect across both large (Study 1) and shorter time scales (Study 2) and illuminate how the key processes are related to personality and emotion dispositions. Implications for the understanding of affect dynamics and affective dysfunctioning in psychopathology are also discussed.},
  langid = {english},
  pmid = {20853980},
  keywords = {Adult,Affect,Belgium,Emotions,Female,Humans,Individuality,Male,{Models, Psychological},Nonlinear Dynamics,Personality,Temperament,Time Factors},
  file = {/Users/timokoch/Zotero/storage/89CEARC7/Kuppens et al. - 2010 - Feelings Change Accounting for Individual Differe.pdf}
}

@article{kuppensFeelingsChangeAccounting2010a,
  title = {Feelings {{Change}}: {{Accounting}} for {{Individual Differences}} in the {{Temporal Dynamics}} of {{Affect}}},
  shorttitle = {Feelings {{Change}}},
  author = {Kuppens, Peter and Oravecz, Zita and Tuerlinckx, Francis},
  year = {2010},
  month = dec,
  journal = {Journal of personality and social psychology},
  volume = {99},
  pages = {1042--60},
  doi = {10.1037/a0020962},
  abstract = {People display a remarkable variability in the patterns and trajectories with which their feelings change over time. In this article, we present a theoretical account for the dynamics of affect (DynAffect) that identifies the major processes underlying individual differences in the temporal dynamics of affective experiences. It is hypothesized that individuals are characterized by an affective home base, a baseline attractor state around which affect fluctuates. These fluctuations vary as the result of internal or external processes to which an individual is more or less sensitive and are regulated and tied back to the home base by the attractor strength. Individual differences in these 3 processes--affective home base, variability, and attractor strength--are proposed to underlie individual differences in affect dynamics. The DynAffect account is empirically evaluated by means of a diffusion modeling approach in 2 extensive experience-sampling studies on people's core affective experiences. The findings show that the model is capable of adequately capturing the observed dynamics in core affect across both large (Study 1) and shorter time scales (Study 2) and illuminate how the key processes are related to personality and emotion dispositions. Implications for the understanding of affect dynamics and affective dysfunctioning in psychopathology are also discussed.},
  file = {/Users/timokoch/Zotero/storage/NKPCJCIZ/Kuppens et al. - 2010 - Feelings Change Accounting for Individual Differe.pdf}
}

@article{kuppensRelationValenceArousal2013,
  title = {The Relation between Valence and Arousal in Subjective Experience},
  author = {Kuppens, Peter and Tuerlinckx, Francis and Russell, James A. and Barrett, Lisa Feldman},
  year = {2013},
  month = jul,
  journal = {Psychological Bulletin},
  volume = {139},
  number = {4},
  pages = {917--940},
  issn = {1939-1455},
  doi = {10.1037/a0030811},
  abstract = {Affect is basic to many if not all psychological phenomena. This article examines 2 of the most fundamental properties of affective experience--valence and arousal--asking how they are related to each other on a moment to moment basis. Over the past century, 6 distinct types of relations have been suggested or implicitly presupposed in the literature. We critically review the available evidence for each proposal and argue that the evidence does not provide a conclusive answer. Next, we use statistical modeling to verify the different proposals in 8 data sets (with Ns ranging from 80 to 1,417) where participants reported their affective experiences in response to experimental stimuli in laboratory settings or as momentary or remembered in natural settings. We formulate 3 key conclusions about the relation between valence and arousal: (a) on average, there is a weak but consistent V-shaped relation of arousal as a function of valence, but (b) there is large variation at the individual level, so that (c) valence and arousal can in principle show a variety of relations depending on person or circumstances. This casts doubt on the existence of a static, lawful relation between valence and arousal. The meaningfulness of the observed individual differences is supported by their personality and cultural correlates. The malleability and individual differences found in the structure of affect must be taken into account when studying affect and its role in other psychological phenomena.},
  langid = {english},
  pmid = {23231533},
  keywords = {Affect,Arousal,{Data Interpretation, Statistical},Humans,Individuality,{Models, Psychological},Pleasure,Self Report,Statistics as Topic}
}

@article{kuppensRelationValenceArousal2017,
  title = {The {{Relation Between Valence}} and {{Arousal}} in {{Subjective Experience Varies With Personality}} and {{Culture}}: {{Relation}} of {{Valence}} to {{Arousal}}},
  shorttitle = {The {{Relation Between Valence}} and {{Arousal}} in {{Subjective Experience Varies With Personality}} and {{Culture}}},
  author = {Kuppens, Peter and Tuerlinckx, Francis and Yik, Michelle and Koval, Peter and Coosemans, Joachim and Zeng, Kevin J. and Russell, James A.},
  year = {2017},
  month = aug,
  journal = {Journal of Personality},
  volume = {85},
  number = {4},
  pages = {530--542},
  issn = {00223506},
  doi = {10.1111/jopy.12258},
  urldate = {2021-12-14},
  abstract = {Objective: While in general arousal increases with positive or negative valence (a so-called V-shaped relation), there are large differences among individuals in how these two fundamental dimensions of affect are related in people's experience. In two studies, we examined two possible sources of this variation: personality and culture. Method: In Study 1, participants (Belgian university students) recalled a recent event that was characterized by high or low valence or arousal and reported on their feelings and their personality in terms of the Five-Factor Model. In Study 2, participants from Canada, China/Hong Kong, Japan, Korea, and Spain reported on their feelings in a thin slice of time and on their personality. Results: In Study 1, we replicated the V-shape as characterizing the relation between valence and arousal, and identified personality correlates of experiencing particular valence{\textendash}arousal combinations. In Study 2, we documented how the V-shaped relation varied as a function of Western versus Eastern cultural background and personality. Conclusions: The results showed that the steepness of the V-shaped relation between valence and arousal increases with Extraversion within cultures, and with a West-East distinction between cultures. Implications for the personality{\textendash}emotion link and research on cultural differences in affect are discussed.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/QK5UE2CH/Kuppens et al. - 2017 - The Relation Between Valence and Arousal in Subjec.pdf}
}

@article{kutsuzawaClassification74Facial2022,
  title = {Classification of 74 Facial Emoji's Emotional States on the Valence-Arousal Axes},
  author = {Kutsuzawa, Gaku and Umemura, Hiroyuki and Eto, Koichiro and Kobayashi, Yoshiyuki},
  year = {2022},
  month = jan,
  journal = {Scientific Reports},
  volume = {12},
  doi = {10.1038/s41598-021-04357-7},
  abstract = {Emojis are frequently used by people worldwide as a tool to express one's emotional states and have recently been considered for assessment in research. However, details regarding the ways in which they correspond to human emotional states remain unidentified. Thus, this study aimed to understand how emojis are classified on the valence and arousal axes and to examine the relationship between the former and human emotional states. In an online survey involving 1082 participants, a nine-point scale was employed to evaluate the valence and arousal levels of 74 facial emojis. Results from the cluster analysis revealed these emojis to be categorized into six different clusters on the two axes of valence and arousal. Further, the one-way analysis of variance indicated that these clusters have six valence and four arousal levels. From the results, each cluster was interpreted as (1) a strong negative sentiment, (2) a moderately negative sentiment, (3) a neutral sentiment with a negative bias, (4) a neutral sentiment with a positive bias, (5) a moderately positive sentiment, and (6) a strong positive sentiment. Therefore, facial emojis were found to comprehensively express the human emotional states.},
  file = {/Users/timokoch/Zotero/storage/U8BAAUSH/Kutsuzawa et al. - 2022 - Classification of 74 facial emoji’s emotional stat.pdf}
}

@article{laneDistinctionsEmotionMood2005,
  title = {Distinctions between {{Emotion}} and {{Mood}}},
  author = {Lane, Andrew and Beedie, Christopher and Terry, Peter},
  year = {2005},
  month = sep,
  journal = {Cognition and Emotion},
  volume = {19},
  doi = {10.1080/02699930541000057},
  abstract = {Most academics agree that emotions and moods are related but distinct phenomena. The present study assessed emotion-mood distinctions among a non-academic population and compared these views with distinctions proposed in the literature. Content analysis of responses from 106 participants identified 16 themes, with cause (65\% of respondents), duration (40\%), control (25\%), experience (15\%) and consequences (14\%) the most frequently cited distinctions. Among 65 contributions to the academic literature, eight themes were proposed, with duration (62\% of authors), intentionality (41\%), cause (31\%), consequences (31\%) and function (18\%) the most frequently cited. When the eight themes cited by both academics and non-academics were rank ordered, approximately 60\% overlap in opinion was evident. A data-derived summary of emotion-mood distinctions is provided. These data should prove useful to investigators interested in developing a clearer scientific distinction between emotion and mood than is currently available.},
  file = {/Users/timokoch/Zotero/storage/8IAUZKJ2/Lane et al. - 2005 - Distinctions between Emotion and Mood.pdf}
}

@article{langMlr3ModernObjectoriented2019,
  title = {Mlr3: {{A}} Modern Object-Oriented Machine Learning Framework in {{R}}},
  shorttitle = {Mlr3},
  author = {Lang, Michel and Binder, Martin and Richter, Jakob and Schratz, Patrick and Pfisterer, Florian and Coors, Stefan and Au, Quay and Casalicchio, Giuseppe and Kotthoff, Lars and Bischl, Bernd},
  year = {2019},
  month = dec,
  journal = {Journal of Open Source Software},
  volume = {4},
  number = {44},
  pages = {1903},
  issn = {2475-9066},
  doi = {10.21105/joss.01903},
  urldate = {2020-11-30},
  abstract = {Lang et al., (2019). mlr3: A modern object-oriented machine learning framework in R. Journal of Open Source Software, 4(44), 1903, https://doi.org/10.21105/joss.01903},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/7IRM4SD9/Lang et al. - 2019 - mlr3 A modern object-oriented machine learning fr.pdf;/Users/timokoch/Zotero/storage/TE25YB9L/joss.html}
}

@misc{LanguageWellBeingTracking,
  title = {The {{Language}} of {{Well-Being}}: {{Tracking Fluctuations}} in {{Emotion Experience}} through {{Everyday Speech}} | {{Request PDF}}},
  shorttitle = {The {{Language}} of {{Well-Being}}},
  journal = {ResearchGate},
  urldate = {2019-02-19},
  abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
  howpublished = {https://www.researchgate.net/publication/331003400\_The\_Language\_of\_Well-Being\_Tracking\_Fluctuations\_in\_Emotion\_Experience\_through\_Everyday\_Speech},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/T5IMCSUL/331003400_The_Language_of_Well-Being_Tracking_Fluctuations_in_Emotion_Experience_through_Everyd.html}
}

@article{lassalleEUEmotionVoiceDatabase2019,
  title = {The {{EU-Emotion Voice Database}}},
  author = {Lassalle, Amandine and Pigat, Delia and O'Reilly, Helen and Berggen, Steve and {Fridenson-Hayo}, Shimrit and Tal, Shahar and Elfstr{\"o}m, Sigrid and R{\aa}de, Anna and Golan, Ofer and B{\"o}lte, Sven and {Baron-Cohen}, Simon and Lundqvist, Daniel},
  year = {2019},
  month = apr,
  journal = {Behavior Research Methods},
  volume = {51},
  number = {2},
  pages = {493--506},
  issn = {1554-3528},
  doi = {10.3758/s13428-018-1048-1},
  urldate = {2019-05-23},
  abstract = {In this study, we report the validation results of the EU-Emotion Voice Database, an emotional voice database available for scientific use, containing a total of 2,159 validated emotional voice stimuli. The EU-Emotion voice stimuli consist of audio-recordings of 54 actors, each uttering sentences with the intention of conveying 20 different emotional states (plus neutral). The database is organized in three separate emotional voice stimulus sets in three different languages (British English, Swedish, and Hebrew). These three sets were independently validated by large pools of participants in the UK, Sweden, and Israel. Participants' validation of the stimuli included emotion categorization accuracy and ratings of emotional valence, intensity, and arousal. Here we report the validation results for the emotional voice stimuli from each site and provide validation data to download as a supplement, so as to make these data available to the scientific community. The EU-Emotion Voice Database is part of the EU-Emotion Stimulus Set, which in addition contains stimuli of emotions expressed in the visual modality (by facial expression, body language, and social scene) and is freely available to use for academic research purposes.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/HX8TSM6T/Lassalle et al. - 2019 - The EU-Emotion Voice Database.pdf}
}

@article{laukkaDimensionalApproachVocal2005,
  title = {A Dimensional Approach to Vocal Expression of Emotion},
  author = {Laukka, Petri and Juslin, Patrik and Bresin, Roberto},
  year = {2005},
  month = aug,
  journal = {Cognition and Emotion},
  volume = {19(5)},
  pages = {633--653},
  doi = {10.1080/02699930441000445},
  abstract = {This study explored a dimensional approach to vocal expression of emotion. Actors vocally portrayed emotions (anger, disgust, fear, happiness, sadness) with weak and strong emotion intensity. Listeners (30 university students and 6 speech experts) rated each portrayal on four emotion dimensions (activation, valence, potency, emotion intensity). The portrayals were also acoustically analysed with respect to 20 vocal cues (e.g., speech rate, voice intensity, fundamental frequency, spectral energy distribution). The results showed that: (a) there were distinct patterns of ratings of activation, valence, and potency for the different emotions; (b) all four emotion dimensions were correlated with several vocal cues; (c) listeners' ratings could be successfully predicted from the vocal cues for all dimensions except valence; and (d) the intensity dimension was positively correlated with the activation dimension in the listeners' ratings.}
}

@article{laukkaDimensionalApproachVocal2005a,
  title = {A Dimensional Approach to Vocal Expression of Emotion},
  author = {Laukka, Petri and Juslin, Patrik and Bresin, Roberto},
  year = {2005},
  month = aug,
  journal = {Cognition and Emotion},
  volume = {19(5)},
  pages = {633--653},
  doi = {10.1080/02699930441000445},
  abstract = {This study explored a dimensional approach to vocal expression of emotion. Actors vocally portrayed emotions (anger, disgust, fear, happiness, sadness) with weak and strong emotion intensity. Listeners (30 university students and 6 speech experts) rated each portrayal on four emotion dimensions (activation, valence, potency, emotion intensity). The portrayals were also acoustically analysed with respect to 20 vocal cues (e.g., speech rate, voice intensity, fundamental frequency, spectral energy distribution). The results showed that: (a) there were distinct patterns of ratings of activation, valence, and potency for the different emotions; (b) all four emotion dimensions were correlated with several vocal cues; (c) listeners' ratings could be successfully predicted from the vocal cues for all dimensions except valence; and (d) the intensity dimension was positively correlated with the activation dimension in the listeners' ratings.},
  file = {/Users/timokoch/Zotero/storage/6KEQK744/Laukka et al. - 2005 - A dimensional approach to vocal expression of emot.pdf}
}

@article{laukkaExpressionRecognitionEmotions2016,
  title = {The {{Expression}} and {{Recognition}} of {{Emotions}} in the {{Voice Across Five Nations}}: {{A Lens Model Analysis Based}} on {{Acoustic Features}}},
  shorttitle = {The {{Expression}} and {{Recognition}} of {{Emotions}} in the {{Voice Across Five Nations}}},
  author = {Laukka, Petri and Elfenbein, Hillary and Thingujam, Nutankumar and Rockstuhl, Thomas and Iraki, Frederick and Chui, Wanda and Althoff, Jean},
  year = {2016},
  month = aug,
  journal = {Journal of personality and social psychology},
  volume = {111},
  doi = {10.1037/pspi0000066},
  abstract = {This study extends previous work on emotion communication across cultures with a large-scale investigation of the physical expression cues in vocal tone. In doing so, it provides the first direct test of a key proposition of dialect theory, namely that greater accuracy of detecting emotions from one's own cultural group-known as in-group advantage-results from a match between culturally specific schemas in emotional expression style and culturally specific schemas in emotion recognition. Study 1 used stimuli from 100 professional actors from five English-speaking nations vocally conveying 11 emotional states (anger, contempt, fear, happiness, interest, lust, neutral, pride, relief, sadness, and shame) using standard-content sentences. Detailed acoustic analyses showed many similarities across groups, and yet also systematic group differences. This provides evidence for cultural accents in expressive style at the level of acoustic cues. In Study 2, listeners evaluated these expressions in a 5 {\texttimes} 5 design balanced across groups. Cross-cultural accuracy was greater than expected by chance. However, there was also in-group advantage, which varied across emotions. A lens model analysis of fundamental acoustic properties examined patterns in emotional expression and perception within and across groups. Acoustic cues were used relatively similarly across groups both to produce and judge emotions, and yet there were also subtle cultural differences. Speakers appear to have a culturally nuanced schema for enacting vocal tones via acoustic cues, and perceivers have a culturally nuanced schema in judging them. Consistent with dialect theory's prediction, in-group judgments showed a greater match between these schemas used for emotional expression and perception. (PsycINFO Database Record},
  file = {/Users/timokoch/Zotero/storage/DLSCQ2ZP/Laukka et al. - 2016 - The Expression and Recognition of Emotions in the .pdf}
}

@phdthesis{laukkaVocalExpressionEmotion2004,
  title = {Vocal Expression of Emotion: Discrete-Emotions and Dimensional Accounts},
  shorttitle = {Vocal Expression of Emotion},
  author = {Laukka, Petri},
  year = {2004},
  school = {Acta Universitatis Upsaliensis},
  file = {/Users/timokoch/Zotero/storage/9IXBQHNC/FULLTEXT01.pdf;/Users/timokoch/Zotero/storage/T69QWWIV/record.html}
}

@article{lausenEmotionRecognitionConfidence2020,
  title = {Emotion Recognition and Confidence Ratings Predicted by Vocal Stimulus Type and Prosodic Parameters},
  author = {Lausen, Adi and Hammerschmidt, Kurt},
  year = {2020},
  month = jun,
  journal = {Humanities and Social Sciences Communications},
  volume = {7},
  number = {1},
  pages = {1--17},
  publisher = {{Palgrave}},
  issn = {2662-9992},
  doi = {10.1057/s41599-020-0499-z},
  urldate = {2020-11-16},
  abstract = {Human speech expresses emotional meaning not only through semantics, but also through certain attributes of the voice, such as pitch or loudness. In investigations of vocal emotion recognition, there is considerable variability in the types of stimuli and procedures used to examine their influence on emotion recognition. In addition, accurate metacognition was argued to promote correct and confident interpretations in emotion recognition tasks. Nevertheless, such associations have rarely been studied previously. We addressed this gap by examining the impact of vocal stimulus type and prosodic speech attributes on emotion recognition and a person's confidence in a given response. We analysed a total of 1038 emotional expressions according to a baseline set of 13 prosodic acoustic parameters. Results showed that these parameters provided sufficient discrimination between expressions of emotional categories to permit accurate statistical classification. Emotion recognition and confidence judgments were found to depend on stimulus material as they could be reliably predicted by different constellations of acoustic features. Finally, results indicated that listeners' accuracy and confidence judgements were significantly higher for affect bursts than speech-embedded stimuli and that the correct classification of emotional expressions elicited increased confidence judgements. Together, these findings show that vocal stimulus type and prosodic attributes of speech strongly influence emotion recognition and listeners' confidence in these given responses.},
  copyright = {2020 The Author(s)},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/PTWZ2YSK/Lausen und Hammerschmidt - 2020 - Emotion recognition and confidence ratings predict.pdf;/Users/timokoch/Zotero/storage/UHRCZ4I7/s41599-020-0499-z.html}
}

@article{lazarevicAmbulatoryAssessmentLanguage2020,
  title = {Ambulatory Assessment of Language Use: {{Evidence}} on the Temporal Stability of {{Electronically Activated Recorder}} and Stream of Consciousness Data},
  shorttitle = {Ambulatory Assessment of Language Use},
  author = {Lazarevic, Ljiljana and Bjekic, Jovana and {\v Z}ivanovi{\'c}, Marko and Knezevic, Goran},
  year = {2020},
  month = feb,
  journal = {Behavior Research Methods},
  volume = {52},
  doi = {10.3758/s13428-020-01361-z},
  abstract = {The ambulatory assessment offers a wide range of methods enabling researchers to investigate psychological, behavioral, emotional, and biological processes. These methods enable us to gather data on individual differences in language use for psychological research. Two studies were conducted with an aim to evaluate and compare the temporal stability of language measures extracted by LIWC software form data obtained by two frequently used methods for assessment of language use, i.e., Electronically Activated Recorder (EAR) and stream of consciousness (SOC) task. Additionally, we examined the amount of variance in language use (assessed by both methods) that can be attributed to intra-individual variability and stable individual differences. Study 1 was focused on investigating language use obtained from 74 respondents using the EAR for 3 consecutive days. Study 2 was conducted on 250 respondents participating in a SOC task where verbal production was collected at ten time points over a 2-month period. Results show that measures obtained using the SOC task have higher temporal stability and consistency, and to a certain extent enable better detection of individual differences. Taking into account certain situational variations improves the reliability of EAR measures.},
  file = {/Users/timokoch/Zotero/storage/6QDYS3WA/Lazarevic et al. - 2020 - Ambulatory assessment of language use Evidence on.pdf}
}

@article{lazarevicAmbulatoryAssessmentLanguage2020a,
  title = {Ambulatory Assessment of Language Use: {{Evidence}} on the Temporal Stability of {{Electronically Activated Recorder}} and Stream of Consciousness Data},
  shorttitle = {Ambulatory Assessment of Language Use},
  author = {Lazarevic, Ljiljana and Bjekic, Jovana and Zivanovic, Marko and Knezevic, Goran},
  year = {2020},
  month = feb,
  journal = {Behavior Research Methods},
  doi = {10.3758/s13428-020-01361-z},
  abstract = {The ambulatory assessment offers a wide range of methods enabling researchers to investigate psychological, behavioral, emotional, and biological processes. These methods enable us to gather data on individual differences in language use for psychological research. Two studies were conducted with an aim to evaluate and compare the temporal stability of language measures extracted by LIWC software form data obtained by two frequently used methods for assessment of language use, i.e., Electronically Activated Recorder (EAR) and stream of consciousness (SOC) task. Additionally, we examined the amount of variance in language use (assessed by both methods) that can be attributed to intra-individual variability and stable individual differences. Study 1 was focused on investigating language use obtained from 74 respondents using the EAR for 3 consecutive days. Study 2 was conducted on 250 respondents participating in a SOC task where verbal production was collected at ten time points over a 2-month period. Results show that measures obtained using the SOC task have higher temporal stability and consistency, and to a certain extent enable better detection of individual differences. Taking into account certain situational variations improves the reliability of EAR measures.}
}

@article{lazerComputationalSocialScience2009,
  title = {Computational {{Social Science}}},
  author = {Lazer, David and Pentland, Alex and Adamic, Lada and Aral, Sinan and Barab{\'a}si, Albert-L{\'a}szl{\'o} and Brewer, Devon and Christakis, Nicholas and Contractor, Noshir and Fowler, James and Gutmann, Myron and Jebara, Tony and King, Gary and Macy, Michael and Roy, Deb and Van Alstyne, Marshall},
  year = {2009},
  month = feb,
  journal = {Science},
  volume = {323},
  number = {5915},
  pages = {721--723},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/science.1167742},
  urldate = {2022-11-07},
  file = {/Users/timokoch/Zotero/storage/9CKAS7NG/Lazer et al. - 2009 - Computational Social Science.pdf}
}

@article{lazerComputationalSocialScience2020,
  title = {Computational Social Science: {{Obstacles}} and Opportunities},
  shorttitle = {Computational Social Science},
  author = {Lazer, David and Pentland, Alex and Watts, Duncan J. and Aral, Sinan and Athey, Susan and Contractor, Noshir and Freelon, Deen and {Gonzalez-Bailon}, Sandra and King, Gary and Margetts, Helen and Nelson, Alondra and Salganik, Matthew J. and Strohmaier, Markus and Vespignani, Alessandro and Wagner, Claudia},
  year = {2020},
  month = aug,
  journal = {Science},
  volume = {369},
  number = {6507},
  pages = {1060--1062},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/science.aaz8170},
  urldate = {2022-11-07},
  file = {/Users/timokoch/Zotero/storage/7DZ8R3JT/Lazer et al. - 2020 - Computational social science Obstacles and opport.pdf}
}

@article{leeInfluenceEmotionKeyboard2015,
  title = {The {{Influence}} of {{Emotion}} on {{Keyboard Typing}}: {{An Experimental Study Using Auditory Stimuli}}},
  shorttitle = {The {{Influence}} of {{Emotion}} on {{Keyboard Typing}}},
  author = {Lee, Po-Ming and Tsui, Wei-Hsuan and Hsiao, Tzu-Chien},
  year = {2015},
  month = nov,
  journal = {PLOS ONE},
  volume = {10},
  number = {6},
  pages = {e0129056},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0129056},
  urldate = {2022-11-21},
  abstract = {In recent years, a novel approach for emotion recognition has been reported, which is by keystroke dynamics. The advantages of using this approach are that the data used is rather non-intrusive and easy to obtain. However, there were only limited investigations about the phenomenon itself in previous studies. Hence, this study aimed to examine the source of variance in keyboard typing patterns caused by emotions. A controlled experiment to collect subjects' keystroke data in different emotional states induced by International Affective Digitized Sounds (IADS) was conducted. Two-way Valence (3) x Arousal (3) ANOVAs was used to examine the collected dataset. The results of the experiment indicate that the effect of arousal is significant in keystroke duration (p {$<$} .05), keystroke latency (p {$<$} .01), but not in the accuracy rate of keyboard typing. The size of the emotional effect is small, compared to the individual variability. Our findings support the conclusion that the keystroke duration and latency are influenced by arousal. The finding about the size of the effect suggests that the accuracy rate of emotion recognition technology could be further improved if personalized models are utilized. Notably, the experiment was conducted using standard instruments and hence is expected to be highly reproducible.},
  langid = {english},
  keywords = {Algorithms,Analysis of variance,Computer applications,Computers,Emotions,Fingers,Programming languages,Psychological stress},
  file = {/Users/timokoch/Zotero/storage/XVWHAY89/Lee et al. - 2015 - The Influence of Emotion on Keyboard Typing An Ex.pdf;/Users/timokoch/Zotero/storage/ZFUXLSVB/article.html}
}

@article{lemauProfessionalActorsDemonstrate2021,
  title = {Professional Actors Demonstrate Variability, Not Stereotypical Expressions, When Portraying Emotional States in Photographs},
  author = {Le Mau, Tuan and Hoemann, Katie and Lyons, Sam H. and Fugate, Jennifer M. B. and Brown, Emery N. and Gendron, Maria and Barrett, Lisa Feldman},
  year = {2021},
  month = aug,
  journal = {Nature Communications},
  volume = {12},
  number = {1},
  pages = {5037},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-021-25352-6},
  urldate = {2022-11-03},
  abstract = {It is long~hypothesized that there is a reliable, specific mapping between certain emotional states and the facial movements that express those states. This hypothesis is often tested by asking untrained participants to pose the facial movements they believe they use to express emotions during generic scenarios. Here, we test this hypothesis using, as stimuli, photographs of facial configurations posed by professional actors in response to contextually-rich scenarios. The scenarios portrayed in the photographs were rated by a convenience sample of participants for the extent to which they evoked an instance of 13 emotion categories, and actors' facial poses were coded for their specific movements. Both unsupervised and supervised machine learning find that in these photographs, the actors portrayed emotional states with variable facial configurations; instances of only three emotion categories (fear, happiness, and surprise) were portrayed with moderate reliability and specificity. The photographs were separately rated by another sample of participants for the extent to which they portrayed an instance of the 13 emotion categories; they were rated when presented alone and when presented with their associated scenarios, revealing that emotion inferences by participants also vary in a context-sensitive manner. Together, these findings suggest that facial movements and perceptions of emotion vary by situation and transcend stereotypes of emotional expressions. Future research may build on these findings by incorporating dynamic stimuli rather than photographs and studying a broader range of cultural contexts.},
  copyright = {2021 The Author(s)},
  langid = {english},
  keywords = {Communication,Human behaviour},
  file = {/Users/timokoch/Zotero/storage/XANI8XXA/Le Mau et al. - 2021 - Professional actors demonstrate variability, not s.pdf;/Users/timokoch/Zotero/storage/WL3M5PPB/s41467-021-25352-6.html}
}

@misc{LEXHUBArticles,
  title = {{{LEXHUB}} - {{Articles}}},
  urldate = {2020-10-16},
  abstract = {LexHub is an online community space designed to help a range of audiences understand, execute, and share large-scale language analyses deriving insights about people.},
  howpublished = {http://www.lexhub.org/articles/135},
  file = {/Users/timokoch/Zotero/storage/DUV8DKRV/135.html}
}

@article{limCulturalDifferencesEmotion2016,
  title = {Cultural Differences in Emotion: Differences in Emotional Arousal Level between the {{East}} and the {{West}}},
  shorttitle = {Cultural Differences in Emotion},
  author = {Lim, Nangyeon},
  year = {2016},
  month = jun,
  journal = {Integrative Medicine Research},
  volume = {5},
  number = {2},
  pages = {105--109},
  issn = {2213-4220},
  doi = {10.1016/j.imr.2016.03.004},
  urldate = {2021-12-14},
  abstract = {Whether emotion is universal or social is a recurrent issue in the history of emotion study among psychologists. Some researchers view emotion as a universal construct, and that a large part of emotional experience is biologically based. However, emotion is not only biologically determined, but is also influenced by the environment. Therefore, cultural differences exist in some aspects of emotions, one such important aspect of emotion being emotional arousal level. All affective states are systematically represented as two bipolar dimensions, valence and arousal. Arousal level of actual and ideal emotions has consistently been found to have cross-cultural differences. In Western or individualist culture, high arousal emotions are valued and promoted more than low arousal emotions. Moreover, Westerners experience high arousal emotions more than low arousal emotions. By contrast, in Eastern or collectivist culture, low arousal emotions are valued more than high arousal emotions. Moreover, people in the East actually experience and prefer to experience low arousal emotions more than high arousal emotions. Mechanism of these cross-cultural differences and implications are also discussed.},
  langid = {english},
  keywords = {collectivist culture,cultural difference,emotional arousal level,individualist culture},
  file = {/Users/timokoch/Zotero/storage/VTIFSM3N/Lim - 2016 - Cultural differences in emotion differences in em.pdf}
}

@article{liMiningRelationshipEmoji,
  title = {Mining the {{Relationship}} between {{Emoji Usage Patterns}} and {{Personality}}},
  author = {Li, Weijian and Chen, Yuxiao and Hu, Tianran and Luo, Jiebo},
  pages = {4},
  abstract = {Emojis have been widely used in textual communications as a new way to convey nonverbal cues. An interesting observation is the various emoji usage patterns among different users. In this paper, we investigate the correlation between user personality traits and their emoji usage patterns, particularly on overall amounts and specific preferences. To achieve this goal, we build a large Twitter dataset which includes 352,245 users and over 1.13 billion tweets associated with calculated personality traits and emoji usage patterns. Our correlation and emoji prediction results provide insights into the power of diverse personalities that lead to varies emoji usage patterns as well as its potential in emoji recommendation tasks.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/IATZE3J5/Li et al. - Mining the Relationship between Emoji Usage Patter.pdf}
}

@article{liMiningRelationshipEmoji2018,
  title = {Mining the {{Relationship}} between {{Emoji Usage Patterns}} and {{Personality}}},
  author = {Li, Weijian and Chen, Yuxiao and Hu, Tianran and Luo, Jiebo},
  year = {2018},
  month = apr,
  journal = {arXiv:1804.05143 [cs]},
  eprint = {1804.05143},
  primaryclass = {cs},
  urldate = {2019-07-29},
  abstract = {Emojis have been widely used in textual communications as a new way to convey nonverbal cues. An interesting observation is the various emoji usage patterns among different users. In this paper, we investigate the correlation between user personality traits and their emoji usage patterns, particularly on overall amounts and specific preferences. To achieve this goal, we build a large Twitter dataset which includes 352,245 users and over 1.13 billion tweets associated with calculated personality traits and emoji usage patterns. Our correlation and emoji prediction results provide insights into the power of diverse personalities that lead to varies emoji usage patterns as well as its potential in emoji recommendation tasks.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Social and Information Networks},
  file = {/Users/timokoch/Zotero/storage/45B88RDR/Li et al. - 2018 - Mining the Relationship between Emoji Usage Patter.pdf}
}

@article{linProsodyDominatesSemantics2020,
  title = {Prosody {{Dominates Over Semantics}} in {{Emotion Word Processing}}: {{Evidence From Cross-Channel}} and {{Cross-Modal Stroop Effects}}},
  shorttitle = {Prosody {{Dominates Over Semantics}} in {{Emotion Word Processing}}},
  author = {Lin, Yi and Ding, Hongwei and Zhang, Yang},
  year = {2020},
  month = mar,
  journal = {Journal of Speech, Language, and Hearing Research},
  volume = {63},
  number = {3},
  pages = {896--912},
  publisher = {{American Speech-Language-Hearing Association}},
  doi = {10.1044/2020_JSLHR-19-00258},
  urldate = {2021-06-30},
  abstract = {Purpose       Emotional speech communication involves multisensory integration of linguistic (e.g.,          semantic content) and paralinguistic (e.g., prosody and facial expressions) messages.          Previous studies on linguistic versus paralinguistic salience effects in emotional          speech processing have produced inconsistent findings. In this study, we investigated          the relative perceptual saliency of emotion cues in cross-channel auditory alone task          (i.e., semantics{\textendash}prosody Stroop task) and cross-modal audiovisual task (i.e., semantics{\textendash}prosody{\textendash}face          Stroop task).              Method       Thirty normal Chinese adults participated in two Stroop experiments with spoken emotion          adjectives in Mandarin Chinese. Experiment 1 manipulated auditory pairing of emotional          prosody (happy or sad) and lexical semantic content in congruent and incongruent conditions.          Experiment 2 extended the protocol to cross-modal integration by introducing visual          facial expression during auditory stimulus presentation. Participants were asked to          judge emotional information for each test trial according to the instruction of selective          attention.              Results       Accuracy and reaction time data indicated that, despite an increase in cognitive demand          and task complexity in Experiment 2, prosody was consistently more salient than semantic          content for emotion word processing and did not take precedence over facial expression.          While congruent stimuli enhanced performance in both experiments, the facilitatory          effect was smaller in Experiment 2.              Conclusion       Together, the results demonstrate the salient role of paralinguistic prosodic cues          in emotion word processing and congruence facilitation effect in multisensory integration.          Our study contributes tonal language data on how linguistic and paralinguistic messages          converge in multisensory speech processing and lays a foundation for further exploring          the brain mechanisms of cross-channel/modal emotion integration with potential clinical          applications.},
  file = {/Users/timokoch/Zotero/storage/AIJDGYWH/Lin Yi et al. - 2020 - Prosody Dominates Over Semantics in Emotion Word P.pdf}
}

@inproceedings{liuAnalyzingPersonalitySocial2016,
  title = {Analyzing {{Personality}} through {{Social Media Profile Picture Choice}}},
  booktitle = {{{ICWSM}}},
  author = {Liu, Leqi and {Preotiuc-Pietro}, Daniel and Samani, Zahra Riahi and Moghaddam, Mohsen Ebrahimi and Ungar, Lyle H.},
  year = {2016},
  pages = {211--220}
}

@misc{liuCrossPlatformDifferenceFacebook2022,
  title = {Cross-{{Platform Difference}} in {{Facebook}} and {{Text Messages Language Use}}: {{Illustrated}} by {{Depression Diagnosis}}},
  shorttitle = {Cross-{{Platform Difference}} in {{Facebook}} and {{Text Messages Language Use}}},
  author = {Liu, Tingting and Giorgi, Salvatore and Tao, Xiangyu and Bellew, Douglas and Curtis, Brenda and Ungar, Lyle},
  year = {2022},
  month = feb,
  number = {arXiv:2202.01802},
  eprint = {2202.01802},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2202.01802},
  urldate = {2022-12-22},
  abstract = {How does language differ across one's Facebook status updates vs. one's text messages (SMS)? In this study, we show how Facebook and SMS use differs in psycho-linguistic characteristics and how these differences drive downstream analyses with an illustration of depression diagnosis. We use a sample of consenting participants who shared Facebook status updates, SMS data, and answered a standard psychological depression screener. We quantify domain differences using psychologically driven lexical methods and find that language on Facebook involves more personal concerns, experiences, and content features while the language in SMS contains more informal and style features. Next, we estimate depression from both text domains, using a depression model trained on Facebook data, and find a drop in accuracy when predicting self-reported depression assessments from the SMS-based depression estimates. Finally, we evaluate a simple domain adaption correction based on words driving the cross-platform differences and applied it to the SMS-derived depression estimates, resulting in significant improvement in prediction. Our work shows the Facebook vs. SMS difference in language use and suggests the necessity of cross-domain adaption for text-based predictions.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Human-Computer Interaction,Computer Science - Machine Learning},
  file = {/Users/timokoch/Zotero/storage/U38AUQJH/Liu et al. - 2022 - Cross-Platform Difference in Facebook and Text Mes.pdf;/Users/timokoch/Zotero/storage/BPRBFZYI/2202.html}
}

@article{liuEmojiUseChina2022,
  title = {Emoji Use in {{China}}: Popularity Patterns and Changes Due to {{COVID-19}}},
  shorttitle = {Emoji Use in {{China}}},
  author = {Liu, Chuchu and Tan, Xu and Zhou, Tao and Zhang, Wei and Liu, Jianguo and Lu, Xin},
  year = {2022},
  month = nov,
  journal = {Applied Intelligence},
  volume = {52},
  number = {14},
  pages = {16138--16148},
  issn = {1573-7497},
  doi = {10.1007/s10489-022-03195-y},
  urldate = {2023-03-01},
  abstract = {Emojis are small pictograms that are frequently embedded within micro-texts to more directly express emotional meanings. To understand the changes in the emoji usage of internet users during the COVID-19 outbreak, we analysed a large dataset collected from Weibo, the most popular Twitter-like social media platform in China, from December 1, 2019, to March 20, 2020. The data contained 38,183,194 microblog posts published by 2,239,472 unique users in Wuhan. We calculated the basic statistics of users' usage of emojis, topics, and sentiments and analysed the temporal patterns of emoji occurrence. After examining the emoji co-occurrence structure, we finally explored other factors that may affect individual emoji usage. We found that the COVID-19 outbreak greatly changed the pattern of emoji usage; i.e., both the proportion of posts containing emojis and the ratio of users using emojis declined substantially, while the number of posts remained the same. The daily proportion of Happy emojis significantly declined to approximately 32\%, but the proportions of Sad- and Encouraging-related emojis rose to 24\% and 34\%, respectively. Despite a significant decrease in the number of nodes and edges in the emoji co-occurrence network, the average degree of the network increased from 34 to 39.8, indicating that the diversity of emoji usage increased. Most interestingly, we found that male users were more inclined towards using regular textual language with fewer emojis after the pandemic, suggesting that during public crises, male groups appeared to control their emotional display. In summary, the COVID-19 pandemic remarkably impacted individual sentiments, and the normal pattern of emoji usage tends to change significantly following a public emergency.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/C93C6LSL/Liu et al. - 2022 - Emoji use in China popularity patterns and change.pdf}
}

@article{liuMultimodalPrivacypreservingMood2020,
  title = {Multimodal {{Privacy-preserving Mood Prediction}} from {{Mobile Data}}: {{A Preliminary Study}}},
  shorttitle = {Multimodal {{Privacy-preserving Mood Prediction}} from {{Mobile Data}}},
  author = {Liu, Terrance and Liang, Paul Pu and Muszynski, Michal and Ishii, Ryo and Brent, David and Auerbach, Randy and Allen, Nicholas and Morency, Louis-Philippe},
  year = {2020},
  month = dec,
  journal = {arXiv:2012.02359 [cs, stat]},
  eprint = {2012.02359},
  primaryclass = {cs, stat},
  urldate = {2020-12-30},
  abstract = {Mental health conditions remain under-diagnosed even in countries with common access to advanced medical care. The ability to accurately and efficiently predict mood from easily collectible data has several important implications towards the early detection and intervention of mental health disorders. One promising data source to help monitor human behavior is from daily smartphone usage. However, care must be taken to summarize behaviors without identifying the user through personal (e.g., personally identifiable information) or protected attributes (e.g., race, gender). In this paper, we study behavioral markers or daily mood using a recent dataset of mobile behaviors from high-risk adolescent populations. Using computational models, we find that multimodal modeling of both text and app usage features is highly predictive of daily mood over each modality alone. Furthermore, we evaluate approaches that reliably obfuscate user identity while remaining predictive of daily mood. By combining multimodal representations with privacy-preserving learning, we are able to push forward the performance-privacy frontier as compared to unimodal approaches.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computers and Society,Computer Science - Machine Learning,Statistics - Applications},
  file = {/Users/timokoch/Zotero/storage/8TILWX52/Liu et al. - 2020 - Multimodal Privacy-preserving Mood Prediction from.pdf;/Users/timokoch/Zotero/storage/MIUAFJ4J/2012.html}
}

@article{liuRelationshipTextMessage2021,
  title = {The Relationship between Text Message Sentiment and Self-Reported Depression},
  author = {Liu, Tony and Meyerhoff, Jonah and Eichstaedt, Johannes C. and Karr, Chris J. and Kaiser, Susan M. and Kording, Konrad P. and Mohr, David C. and Ungar, Lyle H.},
  year = {2021},
  month = dec,
  journal = {Journal of Affective Disorders},
  issn = {0165-0327},
  doi = {10.1016/j.jad.2021.12.048},
  urldate = {2021-12-28},
  abstract = {Background Personal sensing has shown promise for detecting behavioral correlates of depression, but there is little work examining personal sensing of cognitive and affective states. Digital language, particularly through personal text messages, is one source that can measure these markers. Methods We correlated privacy-preserving sentiment analysis of text messages with self-reported depression symptom severity. We enrolled 219 U.S. adults in a 16 week longitudinal observational study. Participants installed a personal sensing app on their phones, which administered self-report PHQ-8 assessments of their depression severity, collected phone sensor data, and computed anonymized language sentiment scores from their text messages. We also trained machine learning models for predicting end-of-study self-reported depression status using on blocks of phone sensor and text features. Results In correlation analyses, we find that degrees of depression, emotional, and personal pronoun language categories correlate most strongly with self-reported depression, validating prior literature. Our classification models which predict binary depression status achieve a leave-one-out AUC of 0.72 when only considering text features and 0.76 when combining text with other networked smartphone sensors. Limitations Participants were recruited from a panel that over-represented women, caucasians, and individuals with self-reported depression at baseline. As language use differs across demographic factors, generalizability beyond this population may be limited. The study period also coincided with the initial COVID-19 outbreak in the United States, which may have affected smartphone sensor data quality. Conclusions Effective depression prediction through text message sentiment, especially when combined with other personal sensors, could enable comprehensive mental health monitoring and intervention.},
  langid = {english},
  keywords = {Depression,digital phenotyping,language sentiment analysis,machine learning,personal sensing},
  file = {/Users/timokoch/Zotero/storage/FURKUAPP/Liu et al. - 2022 - The relationship between text message sentiment an.pdf;/Users/timokoch/Zotero/storage/DYRU797U/S0165032721013598.html}
}

@misc{liuRoBERTaRobustlyOptimized2019,
  title = {{{RoBERTa}}: {{A Robustly Optimized BERT Pretraining Approach}}},
  shorttitle = {{{RoBERTa}}},
  author = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  year = {2019},
  month = jul,
  number = {arXiv:1907.11692},
  eprint = {1907.11692},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1907.11692},
  urldate = {2023-02-09},
  abstract = {Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/timokoch/Zotero/storage/PH6I8ICH/Liu et al. - 2019 - RoBERTa A Robustly Optimized BERT Pretraining App.pdf;/Users/timokoch/Zotero/storage/DIPX3BXK/1907.html}
}

@inproceedings{ljubesicLanguageindependentGenderPrediction2017,
  title = {Language-Independent {{Gender Prediction}} on {{Twitter}}},
  booktitle = {Proceedings of the {{Second Workshop}} on {{NLP}} and {{Computational Social Science}}},
  author = {Ljube{\v s}i{\'c}, Nikola and Fi{\v s}er, Darja and Erjavec, Toma{\v z}},
  year = {2017},
  pages = {1--6},
  publisher = {{Association for Computational Linguistics}},
  address = {{Vancouver, Canada}},
  doi = {10.18653/v1/W17-2901},
  urldate = {2020-03-30},
  abstract = {In this paper we present a set of experiments and analyses on predicting the gender of Twitter users based on languageindependent features extracted either from the text or the metadata of users' tweets. We perform our experiments on the TwiSty dataset containing manual gender annotations for users speaking six different languages. Our classification results show that, while the prediction model based on language-independent features performs worse than the bag-of-words model when training and testing on the same language, it regularly outperforms the bag-of-words model when applied to different languages, showing very stable results across various languages. Finally we perform a comparative analysis of feature effect sizes across the six languages and show that differences in our features correspond to cultural distances.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/KESH8RVE/Ljubešić et al. - 2017 - Language-independent Gender Prediction on Twitter.pdf}
}

@article{lohrAgeBigData2012,
  title = {The Age of Big Data},
  author = {Lohr, Steve},
  year = {2012},
  journal = {New York Times},
  volume = {11},
  number = {2012}
}

@article{loNonverbalCommunicationFunctions2008,
  title = {The Nonverbal Communication Functions of Emoticons in Computer-Mediated Communication},
  author = {Lo, Shao-Kang},
  year = {2008},
  journal = {CyberPsychology \& Behavior},
  volume = {11},
  number = {5},
  pages = {595--597},
  issn = {1094-9313}
}

@article{lowellEffectSpeakingContext2016,
  title = {The Effect of Speaking Context on Spectral- and Cepstral-Based Acoustic Features of Normal Voice},
  author = {Lowell, Soren Y. and Hylkema, Jennifer A.},
  year = {2016},
  month = jan,
  journal = {Clinical Linguistics \& Phonetics},
  volume = {30},
  number = {1},
  pages = {1--11},
  publisher = {{Taylor \& Francis}},
  issn = {0269-9206},
  doi = {10.3109/02699206.2015.1087049},
  urldate = {2021-06-30},
  abstract = {The effect of speaking context on four cepstral- and spectral-based acoustic measures was investigated in 20 participants with normal voice. Speakers produced three different continuous speaking tasks that varied in duration and phonemic content. Cepstral and spectral measures that can be validly derived from continuous speech were computed across the three speaking contexts. Cepstral peak prominence (CPP), low/high spectral ratio, and the standard deviation (SD) of the low/high spectral ratio did not significantly differ across speaking contexts, and correlations for the first two measures were strong among the three speaking tasks. The SD of the CPP showed significant task differences, and relationships between the speaking contexts were generally moderate. These findings suggest that in speakers with normal voice, the differing phonemic content across several frequently used speaking stimuli minimally impacted group means for three clinically relevant cepstral- and spectral-based acoustic measures.},
  pmid = {26595764},
  keywords = {Acoustic,cepstral,context,continuous,phonemic,spectral,speech,voice},
  file = {/Users/timokoch/Zotero/storage/LKWGQCHM/02699206.2015.html}
}

@article{lucasExplainingExtraversionPositive2008,
  title = {Explaining the {{Extraversion}}/{{Positive Affect Relation}}: {{Sociability Cannot Account}} for {{Extraverts}}' {{Greater Happiness}}},
  shorttitle = {Explaining the {{Extraversion}}/{{Positive Affect Relation}}},
  author = {Lucas, Richard E. and Le, Kimdy and Dyrenforth, Portia S.},
  year = {2008},
  journal = {Journal of Personality},
  volume = {76},
  number = {3},
  pages = {385--414},
  issn = {1467-6494},
  doi = {10.1111/j.1467-6494.2008.00490.x},
  urldate = {2023-02-01},
  abstract = {The association between Extraversion and positive affect is one of the most robust findings in the study of personality and emotion. Temperament models posit that the association is direct; instrumental models posit that the association is mediated by additional processes. Two experience sampling studies were conducted to test instrumental mechanisms that might underlie the effect. According to a mediation model, extraverts' greater social activity can account for their increased positive affect when compared to introverts. According to a person-by-situation interaction model, extraverts react more positively to social situations than do introverts, and this interaction can account for the association. Only weak support for the instrumental models was found; consistent with temperament models, a moderate direct association remained even after controlling for these effects.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/6GVV86Y5/j.1467-6494.2008.00490.html}
}

@article{luhmannUsingBigData2017,
  title = {Using {{Big Data}} to Study Subjective Well-Being},
  author = {Luhmann, Maike},
  year = {2017},
  month = dec,
  journal = {Current Opinion in Behavioral Sciences},
  volume = {18},
  pages = {28--33},
  doi = {10.1016/j.cobeha.2017.07.006},
  abstract = {Subjective well-being comprises emotional experiences and life satisfaction. This article reviews how Big Data can be used to measure, study, and change subjective well-being. Most Big Data approaches measure subjective well-being by analyzing language patterns on Twitter or Facebook. These approaches provide satisfactory accuracy for emotional experiences, but not yet for life satisfaction. Other measurement approaches include the analysis of other digital traces such as Facebook profiles and the analysis of mobile phone usage patterns. Big Data can be used to study subjective well-being on individual levels, regional levels, and across time. Potentials and limitations of using Big Data in studies on subjective well-being are discussed.},
  file = {/Users/timokoch/Zotero/storage/SRWUYGX8/Luhmann - 2017 - Using Big Data to study subjective well-being.pdf}
}

@article{luLearningConceptDrift2019,
  title = {Learning under {{Concept Drift}}: {{A Review}}},
  shorttitle = {Learning under {{Concept Drift}}},
  author = {Lu, Jie and Liu, Anjin and Dong, Fan and Gu, Feng and Gama, Jo{\~a}o and Zhang, Guangquan},
  year = {2019},
  month = dec,
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {31},
  number = {12},
  pages = {2346--2363},
  issn = {1558-2191},
  doi = {10.1109/TKDE.2018.2876857},
  abstract = {Concept drift describes unforeseeable changes in the underlying distribution of streaming data overtime. Concept drift research involves the development of methodologies and techniques for drift detection, understanding, and adaptation. Data analysis has revealed that machine learning in a concept drift environment will result in poor learning results if the drift is not addressed. To help researchers identify which research topics are significant and how to apply related techniques in data analysis tasks, it is necessary that a high quality, instructive review of current research developments and trends in the concept drift field is conducted. In addition, due to the rapid development of concept drift in recent years, the methodologies of learning under concept drift have become noticeably systematic, unveiling a framework which has not been mentioned in literature. This paper reviews over 130 high quality publications in concept drift related research areas, analyzes up-to-date developments in methodologies and techniques, and establishes a framework of learning under concept drift including three main components: concept drift detection, concept drift understanding, and concept drift adaptation. This paper lists and discusses 10 popular synthetic datasets and 14 publicly available benchmark datasets used for evaluating the performance of learning algorithms aiming at handling concept drift. Also, concept drift related research directions are covered and discussed. By providing state-of-the-art knowledge, this survey will directly support researchers in their understanding of research developments in the field of learning under concept drift.},
  keywords = {adaptive learning,Big Data,Cameras,change detection,Concept drift,concept drift adaptation,concept drift detection,concept drift environment,concept drift field,concept drift related research areas,concept drift understanding,data analysis,Data analysis,data mining,Data models,data streams,drift research,learning,learning (artificial intelligence),Machine learning,Market research,Mobile handsets,pattern classification},
  file = {/Users/timokoch/Zotero/storage/H882NMZV/8496795.html}
}

@inproceedings{luStressSenseDetectingStress2012,
  title = {{{StressSense}}: Detecting Stress in Unconstrained Acoustic Environments Using Smartphones},
  shorttitle = {{{StressSense}}},
  booktitle = {Proceedings of the 2012 {{ACM Conference}} on {{Ubiquitous Computing}} - {{UbiComp}} '12},
  author = {Lu, Hong and Frauendorfer, Denise and Rabbi, Mashfiqui and Mast, Marianne Schmid and Chittaranjan, Gokul T. and Campbell, Andrew T. and {Gatica-Perez}, Daniel and Choudhury, Tanzeem},
  year = {2012},
  pages = {351},
  publisher = {{ACM Press}},
  address = {{Pittsburgh, Pennsylvania}},
  doi = {10.1145/2370216.2370270},
  urldate = {2018-12-07},
  abstract = {Stress can have long term adverse effects on individuals' physical and mental well-being. Changes in the speech production process is one of many physiological changes that happen during stress. Microphones, embedded in mobile phones and carried ubiquitously by people, provide the opportunity to continuously and non-invasively monitor stress in real-life situations. We propose StressSense for unobtrusively recognizing stress from human voice using smartphones. We investigate methods for adapting a one-size-fitsall stress model to individual speakers and scenarios. We demonstrate that the StressSense classifier can robustly identify stress across multiple individuals in diverse acoustic environments: using model adaptation StressSense achieves 81\% and 76\% accuracy for indoor and outdoor environments, respectively. We show that StressSense can be implemented on commodity Android phones and run in real-time. To the best of our knowledge, StressSense represents the first system to consider voice based stress detection and model adaptation in diverse real-life conversational situations using smartphones.},
  isbn = {978-1-4503-1224-0},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/N2J9T3U5/Lu et al. - 2012 - StressSense detecting stress in unconstrained aco.pdf}
}

@article{mahmoodiBigDataApproaches2017,
  title = {Big {{Data}} Approaches in Social and Behavioral Science: Four Key Trade-Offs and a Call for Integration},
  shorttitle = {Big {{Data}} Approaches in Social and Behavioral Science},
  author = {Mahmoodi, J and Leckelt, M and {van Zalk}, {\relax MWH} and Geukes, K and Back, {\relax MD}},
  year = {2017},
  month = dec,
  journal = {Current Opinion in Behavioral Sciences},
  series = {Big Data in the Behavioural Sciences},
  volume = {18},
  pages = {57--62},
  issn = {2352-1546},
  doi = {10.1016/j.cobeha.2017.07.001},
  urldate = {2022-11-08},
  abstract = {Big Data approaches have given rise to novel methodological tools to investigate human decisions and behaviors beyond what is possible with traditional forms of analysis. Like any other paradigm in the social and behavioral sciences, however, Big Data is not immune to a number of typical trade-offs: (1) Prediction versus explanation, pertaining to the overall research goals; (2) induction versus deduction, regarding the epistemological focus; (3) bigness versus representativeness in sampling approaches; and (4) data access versus scientific independence, addressing the forms of data usage. In this paper, we discuss these trade-offs and how Big Data and traditional approaches typically relate to them, and propose ways to overcome each trade-off by integrating advantages of different research approaches in the social and behavioral sciences with Big Data.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/9ZXZHAW7/Mahmoodi et al. - 2017 - Big Data approaches in social and behavioral scien.pdf;/Users/timokoch/Zotero/storage/RSYHINUC/S235215461730075X.html}
}

@article{mairesseUsingLinguisticCues2007,
  title = {Using {{Linguistic Cues}} for the {{Automatic Recognition}} of {{Personality}} in {{Conversation}} and {{Text}}},
  author = {Mairesse, F. and Walker, M. A. and Mehl, Matthias R. and Moore, R. K.},
  year = {2007},
  month = nov,
  journal = {Journal of Artificial Intelligence Research},
  volume = {30},
  pages = {457--500},
  issn = {1076-9757},
  doi = {10.1613/jair.2349},
  urldate = {2019-07-01},
  abstract = {It is well known that utterances convey a great deal of information about the speaker in addition to their semantic content. One such type of information consists of cues to the speaker's personality traits, the most fundamental dimension of variation between humans. Recent work explores the automatic detection of other types of pragmatic variation in text and conversation, such as emotion, deception, speaker charisma, dominance, point of view, subjectivity, opinion and sentiment. Personality affects these other aspects of linguistic production, and thus personality recognition may be useful for these tasks, in addition to many other potential applications. However, to date, there is little work on the automatic recognition of personality traits. This article reports experimental results for recognition of all Big Five personality traits, in both conversation and text, utilising both self and observer ratings of personality. While other work reports classification results, we experiment with classification, regression and ranking models. For each model, we analyse the effect of different feature sets on accuracy. Results show that for some traits, any type of statistical model performs significantly better than the baseline, but ranking models perform best overall. We also present an experiment suggesting that ranking models are more accurate than multi-class classifiers for modelling personality. In addition, recognition models trained on observed personality perform better than models trained using selfreports, and the optimal feature set depends on the personality trait. A qualitative analysis of the learned models confirms previous findings linking language and personality, while revealing many new linguistic markers.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/A63474LY/Mairesse et al. - 2007 - Using Linguistic Cues for the Automatic Recognitio.pdf}
}

@article{managoSelfpresentationGenderMySpace2008,
  title = {Self-Presentation and Gender on {{MySpace}}},
  author = {Manago, Adriana M. and Graham, Michael B. and Greenfield, Patricia M. and Salimkhan, Goldie},
  year = {2008},
  month = nov,
  journal = {Journal of Applied Developmental Psychology},
  volume = {29},
  number = {6},
  pages = {446--458},
  issn = {01933973},
  doi = {10.1016/j.appdev.2008.07.001},
  urldate = {2020-03-18},
  abstract = {Within the cultural context of MySpace, this study explores the ways emerging adults experience social networking. Through focus group methodology, the role of virtual peer interaction in the development of personal, social, and gender identities was investigated. Findings suggest that college students utilize MySpace for identity exploration, engaging in social comparison and expressing idealized aspects of the selves they wish to become. The public nature of self and relationship displays introduce feedback mechanisms by which emerging adults can legitimize images as associated with the self. Also, male{\textendash}female differences in self-presentation parallel, and possibly intensify, gender norms offline. Our study suggests that social networking sites provide valuable opportunities for emerging adults to realize possible selves; however, increased pressure for female sexual objectification and intensified social comparison may also negatively impact identity development. A balanced view, presenting both opportunities and drawbacks, should be encouraged in policies regarding youth participation in social networking sites.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/JKGFYV39/Manago et al. - 2008 - Self-presentation and gender on MySpace.pdf}
}

@misc{mandellSpotifyPatentsVoice2020,
  title = {Spotify {{Patents A Voice Assistant That Can Read Your Emotions}}},
  author = {Mandell, Josh},
  year = {2020},
  journal = {Forbes},
  urldate = {2021-06-30},
  abstract = {Spotify appears to be interested in challenging Alexa and Siri with its own state of the art voice assistant.},
  chapter = {Hollywood \& Entertainment},
  howpublished = {https://www.forbes.com/sites/joshmandell/2020/03/12/spotify-patents-a-voice-assistant--that-can-read-your-emotions/},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/GRX5YUUD/spotify-patents-a-voice-assistant--that-can-read-your-emotions.html}
}

@inproceedings{mandiEmotionDetectionSmartphone2022,
  title = {Emotion Detection from Smartphone Keyboard Interactions: Role of Temporal vs Spectral Features},
  shorttitle = {Emotion Detection from Smartphone Keyboard Interactions},
  booktitle = {Proceedings of the 37th {{ACM}}/{{SIGAPP Symposium}} on {{Applied Computing}}},
  author = {Mandi, Salma and Ghosh, Surjya and De, Pradipta and Mitra, Bivas},
  year = {2022},
  month = apr,
  pages = {677--680},
  publisher = {{ACM}},
  address = {{Virtual Event}},
  doi = {10.1145/3477314.3507159},
  urldate = {2022-07-15},
  abstract = {Keystroke or typing dynamics represent two key facets - rhythm corresponds to spectral-domain characteristics and timing corresponds to time-domain behavior , which are created when a person types. The presence of inherent time-domain and frequency-domain characteristics in smartphone keyboard interactions motivate us to perform a comparative analysis of time-domain and frequencydomain features for emotion detection. We design, and develop an Android-based data collection application, which collects keyboard interaction logs and emotion self-reports (happy, sad, stressed, relaxed) from 18 subjects in a 3-week in-the-wild study. For the time-domain analysis, we extract a set of time-domain features and construct Random Forest-based personalized model; whereas for the spectral-domain analysis, first transform the interaction details into frequency-domain using DFT (Discrete Fourier Transform) and then extract a set of spectral-domain features to construct a personalized model for emotion detection. The empirical analysis from the study reveals that the time-domain models return superior classification performance (average AUCROC 72\%) than the frequency-domain models (average 67\%). It also signifies the importance of several time-domain and frequency-domain features as a strong discriminator of emotion states.},
  isbn = {978-1-4503-8713-2},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/5CPNLUQI/Mandi et al. - 2022 - Emotion detection from smartphone keyboard interac.pdf}
}

@article{marengoAssessingPersonalityUsing2017,
  title = {Assessing Personality Using Emoji: {{An}} Exploratory Study},
  author = {Marengo, Davide and Giannotta, Fabrizia and Settanni, Michele},
  year = {2017},
  journal = {Personality and Individual Differences},
  volume = {112},
  pages = {74--78},
  issn = {01918869},
  doi = {10.1016/j.paid.2017.02.037}
}

@article{marengoAssessingPersonalityUsing2017a,
  title = {Assessing Personality Using Emoji: {{An}} Exploratory Study},
  shorttitle = {Assessing Personality Using Emoji},
  author = {Marengo, Davide and Giannotta, Fabrizia and Settanni, Michele},
  year = {2017},
  month = jul,
  journal = {Personality and Individual Differences},
  volume = {112},
  pages = {74--78},
  issn = {01918869},
  doi = {10.1016/j.paid.2017.02.037},
  urldate = {2019-07-29},
  abstract = {The increasing popularity of text-based computer mediated communication, such as instant messaging and mobile texting, have resulted in the emergence of a new pictographic form of language, i.e. emoji, offering an intuitive and informal way to convey emotions and attitudes, replacing words or phrases in text messages. Based on these characteristics, could identification with emoji be associated with personality? Could they be used instead of text-based items in personality assessment? The present study aimed at exploring these questions. The sample is composed of 234 young adults recruited online (age: M = 24.79, SD = 6.47; 62\% female). Participants responded to a brief Big-Five personality questionnaire and a 91-item survey assessing participants' degree of self-identification with emoji selected from the Apple Color Emoji fontset. Results indicated that 36 out of 91 examined emoji are significantly related with three of the Big-Five personality traits - emotional stability, extraversion, and agreeableness - that are consistently linked with emotion and affective processing. Emoji-based measures of these personality traits show moderate-to-large concurrent validity with scores from a validated personality questionnaire (r = 0.6{\textendash}0.8). Overall, our study advances the idea that emoji might be employed to develop a language-free assessment tool for personality.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/ZV6MT3RZ/Marengo et al. - 2017 - Assessing personality using emoji An exploratory .pdf}
}

@inproceedings{markovikjMiningFacebookData2013,
  title = {Mining Facebook Data for Predictive Personality Modeling},
  booktitle = {Proceedings of the 7th International {{AAAI}} Conference on {{Weblogs}} and {{Social Media}} ({{ICWSM}} 2013), {{Boston}}, {{MA}}, {{USA}}},
  author = {Markovikj, Dejan and Gievska, Sonja and Kosinski, Michal and Stillwell, David},
  year = {2013},
  pages = {23--26}
}

@article{marquardtAgeGenderIdentification2014,
  title = {Age and {{Gender Identification}} in {{Social Media}}},
  author = {Marquardt, James and Farnadi, Golnoosh and Vasudevan, Gayathri and Davalos, Sergio and Teredesai, Ankur and Cock, Martine De},
  year = {2014},
  journal = {Proceedings of CLEF 2014 Evaluation Labs},
  number = {1180},
  pages = {1129--1136},
  abstract = {This paper describes the submission of the University of Washington's Center for Data Science to the PAN 2014 author profiling task. We examine the predictive quality in terms of age and gender of several sets of features extracted from various genres of online social media. Through comparison, we establish a feature set which maximizes accuracy of gender and age prediction across all genres examined. We report accuracies obtained by two approaches to the multi-label classification problem of predicting both age and gender; a model wherein the multi-label problem is reduced to a single-label problem using powerset transformation, and a chained classifier approach wherein the output of a dedicated classifier for gender is used as input for a classifier for age.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/WFJUILZ8/Marquardt et al. - Age and Gender Identiﬁcation in Social Media.pdf}
}

@article{marreroEvaluatingVoiceSamples2022,
  title = {Evaluating Voice Samples as a Potential Source of Information about Personality},
  author = {Marrero, Zachariah N. K. and Gosling, Samuel D. and Pennebaker, James W. and Harari, Gabriella M.},
  year = {2022},
  month = oct,
  journal = {Acta Psychologica},
  volume = {230},
  pages = {103740},
  issn = {0001-6918},
  doi = {10.1016/j.actpsy.2022.103740},
  urldate = {2022-11-15},
  abstract = {Speech is a powerful medium through which a variety of psychologically relevant phenomena are expressed. Here we take a first step in evaluating the potential of using voice samples as non-self-report measures of personality. In particular, we examine the extent to which linguistic and vocal information extracted from semi-structured vocal samples can be used to predict conventional measures of personality. We extracted 94 linguistic features (using Linquistic Inquiry Word Count, 2015) and 272 vocal features (using pyAudioAnalysis) from 614 voice samples of at least 50 words. Using a two-stage, fully automatable machine learning pipeline we evaluated the extent to which these features predicted self-report personality scales (Big Five Inventory). For comparison purposes, we also examined the predictive performance of these voice features with respect to depression, age, and gender. Results showed that voice samples accounted for 10.67~\% of the variance in personality traits on average and that the same samples could also predict depression, age, and gender. Moreover, the results reported here provide a conservative estimate of the degree to which features derived from voice samples could be used to predict personality traits and suggest a number of opportunities to optimize personality prediction and better understand how voice samples carry information about personality.},
  langid = {english},
  keywords = {Audio data,LIWC,Machine learning,Personality prediction,Voice},
  file = {/Users/timokoch/Zotero/storage/UCLQAHPY/Marrero et al. - 2022 - Evaluating voice samples as a potential source of .pdf;/Users/timokoch/Zotero/storage/44CRJ5BA/S0001691822002554.html}
}

@article{martincPan2017Author2017,
  title = {Pan 2017: {{Author}} Profiling-Gender and Language Variety Prediction},
  author = {Martinc, Matej and {\v S}krjanec, Iza and Zupan, Katja and Pollak, Senja},
  year = {2017},
  journal = {Cappellato et al.[13]}
}

@article{massachiSochiatristSignalsAffect2020,
  title = {Sochiatrist: {{Signals}} of {{Affect}} in {{Messaging Data}}},
  shorttitle = {Sochiatrist},
  author = {Massachi, Talie and Fong, Grant and Mathur, Varun and Pendse, Sachin R. and Hoefer, Gabriela and Fu, Jessica J. and Wang, Chong and Ramoji, Nikita and Nugent, Nicole R. and Ranney, Megan L. and Dickstein, Daniel P. and Armey, Michael F. and Pavlick, Ellie and Huang, Jeff},
  year = {2020},
  month = oct,
  journal = {Proceedings of the ACM on Human-Computer Interaction},
  volume = {4},
  number = {CSCW2},
  pages = {1--25},
  issn = {2573-0142},
  doi = {10.1145/3415182},
  urldate = {2021-10-06},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/YUF8R6DU/Massachi et al. - 2020 - Sochiatrist Signals of Affect in Messaging Data.pdf}
}

@article{mastorasTouchscreenTypingPattern2019,
  title = {Touchscreen Typing Pattern Analysis for Remote Detection of the Depressive Tendency},
  author = {Mastoras, Rafail-Evangelos and Iakovakis, Dimitrios and Hadjidimitriou, Stelios and Charisis, Vasileios and Kassie, Seada and Alsaadi, Taoufik and Khandoker, Ahsan and Hadjileontiadis, Leontios J.},
  year = {2019},
  month = sep,
  journal = {Scientific Reports},
  volume = {9},
  number = {1},
  pages = {13414},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  doi = {10.1038/s41598-019-50002-9},
  urldate = {2023-01-16},
  abstract = {Depressive disorder (DD) is a mental illness affecting more than 300 million people worldwide, whereas social stigma and subtle, variant symptoms impede diagnosis. Psychomotor retardation is a common component of DD with a negative impact on motor function, usually reflected on patients' routine activities, including, nowadays, their interaction with mobile devices. Therefore, such interactions constitute an enticing source of information towards unsupervised screening for DD symptoms in daily life. In this vein, this paper proposes a machine learning-based method for discriminating between subjects with depressive tendency and healthy controls, as denoted by self-reported Patient Health Questionnaire-9 (PHQ-9) compound scores, based on typing patterns captured in-the-wild. The latter consisted of keystroke timing sequences and typing metadata, passively collected during natural typing on touchscreen smartphones by 11/14 subjects with/without depressive tendency. Statistical features were extracted and tested in univariate and multivariate classification pipelines to reach a decision on subjects' status. The best-performing pipeline achieved an AUC\,=\,0.89 (0.72{\textendash}1.00; 95\% Confidence Interval) and 0.82/0.86 sensitivity/specificity, with the outputted probabilities significantly correlating ({$>$}0.60) with the respective PHQ-9 scores. This work adds to the findings of previous research associating typing patterns with psycho-motor impairment and contributes to the development of an unobtrusive, high-frequency monitoring of depressive tendency in everyday living.},
  copyright = {2019 The Author(s)},
  langid = {english},
  keywords = {Biomedical engineering,Signs and symptoms},
  file = {/Users/timokoch/Zotero/storage/T8CS578I/Mastoras et al. - 2019 - Touchscreen typing pattern analysis for remote det.pdf}
}

@article{matejkaTalkingEmotionProsody2013,
  title = {Talking about {{Emotion}}: {{Prosody}} and {{Skin Conductance Indicate Emotion Regulation}}},
  shorttitle = {Talking about {{Emotion}}},
  author = {Matejka, Moritz and Kazzer, Philipp and Seehausen, Maria and Bajbouj, Malek and {Klann-Delius}, Gisela and Menninghaus, Winfried and Jacobs, Arthur M. and Heekeren, Hauke R. and Prehn, Kristin},
  year = {2013},
  journal = {Frontiers in Psychology},
  volume = {4},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2013.00260},
  urldate = {2019-07-11},
  abstract = {Talking about emotion and putting feelings into words has been hypothesized to regulate emotion in psychotherapy as well as in everyday conversation. However, the exact dynamics of how different strategies of verbalization regulate emotion and how these strategies are reflected in characteristics of the voice has received little scientific attention. In the present study, we showed emotional pictures to 30 participants and asked them to verbally admit or deny an emotional experience or a neutral fact concerning the picture in a simulated conversation. We used a 2 {\texttimes} 2 factorial design manipulating the focus (on emotion or facts) as well as the congruency (admitting or denying) of the verbal expression. Analyses of skin conductance response (SCR) and voice during the verbalization conditions revealed a main effect of the factor focus. SCR and pitch of the voice were lower during emotion compared to fact verbalization, indicating lower autonomic arousal. In contradiction to these physiological parameters, participants reported that fact verbalization was more effective in down-regulating their emotion than emotion verbalization. These subjective ratings, however, were in line with voice parameters associated with emotional valence. That is, voice intensity showed that fact verbalization reduced negative valence more than emotion verbalization. In sum, the results of our study provide evidence that emotion verbalization as compared to fact verbalization is an effective emotion regulation strategy. Moreover, based on the results of our study we propose that different verbalization strategies influence valence and arousal aspects of emotion selectively.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/EYGYCYQQ/Matejka et al. - 2013 - Talking about Emotion Prosody and Skin Conductanc.pdf}
}

@inproceedings{materoEvaluatingContextualEmbeddings2022,
  title = {Evaluating {{Contextual Embeddings}} and Their {{Extraction Layers}} for {{Depression Assessment}}},
  booktitle = {Proceedings of the 12th {{Workshop}} on {{Computational Approaches}} to {{Subjectivity}}, {{Sentiment}} \& {{Social Media Analysis}}},
  author = {Matero, Matthew and Hung, Albert and Schwartz, H. Andrew},
  year = {2022},
  month = may,
  pages = {89--94},
  publisher = {{Association for Computational Linguistics}},
  address = {{Dublin, Ireland}},
  doi = {10.18653/v1/2022.wassa-1.9},
  urldate = {2022-08-12},
  abstract = {Many recent works in natural language processing have demonstrated ability to assess aspects of mental health from personal discourse. At the same time, pre-trained contextual word embedding models have grown to dominate much of NLP but little is known empirically on how to best apply them for mental health assessment. Using degree of depression as a case study, we do an empirical analysis on which off-the-shelf language model, individual layers, and combinations of layers seem most promising when applied to human-level NLP tasks. Notably, we find RoBERTa most effective and, despite the standard in past work suggesting the second-to-last or concatenation of the last 4 layers, we find layer 19 (sixth-to last) is at least as good as layer 23 when using 1 layer. Further, when using multiple layers, distributing them across the second half (i.e. Layers 12+), rather than last 4, of the 24 layers yielded the most accurate results.},
  file = {/Users/timokoch/Zotero/storage/XTUZZVL2/Matero et al. - 2022 - Evaluating Contextual Embeddings and their Extract.pdf}
}

@article{matzPsychologicalTargetingEffective2017,
  title = {Psychological Targeting as an Effective Approach to Digital Mass Persuasion},
  author = {Matz, Sandra and Kosinski, Michal and Nave, G. and Stillwell, D. J.},
  year = {2017},
  month = nov,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {114},
  number = {48},
  pages = {12714--12719},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1710966114},
  urldate = {2020-10-13},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/4BDJWW66/Matz et al. - 2017 - Psychological targeting as an effective approach t.pdf}
}

@article{matzUsingBigData2017,
  title = {Using {{Big Data}} as a Window into Consumers' Psychology},
  author = {Matz, Sandra and Netzer, Oded},
  year = {2017},
  month = dec,
  journal = {Current Opinion in Behavioral Sciences},
  volume = {18},
  pages = {7--12},
  issn = {23521546},
  doi = {10.1016/j.cobeha.2017.05.009},
  urldate = {2020-04-12},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/RPMU98BP/Matz und Netzer - 2017 - Using Big Data as a window into consumers’ psychol.pdf}
}

@book{mayCiceroIdealOrator2001,
  title = {Cicero on the Ideal Orator},
  author = {May, J. M.},
  year = {2001},
  publisher = {{Oxford University Press, USA}},
  isbn = {0-19-509198-1}
}

@article{mccraeAgeDifferencesPersonality2004,
  title = {Age Differences in Personality Traits across Cultures: Self-Report and Observer Perspectives},
  shorttitle = {Age Differences in Personality Traits across Cultures},
  author = {McCrae, Robert R. and Costa, Paul T. and H??eb{\'i}??kov{\'a}, Martina and Urb{\'a}nek, Tom{\'a}?? and Martin, Thomas A. and Oryol, Valery E. and Rukavishnikov, Alexey A. and Senin, Ivan G.},
  year = {2004},
  month = mar,
  journal = {European Journal of Personality},
  volume = {18},
  number = {2},
  pages = {143--157},
  issn = {0890-2070, 1099-0984},
  doi = {10.1002/per.510},
  urldate = {2020-08-03},
  abstract = {Using self-report measures, longitudinal studies in the US and cross-sectional studies from many cultures suggest that the broad factors of Neuroticism, Extraversion, and Openness to Experience decline from adolescence to adulthood, whereas Agreeableness and Conscientiousness increase. Data are inconsistent on the rate of change during adulthood, and on the generalizability of self-report findings to informant ratings. We analysed crosssectional data from self-reports and informant ratings on the Revised NEO Personality Inventory in Czech (N {$\frac{1}{4}$} 705) and Russian (N {$\frac{1}{4}$} 800) samples. Some curvilinear effects were found, chiefly in the Czech sample; informant data generally replicated self-reports, although the effects were weaker. Although many of the details are not yet clear, there appear to be pan-cultural trends in personality development that are consistent with the hypothesis of intrinsic maturation. Copyright \# 2004 John Wiley \& Sons, Ltd.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/IPFWERXN/McCrae et al. - 2004 - Age differences in personality traits across cultu.pdf}
}

@article{mccraeIntroductionFivefactorModel1992,
  title = {An Introduction to the Five-Factor Model and Its Applications},
  author = {Mccrae, Robert R. and John, Oliver P.},
  year = {1992},
  journal = {Journal of Personality},
  pages = {175--215},
  abstract = {null},
  file = {/Users/timokoch/Zotero/storage/T67TG4WW/Mccrae und John - 1992 - An introduction to the five-factor model and its a.pdf;/Users/timokoch/Zotero/storage/QU5JZEAG/summary.html}
}

@article{mccraeSelfconceptStabilityPersonality1982,
  title = {Self-Concept and the Stability of Personality: {{Cross-sectional}} Comparisons of Self-Reports and Ratings.},
  shorttitle = {Self-Concept and the Stability of Personality},
  author = {McCrae, Robert R. and Costa, Paul T.},
  year = {1982},
  journal = {Journal of Personality and Social Psychology},
  volume = {43},
  number = {6},
  pages = {1282--1292},
  issn = {0022-3514},
  doi = {10.1037/0022-3514.43.6.1282},
  urldate = {2020-08-03},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/I2BDS9KC/McCrae und Costa - 1982 - Self-concept and the stability of personality Cro.pdf}
}

@article{mccraeSelfconceptStabilityPersonality1982a,
  title = {Self-Concept and the Stability of Personality: {{Cross-sectional}} Comparisons of Self-Reports and Ratings.},
  shorttitle = {Self-Concept and the Stability of Personality},
  author = {McCrae, Robert R. and Costa, Paul T.},
  year = {1982},
  journal = {Journal of Personality and Social Psychology},
  volume = {43},
  number = {6},
  pages = {1282--1292},
  issn = {0022-3514},
  doi = {10.1037/0022-3514.43.6.1282},
  urldate = {2020-08-03},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/48HSPL49/McCrae und Costa - 1982 - Self-concept and the stability of personality Cro.pdf}
}

@misc{meegahapolaGeneralizationPersonalizationMobile2022,
  title = {Generalization and {{Personalization}} of {{Mobile Sensing-Based Mood Inference Models}}: {{An Analysis}} of {{College Students}} in {{Eight Countries}}},
  shorttitle = {Generalization and {{Personalization}} of {{Mobile Sensing-Based Mood Inference Models}}},
  author = {Meegahapola, Lakmal and Droz, William and Kun, Peter and {de Gotzen}, Amalia and Nutakki, Chaitanya and Diwakar, Shyam and Correa, Salvador Ruiz and Song, Donglei and Xu, Hao and Bidoglia, Miriam and Gaskell, George and Chagnaa, Altangerel and Ganbold, Amarsanaa and Zundui, Tsolmon and Caprini, Carlo and Miorandi, Daniele and Hume, Alethia and Zarza, Jose Luis and Cernuzzi, Luca and Bison, Ivano and Britez, Marcelo Rodas and Busso, Matteo and {Chenu-Abente}, Ronald and Gunel, Can and Giunchiglia, Fausto and Schelenz, Laura and {Gatica-Perez}, Daniel},
  year = {2022},
  month = nov,
  eprint = {2211.03009},
  primaryclass = {cs},
  doi = {10.1145/3569483},
  urldate = {2022-11-17},
  abstract = {Mood inference with mobile sensing data has been studied in ubicomp literature over the last decade. This inference enables context-aware and personalized user experiences in general mobile apps and valuable feedback and interventions in mobile health apps. However, even though model generalization issues have been highlighted in many studies, the focus has always been on improving the accuracies of models using different sensing modalities and machine learning techniques, with datasets collected in homogeneous populations. In contrast, less attention has been given to studying the performance of mood inference models to assess whether models generalize to new countries. In this study, we collected a mobile sensing dataset with 329K self-reports from 678 participants in eight countries (China, Denmark, India, Italy, Mexico, Mongolia, Paraguay, UK) to assess the effect of geographical diversity on mood inference models. We define and evaluate country-specific (trained and tested within a country), continent-specific (trained and tested within a continent), country-agnostic (tested on a country not seen on training data), and multi-country (trained and tested with multiple countries) approaches trained on sensor data for two mood inference tasks with population-level (non-personalized) and hybrid (partially personalized) models. We show that partially personalized country-specific models perform the best yielding area under the receiver operating characteristic curve (AUROC) scores of the range 0.78-0.98 for two-class (negative vs. positive valence) and 0.76-0.94 for three-class (negative vs. neutral vs. positive valence) inference. Overall, we uncover generalization issues of mood inference models to new countries and how the geographical similarity of countries might impact mood inference.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computers and Society,Computer Science - Human-Computer Interaction,Computer Science - Multimedia},
  file = {/Users/timokoch/Zotero/storage/FHL94VLN/Meegahapola et al. - 2022 - Generalization and Personalization of Mobile Sensi.pdf;/Users/timokoch/Zotero/storage/I4FQUVGC/2211.html}
}

@article{meegahapolaGeneralizationPersonalizationMobile2023,
  title = {Generalization and {{Personalization}} of {{Mobile Sensing-Based Mood Inference Models}}: {{An Analysis}} of {{College Students}} in {{Eight Countries}}},
  shorttitle = {Generalization and {{Personalization}} of {{Mobile Sensing-Based Mood Inference Models}}},
  author = {Meegahapola, Lakmal and Droz, William and Kun, Peter and {de G{\"o}tzen}, Amalia and Nutakki, Chaitanya and Diwakar, Shyam and Correa, Salvador Ruiz and Song, Donglei and Xu, Hao and Bidoglia, Miriam and Gaskell, George and Chagnaa, Altangerel and Ganbold, Amarsanaa and Zundui, Tsolmon and Caprini, Carlo and Miorandi, Daniele and Hume, Alethia and Zarza, Jose Luis and Cernuzzi, Luca and Bison, Ivano and Britez, Marcelo Rodas and Busso, Matteo and {Chenu-Abente}, Ronald and G{\"u}nel, Can and Giunchiglia, Fausto and Schelenz, Laura and {Gatica-Perez}, Daniel},
  year = {2023},
  month = jan,
  journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
  volume = {6},
  number = {4},
  pages = {176:1--176:32},
  doi = {10.1145/3569483},
  urldate = {2023-03-13},
  abstract = {Mood inference with mobile sensing data has been studied in ubicomp literature over the last decade. This inference enables context-aware and personalized user experiences in general mobile apps and valuable feedback and interventions in mobile health apps. However, even though model generalization issues have been highlighted in many studies, the focus has always been on improving the accuracies of models using different sensing modalities and machine learning techniques, with datasets collected in homogeneous populations. In contrast, less attention has been given to studying the performance of mood inference models to assess whether models generalize to new countries. In this study, we collected a mobile sensing dataset with 329K self-reports from 678 participants in eight countries (China, Denmark, India, Italy, Mexico, Mongolia, Paraguay, UK) to assess the effect of geographical diversity on mood inference models. We define and evaluate country-specific (trained and tested within a country), continent-specific (trained and tested within a continent), country-agnostic (tested on a country not seen on training data), and multi-country (trained and tested with multiple countries) approaches trained on sensor data for two mood inference tasks with population-level (non-personalized) and hybrid (partially personalized) models. We show that partially personalized country-specific models perform the best yielding area under the receiver operating characteristic curve (AUROC) scores of the range 0.78--0.98 for two-class (negative vs. positive valence) and 0.76--0.94 for three-class (negative vs. neutral vs. positive valence) inference. Further, with the country-agnostic approach, we show that models do not perform well compared to country-specific settings, even when models are partially personalized. We also show that continent-specific models outperform multi-country models in the case of Europe. Overall, we uncover generalization issues of mood inference models to new countries and how the geographical similarity of countries might impact mood inference.},
  keywords = {affect,distributional shift,domain shift,generalization,mood,mood inference,mood tracking,passive sensing,personalization,smartphone sensing,valence},
  file = {/Users/timokoch/Zotero/storage/C8PLM6EC/Meegahapola et al. - 2023 - Generalization and Personalization of Mobile Sensi.pdf}
}

@article{mehlElectronicallyActivatedRecorder2001,
  title = {The {{Electronically Activated Recorder}} ({{EAR}}): {{A}} Device for Sampling Naturalistic Daily Activities and Conversations},
  shorttitle = {The {{Electronically Activated Recorder}} ({{EAR}})},
  author = {Mehl, Matthias R. and Pennebaker, James W. and Crow, D. Michael and Dabbs, James and Price, John H.},
  year = {2001},
  month = nov,
  journal = {Behavior Research Methods, Instruments, \& Computers},
  volume = {33},
  number = {4},
  pages = {517--523},
  issn = {0743-3808, 1532-5970},
  doi = {10.3758/BF03195410},
  urldate = {2022-12-02},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/KUVQHNCN/Mehl et al. - 2001 - The Electronically Activated Recorder (EAR) A dev.pdf}
}

@article{mehlElectronicallyActivatedRecorder2017,
  title = {The {{Electronically Activated Recorder}} ({{EAR}}): {{A Method}} for the {{Naturalistic Observation}} of {{Daily Social Behavior}}},
  shorttitle = {The {{Electronically Activated Recorder}} ({{EAR}})},
  author = {Mehl, Matthias R.},
  year = {2017},
  month = apr,
  journal = {Current Directions in Psychological Science},
  volume = {26},
  number = {2},
  pages = {184--190},
  publisher = {{SAGE Publications Inc}},
  issn = {0963-7214},
  doi = {10.1177/0963721416680611},
  urldate = {2021-09-16},
  abstract = {This article reviews the Electronically Activated Recorder (EAR) as an ambulatory ecological momentary assessment tool for the real-world observation of daily behavior. Technically, the EAR is an audio recorder that intermittently records snippets of ambient sounds while participants go about their lives. Conceptually, it is a naturalistic observation method that yields an acoustic log of a person's day as it unfolds. The power of the EAR lies in unobtrusively collecting authentic real-life observational data. In preserving a high degree of naturalism at the level of the raw recordings, it resembles ethnographic methods; through its sampling and coding, it enables larger empirical studies. This article provides an overview of the EAR method; reviews its validity, utility, and limitations; and discusses it in the context of current developments in ambulatory assessment, specifically the emerging field of mobile sensing.},
  langid = {english},
  keywords = {ambulatory assessment,ecological momentary assessment,naturalistic observation,smartphone sensing},
  file = {/Users/timokoch/Zotero/storage/R6UNYG9D/Mehl - 2017 - The Electronically Activated Recorder (EAR) A Met.pdf}
}

@article{mehlHowTakingWord,
  title = {How {{Taking}} a {{Word}} for a {{Word Can Be Problematic}}: {{Context-Dependent Linguistic Markers}} of {{Extraversion}} and {{Neuroticism}}},
  author = {Mehl, Matthias R},
  pages = {21},
  abstract = {This study conceptually extends recent research on linguistic markers of psychological processes by demonstrating that psychological correlates of word use can vary with the context in which the words are used. The word use of 90 participants was analyzed across two theoretically defined communication contexts. Information about participants' public language use was derived from recorded snippets of their daily conversations with others. Information about their private language use was derived from stream-of-consciousness essays. Personality trait{\textendash}word use associations emerged as highly context dependent. Extraversion as a public trait was related to verbal productivity in public but not private language. Neuroticism as a private trait was related to the verbal expression of emotions in private but not public language. Verbal immediacy was indicative of Extraversion in public and Neuroticism in private language use. The findings illustrate the importance of considering communication contexts in research on psychological implications of natural language use.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/79NIG5HU/Mehl - How Taking a Word for a Word Can Be Problematic C.pdf}
}

@article{mehlHowTakingWord2012,
  title = {How {{Taking}} a {{Word}} for a {{Word Can Be Problematic}}: {{Context-Dependent Linguistic Markers}} of {{Extraversion}} and {{Neuroticism}}},
  shorttitle = {How {{Taking}} a {{Word}} for a {{Word Can Be Problematic}}},
  author = {Mehl, Matthias R. and Robbins, Megan L. and Holleran, Shannon E.},
  year = {2012},
  journal = {Journal of Methods and Measurement in the Social Sciences},
  volume = {3},
  number = {2},
  pages = {30--50},
  issn = {2159-7855},
  doi = {10.2458/v3i2.16477},
  urldate = {2023-01-14},
  abstract = {This study conceptually extends recent research on linguistic markers of psychological processes by demonstrating that psychological correlates of word use can vary with the context in which the words are used. The word use of 90 participants was analyzed across two theoretically defined communication contexts. Information about participants' public language use was derived from recorded snippets of their daily conversations with others. Information about their private language use was derived from stream-of-consciousness essays. Personality trait{\textendash}word use associations emerged as highly context dependent. Extraversion as a public trait was related to verbal productivity in public but not private language. Neuroticism as a private trait was related to the verbal expression of emotions in private but not public language. Verbal immediacy was indicative of Extraversion in public and Neuroticism in private language use. The findings illustrate the importance of considering communication contexts in research on psychological implications of natural language use.  ~DOI:10.2458/azu\_jmmss\_v3i2\_mehi},
  copyright = {Copyright (c)},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/3CKUJDKI/Mehl et al. - 2012 - How Taking a Word for a Word Can Be Problematic C.pdf}
}

@article{mehlHowTakingWord2013,
  title = {{How Taking a Word for a Word Can Be Problematic: Context-Dependent Linguistic Markers of Extraversion and Neuroticism}},
  shorttitle = {{How Taking a Word for a Word Can Be Problematic}},
  author = {Mehl, Matthias R. and Robbins, Megan L. and Holleran, Shannon E.},
  year = {2013},
  month = feb,
  journal = {Journal of Methods and Measurement in the Social Sciences},
  volume = {3},
  number = {2},
  publisher = {{University of Arizona Libraries}},
  issn = {2159-7855},
  doi = {10.2458/v3i2.16477},
  urldate = {2022-11-08},
  abstract = {{$<$}p{$>$}This study conceptually extends recent research on linguistic markers of psychological processes by demonstrating that psychological correlates of word use can vary with the context in which the words are used. The word use of 90 participants was analyzed across two theoretically defined communication contexts. Information about participants' public language use was derived from recorded snippets of their daily conversations with others. Information about their private language use was derived from stream-of-consciousness essays. Personality trait{\textendash}word use associations emerged as highly context dependent. Extraversion as a public trait was related to verbal productivity in public but not private language. Neuroticism as a private trait was related to the verbal expression of emotions in private but not public language. Verbal immediacy was indicative of Extraversion in public and Neuroticism in private language use. The findings illustrate the importance of considering communication contexts in research on psychological implications of natural language use.{$<$}/p{$>$}},
  langid = {None},
  file = {/Users/timokoch/Zotero/storage/LNDBMB29/Mehl et al. - 2013 - How Taking a Word for a Word Can Be Problematic C.pdf;/Users/timokoch/Zotero/storage/UCMN2V4P/786.html}
}

@article{mehlNaturalisticObservationHealthRelevant2012,
  title = {Naturalistic {{Observation}} of {{Health-Relevant Social Processes}}: {{The Electronically Activated Recorder}} ({{EAR}}) {{Methodology}} in {{Psychosomatics}}},
  shorttitle = {Naturalistic {{Observation}} of {{Health-Relevant Social Processes}}},
  author = {Mehl, Matthias R. and Robbins, Megan L. and gro{\ss}e Deters, Fenne},
  year = {2012},
  month = may,
  journal = {Psychosomatic Medicine},
  volume = {74},
  number = {4},
  pages = {410--417},
  issn = {0033-3174},
  doi = {10.1097/PSY.0b013e3182545470},
  urldate = {2022-12-02},
  abstract = {This article introduces a novel, observational ambulatory monitoring method called the Electronically Activated Recorder or EAR. The EAR is a digital audio recorder that runs on a handheld computer and periodically and unobtrusively records snippets of ambient sounds from participants' momentary environments. In tracking moment-to-moment ambient sounds, it yields acoustic logs of people's days as they naturally unfold. In sampling only a fraction of the time, it protects participants' privacy and makes large observational studies feasible. As a naturalistic observation method, it provides an observer's account of daily life and is optimized for the objective assessment of audible aspects of social environments, behaviors, and interactions (e.g., habitual preferences for social settings, idiosyncratic interaction styles, and subtle emotional expressions). The article discusses the EAR method conceptually and methodologically, reviews prior research with it, and identifies three concrete ways in which it can enrich psychosomatic research. Specifically, it can (a) calibrate psychosocial effects on health against frequencies of real-world behavior, (b) provide ecological, observational measures of health-related social processes that are independent of self-report, and (c) help with the assessment of subtle and habitual social behaviors that evade self-report but have important health implications. An important avenue for future research lies in merging traditional, self-report based ambulatory monitoring methods with observational approaches such as the EAR to allow for the simultaneous yet methodologically independent assessment of inner, experiential (e.g., loneliness) and outer, observable aspects (e.g., social isolation) of real-world social processes to reveal their unique effects on health.},
  pmcid = {PMC3351696},
  pmid = {22582338},
  file = {/Users/timokoch/Zotero/storage/GENUC4V9/Mehl et al. - 2012 - Naturalistic Observation of Health-Relevant Social.pdf}
}

@article{mehlPersonalityItsNatural2006,
  title = {Personality in Its Natural Habitat: {{Manifestations}} and Implicit Folk Theories of Personality in Daily Life},
  author = {Mehl, Matthias R. and Gosling, Samuel D. and Pennebaker, James W.},
  year = {2006},
  journal = {Journal of Personality and Social Psychology},
  volume = {90},
  number = {5},
  pages = {862--877},
  issn = {0022-3514 1939-1315},
  doi = {10.1037/0022-3514.90.5.862},
  abstract = {To examine the expression of personality in its natural habitat, the authors tracked 96 participants over 2 days using the Electronically Activated Recorder (EAR), which samples snippets of ambient sounds in participants' immediate environments. Participants' Big Five scores were correlated with EAR-derived information on their daily social interactions, locations, activities, moods, and language use; these quotidian manifestations were generally consistent with the trait definitions and (except for Openness) often gender specific. To identify implicit folk theories about daily manifestations of personality, the authors correlated the EAR-derived information with impressions of participants based on their EAR sounds; judges' implicit folk theories were generally accurate (especially for Extraversion) and also partially gender specific. The findings point to the importance of naturalistic observation studies on how personality is expressed and perceived in the natural stream of everyday behavior. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Adolescent,Behavior,Daily Activities,Electronically Activated Recorder,everyday behavior,Female,Folk Psychology,Human Activities,Humans,implicit folk theories,Linguistics,Male,naturalistic observation,person perception,Personality,personality expression,personality judgment,Personality Theory,Sex Factors,Social Environment,Social Perception,Tape Recording,Texas}
}

@article{mehlSoundsSocialLife2003,
  title = {The Sounds of Social Life: {{A}} Psychometric Analysis of Students' Daily Social Environments and Natural Conversations.},
  shorttitle = {The Sounds of Social Life},
  author = {Mehl, Matthias R. and Pennebaker, James W.},
  year = {2003},
  journal = {Journal of Personality and Social Psychology},
  volume = {84},
  number = {4},
  pages = {857--870},
  issn = {1939-1315, 0022-3514},
  doi = {10.1037/0022-3514.84.4.857},
  urldate = {2020-07-07},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/6CTPDX8T/Mehl und Pennebaker - 2003 - The sounds of social life A psychometric analysis.pdf}
}

@book{meierLIWCAufDeutsch2019,
  title = {"{{LIWC}} Auf {{Deutsch}}": {{The Development}}, {{Psychometrics}}, and {{Introduction}} of {{DE-LIWC2015}}},
  shorttitle = {"{{LIWC}} Auf {{Deutsch}}"},
  author = {Meier, Tabea and Boyd, Ryan and Pennebaker, James and Mehl, Matthias R. and Martin, Mike and Wolf, Markus and Horn, Andrea and Meier, T and Boyd, R and Mehl, J and Martin, M and Wolf, M and Horn, M},
  year = {2019},
  month = feb,
  doi = {10.31234/osf.io/uq8zt},
  abstract = {In this manual, we introduce a new version of the German adaptation of the Linguistic Inquiry and Word Count (LIWC), called the DE-LIWC2015. The aim of the present work was to develop an update to the previous version of the German LIWC adaptation (Wolf et al., 2008) that corresponds to the LIWC2015 properties. The overall goal was to enable automated word count analysis that accurately captures the most frequently used words in the German language context, converting them into psychologically meaningful metrics for use in research.},
  file = {/Users/timokoch/Zotero/storage/NUK2PFBR/Meier et al. - 2019 - LIWC auf Deutsch The Development, Psychometrics.pdf}
}

@article{meierLIWCAufDeutsch2019a,
  title = {``{{LIWC}} Auf {{Deutsch}}'': {{The Development}}, {{Psychometrics}}, and {{Introduction}} of {{DE- LIWC2015}}},
  shorttitle = {``{{LIWC}} Auf {{Deutsch}}''},
  author = {Meier, Tabea and Boyd, Ryan L. and Pennebaker, James W. and Mehl, Matthias R. and Martin, Mike and Wolf, Markus and Horn, Andrea B},
  year = {2019},
  journal = {PsyArXiv},
  doi = {10.31234/osf.io/uq8zt},
  urldate = {2019-02-18},
  abstract = {The German adaptation of the LIWC2015 dictionary},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/RG53K2US/Meier et al. - “LIWC auf Deutsch” The Development, Psychometrics.pdf}
}

@article{merchantEvaluatingPredictabilityMedical2019,
  title = {Evaluating the Predictability of Medical Conditions from Social Media Posts},
  author = {Merchant, Raina M. and Asch, David A. and Crutchley, Patrick and Ungar, Lyle H. and Guntuku, Sharath C. and Eichstaedt, Johannes C. and Hill, Shawndra and Padrez, Kevin and Smith, Robert J. and Schwartz, H. Andrew},
  year = {2019},
  month = jun,
  journal = {PLOS ONE},
  volume = {14},
  number = {6},
  pages = {e0215476},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0215476},
  urldate = {2022-05-13},
  abstract = {We studied whether medical conditions across 21 broad categories were predictable from social media content across approximately 20 million words written by 999 consenting patients. Facebook language significantly improved upon the prediction accuracy of demographic variables for 18 of the 21 disease categories; it was particularly effective at predicting diabetes and mental health conditions including anxiety, depression and psychoses. Social media data are a quantifiable link into the otherwise elusive daily lives of patients, providing an avenue for study and assessment of behavioral and environmental disease risk factors. Analogous to the genome, social media data linked to medical diagnoses can be banked with patients' consent, and an encoding of social media language can be used as markers of disease risk, serve as a screening tool, and elucidate disease epidemiology. In what we believe to be the first report linking electronic medical record data with social media data from consenting patients, we identified that patients' Facebook status updates can predict many health conditions, suggesting opportunities to use social media data to determine disease onset or exacerbation and to conduct social media-based health interventions.},
  langid = {english},
  keywords = {Diabetes mellitus,Electronic medical records,Facebook,Forecasting,Language,Medical conditions,Medical risk factors,Social media},
  file = {/Users/timokoch/Zotero/storage/GT3RYWW9/Merchant et al. - 2019 - Evaluating the predictability of medical condition.pdf;/Users/timokoch/Zotero/storage/4DJ4Z5QY/article.html}
}

@misc{messengerpeopleWhatsAppBeliebtesterMessenger2020,
  title = {{WhatsApp beliebtester Messenger in Deutschland}},
  author = {MessengerPeople},
  year = {2020},
  month = may,
  journal = {MessengerPeople},
  urldate = {2020-10-02},
  abstract = {Die WhatsApp Nutzerzahlen Deutschland zeigen: WhatsApp ist der beliebteste Messenger in Deutschland. Hier regelm{\"a}{\ss}ig News zu WhatsApp Nutzerzahlen ✅},
  chapter = {News},
  langid = {ngerman},
  file = {/Users/timokoch/Zotero/storage/UCWBKN4B/whatsapp-nutzerzahlen-deutschland.html}
}

@article{metzgerSocialHeuristicApproaches2010,
  title = {Social and {{Heuristic Approaches}} to {{Credibility Evaluation Online}}},
  author = {Metzger, Miriam J. and Flanagin, Andrew J. and Medders, Ryan B.},
  year = {2010},
  month = aug,
  journal = {Journal of Communication},
  volume = {60},
  number = {3},
  pages = {413--439},
  issn = {00219916},
  doi = {10.1111/j.1460-2466.2010.01488.x},
  urldate = {2019-05-23},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/RKKKV9FM/Metzger et al. - 2010 - Social and Heuristic Approaches to Credibility Eva.pdf}
}

@article{michelettiOptimalSamplingStrategies2020,
  title = {Optimal Sampling Strategies for Characterizing Behavior and Affect from Ambulatory Audio Recordings.},
  author = {Micheletti, Megan and {de Barbaro}, Kaya and Fellows, Michelle D. and Hixon, J. Gregory and Slatcher, Richard B. and Pennebaker, James W.},
  year = {2020},
  month = apr,
  journal = {Journal of Family Psychology},
  issn = {1939-1293, 0893-3200},
  doi = {10.1037/fam0000654},
  urldate = {2020-12-01},
  abstract = {Advances in mobile and wearable technologies mean it is now feasible to record hours to days of participant behavior in its naturalistic context, a great boon for psychologists interested in family processes and development. While automated activity recognition algorithms exist for a limited set of behaviors, time-consuming human annotations are still required to robustly characterize the vast majority of behavioral and affective markers of interest. This report is the first to date which systematically tests the efficacy of different sampling strategies for characterizing behavior from audio recordings to provide practical guidelines for researchers. Using continuous audio recordings of the daily lives of 11 preschoolaged children, we compared sampling techniques to determine the most accurate and efficient approach. Results suggest that sampling both low and high frequency verbal and overt behaviors is best if samples are short in duration, systematically rather than randomly selected, and sampled to cover at least 12.5\% of recordings. Implications for assessment of real-world behavior are discussed.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/HRKN8G8K/Micheletti et al. - 2020 - Optimal sampling strategies for characterizing beh.pdf}
}

@article{millerSmartphonePsychologyManifesto2012,
  title = {The {{Smartphone Psychology Manifesto}}},
  author = {Miller, Geoffrey},
  year = {2012},
  month = may,
  journal = {Perspectives on Psychological Science: A Journal of the Association for Psychological Science},
  volume = {7},
  number = {3},
  pages = {221--237},
  issn = {1745-6916},
  doi = {10.1177/1745691612441215},
  abstract = {By 2025, when most of today's psychology undergraduates will be in their mid-30s, more than 5 billion people on our planet will be using ultra-broadband, sensor-rich smartphones far beyond the abilities of today's iPhones, Androids, and Blackberries. Although smartphones were not designed for psychological research, they can collect vast amounts of ecologically valid data, easily and quickly, from large global samples. If participants download the right "psych apps," smartphones can record where they are, what they are doing, and what they can see and hear and can run interactive surveys, tests, and experiments through touch screens and wireless connections to nearby screens, headsets, biosensors, and other peripherals. This article reviews previous behavioral research using mobile electronic devices, outlines what smartphones can do now and will be able to do in the near future, explains how a smartphone study could work practically given current technology (e.g., in studying ovulatory cycle effects on women's sexuality), discusses some limitations and challenges of smartphone research, and compares smartphones to other research methods. Smartphone research will require new skills in app development and data analysis and will raise tough new ethical issues, but smartphones could transform psychology even more profoundly than PCs and brain imaging did.},
  langid = {english},
  pmid = {26168460},
  keywords = {behavioral informatics,digital sensors,GPS/GIS,human subjects/IRB issues,mobile computing,telecommunications},
  file = {/Users/timokoch/Zotero/storage/U3ILZSKJ/Miller - 2012 - The Smartphone Psychology Manifesto.pdf}
}

@article{millingSpeechNewBlood2022,
  title = {Is {{Speech}} the {{New Blood}}? {{Recent Progress}} in {{AI-Based Disease Detection From Audio}} in a {{Nutshell}}},
  shorttitle = {Is {{Speech}} the {{New Blood}}?},
  author = {Milling, Manuel and Pokorny, Florian and {Bartl-Pokorny}, Katrin and Schuller, Bj{\"o}rn},
  year = {2022},
  month = may,
  journal = {Frontiers in Digital Health},
  volume = {4},
  pages = {886615},
  doi = {10.3389/fdgth.2022.886615},
  abstract = {In recent years, advancements in the field of artificial intelligence (AI) have impacted several areas of research and application. Besides more prominent examples like self-driving cars or media consumption algorithms, AI-based systems have further started to gain more and more popularity in the health care sector, however whilst being restrained by high requirements for accuracy, robustness, and explainability. Health-oriented AI research as a sub-field of digital health investigates a plethora of human-centered modalities. In this article, we address recent advances in the so far understudied but highly promising audio domain with a particular focus on speech data and present corresponding state-of-the-art technologies. Moreover, we give an excerpt of recent studies on the automatic audio-based detection of diseases ranging from acute and chronic respiratory diseases via psychiatric disorders to developmental disorders and neurodegenerative disorders. Our selection of presented literature shows that the recent success of deep learning methods in other fields of AI also more and more translates to the field of digital health, albeit expert-designed feature extractors and classical ML methodologies are still prominently used. Limiting factors, especially for speech-based disease detection systems, are related to the amount and diversity of available data, e. g., the number of patients and healthy controls as well as the underlying distribution of age, languages, and cultures. Finally, we contextualize and outline application scenarios of speech-based disease detection systems as supportive tools for health-care professionals under ethical consideration of privacy protection and faulty prediction.},
  file = {/Users/timokoch/Zotero/storage/5VPTV4SH/Milling et al. - 2022 - Is Speech the New Blood Recent Progress in AI-Bas.pdf}
}

@article{minerAssessingAccuracyAutomatic2020,
  title = {Assessing the Accuracy of Automatic Speech Recognition for Psychotherapy},
  author = {Miner, Adam S. and Haque, Albert and Fries, Jason A. and Fleming, Scott L. and Wilfley, Denise E. and Terence Wilson, G. and Milstein, Arnold and Jurafsky, Dan and Arnow, Bruce A. and Stewart Agras, W. and {Fei-Fei}, Li and Shah, Nigam H.},
  year = {2020},
  month = jun,
  journal = {npj Digital Medicine},
  volume = {3},
  number = {1},
  pages = {1--8},
  publisher = {{Nature Publishing Group}},
  issn = {2398-6352},
  doi = {10.1038/s41746-020-0285-8},
  urldate = {2023-02-13},
  abstract = {Accurate transcription of audio recordings in psychotherapy would improve therapy effectiveness, clinician training, and safety monitoring. Although automatic speech recognition software is commercially available, its accuracy in mental health settings has not been well described. It is unclear which metrics and thresholds are appropriate for different clinical use cases, which may range from population descriptions to individual safety monitoring. Here we show that automatic speech recognition is feasible in psychotherapy, but further improvements in accuracy are needed before widespread use. Our HIPAA-compliant automatic speech recognition system demonstrated a transcription word error rate of 25\%. For depression-related utterances, sensitivity was 80\% and positive predictive value was 83\%. For clinician-identified harm-related sentences, the word error rate was 34\%. These results suggest that automatic speech recognition may support understanding of language patterns and subgroup variation in existing treatments but may not be ready for individual-level safety surveillance.},
  copyright = {2020 The Author(s)},
  langid = {english},
  keywords = {Depression,Translational research},
  file = {/Users/timokoch/Zotero/storage/IYQTN5TJ/Miner et al. - 2020 - Assessing the accuracy of automatic speech recogni.pdf}
}

@inproceedings{minerConversationalAgentsMental2016,
  title = {Conversational {{Agents}} and {{Mental Health}}: {{Theory-Informed Assessment}} of {{Language}} and {{Affect}}},
  shorttitle = {Conversational {{Agents}} and {{Mental Health}}},
  booktitle = {Proceedings of the {{Fourth International Conference}} on {{Human Agent Interaction}}},
  author = {Miner, Adam and Chow, Amanda and Adler, Sarah and Zaitsev, Ilia and Tero, Paul and Darcy, Alison and Paepcke, Andreas},
  year = {2016},
  month = oct,
  series = {{{HAI}} '16},
  pages = {123--130},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2974804.2974820},
  urldate = {2021-12-02},
  abstract = {A study deployed the mental health Relational Frame Theory as grounding for an analysis of sentiment dynamics in human-language dialogs. The work takes a step towards enabling use of conversational agents in mental health settings. Sentiment tendencies and mirroring behaviors in 11k human-human dialogs were compared with behaviors when humans interacted with conversational agents in a similar-sized collection. The study finds that human sentiment-related interaction norms persist in human-agent dialogs, but that humans are twice as likely to respond negatively when faced with a negative utterance by a robot than in a comparable situation with humans. Similarly, inhibition towards use of obscenity is greatly reduced. We introduce a new Affective Neural Net implementation that specializes in analyzing sentiment in real time.},
  isbn = {978-1-4503-4508-8},
  keywords = {conversational agents,neural sentiment model,psychotherapy,relational frame theory,sentiment analysis}
}

@inproceedings{minerConversationalAgentsMental2016a,
  title = {Conversational {{Agents}} and {{Mental Health}}: {{Theory-Informed Assessment}} of {{Language}} and {{Affect}}},
  shorttitle = {Conversational {{Agents}} and {{Mental Health}}},
  booktitle = {Proceedings of the {{Fourth International Conference}} on {{Human Agent Interaction}}},
  author = {Miner, Adam and Chow, Amanda and Adler, Sarah and Zaitsev, Ilia and Tero, Paul and Darcy, Alison and Paepcke, Andreas},
  year = {2016},
  month = oct,
  series = {{{HAI}} '16},
  pages = {123--130},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2974804.2974820},
  urldate = {2021-12-02},
  abstract = {A study deployed the mental health Relational Frame Theory as grounding for an analysis of sentiment dynamics in human-language dialogs. The work takes a step towards enabling use of conversational agents in mental health settings. Sentiment tendencies and mirroring behaviors in 11k human-human dialogs were compared with behaviors when humans interacted with conversational agents in a similar-sized collection. The study finds that human sentiment-related interaction norms persist in human-agent dialogs, but that humans are twice as likely to respond negatively when faced with a negative utterance by a robot than in a comparable situation with humans. Similarly, inhibition towards use of obscenity is greatly reduced. We introduce a new Affective Neural Net implementation that specializes in analyzing sentiment in real time.},
  isbn = {978-1-4503-4508-8},
  keywords = {conversational agents,neural sentiment model,psychotherapy,relational frame theory,sentiment analysis}
}

@article{mishneCapturingGlobalMood,
  title = {Capturing {{Global Mood Levels}} Using {{Blog Posts}}},
  author = {Mishne, Gilad},
  pages = {8},
  abstract = {The personal, diary-like nature of blogs prompts many bloggers to indicate their mood at the time of posting. Aggregating these indications over a large amount of bloggers gives a ``blogosphere state-of-mind'' for each point in time: the intensity of different moods among bloggers at that time. In this paper, we address the task of estimating this state-of-mind from the text written by bloggers. To this end, we build models that predict the levels of various moods according to the language used by bloggers at a given time; our models show high correlation with the moods actually measured, and substantially outperform a baseline.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/MWGFVHA7/Mishne - Capturing Global Mood Levels using Blog Posts.pdf}
}

@article{mishneExperimentsMoodClassification,
  title = {Experiments with {{Mood Classification}} in {{Blog Posts}}},
  author = {Mishne, Gilad},
  pages = {8},
  abstract = {We present preliminary work on classifying blog text according to the mood reported by its author during the writing. Our data consists of a large collection of blog posts {\textendash} online diary entries {\textendash} which include an indication of the writer's mood. We obtain modest, but consistent improvements over a baseline; our results show that further increasing the amount of available training data will lead to an additional increase in accuracy. Additionally, we show that the classification accuracy, although low, is not substantially worse than human performance on the same task. Our main finding is that mood classification is a challenging task using current text analysis methods.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/JQSDW4CI/Mishne - Experiments with Mood Classification in Blog Posts.pdf}
}

@article{modersitzkiWhoImpactedPersonality2021,
  title = {Who {{Is Impacted}}? {{Personality Predicts Individual Differences}} in {{Psychological Consequences}} of the {{COVID-19 Pandemic}} in {{Germany}}},
  shorttitle = {Who {{Is Impacted}}?},
  author = {Modersitzki, Nick and Phan, Le Vy and Kuper, Niclas and Rauthmann, John F.},
  year = {2021},
  month = aug,
  journal = {Social Psychological and Personality Science},
  volume = {12},
  number = {6},
  pages = {1110--1130},
  publisher = {{SAGE Publications Inc}},
  issn = {1948-5506},
  doi = {10.1177/1948550620952576},
  urldate = {2023-02-21},
  abstract = {The COVID-19 pandemic has led to changes in people?s private and public lives that are unprecedented in modern history. However, little is known about the differential psychological consequences of restrictions that have been imposed to fight the pandemic. In a large and diverse German sample (N = 1,320), we examined how individual differences in psychological consequences of the pandemic (perceived restrictiveness of government-supported measures, global pandemic-related appraisals, subjective well-being) were associated with a broad set of faceted personality traits (Big Five, Honesty-Humility, Dark Triad). Facets of Extraversion, Neuroticism, and Openness were among the strongest and most important predictors of psychological outcomes, even after controlling for basic sociodemographic variables (gender, age). These findings suggest that psychological consequences of the pandemic depend on personality and thus add to the growing literature on the importance of considering individual differences in crisis situations.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/7X9GDG4M/Modersitzki et al. - 2021 - Who Is Impacted Personality Predicts Individual D.pdf}
}

@article{mohammadEthicsSheetAutomatic2022,
  title = {Ethics {{Sheet}} for {{Automatic Emotion Recognition}} and {{Sentiment Analysis}}},
  author = {Mohammad, Saif M.},
  year = {2022},
  month = jun,
  journal = {Computational Linguistics},
  volume = {48},
  number = {2},
  pages = {239--278},
  issn = {0891-2017},
  doi = {10.1162/coli_a_00433},
  urldate = {2022-11-08},
  abstract = {The importance and pervasiveness of emotions in our lives makes affective computing a tremendously important and vibrant line of work. Systems for automatic emotion recognition (AER) and sentiment analysis can be facilitators of enormous progress (e.g., in improving public health and commerce) but also enablers of great harm (e.g., for suppressing dissidents and manipulating voters). Thus, it is imperative that the affective computing community actively engage with the ethical ramifications of their creations. In this article, I have synthesized and organized information from AI Ethics and Emotion Recognition literature to present fifty ethical considerations relevant to AER. Notably, this ethics sheet fleshes out assumptions hidden in how AER is commonly framed, and in the choices often made regarding the data, method, and evaluation. Special attention is paid to the implications of AER on privacy and social groups. Along the way, key recommendations are made for responsible AER. The objective of the ethics sheet is to facilitate and encourage more thoughtfulness on why to automate, how to automate, and how to judge success well before the building of AER systems. Additionally, the ethics sheet acts as a useful introductory document on emotion recognition (complementing survey articles).},
  file = {/Users/timokoch/Zotero/storage/L49DYMFA/Mohammad - 2022 - Ethics Sheet for Automatic Emotion Recognition and.pdf;/Users/timokoch/Zotero/storage/HP8MI8YH/Ethics-Sheet-for-Automatic-Emotion-Recognition-and.html}
}

@article{mohammadiAutomaticPersonalityPerception2012,
  title = {Automatic {{Personality Perception}}: {{Prediction}} of {{Trait Attribution Based}} on {{Prosodic Features}}},
  shorttitle = {Automatic {{Personality Perception}}},
  author = {Mohammadi, Gelareh and Vinciarelli, Alessandro},
  year = {2012},
  month = jul,
  journal = {IEEE Transactions on Affective Computing},
  volume = {3},
  number = {3},
  pages = {273--284},
  issn = {1949-3045},
  doi = {10.1109/T-AFFC.2012.5},
  urldate = {2019-07-01},
  abstract = {Whenever we listen to a voice for the first time, we attribute personality traits to the speaker. The process takes place in a few seconds and it is spontaneous and unaware. While the process is not necessarily accurate (attributed traits do not necessarily correspond to the actual traits of the speaker), still it significantly influences our behavior toward others, especially when it comes to social interaction. This paper proposes an approach for the automatic prediction of the traits the listeners attribute to a speaker they never heard before. The experiments are performed over a corpus of 640 speech clips (322 identities in total) annotated in terms of personality traits by 11 assessors. The results show that it is possible to predict with high accuracy (more than 70 percent depending on the particular trait) whether a person is perceived to be in the upper or lower part of the scales corresponding to each of the Big Five, the personality dimensions known to capture most of the individual differences.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/JV5SNSIV/Mohammadi und Vinciarelli - 2012 - Automatic Personality Perception Prediction of Tr.pdf}
}

@inproceedings{mohammadiVoicePersonalityMapping2010,
  title = {The Voice of Personality: Mapping Nonverbal Vocal Behavior into Trait Attributions},
  shorttitle = {The Voice of Personality},
  booktitle = {Proceedings of the 2nd International Workshop on {{Social}} Signal Processing - {{SSPW}} '10},
  author = {Mohammadi, Gelareh and Vinciarelli, Alessandro and Mortillaro, Marcello},
  year = {2010},
  pages = {17},
  publisher = {{ACM Press}},
  address = {{Firenze, Italy}},
  doi = {10.1145/1878116.1878123},
  urldate = {2018-12-09},
  abstract = {This paper reports preliminary experiments on automatic attribution of personality traits based on nonverbal vocal behavioral cues. In particular, the work shows how prosodic features can be used to predict, with an accuracy up to 75\% depending on the trait, the personality assessments performed by human judges on a collection of 640 speech samples. The assessments are based on a short version of the Big Five Inventory, one of the most widely used questionnaires for personality assessment. The judges did not understand the language spoken in the speech samples so that the influence of the verbal content is limited. To the best of our knowledge, this is the first work aimed at inferring automatically traits attributed by judges rather than traits self-reported by subjects.},
  isbn = {978-1-4503-0174-9},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/YUFYVDFL/Mohammadi et al. - 2010 - The voice of personality mapping nonverbal vocal .pdf}
}

@misc{mohammadPracticalEthicalConsiderations2020,
  title = {Practical and {{Ethical Considerations}} in the {{Effective}} Use of {{Emotion}} and {{Sentiment Lexicons}}},
  author = {Mohammad, Saif M.},
  year = {2020},
  month = dec,
  number = {arXiv:2011.03492},
  eprint = {2011.03492},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-01-26},
  abstract = {Lexicons of word-emotion associations are widely used in research and real-world applications. As part of my research, I have created several such lexicons (e.g., the NRC Emotion Lexicon). This paper outlines some practical and ethical considerations involved in the effective use of these lexical resources.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/timokoch/Zotero/storage/VA8X7TCG/Mohammad - 2020 - Practical and Ethical Considerations in the Effect.pdf;/Users/timokoch/Zotero/storage/C5MTRSRV/2011.html}
}

@inproceedings{mollerInvestigatingSelfreportingBehavior2013,
  title = {Investigating Self-Reporting Behavior in Long-Term Studies},
  booktitle = {Proceedings of the {{SIGCHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {M{\"o}ller, Andreas and Kranz, Matthias and Schmid, Barbara and Roalter, Luis and Diewald, Stefan},
  year = {2013},
  month = apr,
  pages = {2931--2940},
  publisher = {{ACM}},
  address = {{Paris France}},
  doi = {10.1145/2470654.2481406},
  urldate = {2023-01-24},
  abstract = {Self-reporting techniques, such as data logging or a diary, are frequently used in long-term studies, but prone to subjects' forgetfulness and other sources of inaccuracy. We conducted a six-week self-reporting study on smartphone usage in order to investigate the accuracy of self-reported information, and used logged data as ground truth to compare the subjects' reports against. Subjects never recorded more than 70\% and, depending on the requested reporting interval, down to less than 40\% of actual app usages. They significantly overestimated how long they used apps. While subjects forgot self-reports when no automatic reminders were sent, a high reporting frequency was perceived as uncomfortable and burdensome. Most significantly, self-reporting even changed the actual app usage of users and hence can lead to deceptive measures if a study relies on no other data sources.},
  isbn = {978-1-4503-1899-0},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/YNJM3G27/Möller et al. - 2013 - Investigating self-reporting behavior in long-term.pdf}
}

@article{molnarImlPackageInterpretable2018,
  title = {Iml: {{An R}} Package for {{Interpretable Machine Learning}}},
  shorttitle = {Iml},
  author = {Molnar, Christoph},
  year = {2018},
  month = jun,
  journal = {Journal of Open Source Software},
  volume = {3},
  number = {26},
  pages = {786},
  issn = {2475-9066},
  doi = {10.21105/joss.00786},
  urldate = {2020-02-10},
  abstract = {Complex, non-parametric models, which are typically used in machine learning, have proven to be successful in many prediction tasks. But these models usually operate as black boxes: While they are good at predicting, they are often not interpretable. Many inherently interpretable models have been suggested, which come at the cost of losing predictive power. Another option is to apply interpretability methods to a black box model after model training. Given the velocity of research on new machine learning models, it is preferable to have model-agnostic tools which can be applied to a random forest as well as to a neural network. Tools for model-agnostic interpretability methods should improve the adoption of machine learning.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/CAKKEBX2/Molnar - 2018 - iml An R package for Interpretable Machine Learni.pdf}
}

@book{molnarInterpretableMachineLearning2019,
  title = {Interpretable {{Machine Learning}}},
  author = {Molnar, Christoph},
  year = {2019},
  urldate = {2020-04-12},
  abstract = {Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable.},
  file = {/Users/timokoch/Zotero/storage/UCAF62UM/interpretable-ml-book.html}
}

@inproceedings{montacieVocalicLexicalProsodic2018,
  title = {Vocalic, {{Lexical}} and {{Prosodic Cues}} for the {{INTERSPEECH}} 2018 {{Self-Assessed Affect Challenge}}},
  booktitle = {Interspeech 2018},
  author = {Montaci{\'e}, Claude and Caraty, Marie-Jos{\'e}},
  year = {2018},
  month = sep,
  pages = {541--545},
  publisher = {{ISCA}},
  doi = {10.21437/Interspeech.2018-1331},
  urldate = {2019-02-13},
  abstract = {The INTERSPEECH 2018 Self-Assessed Affect Challenge consists in the prediction of the affective state of mind from speech. Experiments were conducted on the Ulm State-ofMind in Speech database (USoMS) where subjects self-report their affective state. Dimensional representation of emotion (valence) is used for labeling. We have investigated cues related to the perception of the emotional valence according to three main relevant linguistic levels: phonetics, lexical and prosodic. For this purpose we studied: the degree-ofarticulation, the voice quality, an affect lexicon and the expressive prosodic contours. For the phonetics level, a set of gender-dependent audio-features was computed on vowel analysis (voice quality and speech articulation measurements). At the lexical level, an affect lexicon was extracted from the automatic transcription of the USoMS database. This lexicon has been assessed for the Challenge task comparatively to a reference polarity lexicon. In order to detect expressive prosody, N-gram models of the prosodic contours were computed from an intonation labeling system. At last, an emotional valence classifier was designed combining ComParE and eGeMAPS feature sets with other phonetic, prosodic and lexical features. Experiments have shown an improvement of 2.4\% on the Test set, compared to the baseline performance of the Challenge.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/HH3EZ8QV/Montacié und Caraty - 2018 - Vocalic, Lexical and Prosodic Cues for the INTERSP.pdf}
}

@article{montagPsychoinformaticsComputerScience2016,
  title = {Toward {{Psychoinformatics}}: {{Computer Science Meets Psychology}}},
  shorttitle = {Toward {{Psychoinformatics}}},
  author = {Montag, Christian and Duke, {\'E}ilish and Markowetz, Alexander},
  year = {2016},
  month = jun,
  journal = {Computational and Mathematical Methods in Medicine},
  volume = {2016},
  pages = {e2983685},
  publisher = {{Hindawi}},
  issn = {1748-670X},
  doi = {10.1155/2016/2983685},
  urldate = {2022-11-07},
  abstract = {The present paper provides insight into an emerging research discipline called Psychoinformatics. In the context of Psychoinformatics, we emphasize the cooperation between the disciplines of psychology and computer science in handling large data sets derived from heavily used devices, such as smartphones or online social network sites, in order to shed light on a large number of psychological traits, including personality and mood. New challenges await psychologists in light of the resulting ``Big Data'' sets, because classic psychological methods will only in part be able to analyze this data derived from ubiquitous mobile devices, as well as other everyday technologies. As a consequence, psychologists must enrich their scientific methods through the inclusion of methods from informatics. The paper provides a brief review of one area of this research field, dealing mainly with social networks and smartphones. Moreover, we highlight how data derived from Psychoinformatics can be combined in a meaningful way with data from human neuroscience. We close the paper with some observations of areas for future research and problems that require consideration within this new discipline.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/H5Y62IM3/Montag et al. - 2016 - Toward Psychoinformatics Computer Science Meets P.pdf;/Users/timokoch/Zotero/storage/5LL44N8Z/2983685.html}
}

@article{montagSmartphoneUsage21st2015,
  title = {Smartphone Usage in the 21st Century: Who Is Active on {{WhatsApp}}?},
  shorttitle = {Smartphone Usage in the 21st Century},
  author = {Montag, Christian and B{\l}aszkiewicz, Konrad and Sariyska, Rayna and Lachmann, Bernd and Andone, Ionut and Trendafilov, Boris and Eibes, Mark and Markowetz, Alexander},
  year = {2015},
  month = dec,
  journal = {BMC Research Notes},
  volume = {8},
  number = {1},
  issn = {1756-0500},
  doi = {10.1186/s13104-015-1280-z},
  urldate = {2019-07-29},
  abstract = {Background:\hspace{0.6em} Mounting evidence shows that smartphone usage heavily disrupts our work life and social activities. Moreover, it is possible that overuse could resemble addictive tendencies. A key contributing factor to smartphone overuse seems to be usage of the messaging application WhatsApp. Although WhatsApp is one of the most commonly used communication applications on smartphones, research in this area is scarce. Given the huge societal debate on the impact of smartphone usage on our daily lives, the present study undertook a large-scale investigation in order to provide numbers on smartphone usage generally{\textemdash}and use of WhatsApp in particular, with the aim of providing a basis for a scientific debate. Methods:\hspace{0.6em} In a large sample of N = 2,418 users, we recorded WhatsApp behaviour over a 4 week period. Results:\hspace{0.6em} Our data show that use of WhatsApp accounted for 19.83\% (= 32.11 min) of all smartphone behaviour (compare: Facebook only 9.38\% = 15.19 min). The mean of general daily smartphone usage was 161.95 min. Females used WhatsApp for significantly longer periods of time than males and younger age was associated with longer duration of WhatsApp use. While the personality trait Extraversion was positively associated with daily WhatsApp use, Conscientiousness showed an inverse correlation with the length of daily WhatsApp use. Conclusions:\hspace{0.6em} The numbers on smartphone usage in the present study show that the smartphone dominates our daily life. In particular WhatsApp is a driving force, here. Given the length of daily smartphone and WhatsApp usage, more studies need to be conducted to better understand smartphone usage.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/BG5GTK74/Montag et al. - 2015 - Smartphone usage in the 21st century who is activ.pdf}
}

@article{montagWeStillNeed2022,
  title = {Do We Still Need Psychological Self-Report Questionnaires in the Age of the {{Internet}} of {{Things}}?},
  author = {Montag, Christian and Dagum, Paul and Hall, Brian J. and Elhai, Jon D.},
  year = {2022},
  month = jan,
  journal = {Discover Psychology},
  volume = {2},
  number = {1},
  pages = {1},
  issn = {2731-4537},
  doi = {10.1007/s44202-021-00012-4},
  urldate = {2022-11-08},
  abstract = {Digital data are abundantly available for researchers in the age of the Internet of Things. In the psychological and psychiatric sciences such data can be used in myriad ways to obtain insights into mental states and traits. Most importantly, such data allow researchers to record and analyze behavior in a real-world context, a scientific approach which was expensive and difficult to conduct until only recently. Much research in recent years linked digital footprints to self-report questionnaire data, likely to demonstrate proof of concept(s){\textemdash}for instance linking socializing on the smartphone to self-reported extraversion (a personality trait linked to socializing){\textemdash}in the sciences investigating the human mind. The present perspective piece reflects on this approach by revisiting recent work which has been carried out mining smartphone log and social media data and questions if and when self-report data will still be of relevance in psychological/psychiatric research in the near future.},
  langid = {english},
  keywords = {Big data,Digital footprints,Digital phenotyping,Mobile sensing,Personality,Self-report,Smartphone},
  file = {/Users/timokoch/Zotero/storage/FTJ25GKS/Montag et al. - 2022 - Do we still need psychological self-report questio.pdf}
}

@article{moreno-ortizLanguageHappinessSelfreported2022,
  title = {The Language of Happiness in Self-Reported Descriptions of Happy Moments: {{Words}}, Concepts, and Entities},
  shorttitle = {The Language of Happiness in Self-Reported Descriptions of Happy Moments},
  author = {{Moreno-Ortiz}, Antonio and {P{\'e}rez-Hern{\'a}ndez}, Chantal and {Garc{\'i}a-G{\'a}mez}, Mar{\'i}a},
  year = {2022},
  month = jul,
  journal = {Humanities and Social Sciences Communications},
  volume = {9},
  number = {1},
  pages = {1--13},
  publisher = {{Palgrave}},
  issn = {2662-9992},
  doi = {10.1057/s41599-022-01202-8},
  urldate = {2022-07-05},
  abstract = {This article attempts to study the language of happiness from a double perspective. First, the impact and relevance of sentiment words and expressions in self-reported descriptions of happiness are examined. Second, the sources of happiness that are mentioned in such descriptions are identified. A large sample of ``happy moments'' from the HappyDB corpus is processed employing advanced text analytics techniques. The sentiment analysis results reveal that positive lexical items have a limited role in the description of happy moments. For the second objective, unsupervised machine learning algorithms are used to extract and cluster keywords and manually label the resulting semantic classes. Results indicate that these classes, linguistically materialized in compact lexical families, accurately describe the sources of happiness, a result that is reinforced by our named entities analysis, which also reveals the important role that commercial products and services play as a source of happiness. Thus, this study attempts to provide methodological underpinnings for the automatic processing of self-reported happy moments, and contributes to a better understanding of the linguistic expression of happiness, with interdisciplinary implications for fields such as affective content analysis, sentiment analysis, and cultural, social and behavioural studies.},
  copyright = {2022 The Author(s)},
  langid = {english},
  keywords = {Cultural and media studies,Language and linguistics,Science,technology and society},
  file = {/Users/timokoch/Zotero/storage/9TE3TTMV/Moreno-Ortiz et al. - 2022 - The language of happiness in self-reported descrip.pdf;/Users/timokoch/Zotero/storage/N9T245XZ/s41599-022-01202-8.html}
}

@book{muaremiAssessingBipolarEpisodes2014,
  title = {Assessing {{Bipolar Episodes Using Speech Cues Derived}} from {{Phone Calls}}},
  author = {Muaremi, Amir and Gravenhorst, Franz and Gr{\"u}nerbl, Agnes and Arnrich, Bert and Tr{\"o}ster, Gerhard},
  year = {2014},
  month = may,
  journal = {Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST},
  volume = {100},
  doi = {10.1007/978-3-319-11564-1_11},
  abstract = {In this work 1 we show how phone call conversations can be used to objectively predict manic and depressive episodes of bipolar dis-ordered people. In particular, we use phone call statistics, parameters derived from dyadic phone conversations and emotional acoustic fea-tures to build and test user-specific classification models. Using random forest, we were able to detect the bipolar states with an average F1 score of 83 \%, and we identified the speaking length and phone call length, the HNR value, the number of short turns and the variance of pitch F0 to be the most important variables for prediction.},
  isbn = {978-3-319-11563-4},
  file = {/Users/timokoch/Zotero/storage/BV3YRKGV/Muaremi et al. - 2014 - Assessing Bipolar Episodes Using Speech Cues Deriv.pdf}
}

@article{mullerDepressionPredictionsGPSbased2021,
  title = {Depression Predictions from {{GPS-based}} Mobility Do Not Generalize Well to Large Demographically Heterogeneous Samples},
  author = {M{\"u}ller, Sandrine R. and Chen, Xi Leslie and Peters, Heinrich and Chaintreau, Augustin and Matz, Sandra C.},
  year = {2021},
  month = jul,
  journal = {Scientific Reports},
  volume = {11},
  number = {1},
  pages = {14007},
  issn = {2045-2322},
  doi = {10.1038/s41598-021-93087-x},
  abstract = {Depression is one of the most common mental health issues in the United States, affecting the lives of millions of people suffering from it as well as those close to them. Recent advances in research on mobile sensing technologies and machine learning have suggested that a person's depression can be passively measured by observing patterns in people's mobility behaviors. However, the majority of work in this area has relied on highly homogeneous samples, most frequently college students. In this study, we analyse over 57 million GPS data points to show that the same procedure that leads to high prediction accuracy in a homogeneous student sample (N = 57; AUC = 0.82), leads to accuracies only slightly higher than chance in a U.S.-wide sample that is heterogeneous in its socio-demographic composition as well as mobility patterns (N = 5,262; AUC = 0.57). This pattern holds across three different modelling approaches which consider both linear and non-linear relationships. Further analyses suggest that the prediction accuracy is low across different socio-demographic groups, and that training the models on more homogeneous subsamples does not substantially improve prediction accuracy. Overall, the findings highlight the challenge of applying mobility-based predictions of depression at scale.},
  langid = {english},
  pmcid = {PMC8263566},
  pmid = {34234186},
  keywords = {Adult,Depression,Female,Geographic Information Systems,Humans,Machine Learning,Male,{Models, Theoretical},Population Surveillance,Reproducibility of Results,Social Mobility,Students,United States,Young Adult},
  file = {/Users/timokoch/Zotero/storage/YDUXKNHF/Müller et al. - 2021 - Depression predictions from GPS-based mobility do .pdf}
}

@article{murraySimulationEmotionSynthetic1993,
  title = {Toward the Simulation of Emotion in Synthetic Speech: {{A}} Review of the Literature on Human Vocal Emotion},
  shorttitle = {Toward the Simulation of Emotion in Synthetic Speech},
  author = {Murray, Iain R. and Arnott, John L.},
  year = {1993},
  month = feb,
  journal = {The Journal of the Acoustical Society of America},
  volume = {93},
  number = {2},
  pages = {1097--1108},
  publisher = {{Acoustical Society of America}},
  issn = {0001-4966},
  doi = {10.1121/1.405558},
  urldate = {2020-12-03},
  file = {/Users/timokoch/Zotero/storage/XBJZYN2M/Murray und Arnott - 1993 - Toward the simulation of emotion in synthetic spee.pdf;/Users/timokoch/Zotero/storage/L6QKHV6W/1.html}
}

@article{murrayThematicApperceptionTest1943,
  title = {Thematic Apperception Test},
  author = {Murray, Henry Alexander},
  year = {1943}
}

@article{nadeauInferenceGeneralizationError2003,
  title = {Inference for the {{Generalization Error}}},
  author = {Nadeau, Claude and Bengio, Yoshua},
  year = {2003},
  month = sep,
  journal = {Machine Learning},
  volume = {52},
  number = {3},
  pages = {239--281},
  issn = {1573-0565},
  doi = {10.1023/A:1024068626366},
  urldate = {2020-11-02},
  abstract = {In order to compare learning algorithms, experimental results reported in the machine learning literature often use statistical tests of significance to support the claim that a new learning algorithm generalizes better. Such tests should take into account the variability due to the choice of training set and not only that due to the test examples, as is often the case. This could lead to gross underestimation of the variance of the cross-validation estimator, and to the wrong conclusion that the new algorithm is significantly better when it is not. We perform a theoretical investigation of the variance of a variant of the cross-validation estimator of the generalization error that takes into account the variability due to the randomness of the training set as well as test examples. Our analysis shows that all the variance estimators that are based only on the results of the cross-validation experiment must be biased. This analysis allows us to propose new estimators of this variance. We show, via simulations, that tests of hypothesis about the generalization error using those new variance estimators have better properties than tests involving variance estimators currently in use and listed in Dietterich (1998). In particular, the new tests have correct size and good power. That is, the new tests do not reject the null hypothesis too often when the hypothesis is true, but they tend to frequently reject the null hypothesis when the latter is false.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/D7B69JRK/Nadeau und Bengio - 2003 - Inference for the Generalization Error.pdf}
}

@article{newmanGenderDifferencesLanguage2008,
  title = {Gender {{Differences}} in {{Language Use}}: {{An Analysis}} of 14,000 {{Text Samples}}},
  author = {Newman, Matthew L. and Groom, Carla J. and Handelman, Lori D. and Pennebaker, James W.},
  year = {2008},
  journal = {Discourse Processes},
  volume = {45},
  number = {3},
  pages = {211--236},
  issn = {0163-853X 1532-6950},
  doi = {10.1080/01638530802073712},
  file = {/Users/timokoch/Zotero/storage/UYJZEYCV/Newman et al. - 2008 - Gender Differences in Language Use An Analysis of.pdf}
}

@article{newmanGenderDifferencesLanguage2008a,
  title = {Gender {{Differences}} in {{Language Use}}: {{An Analysis}} of 14,000 {{Text Samples}}},
  shorttitle = {Gender {{Differences}} in {{Language Use}}},
  author = {Newman, Matthew L. and Groom, Carla J. and Handelman, Lori D. and Pennebaker, James W.},
  year = {2008},
  month = may,
  journal = {Discourse Processes},
  volume = {45},
  number = {3},
  pages = {211--236},
  issn = {0163-853X, 1532-6950},
  doi = {10.1080/01638530802073712},
  urldate = {2020-07-07},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/QKF477MC/Newman et al. - 2008 - Gender Differences in Language Use An Analysis of.pdf}
}

@article{newmanLyingWordsPredicting2003,
  title = {Lying {{Words}}: {{Predicting Deception}} from {{Linguistic Styles}}},
  shorttitle = {Lying {{Words}}},
  author = {Newman, Matthew L. and Pennebaker, James W. and Berry, Diane S. and Richards, Jane M.},
  year = {2003},
  month = may,
  journal = {Personality and Social Psychology Bulletin},
  volume = {29},
  number = {5},
  pages = {665--675},
  issn = {0146-1672, 1552-7433},
  doi = {10.1177/0146167203029005010},
  urldate = {2019-08-09},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/YT8VMLW9/Newman et al. - 2003 - Lying Words Predicting Deception from Linguistic .pdf}
}

@inproceedings{nguyenAuthorAgePrediction2011,
  title = {Author {{Age Prediction}} from {{Text}} Using {{Linear Regression}}},
  booktitle = {Proceedings of the 5th {{ACL-HLT Workshop}} on {{Language Technology}} for {{Cultural Heritage}}, {{Social Sciences}}, and {{Humanities}}},
  author = {Nguyen, Dong and Smith, Noah A. and Ros{\'e}, Carolyn P.},
  year = {2011},
  month = jun,
  pages = {115--123},
  publisher = {{Association for Computational Linguistics}},
  address = {{Portland, OR, USA}},
  urldate = {2020-10-29},
  file = {/Users/timokoch/Zotero/storage/LSNZE77T/Nguyen et al. - 2011 - Author Age Prediction from Text using Linear Regre.pdf}
}

@inproceedings{nguyenHowOldYou2013,
  title = {" {{How Old Do You Think I Am}}?"; {{A Study}} of {{Language}} and {{Age}} in {{Twitter}}},
  booktitle = {Proceedings of the Seventh International {{AAAI}} Conference on Weblogs and Social Media},
  author = {Nguyen, Dong and Gravel, Rilana and Trieschnigg, Dolf and Meder, Theo},
  year = {2013},
  publisher = {{AAAI Press}},
  file = {/Users/timokoch/Zotero/storage/PVVJWBIN/Nguyen et al. - How Old Do You Think I Am A Study of Language an.pdf}
}

@incollection{nguyenPredictionAgeSentiment2011,
  title = {Prediction of {{Age}}, {{Sentiment}}, and {{Connectivity}} from {{Social Media Text}}},
  booktitle = {Web {{Information System Engineering}} {\textendash} {{WISE}} 2011},
  author = {Nguyen, Thin and Phung, Dinh and Adams, Brett and Venkatesh, Svetha},
  editor = {Bouguettaya, Athman and Hauswirth, Manfred and Liu, Ling},
  year = {2011},
  volume = {6997},
  pages = {227--240},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-24434-6_17},
  urldate = {2019-07-29},
  abstract = {Social media corpora, including the textual output of blogs, forums, and messaging applications, provide fertile ground for linguistic analysis material diverse in topic and style, and at Web scale. We investigate manifest properties of textual messages, including latent topics, psycholinguistic features, and author mood, of a large corpus of blog posts, to analyze the impact of age, emotion, and social connectivity. These properties are found to be significantly different across the examined cohorts, which suggest discriminative features for a number of useful classification tasks. We build binary classifiers for old versus young bloggers, social versus solo bloggers, and happy versus sad posts with high performance. Analysis of discriminative features shows that age turns upon choice of topic, whereas sentiment orientation is evidenced by linguistic style. Good prediction is achieved for social connectivity using topic and linguistic features, leaving tagged mood a modest role in all classifications.},
  isbn = {978-3-642-24433-9 978-3-642-24434-6},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/DGSBXT5G/Nguyen et al. - 2011 - Prediction of Age, Sentiment, and Connectivity fro.pdf}
}

@incollection{nieYourSearchBehavior2014,
  title = {Your {{Search Behavior}} and {{Your Personality}}},
  booktitle = {Pervasive {{Computing}} and the {{Networked World}}},
  author = {Nie, Dong and Li, Ang and Guan, Zengda and Zhu, Tingshao},
  editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Kobsa, Alfred and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Terzopoulos, Demetri and Tygar, Doug and Weikum, Gerhard and Zu, Qiaohong and {Vargas-Vera}, Maria and Hu, Bo},
  year = {2014},
  volume = {8351},
  pages = {459--470},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-09265-2_47},
  urldate = {2019-06-11},
  abstract = {Search is very important to acquire useful information from the Web. To provide better search service, we need to look into how people conduct search. In this paper, we focus on web search behavior, and try to identify how it relates to the personality traits, then investigate the potential personality predicting model based on search behaviors. Several features are extracted from web search behavior, corresponding personality-trait scores are obtained, too. Correlation analysis method is used to deal with the data, the results show that part of searching behaviors are correlated with personality traits in some degree.},
  isbn = {978-3-319-09264-5 978-3-319-09265-2},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/FJ34YBCL/Nie et al. - 2014 - Your Search Behavior and Your Personality.pdf}
}

@misc{niuRealTimeExecutionLargescale2020,
  title = {Real-{{Time Execution}} of {{Large-scale Language Models}} on {{Mobile}}},
  author = {Niu, Wei and Kong, Zhenglun and Yuan, Geng and Jiang, Weiwen and Guan, Jiexiong and Ding, Caiwen and Zhao, Pu and Liu, Sijia and Ren, Bin and Wang, Yanzhi},
  year = {2020},
  month = oct,
  number = {arXiv:2009.06823},
  eprint = {2009.06823},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-01-14},
  abstract = {Pre-trained large-scale language models have increasingly demonstrated high accuracy on many natural language processing (NLP) tasks. However, the limited weight storage and computational speed on hardware platforms have impeded the popularity of pre-trained models, especially in the era of edge computing. In this paper, we seek to find the best model structure of BERT for a given computation size to match specific devices. We propose the first compiler-aware neural architecture optimization framework. Our framework can guarantee the identified model to meet both resource and real-time specifications of mobile devices, thus achieving real-time execution of large transformer-based models like BERT variants. We evaluate our model on several NLP tasks, achieving competitive results on well-known benchmarks with lower latency on mobile devices. Specifically, our model is 5.2x faster on CPU and 4.1x faster on GPU with 0.5-2\% accuracy loss compared with BERT-base. Our overall framework achieves up to 7.8x speedup compared with TensorFlow-Lite with only minor accuracy loss.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/timokoch/Zotero/storage/K8U9KV2Q/Niu et al. - 2020 - Real-Time Execution of Large-scale Language Models.pdf;/Users/timokoch/Zotero/storage/3XDUR9IE/2009.html}
}

@article{nookLinguisticMeasuresPsychological2022,
  title = {Linguistic Measures of Psychological Distance Track Symptom Levels and Treatment Outcomes in a Large Set of Psychotherapy Transcripts},
  author = {Nook, Erik C. and Hull, Thomas D. and Nock, Matthew K. and Somerville, Leah H.},
  year = {2022},
  month = mar,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {119},
  number = {13},
  pages = {e2114737119},
  publisher = {{Proceedings of the National Academy of Sciences}},
  doi = {10.1073/pnas.2114737119},
  urldate = {2022-03-23},
  file = {/Users/timokoch/Zotero/storage/3TEJHHC8/Nook et al. - 2022 - Linguistic measures of psychological distance trac.pdf}
}

@misc{nooneEmotionRecognitionMostly2022,
  title = {Emotion Recognition Is Mostly Ineffective. {{Why}} Are Companies Still Investing in It?},
  author = {Noone, Greg},
  year = {2022},
  month = jun,
  journal = {Tech Monitor},
  urldate = {2022-12-02},
  abstract = {Despite criticism of the AI technology, some companies are still moving ahead with plans for emotion recognition software.},
  langid = {american},
  file = {/Users/timokoch/Zotero/storage/8WW6JGZ6/emotion-recognition.html}
}

@article{novakSentimentEmojis2015,
  title = {Sentiment of Emojis},
  author = {Novak, Petra Kralj and Smailovi{\'c}, Jasmina and Sluban, Borut and Mozeti{\v c}, Igor},
  year = {2015},
  journal = {PLoS One},
  volume = {10},
  number = {12},
  pages = {e0144296},
  issn = {1932-6203}
}

@article{nowsonIdentifyingMoreBloggers2007,
  title = {Identifying More Bloggers},
  author = {Nowson, Scott and Oberlander, Jon},
  year = {2007},
  journal = {Proceedings of ICWSM}
}

@article{nygaardCommunicatingEmotionLinking2008,
  title = {Communicating Emotion: {{Linking}} Affective Prosody and Word Meaning},
  shorttitle = {Communicating Emotion},
  author = {Nygaard, Lynne and Queen, Jennifer},
  year = {2008},
  month = sep,
  journal = {Journal of experimental psychology. Human perception and performance},
  volume = {34},
  pages = {1017--30},
  doi = {10.1037/0096-1523.34.4.1017},
  abstract = {The present study investigated the role of emotional tone of voice in the perception of spoken words. Listeners were presented with words that had either a happy, sad, or neutral meaning. Each word was spoken in a tone of voice (happy, sad, or neutral) that was congruent, incongruent, or neutral with respect to affective meaning, and naming latencies were collected. Across experiments, tone of voice was either blocked or mixed with respect to emotional meaning. The results suggest that emotional tone of voice facilitated linguistic processing of emotional words in an emotion-congruent fashion. These findings suggest that information about emotional tone is used in the processing of linguistic content influencing the recognition and naming of spoken words in an emotion-congruent manner.},
  file = {/Users/timokoch/Zotero/storage/TVRLLVM3/Nygaard und Queen - 2008 - Communicating emotion Linking affective prosody a.pdf}
}

@article{nygaardSemanticsProsodyAcoustic2009,
  title = {The {{Semantics}} of {{Prosody}}: {{Acoustic}} and {{Perceptual Evidence}} of {{Prosodic Correlates}} to {{Word Meaning}}},
  shorttitle = {The {{Semantics}} of {{Prosody}}},
  author = {Nygaard, Lynne C. and Herold, Debora S. and Namy, Laura L.},
  year = {2009},
  journal = {Cognitive Science},
  volume = {33},
  number = {1},
  pages = {127--146},
  issn = {1551-6709},
  doi = {10.1111/j.1551-6709.2008.01007.x},
  urldate = {2021-06-30},
  abstract = {This investigation examined whether speakers produce reliable prosodic correlates to meaning across semantic domains and whether listeners use these cues to derive word meaning from novel words. Speakers were asked to produce phrases in infant-directed speech in which novel words were used to convey one of two meanings from a set of antonym pairs (e.g., big/small). Acoustic analyses revealed that some acoustic features were correlated with overall valence of the meaning. However, each word meaning also displayed a unique acoustic signature, and semantically related meanings elicited similar acoustic profiles. In two perceptual tests, listeners either attempted to identify the novel words with a matching meaning dimension (picture pair) or with mismatched meaning dimensions. Listeners inferred the meaning of the novel words significantly more often when prosody matched the word meaning choices than when prosody mismatched. These findings suggest that speech contains reliable prosodic markers to word meaning and that listeners use these prosodic cues to differentiate meanings. That prosody is semantic suggests a reconceptualization of traditional distinctions between linguistic and nonlinguistic properties of spoken language.},
  langid = {english},
  keywords = {Acoustic analysis of speech,Prosody,Semantics,Spoken language processing,Word learning,Word meaning},
  file = {/Users/timokoch/Zotero/storage/6MSL7MBY/Nygaard et al. - 2009 - The Semantics of Prosody Acoustic and Perceptual .pdf;/Users/timokoch/Zotero/storage/I5DFXLQF/j.1551-6709.2008.01007.html}
}

@article{oconnorComputationalTextAnalysis,
  title = {Computational {{Text Analysis}} for {{Social Science}}: {{Model Assumptions}} and {{Complexity}}},
  author = {O'Connor, Brendan and Bamman, David and Smith, Noah A},
  pages = {7},
  abstract = {Across many disciplines, interest is increasing in the use of computational text analysis in the service of social science questions. We survey the spectrum of current methods, which lie on two dimensions: (1) computational and statistical model complexity; and (2) domain assumptions. This comparative perspective suggests directions of research to better align new methods with the goals of social scientists.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/GDBNLYBM/O’Connor et al. - Computational Text Analysis for Social Science Mo.pdf;/Users/timokoch/Zotero/storage/ICAYF2UZ/O’Connor et al. - Computational Text Analysis for Social Science Mo.pdf}
}

@article{oleszkiewiczWhoUsesEmoticons2017,
  title = {Who Uses Emoticons? {{Data}} from 86 702 {{Facebook}} Users},
  author = {Oleszkiewicz, Anna and Karwowski, Maciej and Pisanski, Katarzyna and Sorokowski, Piotr and Sobrado, Boaz and Sorokowska, Agnieszka},
  year = {2017},
  journal = {Personality and Individual Differences},
  volume = {119},
  pages = {289--295},
  issn = {01918869},
  doi = {10.1016/j.paid.2017.07.034},
  file = {/Users/timokoch/Zotero/storage/NKU4HQE8/Oleszkiewicz et al. - 2017 - Who uses emoticons Data from 86 702 Facebook user.pdf}
}

@article{orruMachineLearningPsychometrics2020,
  title = {Machine {{Learning}} in {{Psychometrics}} and {{Psychological Research}}},
  author = {Orr{\`u}, Graziella and Monaro, Merylin and Conversano, Ciro and Gemignani, Angelo and Sartori, Giuseppe},
  year = {2020},
  journal = {Frontiers in Psychology},
  volume = {10},
  issn = {1664-1078},
  urldate = {2022-11-08},
  abstract = {Recent controversies about the level of replicability of behavioral research analyzed using statistical inference have cast interest in developing more efficient techniques for analyzing the results of psychological experiments. Here we claim that complementing the analytical workflow of psychological experiments with Machine Learning-based analysis will both maximize accuracy and minimize replicability issues. As compared to statistical inference, ML analysis of experimental data is model agnostic and primarily focused on prediction rather than inference. We also highlight some potential pitfalls resulting from adoption of Machine Learning based experiment analysis. If not properly used it can lead to over-optimistic accuracy estimates similarly observed using statistical inference. Remedies to such pitfalls are also presented such and building model based on cross validation and the use of ensemble models. ML models are typically regarded as black boxes and we will discuss strategies aimed at rendering more transparent the predictions.},
  file = {/Users/timokoch/Zotero/storage/HQ2ZAFUC/Orrù et al. - 2020 - Machine Learning in Psychometrics and Psychologica.pdf}
}

@inproceedings{paetzelAttributionEmotionalState2018,
  title = {The {{Attribution}} of {{Emotional State}} - {{How Embodiment Features}} and {{Social Traits Affect}} the {{Perception}} of an {{Artificial Agent}}},
  booktitle = {2018 27th {{IEEE International Symposium}} on {{Robot}} and {{Human Interactive Communication}} ({{RO-MAN}})},
  author = {Paetzel, Maike and Castellano, Ginevra and Varni, Giovanna and Hupont, Isabelle and Chetouani, Mohamed and Peters, Christopher},
  year = {2018},
  month = aug,
  pages = {495--502},
  publisher = {{IEEE}},
  address = {{Nanjing}},
  doi = {10.1109/ROMAN.2018.8525700},
  urldate = {2022-11-03},
  abstract = {Understanding emotional states is a challenging task which frequently leads to misinterpretation even in human observers. While the perception of emotions has been studied extensively in human psychology, little is known about what factors influence the human perception of emotions in robots and virtual characters. In this paper, we build on the Brunswik lens model to investigate the influence of (a) the agent's embodiment using a 2D virtual character, a 3D blended embodiment, a recording of the 3D platform and a recording of a human, as well as (b) the level of human-likeness on people's ability to interpret emotional facial expressions in an agent. In addition, we measure social traits of the human observers and analyze how they correlate to the success in recognizing emotional expressions. We find that interpersonal differences play a minor role in the perception of emotional states. However, both embodiment and human-likeness as well as related perceptual dimensions such as perceived social presence and uncanniness have an effect on the attribution of emotional states.},
  isbn = {978-1-5386-7980-7},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/WFJYDFI5/Paetzel et al. - 2018 - The Attribution of Emotional State - How Embodimen.pdf}
}

@article{pajupuuINFLUENCEVERBALCONTENT,
  title = {{{INFLUENCE OF VERBAL CONTENT ON ACOUSTICS OF SPEECH EMOTIONS}}},
  author = {Pajupuu, Hille and Pajupuu, Jaan and Tamuri, Kairi and Altrov, Rene},
  pages = {5},
  abstract = {This paper deals with the issue of the influence of verbal content on listeners who have to identify or evaluate speech emotions, and whether or not the emotional aspect of verbal content should be eliminated. We compare the acoustic parameters of sentences expressing joy, anger, sadness and neutrality of two groups: (1) where the verbal content aids the listener in identifying emotions; and (2), where the verbal content does not aid the listener in identifying emotions. The results reveal few significant differences in the acoustic parameters of emotions in the two groups of sentences, and indicate that the elimination of emotional verbal content in speech presented for emotion identification or evaluation is, in most cases, not necessary.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/R7FRX4HR/Pajupuu et al. - INFLUENCE OF VERBAL CONTENT ON ACOUSTICS OF SPEECH.pdf}
}

@article{pajupuuInfluenceVerbalContent2015,
  title = {Influence of Verbal Content on Acoustics of Speech Emotions},
  author = {Pajupuu, Hille and Pajupuu, Jaan and Tamuri, Kairi and Altrov, Rene},
  year = {2015},
  month = jan,
  journal = {Proceedings of the 18th International Congress of Phonetic Sciences},
  abstract = {This paper deals with the issue of the influence of verbal content on listeners who have to identify or evaluate speech emotions, and whether or not the emotional aspect of verbal content should be eliminated. We compare the acoustic parameters of sentences expressing joy, anger, sadness and neutrality of two groups: (1) where the verbal content aids the listener in identifying emotions; and (2), where the verbal content does not aid the listener in identifying emotions. The results reveal few significant differences in the acoustic parameters of emotions in the two groups of sentences, and indicate that the elimination of emotional verbal content in speech presented for emotion identification or evaluation is, in most cases, not necessary.},
  file = {/Users/timokoch/Zotero/storage/SM7VQFAH/Pajupuu et al. - 2015 - Influence of verbal content on acoustics of speech.pdf}
}

@article{parkAutomaticPersonalityAssessment2015,
  title = {Automatic Personality Assessment through Social Media Language},
  author = {Park, G. and Schwartz, H. A. and Eichstaedt, J. C. and Kern, M. L. and Kosinski, M. and Stillwell, D. J. and Ungar, L. H. and Seligman, M. E.},
  year = {2015},
  month = jun,
  journal = {J Pers Soc Psychol},
  volume = {108},
  number = {6},
  pages = {934--52},
  issn = {1939-1315 (Electronic) 0022-3514 (Linking)},
  doi = {10.1037/pspp0000020},
  abstract = {Language use is a psychologically rich, stable individual difference with well-established correlations to personality. We describe a method for assessing personality using an open-vocabulary analysis of language from social media. We compiled the written language from 66,732 Facebook users and their questionnaire-based self-reported Big Five personality traits, and then we built a predictive model of personality based on their language. We used this model to predict the 5 personality factors in a separate sample of 4,824 Facebook users, examining (a) convergence with self-reports of personality at the domain- and facet-level; (b) discriminant validity between predictions of distinct traits; (c) agreement with informant reports of personality; (d) patterns of correlations with external criteria (e.g., number of friends, political attitudes, impulsiveness); and (e) test-retest reliability over 6-month intervals. Results indicated that language-based assessments can constitute valid personality measures: they agreed with self-reports and informant reports of personality, added incremental validity over informant reports, adequately discriminated between traits, exhibited patterns of correlations with external criteria similar to those found with self-reported personality, and were stable over 6-month intervals. Analysis of predictive language can provide rich portraits of the mental life associated with traits. This approach can complement and extend traditional methods, providing researchers with an additional measure that can quickly and cheaply assess large groups of participants with minimal burden.},
  keywords = {*Language,*Personality Assessment,*Social Media,Female,Humans,Linguistics,Male,Personality,Personality Tests,Reproducibility of Results,Self Report,Young Adult},
  file = {/Users/timokoch/Zotero/storage/GWT7FSKB/Park et al. - 2015 - Automatic personality assessment through social me.pdf}
}

@article{parkEmoticonStyleInterpreting,
  title = {Emoticon {{Style}}: {{Interpreting Differences}} in {{Emoticons Across Cultures}}},
  author = {Park, Jaram and Barash, Vladimir and Fink, Clay and Cha, Meeyoung},
  pages = {10},
  abstract = {Emoticons are a key aspect of text-based communication, and are the equivalent of nonverbal cues to the medium of online chat, forums, and social media like Twitter. As emoticons become more widespread in computer mediated communication, a vocabulary of different symbols with subtle emotional distinctions emerges especially across different cultures. In this paper, we investigate the semantic, cultural, and social aspects of emoticon usage on Twitter and show that emoticons are not limited to conveying a specific emotion or used as jokes, but rather are socio-cultural norms, whose meaning can vary depending on the identity of the speaker. We also demonstrate how these norms propagate through the Twitter @-reply network. We confirm our results on a large-scale dataset of over one billion Tweets from different time periods and countries.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/DXYKUFJ8/Park et al. - Emoticon Style Interpreting Differences in Emotic.pdf}
}

@article{parkWomenAreWarmer2016,
  title = {Women Are {{Warmer}} but {{No Less Assertive}} than {{Men}}: {{Gender}} and {{Language}} on {{Facebook}}},
  shorttitle = {Women Are {{Warmer}} but {{No Less Assertive}} than {{Men}}},
  author = {Park, Gregory and Yaden, David Bryce and Schwartz, H. Andrew and Kern, Margaret L. and Eichstaedt, Johannes C. and Kosinski, Michal and Stillwell, David and Ungar, Lyle H. and Seligman, Martin E. P.},
  year = {2016},
  month = may,
  journal = {PLOS ONE},
  volume = {11},
  number = {5},
  pages = {e0155885},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0155885},
  urldate = {2021-02-24},
  abstract = {Using a large social media dataset and open-vocabulary methods from computational linguistics, we explored differences in language use across gender, affiliation, and assertiveness. In Study 1, we analyzed topics (groups of semantically similar words) across 10 million messages from over 52,000 Facebook users. Most language differed little across gender. However, topics most associated with self-identified female participants included friends, family, and social life, whereas topics most associated with self-identified male participants included swearing, anger, discussion of objects instead of people, and the use of argumentative language. In Study 2, we plotted male- and female-linked language topics along two interpersonal dimensions prevalent in gender research: affiliation and assertiveness. In a sample of over 15,000 Facebook users, we found substantial gender differences in the use of affiliative language and slight differences in assertive language. Language used more by self-identified females was interpersonally warmer, more compassionate, polite, and{\textemdash}contrary to previous findings{\textemdash}slightly more assertive in their language use, whereas language used more by self-identified males was colder, more hostile, and impersonal. Computational linguistic analysis combined with methods to automatically label topics offer means for testing psychological theories unobtrusively at large scale.},
  langid = {english},
  keywords = {Emotions,Facebook,Language,Psycholinguistics,Psychology,Semantics,Social media,Social psychology},
  file = {/Users/timokoch/Zotero/storage/QVU3NGC2/Park et al. - 2016 - Women are Warmer but No Less Assertive than Men G.pdf;/Users/timokoch/Zotero/storage/RJKPZWWP/article.html}
}

@inproceedings{parthasarathyImprovingEmotionClassification2019,
  title = {Improving {{Emotion Classification}} through {{Variational Inference}} of {{Latent Variables}}},
  booktitle = {{{ICASSP}} 2019 - 2019 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  author = {Parthasarathy, Srinivas and Rozgic, Viktor and Sun, Ming and Wang, Chao},
  year = {2019},
  month = may,
  pages = {7410--7414},
  issn = {2379-190X},
  doi = {10.1109/ICASSP.2019.8682823},
  abstract = {Conventional models for emotion recognition from speech signal are trained in supervised fashion using speech utterances with emotion labels. In this study we hypothesize that speech signal depends on multiple latent variables including the emotional state, age, gender, and speech content. We propose an Adversarial Autoencoder (AAE) to perform variational inference over the latent variables and reconstruct the input feature representations. Reconstruction of feature representations is used as an auxiliary task to aid the primary emotion recognition task. Experiments on the IEMOCAP dataset demonstrate that the auxiliary learning tasks improve emotion classification accuracy compared to a baseline supervised classifier. Further, we demonstrate that the proposed learning approach can be used for the end-to-end speech emotion recognition, as its applicable for models that operate on frame-level inputs.},
  keywords = {Adversarial training,Autoencoder,Emotion recognition,Feature extraction,Indexes,Speech recognition,Sun,Task analysis,Training}
}

@incollection{paulhusSelfreportMethod2007,
  title = {The Self-Report Method},
  booktitle = {Handbook of Research Methods in Personality Psychology},
  author = {Paulhus, Delroy L. and Vazire, Simine},
  year = {2007},
  pages = {224--239},
  publisher = {{The Guilford Press}},
  address = {{New York, NY, US}},
  abstract = {Personality assessment remains the field's most commonly used mode of assessment. Despite its popularity and demonstrated utility, the self-report method has been a frequent target of criticism from the early days of psychological assessment right up to the present. The psychological processes underlying an act of self-reporting are now understood to be exceedingly complex. Examination of these processes requires burrowing deep into the affective and cognitive substrates of personality. Among the challenging issues are the role of motives in self-perception, the applicability of performative models, the effectiveness of introspection, the degree of automaticity, and the meaning of nonresponding. The goal of this chapter is more limited: to provide a brief guide to nonexpert researchers interested in using the self-report method to assess personality. We begin by delineating three categories of self-reports. We then review the advantages and the disadvantages of the self-report method. Next, we examine the convergence of self-reports with other methods of assessing personality. Finally, we provide a practical guide to choosing a self-report instrument. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  isbn = {978-1-59385-111-8},
  keywords = {Methodology,Personality,Personality Measures,Personality Processes,Psychological Assessment,Self-Report},
  file = {/Users/timokoch/Zotero/storage/CNW3QVRC/Paulhus und Vazire - 2007 - The self-report method.pdf}
}

@article{pavalanathanEmoticonsVsEmojis2015,
  title = {Emoticons vs. Emojis on {{Twitter}}: {{A}} Causal Inference Approach},
  author = {Pavalanathan, Umashanthi and Eisenstein, Jacob},
  year = {2015},
  journal = {arXiv preprint arXiv:1510.08480},
  eprint = {1510.08480},
  archiveprefix = {arxiv},
  keywords = {gelesen},
  file = {/Users/timokoch/Zotero/storage/CNSTW24M/Pavalanathan und Eisenstein - 2015 - Emoticons vs. emojis on Twitter A causal inferenc.pdf}
}

@misc{PDFCrossCorpusAcoustic,
  title = {({{PDF}}) {{Cross-Corpus Acoustic Emotion Recognition}}: {{Variances}} and {{Strategies}}.},
  shorttitle = {({{PDF}}) {{Cross-Corpus Acoustic Emotion Recognition}}},
  journal = {ResearchGate},
  urldate = {2019-02-10},
  abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
  howpublished = {https://www.researchgate.net/publication/220395374\_Cross-Corpus\_Acoustic\_Emotion\_Recognition\_Variances\_and\_Strategies},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/DVVTUMVP/220395374_Cross-Corpus_Acoustic_Emotion_Recognition_Variances_and_Strategies.html}
}

@misc{PDFFeelingsChange,
  title = {({{PDF}}) {{Feelings Change}}: {{Accounting}} for {{Individual Differences}} in the {{Temporal Dynamics}} of {{Affect}}},
  shorttitle = {({{PDF}}) {{Feelings Change}}},
  journal = {ResearchGate},
  urldate = {2019-03-07},
  abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
  howpublished = {https://www.researchgate.net/publication/46379499\_Feelings\_Change\_Accounting\_for\_Individual\_Differences\_in\_the\_Temporal\_Dynamics\_of\_Affect},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/2LUDY35W/46379499_Feelings_Change_Accounting_for_Individual_Differences_in_the_Temporal_Dynamics_of_Affe.html}
}

@misc{PDFHowMood,
  title = {(2) ({{PDF}}) {{How}} Mood Turns on Language},
  journal = {ResearchGate},
  urldate = {2019-01-29},
  abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
  howpublished = {https://www.researchgate.net/publication/228476593\_How\_mood\_turns\_on\_language},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/I8YP3TXE/228476593_How_mood_turns_on_language.html}
}

@misc{PDFINTERSPEECH2012,
  title = {({{PDF}}) {{The INTERSPEECH}} 2012 Speaker Trait Challenge},
  journal = {ResearchGate},
  urldate = {2019-02-12},
  abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
  howpublished = {https://www.researchgate.net/publication/224929663\_The\_INTERSPEECH\_2012\_speaker\_trait\_challenge},
  langid = {english}
}

@misc{PDFINTERSPEECH2018,
  title = {({{PDF}}) {{The INTERSPEECH}} 2018 {{Computational Paralinguistics Challenge}}: {{Atypical}} and {{Self-Assessed Affect}}, {{Crying}} and {{Heart Beats}}},
  shorttitle = {({{PDF}}) {{The INTERSPEECH}} 2018 {{Computational Paralinguistics Challenge}}},
  journal = {ResearchGate},
  urldate = {2019-02-13},
  abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
  howpublished = {https://www.researchgate.net/publication/327389283\_The\_INTERSPEECH\_2018\_Computational\_Paralinguistics\_Challenge\_Atypical\_and\_Self-Assessed\_Affect\_Crying\_and\_Heart\_Beats},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/G5BXSPYZ/327389283_The_INTERSPEECH_2018_Computational_Paralinguistics_Challenge_Atypical_and_Self-Assess.html}
}

@misc{PDFLanguageUse,
  title = {({{PDF}}) {{Language Use}} of {{Depressed}} and {{Depression-Vulnerable College Students}}},
  journal = {ResearchGate},
  urldate = {2019-02-12},
  abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
  howpublished = {https://www.researchgate.net/publication/254221761\_Language\_Use\_of\_Depressed\_and\_Depression-Vulnerable\_College\_Students},
  langid = {english}
}

@misc{PDFNewDataset,
  title = {({{PDF}}) {{A}} New {{Dataset}} of {{Telephone-Based Human-Human Call-Center Interaction}} with {{Emotional Evaluation}}},
  journal = {ResearchGate},
  urldate = {2019-02-12},
  abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
  howpublished = {https://www.researchgate.net/publication/282854832\_A\_new\_Dataset\_of\_Telephone-Based\_Human-Human\_Call-Center\_Interaction\_with\_Emotional\_Evaluation/citations},
  langid = {english}
}

@misc{PDFResponsiveSensitive,
  title = {({{PDF}}) {{Towards}} Responsive {{Sensitive Artificial Listeners}}},
  journal = {ResearchGate},
  urldate = {2019-02-12},
  abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
  howpublished = {https://www.researchgate.net/publication/224929701\_Towards\_responsive\_Sensitive\_Artificial\_Listeners},
  langid = {english}
}

@misc{PDFSelfReport,
  title = {({{PDF}}) {{Self}}-{{Report Questionnaires}}},
  journal = {ResearchGate},
  urldate = {2019-03-07},
  abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
  howpublished = {https://www.researchgate.net/publication/313966621\_Self-Report\_Questionnaires},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/J8KS3HQM/313966621_Self-Report_Questionnaires.html}
}

@misc{PDFStabilityChange,
  title = {(9) ({{PDF}}) {{Stability}} and {{Change}} of {{Personality Across}} the {{Life Course}}: {{The Impact}} of {{Age}} and {{Major Life Events}} on {{Mean-Level}} and {{Rank-Order Stability}} of the {{Big Five}}},
  shorttitle = {(9) ({{PDF}}) {{Stability}} and {{Change}} of {{Personality Across}} the {{Life Course}}},
  journal = {ResearchGate},
  urldate = {2020-08-03},
  abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
  howpublished = {https://www.researchgate.net/publication/51588000\_Stability\_and\_Change\_of\_Personality\_Across\_the\_Life\_Course\_The\_Impact\_of\_Age\_and\_Major\_Life\_Events\_on\_Mean-Level\_and\_Rank-Order\_Stability\_of\_the\_Big\_Five},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/MQN89Z6U/51588000_Stability_and_Change_of_Personality_Across_the_Life_Course_The_Impact_of_Age_and_Major.html}
}

@misc{PDFStabilityChangea,
  title = {(9) ({{PDF}}) {{Stability}} and {{Change}} of {{Personality Across}} the {{Life Course}}: {{The Impact}} of {{Age}} and {{Major Life Events}} on {{Mean-Level}} and {{Rank-Order Stability}} of the {{Big Five}}},
  shorttitle = {(9) ({{PDF}}) {{Stability}} and {{Change}} of {{Personality Across}} the {{Life Course}}},
  journal = {ResearchGate},
  urldate = {2020-08-03},
  abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
  howpublished = {https://www.researchgate.net/publication/51588000\_Stability\_and\_Change\_of\_Personality\_Across\_the\_Life\_Course\_The\_Impact\_of\_Age\_and\_Major\_Life\_Events\_on\_Mean-Level\_and\_Rank-Order\_Stability\_of\_the\_Big\_Five},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/XPJPMNH9/51588000_Stability_and_Change_of_Personality_Across_the_Life_Course_The_Impact_of_Age_and_Major.html}
}

@misc{PDFStateMind,
  title = {({{PDF}}) {{State}} of {{Mind}}: {{Classification}} through {{Self-reported Affect}} and {{Word Use}} in {{Speech}}.},
  shorttitle = {({{PDF}}) {{State}} of {{Mind}}},
  journal = {ResearchGate},
  urldate = {2019-02-13},
  abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
  howpublished = {https://www.researchgate.net/publication/327389264\_State\_of\_Mind\_Classification\_through\_Self-reported\_Affect\_and\_Word\_Use\_in\_Speech},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/M8FS8LNY/327389264_State_of_Mind_Classification_through_Self-reported_Affect_and_Word_Use_in_Speech.html}
}

@book{pearVoicePersonality1931,
  title = {Voice and Personality},
  author = {Pear, Tom Hatherley},
  year = {1931},
  publisher = {{Chapman and Hall}},
  address = {{London}},
  langid = {english},
  annotation = {OCLC: 1124560}
}

@inproceedings{peersmanPredictingAgeGender2011,
  title = {Predicting Age and Gender in Online Social Networks},
  booktitle = {Proceedings of the 3rd International Workshop on {{Search}} and Mining User-Generated Contents - {{SMUC}} '11},
  author = {Peersman, Claudia and Daelemans, Walter and Van Vaerenbergh, Leona},
  year = {2011},
  pages = {37},
  publisher = {{ACM Press}},
  address = {{Glasgow, Scotland, UK}},
  doi = {10.1145/2065023.2065035},
  urldate = {2020-10-01},
  abstract = {A common characteristic of communication on online social networks is that it happens via short messages, often using nonstandard language variations. These characteristics make this type of text a challenging text genre for natural language processing. Moreover, in these digital communities it is easy to provide a false name, age, gender and location in order to hide one's true identity, providing criminals such as pedophiles with new possibilities to groom their victims. It would therefore be useful if user profiles can be checked on the basis of text analysis, and false profiles flagged for monitoring. This paper presents an exploratory study in which we apply a text categorization approach for the prediction of age and gender on a corpus of chat texts, which we collected from the Belgian social networking site Netlog. We examine which types of features are most informative for a reliable prediction of age and gender on this difficult text type and perform experiments with different data set sizes in order to acquire more insight into the minimum data size requirements for this task.},
  isbn = {978-1-4503-0949-3},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/GEAINB7L/Peersman et al. - 2011 - Predicting age and gender in online social network.pdf}
}

@inproceedings{peersmanPredictingAgeGender2011a,
  title = {Predicting Age and Gender in Online Social Networks},
  booktitle = {Proceedings of the 3rd International Workshop on {{Search}} and Mining User-Generated Contents - {{SMUC}} '11},
  author = {Peersman, Claudia and Daelemans, Walter and Van Vaerenbergh, Leona},
  year = {2011},
  pages = {37},
  publisher = {{ACM Press}},
  address = {{Glasgow, Scotland, UK}},
  doi = {10.1145/2065023.2065035},
  urldate = {2020-05-05},
  abstract = {A common characteristic of communication on online social networks is that it happens via short messages, often using nonstandard language variations. These characteristics make this type of text a challenging text genre for natural language processing. Moreover, in these digital communities it is easy to provide a false name, age, gender and location in order to hide one's true identity, providing criminals such as pedophiles with new possibilities to groom their victims. It would therefore be useful if user profiles can be checked on the basis of text analysis, and false profiles flagged for monitoring. This paper presents an exploratory study in which we apply a text categorization approach for the prediction of age and gender on a corpus of chat texts, which we collected from the Belgian social networking site Netlog. We examine which types of features are most informative for a reliable prediction of age and gender on this difficult text type and perform experiments with different data set sizes in order to acquire more insight into the minimum data size requirements for this task.},
  isbn = {978-1-4503-0949-3},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/PTKBGHAL/Peersman et al. - 2011 - Predicting age and gender in online social network.pdf}
}

@article{pellEmotionalSpeechProcessing2011,
  title = {Emotional Speech Processing: {{Disentangling}} the Effects of Prosody and Semantic Cues},
  shorttitle = {Emotional Speech Processing},
  author = {Pell, Marc D. and Jaywant, Abhishek and Monetta, Laura and Kotz, Sonja A.},
  year = {2011},
  month = aug,
  journal = {Cognition \& Emotion},
  volume = {25},
  number = {5},
  pages = {834--853},
  issn = {0269-9931, 1464-0600},
  doi = {10.1080/02699931.2010.516915},
  urldate = {2021-06-30},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/D7WW78CQ/Pell et al. - 2011 - Emotional speech processing Disentangling the eff.pdf}
}

@article{pellertIndividualDynamicsAffective2020,
  title = {The Individual Dynamics of Affective Expression on Social Media},
  author = {Pellert, Max and Schweighofer, Simon and Garcia, David},
  year = {2020},
  month = dec,
  journal = {EPJ Data Science},
  volume = {9},
  doi = {10.1140/epjds/s13688-019-0219-3},
  abstract = {Abstract Understanding the temporal dynamics of affect is crucial for our understanding human emotions in general. In this study, we empirically test a computational model of affective dynamics by analyzing a large-scale dataset of Facebook status updates using text analysis techniques. Our analyses support the central assumptions of our model: After stimulation, affective states, quantified as valence and arousal, exponentially return to an individual-specific baseline. On average, this baseline is at a slightly positive valence value and at a moderate arousal point below the midpoint. Furthermore, affective expression, in this case posting a status update on Facebook, immediately pushes arousal and valence towards the baseline by a proportional value. These results are robust to the choice of the text analysis technique and illustrate the fast timescale of affective dynamics through social media text. These outcomes are of high relevance for affective computing, the detection and modeling of collective emotions, the refinement of psychological research methodology, and the detection of abnormal, and potentially pathological, individual affect dynamics.},
  file = {/Users/timokoch/Zotero/storage/CGSUNJSC/13688_2019_219_MOESM1_ESM.pdf;/Users/timokoch/Zotero/storage/WXPZC7CH/Pellert et al. - 2020 - The individual dynamics of affective expression on.pdf}
}

@article{pellertValidatingDailySocial2022,
  title = {Validating Daily Social Media Macroscopes of Emotions},
  author = {Pellert, Max and Metzler, Hannah and Matzenberger, Michael and Garcia, David},
  year = {2022},
  month = jul,
  journal = {Scientific Reports},
  volume = {12},
  number = {1},
  pages = {11236},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  doi = {10.1038/s41598-022-14579-y},
  urldate = {2022-07-11},
  abstract = {Measuring sentiment in social media text has become an important practice in studying emotions at the macroscopic level. However, this approach can suffer from methodological issues like sampling biases and measurement errors. To date, it has not been validated if social media sentiment can actually measure the temporal dynamics of mood and emotions aggregated at the level of communities. We ran a large-scale survey at an online newspaper to gather daily mood self-reports from its users, and compare these with aggregated results of sentiment analysis of user discussions. We find strong correlations between text analysis results and levels of self-reported mood, as well as between inter-day changes of both measurements. We replicate these results using sentiment data from Twitter. We show that a combination of supervised text analysis methods based on novel deep learning architectures and unsupervised dictionary-based methods have high agreement with the time series of aggregated mood measured with self-reports. Our findings indicate that macro level dynamics of mood expressed on an online platform can be tracked with social media text, especially in situations of high mood variability.},
  copyright = {2022 The Author(s)},
  langid = {english},
  keywords = {Computational science,Computer science,Human behaviour},
  file = {/Users/timokoch/Zotero/storage/A9J2A3ZC/Pellert et al. - 2022 - Validating daily social media macroscopes of emoti.pdf;/Users/timokoch/Zotero/storage/5VZ8TM4B/s41598-022-14579-y.html}
}

@unpublished{pennebakerDevelopmentPsychometricProperties2015,
  title = {The Development and Psychometric Properties of {{LIWC2015}}},
  author = {Pennebaker, James W. and Boyd, Ryan L. and Jordan, Kayla and Blackburn, Kate},
  year = {2015},
  address = {{Austin, TX: University of Texas at Austin.}}
}

@article{pennebakerLinguisticInquiryWord2001,
  title = {Linguistic Inquiry and Word Count: {{LIWC}} 2001},
  author = {Pennebaker, James W. and Francis, Martha E. and Booth, Roger J.},
  year = {2001},
  journal = {Mahway: Lawrence Erlbaum Associates},
  volume = {71},
  number = {2001},
  pages = {2001},
  file = {/Users/timokoch/Zotero/storage/T5M2THDV/Pennebaker et al. - 2001 - Linguistic inquiry and word count LIWC 2001.pdf}
}

@misc{pennebakerLinguisticInquiryWord2015,
  title = {Linguistic {{Inquiry}} and {{Word Count}}: {{LIWC}} 2015 [{{Computer}} Software]. {{Pennebaker Conglomerates}}},
  author = {Pennebaker, James W. and Booth, Roger J. and Boyd, Ryan L. and Francis, Martha E.},
  year = {2015},
  publisher = {{Inc}},
  file = {/Users/timokoch/Zotero/storage/3ZQ9ILXU/Pennebaker et al. - 2015 - Linguistic Inquiry and Word Count LIWC 2015 [Comp.pdf}
}

@article{pennebakerLinguisticStylesLanguage1999,
  title = {Linguistic Styles: {{Language}} Use as an Individual Difference},
  author = {Pennebaker, James W. and King, Laura A.},
  year = {1999},
  journal = {Journal of Personality and Social Psychology},
  volume = {77},
  number = {6},
  pages = {1296--1312},
  issn = {0022-3514 1939-1315},
  doi = {10.1037/0022-3514.77.6.1296},
  abstract = {Can language use reflect personality style? Studies examined the reliability, factor structure, and validity of written language using a word-based, computerized text analysis program. Daily diaries from 15 substance abuse inpatients, daily writing assignments from 35 students, and journal abstracts from 40 social psychologists demonstrated good internal consistency for over 36 language dimensions. Analyses of the best 15 language dimensions from essays by 838 students yielded 4 factors that replicated across written samples from another 381 students. Finally, linguistic profiles from writing samples were compared with Thematic Apperception Test coding, self-reports, and behavioral measures from 79 students and with self-reports of a 5-factor measure and health markers from more than 1,200 students. Despite modest effect sizes, the data suggest that linguistic style is an independent and meaningful way of exploring personality. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Adolescent,Adult,Aged,Client Characteristics,Drug Abuse,Factor Structure,Female,Hospitalized Patients,Humans,Individual Differences,Linguistics,Male,Middle Aged,Personality,Personality Traits,Psychological Theory,reliability \& factor structure \& validity of written language style as expression of personality style \& individual differences,Reproducibility of Results,Social Psychologists,substance abuse inpatients \& college students \& social psychologists,Text Structure,Written Communication},
  file = {/Users/timokoch/Zotero/storage/GPXLDEYW/Pennebaker und King - 1999 - Linguistic styles Language use as an individual d.pdf}
}

@article{pennebakerLinguisticStylesLanguage1999a,
  title = {Linguistic Styles: {{Language}} Use as an Individual Difference},
  shorttitle = {Linguistic Styles},
  author = {Pennebaker, James W. and King, Laura A.},
  year = {1999},
  journal = {Journal of Personality and Social Psychology},
  volume = {77},
  number = {6},
  pages = {1296--1312},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1315},
  doi = {10.1037/0022-3514.77.6.1296},
  abstract = {Can language use reflect personality style? Studies examined the reliability, factor structure, and validity of written language using a word-based, computerized text analysis program. Daily diaries from 15 substance abuse inpatients, daily writing assignments from 35 students, and journal abstracts from 40 social psychologists demonstrated good internal consistency for over 36 language dimensions. Analyses of the best 15 language dimensions from essays by 838 students yielded 4 factors that replicated across written samples from another 381 students. Finally, linguistic profiles from writing samples were compared with Thematic Apperception Test coding, self-reports, and behavioral measures from 79 students and with self-reports of a 5-factor measure and health markers from more than 1,200 students. Despite modest effect sizes, the data suggest that linguistic style is an independent and meaningful way of exploring personality. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Client Characteristics,Drug Abuse,Factor Structure,Hospitalized Patients,Individual Differences,Linguistics,Personality Traits,Social Psychologists,Text Structure,Written Communication},
  file = {/Users/timokoch/Zotero/storage/KBHRYTZE/1999-15054-015.html}
}

@article{pennebakerPsychologicalAspectsNatural2003,
  title = {Psychological {{Aspects}} of {{Natural Language Use}}: {{Our Words}}, {{Our Selves}}},
  shorttitle = {Psychological {{Aspects}} of {{Natural Language Use}}},
  author = {Pennebaker, James and Mehl, Matthias R. and Niederhoffer, Kate},
  year = {2003},
  month = feb,
  journal = {Annual review of psychology},
  volume = {54},
  pages = {547--77},
  doi = {10.1146/annurev.psych.54.101601.145041},
  abstract = {The words people use in their daily lives can reveal important aspects of their social and psychological worlds. With advances in computer technology, text analysis allows researchers to reliably and quickly assess features of what people say as well as subtleties in their linguistic styles. Following a brief review of several text analysis programs, we summarize some of the evidence that links natural word use to personality, social and situational fluctuations, and psychological interventions. Of particular interest are findings that point to the psychological value of studying particles-parts of speech that include pronouns, articles, prepositions, conjunctives, and auxiliary verbs. Particles, which serve as the glue that holds nouns and regular verbs together, can serve as markers of emotional state, social identity, and cognitive styles.},
  file = {/Users/timokoch/Zotero/storage/J7UYZSNN/Pennebaker et al. - 2003 - Psychological Aspects of Natural Language Use Our.pdf}
}

@article{pennebakerWhenSmallWords2014,
  title = {When {{Small Words Foretell Academic Success}}: {{The Case}} of {{College Admissions Essays}}},
  shorttitle = {When {{Small Words Foretell Academic Success}}},
  author = {Pennebaker, James W. and Chung, Cindy K. and Frazee, Joey and Lavergne, Gary M. and Beaver, David I.},
  editor = {Gong, Qiyong},
  year = {2014},
  month = dec,
  journal = {PLoS ONE},
  volume = {9},
  number = {12},
  pages = {e115844},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0115844},
  urldate = {2019-08-09},
  abstract = {The smallest and most commonly used words in English are pronouns, articles, and other function words. Almost invisible to the reader or writer, function words can reveal ways people think and approach topics. A computerized text analysis of over 50,000 college admissions essays from more than 25,000 entering students found a coherent dimension of language use based on eight standard function word categories. The dimension, which reflected the degree students used categorical versus dynamic language, was analyzed to track college grades over students' four years of college. Higher grades were associated with greater article and preposition use, indicating categorical language (i.e., references to complexly organized objects and concepts). Lower grades were associated with greater use of auxiliary verbs, pronouns, adverbs, conjunctions, and negations, indicating more dynamic language (i.e., personal narratives). The links between the categorical-dynamic index (CDI) and academic performance hint at the cognitive styles rewarded by higher education institutions.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/YNKIRPJZ/Pennebaker et al. - 2014 - When Small Words Foretell Academic Success The Ca.PDF}
}

@article{pennebakerWordsWisdomLanguage2003,
  title = {Words of Wisdom: {{Language}} Use over the Life Span},
  author = {Pennebaker, James W. and Stone, Lori D.},
  year = {2003},
  journal = {Journal of Personality and Social Psychology},
  volume = {85},
  number = {2},
  pages = {291--301},
  issn = {1939-1315 0022-3514},
  doi = {10.1037/0022-3514.85.2.291},
  file = {/Users/timokoch/Zotero/storage/WMVEFV7V/Pennebaker und Stone - 2003 - Words of wisdom Language use over the life span.pdf}
}

@incollection{perez-sabaterEmoticonsRelationalWriting2019,
  title = {Emoticons in {{Relational Writing Practices}} on {{WhatsApp}}: {{Some Reflections}} on {{Gender}}},
  shorttitle = {Emoticons in {{Relational Writing Practices}} on {{WhatsApp}}},
  booktitle = {Analyzing {{Digital Discourse}}: {{New Insights}} and {{Future Directions}}},
  author = {{P{\'e}rez-Sabater}, Carmen},
  editor = {{Bou-Franch}, Patricia and {Garc{\'e}s-Conejos Blitvich}, Pilar},
  year = {2019},
  pages = {163--189},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-92663-6_6},
  urldate = {2021-03-01},
  abstract = {This chapter aims to study the linguistic conventions of use of emoticons in several WhatsApp communities, focusing specifically on gender differences in adults' interactions. Several methodological approaches serve to this end. A discourse analysis of online interactions is contextualized by offline data taken from interviews, while a questionnaire works as an anonymous source of information, and an initial point of departure. The study concludes that subjects' gender plays an important role in determining how emoticons are included in these written conversations for relational purposes. Emoticons in women's chats seldom add a propositional meaning but simply emphasize the participants' belonging to the group, regardless of content. The analysis also reveals that the affordances of WhatsApp do not generally determine the actions of users in emoticon use.},
  isbn = {978-3-319-92663-6},
  langid = {english},
  keywords = {Computer-mediated Communication Modes,Emoticons,Mobile phonesMobile Phones,Spiliotis,WhatsApp Messages},
  file = {/Users/timokoch/Zotero/storage/JMXIY2V4/Pérez-Sabater - 2019 - Emoticons in Relational Writing Practices on Whats.pdf}
}

@misc{perezHowWhatsAppMessages2021,
  title = {How {{WhatsApp}} Messages Can Identify You},
  author = {P{\'e}rez, Montse Hidalgo},
  year = {2021},
  month = aug,
  journal = {EL PA{\'I}S English Edition},
  urldate = {2023-02-14},
  abstract = {A team of researchers has trained an algorithm to extract personal data from anonymous conversations in an experiment that highlights the importance of protecting privacy},
  chapter = {Usa},
  howpublished = {https://english.elpais.com/usa/2021-08-31/how-whatsapp-messages-can-identify-you.html},
  langid = {american},
  file = {/Users/timokoch/Zotero/storage/2JEJ8I8V/how-whatsapp-messages-can-identify-you.html}
}

@article{petrizzoSmartphoneUseClinical2021,
  title = {Smartphone {{Use}} in {{Clinical Voice Recording}} and {{Acoustic Analysis}}: {{A Literature Review}}},
  shorttitle = {Smartphone {{Use}} in {{Clinical Voice Recording}} and {{Acoustic Analysis}}},
  author = {Petrizzo, Danielle and Popolo, Peter S.},
  year = {2021},
  month = may,
  journal = {Journal of Voice},
  volume = {35},
  number = {3},
  pages = {499.e23-499.e28},
  issn = {0892-1997},
  doi = {10.1016/j.jvoice.2019.10.006},
  urldate = {2022-11-15},
  abstract = {Objective With the increase of smartphone use and availability over the last decade, mobile healthcare applications have become more accessible. Many of these applications allow users to track behaviors and goals, and acquire feedback and information while on the go. Recent studies appearing in the literature suggest that smartphones may offer a means of augmenting clinical voice assessment by recording individuals with voice disorders outside the clinic for the purpose of extracting acoustic characteristics. This review examines the effectiveness of smartphones in clinical voice assessment and treatment, as reported in the current literature. Methods The PubMed database was searched using a combination and variation of different term related to smartphones, voice, and recording apps, in order to find articles that address the role of smartphones in clinical voice recording and assessment. Results and Conclusion Six studies published in the last 3 years were reviewed and examined in terms of types of device and operating systems used, types of subjects and disorders studied, voice parameters extracted, and microphones used. Considerations such as impact of environmental noise, and privacy and security issues are also examined. While smartphones and mobile apps have the potential to be valuable tools in voice assessment outside the clinic, further efforts are needed for them to be effectively used in a clinical setting.},
  langid = {english},
  keywords = {Acoustic analysis,Clinical voice assessment,Mobile applications,Smartphones,Voice recording},
  file = {/Users/timokoch/Zotero/storage/U9JLG6G7/Petrizzo und Popolo - 2021 - Smartphone Use in Clinical Voice Recording and Aco.pdf;/Users/timokoch/Zotero/storage/GGUVCB9R/S089219971930284X.html}
}

@article{pfeiferAllFacialEmojis2022,
  title = {Do All Facial Emojis Communicate Emotion? {{The}} Impact of Facial Emojis on Perceived Sender Emotion and Text Processing},
  shorttitle = {Do All Facial Emojis Communicate Emotion?},
  author = {Pfeifer, Valeria A. and Armstrong, Emma L. and Lai, Vicky Tzuyin},
  year = {2022},
  month = jan,
  journal = {Computers in Human Behavior},
  volume = {126},
  pages = {107016},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2021.107016},
  urldate = {2023-01-13},
  abstract = {Facial emojis can express a variety of positive and negative emotions, and are commonly used in digital, written communication. However, little is known about how emojis impact text processing and how different emoji-text combinations give rise to a sender's mental state. In this study, we investigated how facial emojis with positive valence (= happy emojis) and facial emojis with negative valence (= upset emojis) embedded in emotionally ambiguous/neutral text affect the perceived mental state of the sender using ratings (Experiment 1) and the processing of the text messages using Event-Related Potentials (Experiment 2). We predicted that (1) the same text message with happy and upset emojis would convey different sender mental states, and (2) emoji valence would affect the processing of subsequent text in valence-specific ways. Our Experiment 1 results showed that while texts with upset emojis convey specific sender mental states, texts with happy emojis convey positive emotion more generally, with no further differentiation between emojis. In ERPs (Experiment 2), we found that emojis affect subsequent text processing at N400, and emoji valence affects processing downstream at the second word. We concluded that all facial-emojis impact text processing, but happy and upset emojis carry differential social-emotional salience and impact text processing differently when content becomes available.},
  langid = {english},
  keywords = {Emojis,Emotion,ERP,Language,Late positive component},
  file = {/Users/timokoch/Zotero/storage/MRKHGPYU/S0747563221003393.html}
}

@misc{PhoneStudy_AudiologgingTesting,
  title = {{{PhoneStudy}}\_{{Audiologging Testing}}},
  journal = {Google Docs},
  urldate = {2019-05-15},
  abstract = {ersteSchritte Anleitung To Do's zum Testen Schritte File Explorer installieren,https://play.google.com/store/apps/details?id=com.estrongs.android.pop aktuelle APK installieren,siehe Slack, Audiologging-Channel Aufnahme {\"u}ber Audiologging App starten,Text einsprechen Audiologging-Dateien suchen,An...},
  howpublished = {https://docs.google.com/spreadsheets/d/1kWdphPt\_0v47r4AXphxJgpYe3xlACFdNy-WUGflzSGA/edit?usp=sharing\&usp=embed\_facebook},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/PHDIFHIZ/edit.html}
}

@book{picardAffectiveComputing2000,
  title = {Affective Computing},
  author = {Picard, Rosalind W.},
  year = {2000},
  publisher = {{MIT press}},
  isbn = {0-262-66115-2}
}

@article{piccirilloFoundationsIdiographicMethods2019,
  title = {Foundations of Idiographic Methods in Psychology and Applications for Psychotherapy},
  author = {Piccirillo, Marilyn L. and Rodebaugh, Thomas L.},
  year = {2019},
  month = jul,
  journal = {Clinical Psychology Review},
  volume = {71},
  pages = {90--100},
  issn = {0272-7358},
  doi = {10.1016/j.cpr.2019.01.002},
  urldate = {2022-11-07},
  abstract = {Researchers have long called for greater recognition and use of longitudinal, individual-level research in the study of psychopathology and psychotherapy. Much of our current research attempts to indirectly investigate individual-level, or idiographic, psychological processes via group-based, or nomothetic, designs. However, results from nomothetic research do not necessarily translate to the individual-level. In this review, we discuss how idiographic analyses can be integrated into psychotherapy and psychotherapy research. We examine and review key statistical methods for conducting idiographic analyses. These methods include factor-based and vector autoregressive approaches using longitudinal data. The theoretical framework behind each approach is reviewed and critically evaluated. Empirical examples of each approach are discussed, with the aim of helping interested readers consider how they may use idiographic methods to analyze longitudinal data and psychological processes. Finally, we conclude by citing key limitations of the idiographic approach, calling for greater development of these analyses to ease their successful integration into clinical settings.},
  langid = {english},
  keywords = {Idiographic,Individual-level,Methodology,Psychopathology,Psychotherapy},
  file = {/Users/timokoch/Zotero/storage/RMFNVAUX/Piccirillo und Rodebaugh - 2019 - Foundations of idiographic methods in psychology a.pdf;/Users/timokoch/Zotero/storage/CDT4TN9I/S0272735818303015.html}
}

@article{pisanoHowHasCOVID192022,
  title = {How {{Has COVID-19 Impacted Our Language Use}}?},
  author = {Pisano, Francesca and Manfredini, Alessio and Brachi, Daniela and Landi, Luana and Sorrentino, Lucia and Bottone, Marianna and Incoccia, Chiara and Marangolo, Paola},
  year = {2022},
  month = oct,
  journal = {International Journal of Environmental Research and Public Health},
  volume = {19},
  number = {21},
  pages = {13836},
  issn = {1660-4601},
  doi = {10.3390/ijerph192113836},
  abstract = {The COVID-19 pandemic has led to severe consequences for people's mental health. The pandemic has also influenced our language use, shaping our word formation habits. The overuse of new metaphorical meanings has received particular attention from the media. Here, we wanted to investigate whether these metaphors have led to the formation of new semantic associations in memory. A sample of 120 university students was asked to decide whether a target word was or was not related to a prime stimulus. Responses for pandemic pairs in which the target referred to the newly acquired metaphorical meaning of the prime (i.e., "trench"-"hospital") were compared to pre-existing semantically related pairs (i.e., "trench"-"soldier") and neutral pairs (i.e., "trench"-"response"). Results revealed greater accuracy and faster response times for pandemic pairs than for semantic pairs and for semantic pairs compared to neutral ones. These findings suggest that the newly learned pandemic associations have created stronger semantic links in our memory compared to the pre-existing ones. Thus, this work confirms the adaptive nature of human language, and it underlines how the overuse of metaphors evoking dramatic images has been, in part, responsible for many psychological disorders still reported among people nowadays.},
  langid = {english},
  pmcid = {PMC9656816},
  pmid = {36360715},
  keywords = {COVID-19,COVID-19 emergency,Humans,Language,metaphors,misinformation,Pandemics,psychological disorders,public health,Reaction Time,semantic priming,Semantics,social communication,social media},
  file = {/Users/timokoch/Zotero/storage/RD4GJSSA/Pisano et al. - 2022 - How Has COVID-19 Impacted Our Language Use.pdf}
}

@article{politouSurveyMobileAffective2017,
  title = {A Survey on Mobile Affective Computing},
  author = {Politou, Eugenia and Alepis, Efthymios and Patsakis, Constantinos},
  year = {2017},
  month = aug,
  journal = {Computer Science Review},
  volume = {25},
  doi = {10.1016/j.cosrev.2017.07.002},
  abstract = {The spontaneous recognition of emotional states and personality traits of individuals has been puzzling researchers for years whereas pertinent studies demonstrating the progress in the field, despite their diversity, are still encouraging. This work surveys the most well-known research studies and the state-of-the-art on affect recognition domain based on smartphone acquired data, namely smartphone embedded sensors and smartphone usage. Inevitably, supplementary modalities employed in many eminent studies are also reported here for the sake of completeness. Nevertheless, the intention of the survey is threefold; firstly to document all the to-date relevant literature on affect recognition through smartphone modalities, secondly to argue for the full potential of smartphone use in the inference of affect, and thirdly to demonstrate the current research trends towards mobile affective computing.},
  file = {/Users/timokoch/Zotero/storage/9ZX87VAN/Politou et al. - 2017 - A survey on mobile affective computing.pdf}
}

@article{polzehlAngerRecognitionSpeech2011,
  title = {Anger Recognition in Speech Using Acoustic and Linguistic Cues},
  author = {Polzehl, Tim and Schmitt, Alexander and Metze, Florian and Wagner, Michael},
  year = {2011},
  month = nov,
  journal = {Speech Communication},
  series = {Sensing {{Emotion}} and {{Affect}} - {{Facing Realism}} in {{Speech Processing}}},
  volume = {53},
  number = {9},
  pages = {1198--1209},
  issn = {0167-6393},
  doi = {10.1016/j.specom.2011.05.002},
  urldate = {2020-11-20},
  abstract = {The present study elaborates on the exploitation of both linguistic and acoustic feature modeling for anger classification. In terms of acoustic modeling we generate statistics from acoustic audio descriptors, e.g. pitch, loudness, spectral characteristics. Ranking our features we see that loudness and MFCC seem most promising for all databases. For the English database also pitch features are important. In terms of linguistic modeling we apply probabilistic and entropy-based models of words and phrases, e.g. Bag-of-Words (BOW), Term Frequency (TF), Term Frequency {\textendash} Inverse Document Frequency (TF.IDF) and the Self-Referential Information (SRI). SRI clearly outperforms vector space models. Modeling phrases slightly improves the scores. After classification of both acoustic and linguistic information on separated levels we fuse information on decision level adding confidences. We compare the obtained scores on three different databases. Two databases are taken from the IVR customer care domain, another database accounts for a WoZ data collection. All corpora are of realistic speech condition. We observe promising results for the IVR databases while the WoZ database shows lower scores overall. In order to provide comparability between the results we evaluate classification success using the f1 measurement in addition to overall accuracy figures. As a result, acoustic modeling clearly outperforms linguistic modeling. Fusion slightly improves overall scores. With a baseline of approximately 60\% accuracy and .40 f1-measurement by constant majority class voting we obtain an accuracy of 75\% with respective .70 f1 for the WoZ database. For the IVR databases we obtain approximately 79\% accuracy with respective .78 f1 over a baseline of 60\% accuracy with respective .38 f1.},
  langid = {english},
  keywords = {Anger classification,Decision fusion,Emotion detection,IGR ranking,IVR speech,Linguistic and prosodic acoustic modeling},
  file = {/Users/timokoch/Zotero/storage/657K3DSH/Polzehl et al. - 2011 - Anger recognition in speech using acoustic and lin.pdf}
}

@book{polzehlPersonalitySpeech2015,
  title = {Personality in {{Speech}}},
  author = {Polzehl, Tim},
  year = {2015},
  series = {T-{{Labs Series}} in {{Telecommunication Services}}},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-09516-5},
  urldate = {2018-11-05},
  isbn = {978-3-319-09515-8 978-3-319-09516-5},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/BTCT79GV/Polzehl - 2015 - Personality in Speech.pdf}
}

@inproceedings{poonguzhaliFrameworkElectronicHealth2020,
  title = {A {{Framework For Electronic Health Record Using Blockchain Technology}}},
  booktitle = {2020 {{International Conference}} on {{System}}, {{Computation}}, {{Automation}} and {{Networking}} ({{ICSCAN}})},
  author = {Poonguzhali, N. and Gayathri, S. and Deebika, A. and Suriapriya, R.},
  year = {2020},
  month = jul,
  pages = {1--5},
  doi = {10.1109/ICSCAN49426.2020.9262369},
  abstract = {Blockchain technologies are gaining massive impel in the present digital era. The blockchain is a data structure in which the consequent data is appended to the existing data and is maintained by all the participants of the network. The participants are also called as nodes, where the nodes in the blockchain have an agreement in common on the order of the blocks which contains several transactions based on the tool or platform used by the application. Hence, the blockchain is considered as ordered chronological transactions. The health industries are currently focusing on the blockchain technology to maintain the health data in a more secure, confident and decentralized, as in the current record management system they unable to manage the privacy and integrity. The proposed work is to frame an architecture for the Electronic Health Record (EHR) using blockchain technology. The proposed system is a twofold process where first we focus on the block creation and secondly secure the data using Elliptic Curve Cryptography (ECC) Algorithm.},
  keywords = {blockchain,Blockchain,cryptography,ECC,EHR,electronic health record,Elliptic curve cryptography,Hospitals,Medical diagnostic imaging,Medical services,Peer-to-peer computing,Stakeholders},
  file = {/Users/timokoch/Zotero/storage/I6EKVRDT/Poonguzhali et al. - 2020 - A Framework For Electronic Health Record Using Blo.pdf;/Users/timokoch/Zotero/storage/GUS69MZJ/9262369.html}
}

@article{posnerCircumplexModelAffect2005,
  title = {The Circumplex Model of Affect: {{An}} Integrative Approach to Affective Neuroscience, Cognitive Development, and Psychopathology},
  shorttitle = {The Circumplex Model of Affect},
  author = {Posner, Jonathan and Russell, James A. and Peterson, Bradley S.},
  year = {2005},
  journal = {Development and psychopathology},
  volume = {17},
  number = {3},
  pages = {715--734},
  issn = {0954-5794},
  doi = {10.1017/S0954579405050340},
  urldate = {2021-11-23},
  abstract = {The circumplex model of affect proposes that all affective states arise from cognitive interpretations of core neural sensations that are the product of two independent neurophysiological systems. This model stands in contrast to theories of basic emotions, which posit that a discrete and independent neural system subserves every emotion. We propose that basic emotion theories no longer explain adequately the vast number of empirical observations from studies in affective neuroscience, and we suggest that a conceptual shift is needed in the empirical approaches taken to the study of emotion and affective psychopathologies. The circumplex model of affect is more consistent with many recent findings from behavioral, cognitive neuroscience, neuroimaging, and developmental studies of affect. Moreover, the model offers new theoretical and empirical approaches to studying the development of affective disorders as well as the genetic and cognitive underpinnings of affective processing within the central nervous system.},
  pmcid = {PMC2367156},
  pmid = {16262989},
  file = {/Users/timokoch/Zotero/storage/LJC4NBMY/Posner et al. - 2005 - The circumplex model of affect An integrative app.pdf}
}

@article{posnerCircumplexModelAffect2005a,
  title = {The Circumplex Model of Affect: {{An}} Integrative Approach to Affective Neuroscience, Cognitive Development, and Psychopathology},
  shorttitle = {The Circumplex Model of Affect},
  author = {Posner, Jonathan and Russell, James A. and Peterson, Bradley S.},
  year = {2005},
  journal = {Development and psychopathology},
  volume = {17},
  number = {3},
  pages = {715--734},
  issn = {0954-5794},
  doi = {10.1017/S0954579405050340},
  urldate = {2021-11-23},
  abstract = {The circumplex model of affect proposes that all affective states arise from cognitive interpretations of core neural sensations that are the product of two independent neurophysiological systems. This model stands in contrast to theories of basic emotions, which posit that a discrete and independent neural system subserves every emotion. We propose that basic emotion theories no longer explain adequately the vast number of empirical observations from studies in affective neuroscience, and we suggest that a conceptual shift is needed in the empirical approaches taken to the study of emotion and affective psychopathologies. The circumplex model of affect is more consistent with many recent findings from behavioral, cognitive neuroscience, neuroimaging, and developmental studies of affect. Moreover, the model offers new theoretical and empirical approaches to studying the development of affective disorders as well as the genetic and cognitive underpinnings of affective processing within the central nervous system.},
  pmcid = {PMC2367156},
  pmid = {16262989},
  file = {/Users/timokoch/Zotero/storage/SX9NWTXC/Posner et al. - 2005 - The circumplex model of affect An integrative app.pdf}
}

@article{postmesBreachingBuildingSocial2016,
  title = {Breaching or {{Building Social Boundaries}}?},
  author = {Postmes, T. O. M. and Spears, Russell and Lea, Martin},
  year = {2016},
  journal = {Communication Research},
  volume = {25},
  number = {6},
  pages = {689--715},
  issn = {0093-6502 1552-3810},
  doi = {10.1177/009365098025006006}
}

@article{pradaMotivesFrequencyAttitudes2018,
  title = {Motives, Frequency and Attitudes toward Emoji and Emoticon Use},
  author = {Prada, Mar{\'i}lia and Rodrigues, David L. and Garrido, Margarida V. and Lopes, Diniz and Cavalheiro, Bernardo and Gaspar, Rui},
  year = {2018},
  month = oct,
  journal = {Telematics and Informatics},
  volume = {35},
  number = {7},
  pages = {1925--1934},
  issn = {07365853},
  doi = {10.1016/j.tele.2018.06.005},
  urldate = {2020-03-30},
  abstract = {Electronic Mediated Communication (EMC) has become highly prevalent in our daily lives. Many of the communication formats used in EMC are text-based (e.g., instant messaging), and users often include visual paralinguistic cues in their messages. In the current study, we examined the usage of two such cues {\textendash} emoji and emoticons. Specifically, we compared self-reported frequency of use, as well as attitudes (6 bipolar items, e.g., ``fun'' vs. ``boring'') and motives for their usage (9 motives, e.g., ``express how I feel to others''). We also examined these indicators according to age and gender. Overall, participants (N = 474, 72.6\% women; Mage = 30.71, SD = 12.58) reported using emoji (vs. emoticons) more often, revealed more positive attitudes toward emoji usage, and identified more with motives to use them. Moreover, all the ratings were higher among younger (vs. older) participants. Results also showed that women reported to use emoji (but not emoticons) more often and expressed more positive attitudes toward their usage than men. However, these gender differences were particularly evident for younger participants. No gender differences were found for emoticons usage. These findings add to the emerging body of literature by showing the relevance of considering age and gender, and their interplay, when examining patterns of emoji and emoticons use.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/TV96JBQM/Prada et al. - 2018 - Motives, frequency and attitudes toward emoji and .pdf}
}

@misc{PRECIRETechnologies2019,
  title = {{{PRECIRE Technologies}}},
  year = {2019},
  urldate = {2019-03-03},
  howpublished = {https://www.precire.com/},
  file = {/Users/timokoch/Zotero/storage/GAATP34K/www.precire.com.html}
}

@inproceedings{preotiuc-pietroModellingValenceArousal2016,
  title = {Modelling {{Valence}} and {{Arousal}} in {{Facebook}} Posts},
  booktitle = {Proceedings of the 7th {{Workshop}} on {{Computational Approaches}} to {{Subjectivity}}, {{Sentiment}} and {{Social Media Analysis}}},
  author = {{Preo{\c t}iuc-Pietro}, Daniel and Schwartz, H. Andrew and Park, Gregory and Eichstaedt, Johannes C. and Kern, Margaret and Ungar, Lyle and Shulman, Elisabeth},
  year = {2016},
  month = jun,
  pages = {9--15},
  publisher = {{Association for Computational Linguistics}},
  address = {{San Diego, California}},
  doi = {10.18653/v1/W16-0404},
  urldate = {2021-04-21},
  file = {/Users/timokoch/Zotero/storage/JKP8Z87J/Preoţiuc-Pietro et al. - 2016 - Modelling Valence and Arousal in Facebook posts.pdf}
}

@misc{PrivateMessagesAre,
  title = {Private {{Messages Are}} the {{New}} ({{Old}}) {{Social Network}} | {{WIRED}}},
  urldate = {2020-09-10},
  howpublished = {https://www.wired.com/story/private-messages-new-social-networks/},
  file = {/Users/timokoch/Zotero/storage/YQ2Z2QFT/private-messages-new-social-networks.html}
}

@misc{PrivateMessagesArea,
  title = {Private {{Messages Are}} the {{New}} ({{Old}}) {{Social Network}} | {{WIRED}}},
  urldate = {2020-09-10},
  howpublished = {https://www.wired.com/story/private-messages-new-social-networks/},
  file = {/Users/timokoch/Zotero/storage/XG9FPWMS/private-messages-new-social-networks.html}
}

@article{probstHyperparametersTuningMetaLearning,
  title = {Hyperparameters, {{Tuning}} and {{Meta-Learning}} for {{Random Forest}} and {{Other Machine Learning Algorithms}}},
  author = {Probst, Philipp},
  pages = {118},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/BPSUVIF6/Probst - Hyperparameters, Tuning and Meta-Learning for Rand.pdf}
}

@article{probstTunabilityImportanceHyperparameters,
  title = {Tunability: {{Importance}} of {{Hyperparameters}} of {{Machine Learning Algorithms}}},
  author = {Probst, Philipp and Boulesteix, Anne-Laure and Bischl, Bernd},
  pages = {32},
  abstract = {Modern supervised machine learning algorithms involve hyperparameters that have to be set before running them. Options for setting hyperparameters are default values from the software package, manual configuration by the user or configuring them for optimal predictive performance by a tuning procedure. The goal of this paper is two-fold. Firstly, we formalize the problem of tuning from a statistical point of view, define data-based defaults and suggest general measures quantifying the tunability of hyperparameters of algorithms. Secondly, we conduct a large-scale benchmarking study based on 38 datasets from the OpenML platform and six common machine learning algorithms. We apply our measures to assess the tunability of their parameters. Our results yield default values for hyperparameters and enable users to decide whether it is worth conducting a possibly time consuming tuning strategy, to focus on the most important hyperparameters and to choose adequate hyperparameter spaces for tuning.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/EVYQ2TX3/Probst et al. - Tunability Importance of Hyperparameters of Machi.pdf}
}

@article{probstTuneNotTune,
  title = {To {{Tune}} or {{Not}} to {{Tune}} the {{Number}} of {{Trees}} in {{Random Forest}}},
  author = {Probst, Philipp and Boulesteix, Anne-Laure},
  pages = {18},
  abstract = {The number of trees T in the random forest (RF) algorithm for supervised learning has to be set by the user. It is unclear whether T should simply be set to the largest computationally manageable value or whether a smaller T may be sufficient or in some cases even better. While the principle underlying bagging is that more trees are better, in practice the classification error rate sometimes reaches a minimum before increasing again for increasing number of trees. The goal of this paper is four-fold: (i) providing theoretical results showing that the expected error rate may be a non-monotonous function of the number of trees and explaining under which circumstances this happens; (ii) providing theoretical results showing that such non-monotonous patterns cannot be observed for other performance measures such as the Brier score and the logarithmic loss (for classification) and the mean squared error (for regression); (iii) illustrating the extent of the problem through an application to a large number (n = 306) of datasets from the public database OpenML; (iv) finally arguing in favor of setting T to a computationally feasible large number as long as classical error measures based on average loss are considered.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/42AYATDN/Probst und Boulesteix - To Tune or Not to Tune the Number of Trees in Rand.pdf}
}

@article{probstTuneNotTune2017,
  title = {To Tune or Not to Tune the Number of Trees in Random Forest},
  author = {Probst, Philipp and Boulesteix, Anne-Laure},
  year = {2017},
  month = jan,
  journal = {The Journal of Machine Learning Research},
  volume = {18},
  number = {1},
  pages = {6673--6690},
  issn = {1532-4435},
  abstract = {The number of trees T in the random forest (RF) algorithm for supervised learning has to be set by the user. It is unclear whether T should simply be set to the largest computationally manageable value or whether a smaller T may be sufficient or in some cases even better. While the principle underlying bagging is that more trees are better, in practice the classification error rate sometimes reaches a minimum before increasing again for increasing number of trees. The goal of this paper is four-fold: (i) providing theoretical results showing that the expected error rate may be a non-monotonous function of the number of trees and explaining under which circumstances this happens; (ii) providing theoretical results showing that such non-monotonous patterns cannot be observed for other performance measures such as the Brier score and the logarithmic loss (for classification) and the mean squared error (for regression); (iii) illustrating the extent of the problem through an application to a large number (n = 306) of datasets from the public database OpenML; (iv) finally arguing in favor of setting T to a computationally feasible large number as long as classical error measures based on average loss are considered.},
  keywords = {bagging,error rate,number of trees,out-of-bag,random forest},
  file = {/Users/timokoch/Zotero/storage/8MUH77GQ/Probst und Boulesteix - 2017 - To tune or not to tune the number of trees in rand.pdf}
}

@article{probstTuneNotTune2017a,
  title = {To Tune or Not to Tune the Number of Trees in Random Forest?},
  author = {Probst, Philipp and Boulesteix, Anne-Laure},
  year = {2017},
  month = may,
  journal = {arXiv:1705.05654 [cs, stat]},
  eprint = {1705.05654},
  primaryclass = {cs, stat},
  urldate = {2020-09-06},
  abstract = {The number of trees T in the random forest (RF) algorithm for supervised learning has to be set by the user. It is controversial whether T should simply be set to the largest computationally manageable value or whether a smaller T may in some cases be better. While the principle underlying bagging is that more trees are better, in practice the classification error rate sometimes reaches a minimum before increasing again for increasing number of trees. The goal of this paper is four-fold: (i) providing theoretical results showing that the expected error rate may be a non-monotonous function of the number of trees and explaining under which circumstances this happens; (ii) providing theoretical results showing that such non-monotonous patterns cannot be observed for other performance measures such as the Brier score and the logarithmic loss (for classification) and the mean squared error (for regression); (iii) illustrating the extent of the problem through an application to a large number (n = 306) of datasets from the public database OpenML; (iv) finally arguing in favor of setting it to a computationally feasible large number, depending on convergence properties of the desired performance measure.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/timokoch/Zotero/storage/KBU48Q24/Probst und Boulesteix - 2017 - To tune or not to tune the number of trees in rand.pdf}
}

@misc{PsychopathologyEverydayLife,
  title = {Psychopathology {{Of Everyday Life}}, by {{Dr}}. {{Sigmund Freud}}{\textemdash}{{A Project Gutenberg eBook}}},
  urldate = {2022-07-11},
  howpublished = {https://www.gutenberg.org/files/67332/67332-h/67332-h.htm},
  file = {/Users/timokoch/Zotero/storage/8PU8QJJJ/67332-h.html}
}

@article{qiuLimitedIndividualAttention2017,
  title = {Limited Individual Attention and Online Virality of Low-Quality Information},
  author = {Qiu, Xiaoyan and Oliveira, Diego F. M. and Shirazi, Alireza Sahami and Flammini, Alessandro and Menczer, Filippo},
  year = {2017},
  month = jan,
  journal = {arXiv:1701.02694 [physics]},
  eprint = {1701.02694},
  primaryclass = {physics},
  urldate = {2019-05-23},
  abstract = {Social media are massive marketplaces in which memes compete for our attention. We investigate the conditions in which the best ideas prevail in a stylized model of online social network, where agents have behavioral limitations in managing a heavy flow of information. We measure the relationship between the quality of an idea and its likelihood to become prevalent at the system level. We find that both information overload and limited attention contribute to a degradation in the market's discriminative power. A good tradeoff between discriminative power and diversity of information is possible according to the model. However, calibration with empirical data characterizing information load and finite attention in real social media reveals a weak correlation between quality and popularity of information. In these realistic conditions, the model predicts that lowquality information is just as likely to go viral, providing an interpretation for the high volume of misinformation we observe online.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Social and Information Networks,Physics - Physics and Society},
  file = {/Users/timokoch/Zotero/storage/Q69IKCS3/Qiu et al. - 2017 - Limited individual attention and online virality o.pdf}
}

@article{qiuPuttingTheirBest2012,
  title = {Putting {{Their Best Foot Forward}}: {{Emotional Disclosure}} on {{Facebook}}},
  shorttitle = {Putting {{Their Best Foot Forward}}},
  author = {Qiu, Lin and Lin, Han and Leung, Angela K. and Tov, William},
  year = {2012},
  month = oct,
  journal = {Cyberpsychology, Behavior, and Social Networking},
  volume = {15},
  number = {10},
  pages = {569--572},
  issn = {2152-2715, 2152-2723},
  doi = {10.1089/cyber.2012.0200},
  urldate = {2022-04-30},
  abstract = {Facebook has become a widely used online self-representation and communication platform. In this research, we focus on emotional disclosure on Facebook. We conducted two studies, and results from both self-report and observer rating show that individuals are more likely to express positive relative to negative emotions and present better emotional well-being on Facebook than in real life. Our study is the first to demonstrate impression management on Facebook through emotional disclosure. We discuss important theoretical and practical implications of our study.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/ZZ5NLKBP/Qiu et al. - 2012 - Putting Their Best Foot Forward Emotional Disclos.pdf}
}

@article{qiuYouAreWhat2012,
  title = {You Are What You Tweet: {{Personality}} Expression and Perception on {{Twitter}}},
  author = {Qiu, Lin and Lin, Han and Ramsay, Jonathan and Yang, Fang},
  year = {2012},
  journal = {Journal of Research in Personality},
  volume = {46},
  number = {6},
  pages = {710--718},
  issn = {00926566},
  doi = {10.1016/j.jrp.2012.08.008}
}

@article{quan-haaseUsesGratificationsSocial2010,
  title = {Uses and {{Gratifications}} of {{Social Media}}: {{A Comparison}} of {{Facebook}} and {{Instant Messaging}}},
  shorttitle = {Uses and {{Gratifications}} of {{Social Media}}},
  author = {{Quan-Haase}, Anabel and Young, Alyson L.},
  year = {2010},
  month = oct,
  journal = {Bulletin of Science, Technology \& Society},
  volume = {30},
  number = {5},
  pages = {350--361},
  publisher = {{SAGE Publications Inc}},
  issn = {0270-4676},
  doi = {10.1177/0270467610380009},
  urldate = {2021-05-14},
  abstract = {Users have adopted a wide range of digital technologies into their communication repertoire. It remains unclear why they adopt multiple forms of communication instead of substituting one medium for another. It also raises the question: What type of need does each of these media fulfill? In the present article, the authors conduct comparative work that examines the gratifications obtained from Facebook with those from instant messaging. This comparison between media allows one to draw conclusions about how different social media fulfill user needs. Data were collected from undergraduate students through a multimethod study based on 77 surveys and 21 interviews. A factor analysis of gratifications obtained from Facebook revealed six key dimensions: pastime, affection, fashion, share problems, sociability, and social information. Comparative analysis showed that Facebook is about having fun and knowing about the social activities occurring in one's social network, whereas instant messaging is geared more toward relationship maintenance and development. The authors discuss differences in the two technologies and outline a framework based on uses and gratifications theory as to why young people integrate numerous media into their communication habits.},
  langid = {english},
  keywords = {Facebook,instant messaging,social network sites,university students,uses and gratifications}
}

@inproceedings{querciaOurTwitterProfiles2011,
  title = {Our Twitter Profiles, Our Selves: {{Predicting}} Personality with Twitter},
  booktitle = {Privacy, {{Security}}, {{Risk}} and {{Trust}} ({{PASSAT}}) and 2011 {{IEEE Third Inernational Conference}} on {{Social Computing}} ({{SocialCom}}), 2011 {{IEEE Third International Conference}} On},
  author = {Quercia, Daniele and Kosinski, Michal and Stillwell, David and Crowcroft, Jon},
  year = {2011},
  pages = {180--185},
  publisher = {{IEEE}},
  isbn = {1-4577-1931-2}
}

@inproceedings{rachuriEmotionSenseMobilePhones2010,
  title = {{{EmotionSense}}: {{A Mobile Phones}} Based {{Adaptive Platform}} for {{Experimental Social Psychology Research}}},
  shorttitle = {{{EmotionSense}}},
  booktitle = {In {{Proc}}. of {{UbiComp}}'10. {{ACM}}},
  author = {Rachuri, Kiran K. and Musolesi, Mirco and Mascolo, Cecilia and Rentfrow, Peter J. and Longworth, Chris and Aucinas, Andrius},
  year = {2010},
  abstract = {Today's mobile phones represent a rich and powerful com-puting platform, given their sensing, processing and commu-nication capabilities. Phones are also part of the everyday life of billions of people, and therefore represent an excep-tionally suitable tool for conducting social and psychological experiments in an unobtrusive way. In this paper we illustrate EmotionSense, a mobile sens-ing platform for social psychology studies based on mobile phones. Key characteristics include the ability of sensing individual emotions as well as activities, verbal and prox-imity interactions among members of social groups. More-over, the system is programmable by means of a declara-tive language that can be used to express adaptive rules to improve power saving. We evaluate a system prototype on},
  file = {/Users/timokoch/Zotero/storage/Y2XEIPNE/Rachuri et al. - 2010 - EmotionSense A Mobile Phones based Adaptive Platf.pdf;/Users/timokoch/Zotero/storage/4B5C2JKF/summary.html}
}

@article{rajkumarCOVID19MentalHealth2020,
  title = {{{COVID-19}} and Mental Health: {{A}} Review of the Existing Literature},
  shorttitle = {{{COVID-19}} and Mental Health},
  author = {Rajkumar, Ravi Philip},
  year = {2020},
  month = aug,
  journal = {Asian Journal of Psychiatry},
  volume = {52},
  pages = {102066},
  issn = {1876-2018},
  doi = {10.1016/j.ajp.2020.102066},
  urldate = {2023-02-21},
  abstract = {The COVID-19 pandemic is a major health crisis affecting several nations, with over 720,000 cases and 33,000 confirmed deaths reported to date. Such widespread outbreaks are associated with adverse mental health consequences. Keeping this in mind, existing literature on the COVID-19 outbreak pertinent to mental health was retrieved via a literature search of the PubMed database. Published articles were classified according to their overall themes and summarized. Preliminary evidence suggests that symptoms of anxiety and depression (16{\textendash}28\%) and self-reported stress (8\%) are common psychological reactions to the COVID-19 pandemic, and may be associated with disturbed sleep. A number of individual and structural variables moderate this risk. In planning services for such populations, both the needs of the concerned people and the necessary preventive guidelines must be taken into account. The available literature has emerged from only a few of the affected countries, and may not reflect the experience of persons living in other parts of the world. In conclusion, subsyndromal mental health problems are a common response to the COVID-19 pandemic. There is a need for more representative research from other affected countries, particularly in vulnerable populations.},
  langid = {english},
  keywords = {Anxiety,COVID-19,Depression,Public health,Stress},
  file = {/Users/timokoch/Zotero/storage/J8XZ4GIA/Rajkumar - 2020 - COVID-19 and mental health A review of the existi.pdf}
}

@article{ranaOpportunisticContextawareAffect2015,
  title = {Opportunistic and {{Context-aware Affect Sensing}} on {{Smartphones}}: {{The Concept}}, {{Challenges}} and {{Opportunities}}},
  shorttitle = {Opportunistic and {{Context-aware Affect Sensing}} on {{Smartphones}}},
  author = {Rana, Rajib and Hume, Margee and Reilly, John and Jurdak, Raja and {$\pm$}x, Jurdak and Soar, Jeffrey},
  year = {2015},
  month = aug,
  abstract = {Opportunistic affect sensing offers unprecedented potential for capturing spontaneous affect, eliminating biases inherent in the controlled setting. Facial expression and voice are two major affective displays, however most affect sensing systems on smartphone avoid them due to extensive power requirements. Encouragingly, due to the recent advent of low-power DSP (Digital Signal Processing) co-processor and GPU (Graphics Processing Unit) technology, audio and video sensing are becoming more feasible on smartphone. To utilize opportunistically captured facial expression and voice, gathering contextual information about the dynamic audiovisual stimuli is also important. This paper discusses recent advances of affect sensing on the smartphone and identifies the key barriers and potential solutions for implementing opportunistic and context-aware affect sensing on smartphone platforms. In addition to exploring the technical challenges (privacy, battery life and robust algorithms), the challenges of recruiting and retention of mental health patients have also been considered; as experimentation with mental health patients is difficult but crucial to showcase the importance/effectiveness of the smartphone centred affect sensing technology.},
  file = {/Users/timokoch/Zotero/storage/7ZQHFXCS/Rana et al. - 2015 - Opportunistic and Context-aware Affect Sensing on .pdf}
}

@article{rangelUseLanguageAuthor,
  title = {Use of {{Language}} and {{Author Profiling}}: {{Identification}} of {{Gender}} and {{Age}}.},
  author = {Rangel, Francisco and Rosso, Paolo},
  pages = {10},
  abstract = {In the beginning was the Word, and the Word was with God, and the Word was God''. Thus, John 1:11 begins his contribution to the Holy Bible (one of the most-distributed book in the world with hundreds of millions of copies2), the importance of the word lies in the essence of human beings. The discursive style reflects the profile of the author, who decides, often unconsciously, about how to choose and combine words. This provides valuable information about the personality of the author. In this paper we present our approach to identify age and gender of authors based on their use of language. We propose a representation based on stylistic features and obtain encouraging results with a SVM-based approach on the PAN-AP-133 dataset.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/I6YIZWBZ/Rangel und Rosso - Use of Language and Author Profiling Identificati.pdf}
}

@article{rangelUseLanguageAuthora,
  title = {Use of {{Language}} and {{Author Profiling}}: {{Identification}} of {{Gender}} and {{Age}}.},
  author = {Rangel, Francisco and Rosso, Paolo},
  pages = {10},
  abstract = {In the beginning was the Word, and the Word was with God, and the Word was God''. Thus, John 1:11 begins his contribution to the Holy Bible (one of the most-distributed book in the world with hundreds of millions of copies2), the importance of the word lies in the essence of human beings. The discursive style reflects the profile of the author, who decides, often unconsciously, about how to choose and combine words. This provides valuable information about the personality of the author. In this paper we present our approach to identify age and gender of authors based on their use of language. We propose a representation based on stylistic features and obtain encouraging results with a SVM-based approach on the PAN-AP-133 dataset.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/PZADP3TQ/Rangel und Rosso - Use of Language and Author Profiling Identificati.pdf}
}

@inproceedings{raoClassifyingLatentUser2010,
  title = {Classifying Latent User Attributes in Twitter},
  booktitle = {Proceedings of the 2nd International Workshop on {{Search}} and Mining User-Generated Contents - {{SMUC}} '10},
  author = {Rao, Delip and Yarowsky, David and Shreevats, Abhishek and Gupta, Manaswi},
  year = {2010},
  pages = {37},
  publisher = {{ACM Press}},
  address = {{Toronto, ON, Canada}},
  doi = {10.1145/1871985.1871993},
  urldate = {2020-07-06},
  abstract = {Social media outlets such as Twitter have become an important forum for peer interaction. Thus the ability to classify latent user attributes, including gender, age, regional origin, and political orientation solely from Twitter user language or similar highly informal content has important applications in advertising, personalization, and recommendation. This paper includes a novel investigation of stacked-SVM-based classification algorithms over a rich set of original features, applied to classifying these four user attributes. It also includes extensive analysis of features and approaches that are effective and not effective in classifying user attributes in Twitter-style informal written genres as distinct from the other primarily spoken genres previously studied in the userproperty classification literature. Our models, singly and in ensemble, significantly outperform baseline models in all cases. A detailed analysis of model components and features provides an often entertaining insight into distinctive language-usage variation across gender, age, regional origin and political orientation in modern informal communication.},
  isbn = {978-1-4503-0386-6},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/7BESHC4P/Rao et al. - 2010 - Classifying latent user attributes in twitter.pdf}
}

@inproceedings{raoClassifyingLatentUser2010a,
  title = {Classifying Latent User Attributes in Twitter},
  booktitle = {Proceedings of the 2nd International Workshop on {{Search}} and Mining User-Generated Contents - {{SMUC}} '10},
  author = {Rao, Delip and Yarowsky, David and Shreevats, Abhishek and Gupta, Manaswi},
  year = {2010},
  pages = {37},
  publisher = {{ACM Press}},
  address = {{Toronto, ON, Canada}},
  doi = {10.1145/1871985.1871993},
  urldate = {2020-03-18},
  abstract = {Social media outlets such as Twitter have become an important forum for peer interaction. Thus the ability to classify latent user attributes, including gender, age, regional origin, and political orientation solely from Twitter user language or similar highly informal content has important applications in advertising, personalization, and recommendation. This paper includes a novel investigation of stacked-SVM-based classification algorithms over a rich set of original features, applied to classifying these four user attributes. It also includes extensive analysis of features and approaches that are effective and not effective in classifying user attributes in Twitter-style informal written genres as distinct from the other primarily spoken genres previously studied in the userproperty classification literature. Our models, singly and in ensemble, significantly outperform baseline models in all cases. A detailed analysis of model components and features provides an often entertaining insight into distinctive language-usage variation across gender, age, regional origin and political orientation in modern informal communication.},
  isbn = {978-1-4503-0386-6},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/W3FZ8SR8/Rao et al. - 2010 - Classifying latent user attributes in twitter.pdf}
}

@inproceedings{rathnerStateMindClassification2018,
  title = {State of {{Mind}}: {{Classification}} through {{Self-reported Affect}} and {{Word Use}} in {{Speech}}.},
  shorttitle = {State of {{Mind}}},
  booktitle = {Interspeech 2018},
  author = {Rathner, Eva-Maria and Terhorst, Yannik and Cummins, Nicholas and Schuller, Bj{\"o}rn and Baumeister, Harald},
  year = {2018},
  month = sep,
  pages = {267--271},
  publisher = {{ISCA}},
  doi = {10.21437/Interspeech.2018-2043},
  urldate = {2019-02-13},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/4ZZ9HYV6/Rathner et al. - 2018 - State of Mind Classification through Self-reporte.pdf}
}

@article{ratschLearningInterpretableSVMs2006,
  title = {Learning {{Interpretable SVMs}} for {{Biological Sequence Classification}}},
  author = {R{\"a}tsch, Gunnar and Sonnenburg, S{\"o}ren and Sch{\"a}fer, Christin},
  year = {2006},
  month = mar,
  journal = {BMC Bioinformatics},
  volume = {7},
  number = {1},
  pages = {S9},
  issn = {1471-2105},
  doi = {10.1186/1471-2105-7-S1-S9},
  urldate = {2020-09-06},
  abstract = {Support Vector Machines (SVMs) {\textendash} using a variety of string kernels {\textendash} have been successfully applied to biological sequence classification problems. While SVMs achieve high classification accuracy they lack interpretability. In many applications, it does not suffice that an algorithm just detects a biological signal in the sequence, but it should also provide means to interpret its solution in order to gain biological insight.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/Q2QMFNL9/Rätsch et al. - 2006 - Learning Interpretable SVMs for Biological Sequenc.pdf}
}

@misc{rcoreteamLanguageEnvironmentStatistical2020,
  title = {R: {{A Language}} and {{Environment}} for {{Statistical Computing}}},
  author = {R Core Team},
  year = {2020},
  address = {{Vienna, Austria}}
}

@misc{rcoreteamLanguageEnvironmentStatistical2021,
  title = {R: {{A Language}} and {{Environment}} for {{Statistical Computing}}},
  author = {{R Core Team}},
  year = {2021},
  address = {{Vienna, Austria}},
  howpublished = {R Foundation for Statistical Computing}
}

@misc{receptivitiLIWCAPIUser2019,
  title = {{{LIWC API}} - {{User Manual}}},
  author = {Receptiviti},
  year = {2019},
  journal = {Receptiviti},
  urldate = {2019-09-18},
  howpublished = {https://www.receptiviti.com/receptiviti-api-user-manual},
  langid = {american},
  file = {/Users/timokoch/Zotero/storage/NUZD9ZLF/receptiviti-api-user-manual.html}
}

@article{reevesScreenomicsFrameworkCapture2021,
  title = {Screenomics: {{A Framework}} to {{Capture}} and {{Analyze Personal Life Experiences}} and the {{Ways}} That {{Technology Shapes Them}}},
  shorttitle = {Screenomics},
  author = {Reeves, Byron and Ram, Nilam and Robinson, Thomas N. and Cummings, James J. and Giles, C. Lee and Pan, Jennifer and Chiatti, Agnese and Cho, Mj and Roehrick, Katie and Yang, Xiao and Gagneja, Anupriya and Brinberg, Miriam and Muise, Daniel and Lu, Yingdan and Luo, Mufan and Fitzgerald, Andrew and Yeykelis, Leo},
  year = {2021},
  month = mar,
  journal = {Human{\textendash}Computer Interaction},
  volume = {36},
  number = {2},
  pages = {150--201},
  publisher = {{Taylor \& Francis}},
  issn = {0737-0024},
  doi = {10.1080/07370024.2019.1578652},
  urldate = {2023-01-27},
  abstract = {Digital experiences capture an increasingly large part of life, making them a preferred, if not required, method to describe and theorize about human behavior. Digital media also shape behavior by enabling people to switch between different content easily, and create unique threads of experiences that pass quickly through numerous information categories. Current methods of recording digital experiences provide only partial reconstructions of digital lives that weave {\textendash} often within seconds {\textendash} among multiple applications, locations, functions, and media. We describe an end-to-end system for capturing and analyzing the ``screenome'' of life in media, i.e., the record of individual experiences represented as a sequence of screens that people view and interact with over time. The system includes software that collects screenshots, extracts text and images, and allows searching of a screenshot database. We discuss how the system can be used to elaborate current theories about psychological processing of technology, and suggest new theoretical questions that are enabled by multiple timescale analyses. Capabilities of the system are highlighted with eight research examples that analyze screens from adults who have generated data within the system. We end with a discussion of future uses, limitations, theory, and privacy.},
  pmid = {33867652},
  file = {/Users/timokoch/Zotero/storage/89PJLSRK/Reeves et al. - 2021 - Screenomics A Framework to Capture and Analyze Pe.pdf}
}

@article{remusSentiWSPubliclyAvailable,
  title = {{{SentiWS}} {\textendash} a {{Publicly Available German-language Resource}} for {{Sentiment Analysis}}},
  author = {Remus, Robert and Quasthoff, Uwe and Heyer, Gerhard},
  pages = {4},
  abstract = {SentimentWortschatz, or SentiWS for short, is a publicly available German-language resource for sentiment analysis, opinion mining etc. It lists positive and negative sentiment bearing words weighted within the interval of [-1; 1] plus their part of speech tag, and if applicable, their inflections. The current version of SentiWS (v1.8b) contains 1,650 negative and 1,818 positive words, which sum up to 16,406 positive and 16,328 negative word forms, respectively. It not only contains adjectives and adverbs explicitly expressing a sentiment, but also nouns and verbs implicitly containing one. The present work describes the resource's structure, the three sources utilised to assemble it and the semi-supervised method incorporated to weight the strength of its entries. Furthermore the resource's contents are extensively evaluated using a German-language evaluation set we constructed. The evaluation set is verified being reliable and its shown that SentiWS provides a beneficial lexical resource for German-language sentiment analysis related tasks to build on.},
  langid = {english}
}

@inproceedings{remusSentiWSPubliclyAvailable2010,
  title = {{{SentiWS}} - {{A Publicly Available German-language Resource}} for {{Sentiment Analysis}}},
  booktitle = {{{LREC}}},
  author = {Remus, R. and Quasthoff, U. and Heyer, Gerhard},
  year = {2010},
  abstract = {SentimentWortschatz, or SentiWS for short, is a publicly available German-language resource for sentiment analysis, opinion mining etc. It lists positive and negative sentiment bearing words weighted within the interval of [-1; 1] plus their part of speech tag, and if applicable, their inflections. The current version of SentiWS (v1.8b) contains 1,650 negative and 1,818 positive words, which sum up to 16,406 positive and 16,328 negative word forms, respectively. It not only contains adjectives and adverbs explicitly expressing a sentiment, but also nouns and verbs implicitly containing one. The present work describes the resources structure, the three sources utilised to assemble it and the semi-supervised method incorporated to weight the strength of its entries. Furthermore the resources contents are extensively evaluated using a German-language evaluation set we constructed. The evaluation set is verified being reliable and its shown that SentiWS provides a beneficial lexical resource for German-language sentiment analysis related tasks to build on.},
  file = {/Users/timokoch/Zotero/storage/NTVALPE2/Remus et al. - SentiWS – a Publicly Available German-language Res.pdf}
}

@book{remusSentiWSPubliclyAvailable2010a,
  title = {{{SentiWS}} - {{A Publicly Available German-language Resource}} for {{Sentiment Analysis}}},
  author = {Remus, Robert and Quasthoff, Uwe and Heyer, Gerhard},
  year = {2010},
  month = jan,
  abstract = {SentimentWortschatz, or SentiWS for short, is a publicly available German-language resource for sentiment analysis, opinion mining etc. It lists positive and negative sentiment bearing words weighted within the interval of ( 1;1) plus their part of speech tag, and if applicable, their inflections. The current version of SentiWS (v1.8b) contains 1,650 negative and 1,818 positive words, which sum up to 16,406 positive and 16,328 negative word forms, respectively. It not only contains adjectives and adverbs explicitly expressing a sentiment, but also nouns and verbs implicitly containing one. The present work describes the resource's structure, the three sources utilised to assemble it and the semi-supervised method incorporated to weight the strength of its entries. Furthermore the resource's contents are extensively evaluated using a German-language evaluation set we constructed. The evaluation set is verified being reliable and its shown that SentiWS provides a beneficial lexical resource for German-language sentiment analysis related tasks to build on.}
}

@book{remusSentiWSPubliclyAvailablea,
  title = {{{SentiWS}} {\textendash} a {{Publicly Available German-language Resource}} for {{Sentiment Analysis}}},
  author = {Remus, Robert and Quasthoff, Uwe and Heyer, Gerhard},
  abstract = {SentimentWortschatz, or SentiWS for short, is a publicly available German-language resource for sentiment analysis, opinion mining etc. It lists positive and negative sentiment bearing words weighted within the interval of [-1; 1] plus their part of speech tag, and if applicable, their inflections. The current version of SentiWS (v1.8b) contains 1,650 negative and 1,818 positive words, which sum up to 16,406 positive and 16,328 negative word forms, respectively. It not only contains adjectives and adverbs explicitly expressing a sentiment, but also nouns and verbs implicitly containing one. The present work describes the resource's structure, the three sources utilised to assemble it and the semi-supervised method incorporated to weight the strength of its entries. Furthermore the resource's contents are extensively evaluated using a German-language evaluation set we constructed. The evaluation set is verified being reliable and its shown that SentiWS provides a beneficial lexical resource for German-language sentiment analysis related tasks to build on. 1.},
  file = {/Users/timokoch/Zotero/storage/ADXH55XJ/Remus et al. - SentiWS – a Publicly Available German-language Res.pdf;/Users/timokoch/Zotero/storage/4NL5JYQT/summary.html}
}

@article{reshefDetectingNovelAssociations2011,
  title = {Detecting Novel Associations in Large Data Sets},
  author = {Reshef, David N. and Reshef, Yakir A. and Finucane, Hilary K. and Grossman, Sharon R. and McVean, Gilean and Turnbaugh, Peter J. and Lander, Eric S. and Mitzenmacher, Michael and Sabeti, Pardis C.},
  year = {2011},
  journal = {science},
  volume = {334},
  number = {6062},
  pages = {1518--1524},
  issn = {0036-8075}
}

@misc{ResponsibleAIInvestments,
  title = {Responsible {{AI}} Investments and Safeguards for Facial Recognition},
  urldate = {2022-11-30},
  abstract = {Azure Cognitive Services deliver high-quality, consent-driven face recognition that developers use to power verification of human identities on mobile, desktop, and internet of thing (IoT) devices, as well as facial detection and redaction capabilities for accessibility, modern productivity, a...},
  howpublished = {https://azure.microsoft.com/en-us/blog/responsible-ai-investments-and-safeguards-for-facial-recognition/},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/JX8SY2JY/responsible-ai-investments-and-safeguards-for-facial-recognition.html}
}

@inproceedings{reuelMeasuringLanguageSelfDisclosure2022,
  title = {Measuring the {{Language}} of {{Self-Disclosure}} across {{Corpora}}},
  booktitle = {Findings of the {{Association}} for {{Computational Linguistics}}: {{ACL}} 2022},
  author = {Reuel, Ann-Katrin and Peralta, Sebastian and Sedoc, Jo{\~a}o and Sherman, Garrick and Ungar, Lyle},
  year = {2022},
  month = may,
  pages = {1035--1047},
  publisher = {{Association for Computational Linguistics}},
  address = {{Dublin, Ireland}},
  urldate = {2022-05-28},
  abstract = {Being able to reliably estimate self-disclosure {\textendash} a key component of friendship and intimacy {\textendash} from language is important for many psychology studies. We build single-task models on five self-disclosure corpora, but find that these models generalize poorly; the within-domain accuracy of predicted message-level self-disclosure of the best-performing model (mean Pearson's r=0.69) is much higher than the respective across data set accuracy (mean Pearson's r=0.32), due to both variations in the corpora (e.g., medical vs. general topics) and labeling instructions (target variables: self-disclosure, emotional disclosure, intimacy). However, some lexical features, such as expression of negative emotions and use of first person personal pronouns such as `I' reliably predict self-disclosure across corpora. We develop a multi-task model that yields better results, with an average Pearson's r of 0.37 for out-of-corpora prediction.},
  file = {/Users/timokoch/Zotero/storage/C9NGCQX8/Reuel et al. - 2022 - Measuring the Language of Self-Disclosure across C.pdf}
}

@inproceedings{rigbyWhatCanOSS2007,
  title = {What {{Can OSS Mailing Lists Tell Us}}? {{A Preliminary Psychometric Text Analysis}} of the {{Apache Developer Mailing List}}},
  shorttitle = {What {{Can OSS Mailing Lists Tell Us}}?},
  booktitle = {Fourth {{International Workshop}} on {{Mining Software Repositories}} ({{MSR}}'07:{{ICSE Workshops}} 2007)},
  author = {Rigby, Peter C. and Hassan, Ahmed E.},
  year = {2007},
  month = may,
  pages = {23--23},
  publisher = {{IEEE}},
  address = {{Minneapolis, MN, USA}},
  doi = {10.1109/MSR.2007.35},
  urldate = {2019-07-29},
  abstract = {Developer mailing lists are a rich source of information about Open Source Software (OSS) development. The unstructured nature of email makes extracting information difficult. We use a psychometrically-based linguistic analysis tool, the LIWC, to examine the Apache httpd server developer mailing list. We conduct three preliminary experiments to assess the appropriateness of this tool for information extraction from mailing lists. First, using LIWC dimensions that are correlated with the big five personality traits, we assess the personality of four top developers against a baseline for the entire mailing list. The two developers that were responsible for the major Apache releases had similar personalities. Their personalities were different from the baseline and the other developers. Second, the first and last 50 emails for two top developers who have left the project are examined. The analysis shows promise in understanding why developers join and leave a project. Third, we examine word usage on the mailing list for two major Apache releases. The differences may reflect the relative success of each release.},
  isbn = {978-0-7695-2950-9},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/EV7UGMEQ/Rigby und Hassan - 2007 - What Can OSS Mailing Lists Tell Us A Preliminary .pdf}
}

@article{riordanEmojisToolsEmotion2017,
  title = {Emojis as {{Tools}} for {{Emotion Work}}: {{Communicating Affect}} in {{Text Messages}}},
  shorttitle = {Emojis as {{Tools}} for {{Emotion Work}}},
  author = {Riordan, Monica A.},
  year = {2017},
  month = oct,
  journal = {Journal of Language and Social Psychology},
  volume = {36},
  number = {5},
  pages = {549--567},
  publisher = {{SAGE Publications Inc}},
  issn = {0261-927X},
  doi = {10.1177/0261927X17704238},
  urldate = {2023-01-13},
  abstract = {Emojis are pictures commonly used in texting. The use and type of emojis has increased in recent years; particularly emojis that are not faces, but rather objects. While prior work on emojis of faces suggest their primary purpose is to convey affect, few have researched the communicative purpose of emojis of objects. In the current work, two experiments assess whether emojis of objects also convey affect. Different populations of participants are shown text messages with or without different emojis of objects, asked to rate the message?s affective content, and indicate their confidence in their ratings. Overall results suggest that emojis of objects communicate positive affect, specifically joy. These findings are framed in the sociological theory of emotion work, suggesting that the time and effort involved in using emojis may help maintain and enhance social relationships.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/YZBG97B9/Riordan - 2017 - Emojis as Tools for Emotion Work Communicating Af.pdf}
}

@article{riordanEmojisToolsEmotion2017a,
  title = {Emojis as {{Tools}} for {{Emotion Work}}: {{Communicating Affect}} in {{Text Messages}}},
  shorttitle = {Emojis as {{Tools}} for {{Emotion Work}}},
  author = {Riordan, Monica A.},
  year = {2017},
  month = oct,
  journal = {Journal of Language and Social Psychology},
  volume = {36},
  number = {5},
  pages = {549--567},
  publisher = {{SAGE Publications Inc}},
  issn = {0261-927X},
  doi = {10.1177/0261927X17704238},
  urldate = {2020-11-30},
  abstract = {Emojis are pictures commonly used in texting. The use and type of emojis has increased in recent years; particularly emojis that are not faces, but rather objects. While prior work on emojis of faces suggest their primary purpose is to convey affect, few have researched the communicative purpose of emojis of objects. In the current work, two experiments assess whether emojis of objects also convey affect. Different populations of participants are shown text messages with or without different emojis of objects, asked to rate the message's affective content, and indicate their confidence in their ratings. Overall results suggest that emojis of objects communicate positive affect, specifically joy. These findings are framed in the sociological theory of emotion work, suggesting that the time and effort involved in using emojis may help maintain and enhance social relationships.},
  langid = {english}
}

@article{robertsEmpaTweetAnnotatingDetecting,
  title = {{{EmpaTweet}}: {{Annotating}} and {{Detecting Emotions}} on {{Twitter}}},
  author = {Roberts, Kirk and Roach, Michael A and Johnson, Joseph and Guthrie, Josh and Harabagiu, Sanda M},
  pages = {8},
  abstract = {The rise of micro-blogging in recent years has resulted in significant access to emotion-laden text. Unlike emotion expressed in other textual sources (e.g., blogs, quotes in newswire, email, product reviews, or even clinical text), micro-blogs differ by (1) placing a strict limit on length, resulting radically in new forms of emotional expression, and (2) encouraging users to express their daily thoughts in real-time, often resulting in far more emotion statements than might normally occur. In this paper, we introduce a corpus collected from Twitter with annotated micro-blog posts (or ``tweets'') annotated at the tweet-level with seven emotions: ANGER, DISGUST, FEAR, JOY, LOVE, SADNESS, and SURPRISE. We analyze how emotions are distributed in the data we annotated and compare it to the distributions in other emotion-annotated corpora. We also used the annotated corpus to train a classifier that automatically discovers the emotions in tweets. In addition, we present an analysis of the linguistic style used for expressing emotions our corpus. We hope that these observations will lead to the design of novel emotion detection techniques that account for linguistic style and psycholinguistic theories.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/ZRZQ4URA/Roberts et al. - EmpaTweet Annotating and Detecting Emotions on Tw.pdf}
}

@article{robinsDelroyPaulhusSimine,
  title = {Delroy {{L}}. {{Paulhus Simine Vazire}}},
  author = {Robins, In R W and Fraley, R C and Krueger, R F},
  pages = {16},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/NQBWI6E7/Robins et al. - Delroy L. Paulhus Simine Vazire.pdf}
}

@misc{romeroModellingPersonalityChange2021,
  title = {Modelling {{Personality Change During Extreme Exogenous Conditions}}},
  author = {Romero, Peter and Mikiya, Yuki and Nakatsuma, Teruo and Fitz, Stephen and Koch, Timo K.},
  year = {2021},
  month = jul,
  publisher = {{PsyArXiv}},
  doi = {10.31234/osf.io/rtmjw},
  urldate = {2023-02-21},
  abstract = {A Bayesian Study On Social Media Language During The First Wave of the COVID-19 Pandemic. Personality traits change over time, however research on it was sparse, since previous approaches were too time-consuming and expensive. Also, the necessary methodological complexity was beyond the capabilities of classical personality researchers, which resulted in contradictory results and lack of methodological standards. In this paper, we presented a simple and cost-effective method that overcame these restrictions. We introduced a machine learning approach for daily measurements to personality research, and developed a bespoke Bayesian algorithm to analyse the observed change. This resulted in uncovering concrete points of regime-shift that overlapped with relevant exogenous events for a Japanese sample of social media users. With it, we showed that personality measures displayed significant elasticity under extreme exogenous conditions during the first wave of COVID-19 and the subsequent societal countermeasures, which can be interpreted as a temporary shift from normal expression of latent psychological traits z to their respective emergency expression ze. Concretely, we found that the group of top 25\% Conscientiousness users displayed a significant change in the FFM factors Agreeableness and Extraversion. We finally compared our findings with those from similar studies in other cultures, and discussed generalisability as well as future qualitative and quantitative directions for research.},
  langid = {american},
  keywords = {Bayesian Statistics,COVID-19,Five Factor Model,Machine Learning,Personality Change,Psychometrics,Quantitative Methods,Social and Behavioral Sciences},
  file = {/Users/timokoch/Zotero/storage/DJD8WFX2/Romero et al. - 2021 - Modelling Personality Change During Extreme Exogen.pdf}
}

@book{rorschachPsychodiagnosticsDiagnosticTest1951,
  title = {Psychodiagnostics {{A Diagnostic Test Based On Perception}}},
  author = {Rorschach, Hermann},
  editor = {{Universal Digital Library}},
  year = {1951},
  publisher = {{Verlag Hans Huber, Berne}},
  urldate = {2019-02-06},
  langid = {english},
  lccn = {11205}
}

@book{rorschachPsychodiagnosticsDiagnosticTest1969,
  title = {Psychodiagnostics; a Diagnostic Test Based on Perception},
  author = {Rorschach, Hermann and Lemkau, Paul Victor},
  year = {[1969, c1942]},
  publisher = {{H. Huber; Grune \& Stratton}},
  address = {{Berne, New York}},
  urldate = {2019-02-06},
  keywords = {Psychoanalysis.,Rorschach Test.},
  file = {/Users/timokoch/Zotero/storage/KB5K4LFF/102074160.html}
}

@article{rosenfeldStudyWhatsAppUsage2018,
  title = {A {{Study}} of {{WhatsApp Usage Patterns}} and {{Prediction Models}} without {{Message Content}}},
  author = {Rosenfeld, Avi and Sina, Sigal and Sarne, David and Avidov, Or and Kraus, Sarit},
  year = {2018},
  journal = {arXiv preprint arXiv:1802.03393},
  eprint = {1802.03393},
  archiveprefix = {arxiv},
  file = {/Users/timokoch/Zotero/storage/XN25F9DW/Rosenfeld et al. - 2018 - A Study of WhatsApp Usage Patterns and Prediction .pdf}
}

@article{rosenfeldWhatsAppUsagePatterns2018,
  title = {{{WhatsApp}} Usage Patterns and Prediction of Demographic Characteristics without Access to Message Content},
  author = {Rosenfeld, Avi and Sina, Sigal and Sarne, David and Avidov, Or and Kraus, Sarit},
  year = {2018},
  month = sep,
  journal = {Demographic Research},
  volume = {39},
  pages = {647--670},
  issn = {1435-9871},
  doi = {10.4054/DemRes.2018.39.22},
  urldate = {2020-10-29},
  abstract = {BACKGROUND Social networks on the Internet have become ubiquitous applications that allow people to easily share text, pictures, and audio and video files. Popular networks include WhatsApp, Facebook, Reddit, and LinkedIn.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/CBN7HEZA/Rosenfeld et al. - 2018 - WhatsApp usage patterns and prediction of demograp.pdf}
}

@inproceedings{rossetRankingbasedEvaluationRegression2005,
  title = {Ranking-Based Evaluation of Regression Models},
  booktitle = {Data {{Mining}}, {{Fifth IEEE International Conference}} On},
  author = {Rosset, Saharon and Perlich, Claudia and Zadrozny, Bianca},
  year = {2005},
  pages = {8 pp.},
  publisher = {{IEEE}},
  isbn = {0-7695-2278-5}
}

@article{rousseeuwRobustStatisticsOutlier2011,
  title = {Robust Statistics for Outlier Detection},
  author = {Rousseeuw, Peter and Hubert, Mia},
  year = {2011},
  month = jan,
  journal = {Wiley Interdisc. Rew.: Data Mining and Knowledge Discovery},
  volume = {1},
  pages = {73--79},
  doi = {10.1002/widm.2},
  abstract = {The full-text of the 2011 paper is not available, but there is a new and extended version with figures, entitled "Anomaly Detection by Robust Statistics" (WIRES 2018, same authors), which can be downloaded from this page.},
  file = {/Users/timokoch/Zotero/storage/4AL58AQZ/Rousseeuw und Hubert - 2011 - Robust statistics for outlier detection.pdf}
}

@article{rubinWhenAdjustAlpha2021,
  title = {When to Adjust Alpha during Multiple Testing: A Consideration of Disjunction, Conjunction, and Individual Testing},
  shorttitle = {When to Adjust Alpha during Multiple Testing},
  author = {Rubin, Mark},
  year = {2021},
  journal = {Synthese},
  issn = {0039-7857},
  doi = {10.1007/s11229-021-03276-4},
  urldate = {2021-07-08},
  abstract = {Scientists often adjust their significance threshold (alpha level) during null hypothesis significance testing in order to take into account multiple testing and multiple comparisons. This alpha adjustment has become particularly relevant in the context of the replication crisis in science. The present article considers the conditions in which this alpha adjustment is appropriate and the conditions in which it is inappropriate. A distinction is drawn between three types of multiple testing: disjunction testing, conjunction testing, and individual testing. It is argued that alpha adjustment is only appropriate in the case of disjunction testing, in which at least one test result must be significant in order to reject the associated joint null hypothesis. Alpha adjustment is inappropriate in the case of conjunction testing, in which all relevant results must be significant in order to reject the joint null hypothesis. Alpha adjustment is also inappropriate in the case of individual testing, in which each individual result must be significant in order to reject each associated individual null hypothesis. The conditions under which each of these three types of multiple testing is warranted are examined. It is concluded that researchers should not automatically (mindlessly) assume that alpha adjustment is necessary during multiple testing. Illustrations are provided in relation to joint studywise hypotheses and joint multiway ANOVAwise hypotheses.},
  langid = {english}
}

@book{rudeCollege,
  title = {College},
  author = {Rude, Stephanie S. and Gortner, Eva-maria and Pennebaker, James W.},
  abstract = {and depression-vulnerable},
  file = {/Users/timokoch/Zotero/storage/WAICDFHG/Rude et al. - college.pdf;/Users/timokoch/Zotero/storage/73YHZM27/summary.html}
}

@article{rudeLanguageUseDepressed2004,
  title = {Language Use of Depressed and Depression-Vulnerable College Students},
  author = {Rude, Stephanie and Gortner, Eva-Maria and Pennebaker, James},
  year = {2004},
  month = dec,
  journal = {Cognition and Emotion},
  volume = {18},
  number = {8},
  pages = {1121--1133},
  issn = {0269-9931},
  doi = {10.1080/02699930441000030},
  urldate = {2019-02-12},
  abstract = {Essays written by currently-depressed, formerly-depressed, and never-depressed college students were examined for differences in language that might shed light on the cognitive operations associated with depression and depression-vulnerability. A text analysis program computed the incidence of words in predesignated categories. Consistent with Beck's cognitive model and with Pyczsinski and Greenberg's self-focus model of depression, depressed participants used more negatively valenced words and used the word, "I" more than did never-depressed participants. Formerly-depressed (presumably depression-vulnerable) participants did not differ from never-depressed participants on these indices of depressive processing. However, consistent with prediction, formerly-depressed participants' use of the word "I" increased across the essays and was significantly greater than that of never-depressed writers in the final portion of the essays.},
  file = {/Users/timokoch/Zotero/storage/QSPBWE73/02699930441000030.html}
}

@article{russellAffectGridSingleItem1989,
  title = {Affect {{Grid}}: {{A Single-Item Scale}} of {{Pleasure}} and {{Arousal}}},
  author = {Russell, James A. and Weiss, Anna and Mendelsohn, Gerald A},
  year = {1989},
  pages = {10},
  langid = {english}
}

@article{russellAffectGridSingleitem1989a,
  title = {Affect {{Grid}}: {{A}} Single-Item Scale of Pleasure and Arousal},
  shorttitle = {Affect {{Grid}}},
  author = {Russell, James A. and Weiss, Anna and Mendelsohn, Gerald A.},
  year = {1989},
  journal = {Journal of Personality and Social Psychology},
  volume = {57},
  number = {3},
  pages = {493--502},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1315},
  doi = {10.1037/0022-3514.57.3.493},
  abstract = {This article introduces a single-item scale, the Affect Grid, designed as a quick means of assessing affect along the dimensions of pleasure{\textendash}displeasure and arousal{\textendash}sleepiness. The Affect Grid is potentially suitable for any study that requires judgments about affect of either a descriptive or a subjective kind. The scale was shown to have adequate reliability, convergent validity, and discriminant validity in 4 studies in which college students used the Affect Grid to describe (a) their current mood, (b) the meaning of emotion-related words, and (c) the feelings conveyed by facial expressions. Other studies (e.g., J. Snodgrass et al; see record 1989-13842-001) are cited to illustrate the potential uses of the Affect Grid as a measure of mood. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Physiological Arousal,Pleasure,Rating Scales,Test Reliability,Test Validity},
  file = {/Users/timokoch/Zotero/storage/R7PF6IP6/Russell et al. - Affect Grid A Single-Item Scale of Pleasure and A.pdf;/Users/timokoch/Zotero/storage/YV5VJLEA/1990-00158-001.html}
}

@article{russellCircumplexModelAffect1980,
  title = {A {{Circumplex Model}} of {{Affect}}},
  author = {Russell, James A.},
  year = {1980},
  month = dec,
  journal = {Journal of Personality and Social Psychology},
  volume = {39},
  pages = {1161--1178},
  doi = {10.1037/h0077714},
  abstract = {Factor-analytic evidence has led most psychologists to describe affect as a set of dimensions, such as displeasure, distress, depression, excitement, and so on, with each dimension varying independently of the others. However, there is other evidence that rather than being independent, these affective dimensions are interrelated in a highly systematic fashion. The evidence suggests that these interrelationships can be represented by a spatial model in which affective concepts fall in a circle in the following order: pleasure (0), excitement (45), arousal (90), distress (135), displeasure (180), depression (225), sleepiness (270), and relaxation (315). This model was offered both as a way psychologists can represent the structure of affective experience, as assessed through self-report, and as a representation of the cognitive structure that laymen utilize in conceptualizing affect. Supportive evidence was obtained by scaling 28 emotion-denoting adjectives in 4 different ways: R. T. Ross's (1938) technique for a circular ordering of variables, a multidimensional scaling procedure based on perceived similarity among the terms, a unidimensional scaling on hypothesized pleasure{\textendash}displeasure and degree-of-arousal dimensions, and a principal-components analysis of 343 Ss' self-reports of their current affective states. (70 ref) (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
  file = {/Users/timokoch/Zotero/storage/Y59KWVTJ/Russell - 1980 - A Circumplex Model of Affect.pdf}
}

@article{russellCircumplexModelAffect1980a,
  title = {A {{Circumplex Model}} of {{Affect}}},
  author = {Russell, James A.},
  year = {1980},
  month = dec,
  journal = {Journal of Personality and Social Psychology},
  volume = {39},
  pages = {1161--1178},
  doi = {10.1037/h0077714},
  abstract = {Factor-analytic evidence has led most psychologists to describe affect as a set of dimensions, such as displeasure, distress, depression, excitement, and so on, with each dimension varying independently of the others. However, there is other evidence that rather than being independent, these affective dimensions are interrelated in a highly systematic fashion. The evidence suggests that these interrelationships can be represented by a spatial model in which affective concepts fall in a circle in the following order: pleasure (0), excitement (45), arousal (90), distress (135), displeasure (180), depression (225), sleepiness (270), and relaxation (315). This model was offered both as a way psychologists can represent the structure of affective experience, as assessed through self-report, and as a representation of the cognitive structure that laymen utilize in conceptualizing affect. Supportive evidence was obtained by scaling 28 emotion-denoting adjectives in 4 different ways: R. T. Ross's (1938) technique for a circular ordering of variables, a multidimensional scaling procedure based on perceived similarity among the terms, a unidimensional scaling on hypothesized pleasure{\textendash}displeasure and degree-of-arousal dimensions, and a principal-components analysis of 343 Ss' self-reports of their current affective states. (70 ref) (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
  file = {/Users/timokoch/Zotero/storage/8NXVNRFH/Russell - 1980 - A Circumplex Model of Affect.pdf}
}

@article{russellCoreAffectPrototypical1999,
  title = {Core Affect, Prototypical Emotional Episodes, and Other Things Called Emotion: {{Dissecting}} the Elephant},
  shorttitle = {Core Affect, Prototypical Emotional Episodes, and Other Things Called Emotion},
  author = {Russell, James A. and Barrett, Lisa},
  year = {1999},
  month = jun,
  journal = {Journal of personality and social psychology},
  volume = {76},
  pages = {805--19},
  doi = {10.1037//0022-3514.76.5.805},
  abstract = {What is the structure of emotion? Emotion is too broad a class of events to be a single scientific category, and no one structure suffices. As an illustration, core affect is distinguished from prototypical emotional episode. Core affect refers to consciously accessible elemental processes of pleasure and activation, has many causes, and is always present. Its structure involves two bipolar dimensions. Prototypical emotional episode refers to a complex process that unfolds over time, involves causally connected subevents (antecedent; appraisal; physiological, affective, and cognitive changes; behavioral response; self-categorization), has one perceived cause, and is rare. Its structure involves categories (anger, fear, shame, jealousy, etc.) vertically organized as a fuzzy hierarchy and horizontally organized as part of a circumplex.},
  file = {/Users/timokoch/Zotero/storage/ZKANRPDN/Russell und Barrett - 1999 - Core affect, prototypical emotional episodes, and .pdf}
}

@article{russellCoreAffectPrototypical1999a,
  title = {Core Affect, Prototypical Emotional Episodes, and Other Things Called Emotion: {{Dissecting}} the Elephant},
  shorttitle = {Core Affect, Prototypical Emotional Episodes, and Other Things Called Emotion},
  author = {Russell, James A. and Barrett, Lisa Feldman},
  year = {1999},
  journal = {Journal of Personality and Social Psychology},
  volume = {76},
  pages = {805--819},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1315},
  doi = {10.1037/0022-3514.76.5.805},
  abstract = {What is the structure of emotion? Emotion is too broad a class of events to be a single scientific category, and no one structure suffices. As an illustration, core affect is distinguished from prototypical emotional episode. Core affect refers to consciously accessible elemental processes of pleasure and activation, has many causes, and is always present. Its structure involves two bipolar dimensions. Prototypical emotional episode refers to a complex process that unfolds over time, involves causally connected subevents (antecedent; appraisal; physiological, affective, and cognitive changes; behavioral response; self-categorization), has one perceived cause, and is rare. Its structure involves categories (anger, fear, shame, jealousy, etc.) vertically organized as a fuzzy hierarchy and horizontally organized as part of a circumplex. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Emotional Content,Emotions},
  file = {/Users/timokoch/Zotero/storage/P689VQU3/Russell und Barrett - Core Affect, Prototypical Emotional Episodes, and .pdf;/Users/timokoch/Zotero/storage/SFF624ZN/doiLanding.html}
}

@article{sahaInferringMoodInstability2017,
  title = {Inferring {{Mood Instability}} on {{Social Media}} by {{Leveraging Ecological Momentary Assessments}}},
  author = {Saha, Koustuv and Chan, Larry and {de Barbaro}, Kaya and Abowd, Gregory and Choudhury, Munmun},
  year = {2017},
  month = sep,
  journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
  volume = {1},
  pages = {1--27},
  doi = {10.1145/3130960},
  abstract = {Active and passive sensing technologies are providing powerful mechanisms to track, model, and understand a range of health behaviors and well-being states. Despite yielding rich, dense and high fidelity data, current sensing technologies often require highly engineered study designs and persistent participant compliance, making them difficult to scale to large populations and to data acquisition tasks spanning extended time periods. This paper situates social media as a new passive, unobtrusive sensing technology. We propose a semi-supervised machine learning framework to combine small samples of data gathered through active sensing, with large-scale social media data to infer mood instability (MI) in individuals. Starting from a theoretically-grounded measure of MI obtained from mobile ecological momentary assessments (EMAs), we show that our model is able to infer MI in a large population of Twitter users with 96\% accuracy and F-1 score. Additionally, we show that, our model predicts self-identifying Twitter users with bipolar and borderline personality disorder to exhibit twice the likelihood of high MI, compared to that in a suitable control. We discuss the implications and the potential for integrating complementary sensing capabilities to address complex research challenges in precision medicine.}
}

@misc{saidbleikPermutationFeatureImportance2015,
  title = {Permutation {{Feature Importance}}},
  author = {Said Bleik},
  year = {2015}
}

@misc{sametogluValueSocialMedia2022,
  title = {The {{Value}} of {{Social Media Language}} for the {{Assessment}} of {{Wellbeing}}: {{A Systematic Review}} and {{Meta-Analysis}}},
  shorttitle = {The {{Value}} of {{Social Media Language}} for the {{Assessment}} of {{Wellbeing}}},
  author = {Sametoglu, Selim and Pelt, Dirk and Eichstaedt, johannes C. and Ungar, Lyle H. and Bartels, Meike},
  year = {2022},
  month = may,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/qnx2v},
  urldate = {2022-05-23},
  abstract = {Wellbeing is an important concept that concerns researchers, policy makers, and the broader general public. The measurement of individuals' wellbeing levels has predominantly been done through self-reports (e.g., survey questionnaires), which is time-consuming for respondents and costly. Alternatively, wellbeing can be measured in real-time by automatically analysing the language expressed on social media platforms (e.g., Facebook, Twitter, Weibo), through social media language text mining (SMTM). The application of this method for the measurement of wellbeing is relatively new, therefore the validity of SMTM for wellbeing is still being established. We present a systematic review based on 45 studies, and a meta-analysis on 32 effect sizes from a subset of 18 studies reporting correlations between SMTM wellbeing and survey-based ground truth measures. Our qualitative synthesis of the reviewed studies provided insights into current patterns in the literature including (1) most studies were conducted in English speaking samples, (2) Twitter was the most popular social media platform for data collection, (3) closed vocabulary dictionary methods driven and word-level methods of analysis were equally preferred, (5) satisfaction with life was the most popular ground-truth measure across the studies. In addition to this, our qualitative synthesis provided support for the face validity of SMTM for wellbeing by comparing/highlighting the similarities between the broader survey-based wellbeing literature and the findings of the SMTM-based wellbeing studies. Our meta-analysis found that SMTM shows convergent validity with traditional wellbeing measures (r = .54, 95\% CI [.37, .67] for location level studies, and r = .33, 95\% CI [.25, .40] for individual-level assessments).SMTM is a promising and growing method, but researchers should be aware of its current pitfalls such as the non-representativeness of the samples acquired through social media platforms. We provide recommendations for future SMTM studies in the context of wellbeing.},
  langid = {american},
  keywords = {Keywords: Wellbeing,Language analysis,other,Psychology,Social and Behavioral Sciences,Social media,Text mining,Validity,Well-being},
  file = {/Users/timokoch/Zotero/storage/IU8QMDJA/Sametoglu et al. - 2022 - The Value of Social Media Language for the Assessm.pdf}
}

@article{sankoffLanguageChangeLifespan2017,
  title = {Language {{Change Across}} the {{Lifespan}}},
  author = {Sankoff, Gillian},
  year = {2017},
  pages = {22},
  abstract = {Understanding the relationship between language change and variation has progressed considerably over the last several decades, but less is known about how speakers at different life stages deal with ongoing change in their speech communities. Longitudinal studies of individuals and groups reveal three trajectory types postadolescence: stability (the most common), adopting (to some degree) a change led by younger people (the next most common trajectory), or swimming against the community current by reverting to an older pattern in later life (the least common trajectory). Declining plasticity over the life course places limits on possible trajectories, which are also subject to social and cultural influences. This article reviews relevant studies from historical linguistics as well as panel studies on African American English and dialect contact, proposing that future progress will be made by interdisciplinary research combining psycholinguistic and sociolinguistic perspectives. Lifespan trajectories in situations of community stability are also discussed.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/ZR7KU9WH/Sankoff - 2017 - Language Change Across the Lifespan.pdf}
}

@inproceedings{sapDevelopingAgeGender2014,
  title = {Developing {{Age}} and {{Gender Predictive Lexica}} over {{Social Media}}},
  booktitle = {Proceedings of the 2014 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} ({{EMNLP}})},
  author = {Sap, Maarten and Park, Gregory and Eichstaedt, Johannes C. and Kern, Margaret and Stillwell, David and Kosinski, Michal and Ungar, Lyle and Schwartz, Hansen Andrew},
  year = {2014},
  pages = {1146--1151},
  publisher = {{Association for Computational Linguistics}},
  address = {{Doha, Qatar}},
  doi = {10.3115/v1/D14-1121},
  urldate = {2019-07-29},
  abstract = {Demographic lexica have potential for widespread use in social science, economic, and business applications. We derive predictive lexica (words and weights) for age and gender using regression and classification models from word usage in Facebook, blog, and Twitter data with associated demographic labels. The lexica, made publicly available,1 achieved state-of-the-art accuracy in language based age and gender prediction over Facebook and Twitter, and were evaluated for generalization across social media genres as well as in limited message situations.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/B48IWT3P/Sap et al. - 2014 - Developing Age and Gender Predictive Lexica over S.pdf}
}

@article{savageSpotifyWantsSuggest2021,
  title = {Spotify Wants to Suggest Songs Based on Your Emotions},
  author = {Savage, Mark},
  year = {2021},
  month = jan,
  journal = {BBC News},
  urldate = {2021-02-01},
  abstract = {The streaming giant patents a method of suggesting songs based on a scan of your emotional state.},
  chapter = {Entertainment \& Arts},
  langid = {british},
  file = {/Users/timokoch/Zotero/storage/Q8TFC4RG/entertainment-arts-55839655.html}
}

@article{schererEmotionsAreEmergent2009,
  title = {Emotions Are Emergent Processes: They Require a Dynamic Computational Architecture},
  shorttitle = {Emotions Are Emergent Processes},
  author = {Scherer, Klaus R.},
  year = {2009},
  month = dec,
  journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  volume = {364},
  number = {1535},
  pages = {3459--3474},
  issn = {0962-8436},
  doi = {10.1098/rstb.2009.0141},
  urldate = {2022-11-10},
  abstract = {Emotion is a cultural and psychobiological adaptation mechanism which allows each individual to react flexibly and dynamically to environmental contingencies. From this claim flows a description of the elements theoretically needed to construct a virtual agent with the ability to display human-like emotions and to respond appropriately to human emotional expression. This article offers a brief survey of the desirable features of emotion theories that make them ideal blueprints for agent models. In particular, the component process model of emotion is described, a theory which postulates emotion-antecedent appraisal on different levels of processing that drive response system patterning predictions. In conclusion, investing seriously in emergent computational modelling of emotion using a nonlinear dynamic systems approach is suggested.},
  pmcid = {PMC2781886},
  pmid = {19884141},
  file = {/Users/timokoch/Zotero/storage/DRLUFZFR/Scherer - 2009 - Emotions are emergent processes they require a dy.pdf}
}

@article{schererJudgingPersonalityVoice1972,
  title = {Judging Personality from Voice: {{A}} Cross-cultural Approach to an Old Issue in Interpersonal Perception 1},
  author = {Scherer, Klaus R.},
  year = {1972},
  journal = {Journal of Personality},
  volume = {40},
  number = {2},
  pages = {191--210},
  publisher = {{Wiley Online Library}},
  isbn = {0022-3506}
}

@article{schererPersonalityInferenceVoice1978,
  title = {Personality Inference from Voice Quality: {{The}} Loud Voice of Extroversion},
  author = {Scherer, Klaus R.},
  year = {1978},
  journal = {European Journal of Social Psychology},
  volume = {8},
  number = {4},
  pages = {467--487},
  publisher = {{Wiley Online Library}},
  isbn = {0046-2772}
}

@incollection{schererPsychologicalModelsEmotion2000,
  title = {Psychological Models of Emotion},
  booktitle = {The Neuropsychology of Emotion},
  author = {Scherer, Klaus R.},
  year = {2000},
  series = {Series in Affective Science},
  pages = {137--162},
  publisher = {{Oxford University Press}},
  address = {{New York, NY, US}},
  abstract = {This chapter provides an overview of theories currently discussed in the psychology of emotion and the controversies and research issues they generate. In this review, many of the fundamental differences among the models relate to the thorny issue of the definition of the phenomenon called emotion and its conceptualization and operationalization. The disagreement as to the nature of emotion extends to the problem of delimitation of the psychological states or processes to be studied under this label from other affective phenomena. The author first reviews the elements of the definition of emotion that seem to show at least some degree of convergence among different theorists. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
  isbn = {978-0-19-511464-5},
  keywords = {Emotional Abuse,Models,Psychology,Theories},
  file = {/Users/timokoch/Zotero/storage/4NSP3UF6/Scherer - 2000 - Psychological models of emotion.pdf;/Users/timokoch/Zotero/storage/7DPYNC3E/2000-08487-005.html}
}

@article{schererPsychologicalModelsEmotion2000a,
  title = {Psychological Models of Emotion},
  author = {Scherer, Klaus R.},
  year = {2000},
  journal = {The neuropsychology of emotion},
  volume = {137},
  number = {3},
  pages = {137--162},
  file = {/Users/timokoch/Zotero/storage/JSJQBLRT/books.html}
}

@article{schererVocalAffectExpression1986,
  title = {Vocal Affect Expression: {{A}} Review and a Model for Future Research},
  shorttitle = {Vocal Affect Expression},
  author = {Scherer, Klaus R.},
  year = {1986},
  journal = {Psychological Bulletin},
  volume = {99},
  number = {2},
  pages = {143--165},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1455},
  doi = {10.1037/0033-2909.99.2.143},
  abstract = {Contends that in the literature on the vocal expression of emotion, there is a discrepancy between reported high accuracy in vocal-auditory recognition and a lack of evidence for the acoustic differentiation of vocal expression. The latter is explained by (a) a paucity of research on voice quality, (b) neglect of the social signaling functions of affect vocalization, and (c) insufficiently precise conceptualization of the underlying emotional states. A component-patterning model of vocal affect expression is proposed that attempts to link the outcomes of antecedent event evaluation to biologically based response patterns. The likely phonatory and articulatory correlates of the physiological responses characterizing different emotional states are described in the form of 3 major voice types (narrow/wide, lax/tense, full/thin). Specific predictions about changes in acoustic parameters resulting from changing voice types are compared with the pattern of empirical findings yielded by a comprehensive survey of the literature on vocal cues in emotional expression. Although the comparison is largely limited to the lax/tense voice type (because acoustic parameters relevant to the other voice types have not yet been systematically studied), a high degree of convergence is revealed. (120 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Emotional States,Experimentation,Literature Review,Oral Communication,Voice},
  file = {/Users/timokoch/Zotero/storage/X7SCJ9RV/Scherer - Vocal Affect Expression A Review and a Model for .pdf;/Users/timokoch/Zotero/storage/GE9EAMTD/1986-16849-001.html}
}

@article{schererVocalCommunicationEmotion2003,
  title = {Vocal Communication of Emotion: {{A}} Review of Research Paradigms},
  shorttitle = {Vocal Communication of Emotion},
  author = {Scherer, Klaus R.},
  year = {2003},
  month = apr,
  journal = {Speech Communication},
  volume = {40},
  number = {1-2},
  pages = {227--256},
  issn = {01676393},
  doi = {10.1016/S0167-6393(02)00084-5},
  urldate = {2021-11-10},
  abstract = {The current state of research on emotion effects on voice and speech is reviewed and issues for future research efforts are discussed. In particular, it is suggested to use the Brunswikian lens model as a base for research on the vocal communication of emotion. This approach allows one to model the complete process, including both encoding (expression), transmission, and decoding (impression) of vocal emotion communication. Special emphasis is placed on the conceptualization and operationalization of the major elements of the model (i.e., the speaker{\~O}s emotional state, the listener{\~O}s attribution, and the mediating acoustic cues). In addition, the advantages and disadvantages of research paradigms for the induction or observation of emotional expression in voice and speech and the experimental manipulation of vocal cues are discussed, using pertinent examples drawn from past and present research.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/FMM8B5WW/Scherer - 2003 - Vocal communication of emotion A review of resear.pdf}
}

@article{schererWhatAreEmotions2005,
  title = {What Are Emotions? {{And}} How Can They Be Measured?},
  shorttitle = {What Are Emotions?},
  author = {Scherer, Klaus R.},
  year = {2005},
  month = dec,
  journal = {Social Science Information},
  volume = {44},
  number = {4},
  pages = {695--729},
  issn = {0539-0184, 1461-7412},
  doi = {10.1177/0539018405058216},
  urldate = {2022-11-10},
  abstract = {Defining ``emotion'' is a notorious problem. Without consensual conceptualization and operationalization of exactly what phenomenon is to be studied, progress in theory and research is difficult to achieve and fruitless debates are likely to proliferate. A particularly unfortunate example is William James's asking the question ``What is an emotion?'' when he really meant ``feeling'', a misnomer that started a debate which is still ongoing, more than a century later. This contribution attempts to sensitize researchers in the social and behavioral sciences to the importance of definitional issues and their consequences for distinguishing related but fundamentally different affective processes, states, and traits. Links between scientific and folk concepts of emotion are explored and ways to measure emotion and its components are discussed.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/WJ4BVX33/Scherer - 2005 - What are emotions And how can they be measured.pdf}
}

@article{schimmackAffectMeasurementExperience2003,
  title = {Affect {{Measurement}} in {{Experience Sampling Research}}},
  author = {Schimmack, Ulrich},
  year = {2003},
  journal = {Journal of Happiness Studies},
  volume = {4},
  number = {1},
  pages = {79--106},
  issn = {1389-4978},
  doi = {10.1023/A:1023661322862},
  urldate = {2022-12-16},
  abstract = {Experience-sampling studies are used to study the emotional component of subjective well-being (hedonic balance). This manuscript examines conceptual and methodological issues in the measurement of hedonic balance, and it relates aspects of affective experiences (frequency, intensity, and duration) to affective dispositions (extraversion, neuroticism) and life-satisfaction. Aggregates of experiencesampling data are influenced by response styles, but the effect is negligible. Pleasant affects and unpleasant affects show high discriminant validity. Extraversion is more highly related to aspects of pleasant affects than unpleasant affects, and neuroticism is more highly related to aspects of unpleasant affects than pleasant affects. Mean levels (i.e., frequency * intensity) of affects are the aspects that best predict life-satisfaction. The specific item happiness is a better predictor of life-satisfaction than the average of all pleasant affects.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/GVPA6BGK/Schimmack - 2003 - Affect Measurement in Experience Sampling Research.pdf}
}

@inproceedings{schlerEffectsAgeGender2006,
  title = {Effects of Age and Gender on Blogging.},
  booktitle = {{{AAAI}} Spring Symposium: {{Computational}} Approaches to Analyzing Weblogs},
  author = {Schler, Jonathan and Koppel, Moshe and Argamon, Shlomo and Pennebaker, James W.},
  year = {2006},
  volume = {6},
  pages = {199--205},
  file = {/Users/timokoch/Zotero/storage/5PJU8UKN/Schler et al. - 2006 - Effects of Age and Gender on Blogging..pdf}
}

@article{schmidtPersonalityInformationBehavior2016,
  title = {Personality and Information Behavior in Web Search: {{Personality}} and {{Information Behavior}} in {{Web Search}}},
  shorttitle = {Personality and Information Behavior in Web Search},
  author = {Schmidt, Thomas and Wolff, Christian},
  year = {2016},
  journal = {Proceedings of the Association for Information Science and Technology},
  volume = {53},
  number = {1},
  pages = {1--6},
  issn = {23739231},
  doi = {10.1002/pra2.2016.14505301121},
  urldate = {2019-05-28},
  abstract = {In this paper, we describe a quantitative study of personality aspects and their relationship with web search information behavior. We start with introducing personality and give an overview of information behavior research concerning personality aspects. In our study of 30 participants, their personality traits were operationalized by using a version of the Big 5, the B5T, a psychometric questionnaire that maps personality on different dimensions. The participants performed search tasks in a web context and data concerning their information behavior was collected via search logs as well as questionnaires. We show that there are selective correlations of slight and intermediate strength between the variables of information behavior and the personality dimensions. Finally, we discuss possible explanations and implications as well as new impulses for information behavior and retrieval research.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/QJYU4RHZ/Schmidt und Wolff - 2016 - personality and information behavior in web search.pdf}
}

@incollection{schmittStateTraitInteractions2017,
  title = {State/{{Trait Interactions}}},
  booktitle = {Encyclopedia of {{Personality}} and {{Individual Differences}}},
  author = {Schmitt, Manfred and Blum, Gabriela S.},
  editor = {{Zeigler-Hill}, Virgil and Shackelford, Todd K.},
  year = {2017},
  pages = {1--4},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-28099-8_1922-1},
  urldate = {2019-03-18},
  isbn = {978-3-319-28099-8},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/79G7KIYY/Schmitt und Blum - 2017 - StateTrait Interactions.pdf}
}

@article{schoedelBasicProtocolSmartphone2020,
  title = {Basic {{Protocol}}: {{Smartphone Sensing Panel Study}}},
  shorttitle = {Basic {{Protocol}}},
  author = {Schoedel, Ramona and Oldemeier, Michelle},
  year = {2020},
  month = may,
  urldate = {2022-05-10},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/UMTUT88K/672ab24a-ec1c-4f60-8712-4e022a1fa8ec.html}
}

@article{schoedelBasicProtocolSmartphone2020a,
  title = {Basic {{Protocol}}: {{Smartphone Sensing Panel Study}}},
  shorttitle = {Basic {{Protocol}}},
  author = {Schoedel, Ramona and Oldemeier, Michelle},
  year = {2020},
  month = may,
  doi = {10.23668/psycharchives.2901},
  urldate = {2020-12-03},
  abstract = {The study Smartphone Sensing Panel Study aims to create a benchmark dataset for the scientific community, including three data collection modalities: (1) smartphone sensing (2) experience sampling, and (3) monthly online surveys. The study is a panel study lasting for three to six months and resulting in high-dimensional and longitudinal behavioral and situational sensing data, self-report data in situ, and traditional questionnaire data about a broad range of psychological traits and phenomena. A quota sample of N = 800 participants is recruited and asked to install the research app PhoneStudy for three to six months. During the period of study participation, sensing data is continuously logged. Sensing data collection is complemented by monthly online surveys and experience sampling periods},
  copyright = {CC-BY-SA 4.0},
  langid = {english},
  annotation = {Accepted: 2020-05-14T20:07:45Z},
  file = {/Users/timokoch/Zotero/storage/W5WBBIZB/Schoedel und Oldemeier - 2020 - Basic Protocol Smartphone Sensing Panel Study.pdf;/Users/timokoch/Zotero/storage/7KW4QPTL/2522.html}
}

@article{schoedelDigitalFootprintsSensation2019,
  title = {Digital {{Footprints}} of {{Sensation Seeking}}},
  author = {Schoedel, Ramona and Au, Quay and V{\"o}lkel, Sarah Theres and Lehmann, Florian and Becker, Daniela and B{\"u}hner, Markus and Bischl, Bernd and Hussmann, Heinrich and Stachl, Clemens},
  year = {2019},
  month = feb,
  journal = {Zeitschrift f{\"u}r Psychologie},
  issn = {10.1027/2151-2604/a000342},
  urldate = {2019-02-26},
  abstract = {Abstract. The increasing usage of new technologies implies changes for personality research. First, human behavior becomes measurable by digital data, and second, digital manifestations to some extent replace conventional behavior in the analog world. This offers the opportunity to investigate personality traits by means of digital footprints. In this context, the investigation of the personality trait sensation seeking attracted our attention as objective behavioral correlates have been missing so far. By collecting behavioral markers (e.g., communication or app usage) via Android smartphones, we examined whether self-reported sensation seeking scores can be reliably predicted. Overall, 260 subjects participated in our 30-day real-life data logging study. Using a machine learning approach, we evaluated cross-validated model fit based on how accurate sensation seeking scores can be predicted in unseen samples. Our findings highlight the potential of mobile sensing techniques in personality research and sh...},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/YNMVSX8J/a000342.html}
}

@misc{schoedelSnapshotsDailyLife2022,
  title = {Snapshots of {{Daily Life}}: {{Situations Investigated Through}} the {{Lens}} of {{Smartphone Sensing}}},
  shorttitle = {Snapshots of {{Daily Life}}},
  author = {Schoedel, Ramona and Kunz, Fiona and Bergmann, Maximilian and Bemmann, Florian and B{\"u}hner, Markus and Sust, Larissa},
  year = {2022},
  month = aug,
  publisher = {{PsyArXiv}},
  doi = {10.31234/osf.io/f3htz},
  urldate = {2023-01-14},
  abstract = {Daily life unfolds in a sequence of situational contexts, which are pivotal for explaining people's thoughts, feelings, and behaviors. While situational data were previously difficult to collect, the ubiquity of smartphones now opens up new opportunities for assessing situations in situ, that is, while they occur. Seizing this development, the present study demonstrates how smartphones can help establish associations between the psychological perception and the physical reality of situations. We employed an intensive longitudinal sampling design and investigated 9,790 situational snapshots experienced by 455 participants for 14 consecutive days. These snapshots combined self-reported situation characteristics from experience samplings with their corresponding objective situation cues obtained via smartphone sensing. To account for the complexity of real-world situations, we extracted a total of 1,356 granular situation cues from different sensing modalities. We applied linear and nonlinear machine learning algorithms to examine how well these cues predicted the perceived characteristics in terms of the Situational Eight DIAMONDS, finding significant out-of-sample predictions for the five dimensions capturing the situations' Duty, Intellect, Mating, pOsitivity, and Sociality. Analyses of (grouped) feature importance revealed that these predictions relied on complex constellations of cues representing various situational information about the Persons/Interactions and Objects present, the Events/Activities happening, and the current Location and Time. Furthermore, a nomological network analysis provided evidence for the construct validity of our cue-based DIAMONDS predictions. We conclude by discussing how smartphone-based situational snapshots, in general, and our prediction models, in particular, advance psychological research on situations.},
  langid = {american},
  keywords = {mobile sensing,Personality and Situations,psychological situation,situation characteristics,situation cues,situation perception,Situational Eight DIAMONDS,smartphone sensing,Social and Behavioral Sciences,Social and Personality Psychology},
  file = {/Users/timokoch/Zotero/storage/ZTA69JWR/Schoedel et al. - 2022 - Snapshots of Daily Life Situations Investigated T.pdf}
}

@article{schonbrodtDataManagementPsychological2017,
  title = {Data Management in Psychological Science: {{Specification}} of the {{DFG}} Guidelines},
  author = {Sch{\"o}nbrodt, Felix and Gollwitzer, Mario and {Abele-Brehm}, Andrea},
  year = {2017},
  publisher = {{PsyArXiv}}
}

@article{schroderResponsiveSensitiveArtificial2008,
  title = {{Towards responsive Sensitive Artificial Listeners}},
  author = {Schr{\"o}der, Marc and Cowie, Roddy and Heylen, Dirk K. J. and Pantic, Maja and Pelachaud, Catherine and Schuller, Bj{\"o}rn},
  year = {2008},
  month = oct,
  journal = {Proceedings of the Fourth International Workshop on Human-Computer Conversation},
  urldate = {2019-02-12},
  langid = {Undefined},
  file = {/Users/timokoch/Zotero/storage/9VW2V4AF/Schröder et al. - 2008 - Towards responsive Sensitive Artificial Listeners.pdf;/Users/timokoch/Zotero/storage/AFZFX8ZF/towards-responsive-sensitive-artificial-listeners.html}
}

@article{schroederHumanizingVoiceSpeech2017,
  title = {The {{Humanizing Voice}}: {{Speech Reveals}}, and {{Text Conceals}}, a {{More Thoughtful Mind}} in the {{Midst}} of {{Disagreement}}},
  shorttitle = {The {{Humanizing Voice}}},
  author = {Schroeder, Juliana and Kardas, Michael and Epley, Nicholas},
  year = {2017},
  month = dec,
  journal = {Psychological Science},
  volume = {28},
  number = {12},
  pages = {1745--1762},
  issn = {0956-7976, 1467-9280},
  doi = {10.1177/0956797617713798},
  urldate = {2021-11-03},
  abstract = {A person's speech communicates his or her thoughts and feelings. We predicted that beyond conveying the contents of a person's mind, a person's speech also conveys mental capacity, such that hearing a person explain his or her beliefs makes the person seem more mentally capable{\textemdash}and therefore seem to possess more uniquely human mental traits{\textemdash}than reading the same content. We expected this effect to emerge when people are perceived as relatively mindless, such as when they disagree with the evaluator's own beliefs. Three experiments involving polarizing attitudinal issues and political opinions supported these hypotheses. A fourth experiment identified paralinguistic cues in the human voice that convey basic mental capacities. These results suggest that the medium through which people communicate may systematically influence the impressions they form of each other. The tendency to denigrate the minds of the opposition may be tempered by giving them, quite literally, a voice.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/HXDYBVNX/Schroeder et al. - 2017 - The Humanizing Voice Speech Reveals, and Text Con.pdf}
}

@article{schullerBeingBoredRecognising2009,
  title = {Being Bored? {{Recognising}} Natural Interest by Extensive Audiovisual Integration for Real-Life Application},
  shorttitle = {Being Bored?},
  author = {Schuller, Bj{\"o}rn and M{\"u}ller, Ronald and Eyben, Florian and Gast, J{\"u}rgen and H{\"o}rnler, Benedikt and W{\"o}llmer, Martin and Rigoll, Gerhard and H{\"o}thker, Anja and Konosu, Hitoshi},
  year = {2009},
  month = nov,
  journal = {Image and Vision Computing},
  volume = {27},
  number = {12},
  pages = {1760--1774},
  issn = {02628856},
  doi = {10.1016/j.imavis.2009.02.013},
  urldate = {2018-12-09},
  abstract = {Automatic detection of the level of human interest is of high relevance for many technical applications, such as automatic customer care or tutoring systems. However, the recognition of spontaneous interest in natural conversations independently of the subject remains a challenge. Identification of human affective states relying on single modalities only is often impossible, even for humans, since different modalities contain partially disjunctive cues. Multimodal approaches to human affect recognition generally are shown to boost recognition performance, yet are evaluated in restrictive laboratory settings only. Herein we introduce a fully automatic processing combination of Active-Appearance-Model-based facial expression, vision-based eyeactivity estimation, acoustic features, linguistic analysis, non-linguistic vocalisations, and temporal context information in an early feature fusion process. We provide detailed subject-independent results for classification and regression of the Level of Interest using Support-Vector Machines on an audiovisual interest corpus (AV IC) consisting of spontaneous, conversational speech demonstrating ``theoretical'' effectiveness of the approach. Further, to evaluate the approach with regards to real-life usability a user-study is conducted for proof of ``practical'' effectiveness.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/LQC2C89L/Schuller et al. - 2009 - Being bored Recognising natural interest by exten.pdf}
}

@inproceedings{schullerCombiningSpeechRecognition2008,
  title = {Combining Speech Recognition and Acoustic Word Emotion Models for Robust Text-Independent Emotion Recognition},
  booktitle = {2008 {{IEEE International Conference}} on {{Multimedia}} and {{Expo}}},
  author = {Schuller, Bjorn and Vlasenko, Bogdan and Arsic, Dejan and Rigoll, Gerhard and Wendemuth, Andreas},
  year = {2008},
  month = jun,
  pages = {1333--1336},
  publisher = {{IEEE}},
  address = {{Hannover, Germany}},
  doi = {10.1109/ICME.2008.4607689},
  urldate = {2021-11-28},
  abstract = {Recognition of emotion in speech usually uses acoustic models that ignore the spoken content. Likewise one general model per emotion is trained independent of the phonetic structure. Given sufficient data, this approach seemingly works well enough. Yet, this paper tries to answer the question whether acoustic emotion recognition strongly depends on phonetic content, and if models tailored for the spoken unit can lead to higher accuracies. We therefore investigate phoneme-, and word-models by use of a large prosodic, spectral, and voice quality feature space and Support Vector Machines (SVM). Experiments also take the necessity of ASR into account to select appropriate unitmodels. Test-runs on the well-known EMO-DB database facing speaker-independence demonstrate superiority of word emotion models over today's common general models provided sufficient occurrences in the training corpus.},
  isbn = {978-1-4244-2570-9},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/8UU9Z9LN/Schuller et al. - 2008 - Combining speech recognition and acoustic word emo.pdf}
}

@article{schullerCrossCorpusAcousticEmotion2010,
  title = {Cross-{{Corpus Acoustic Emotion Recognition}}: {{Variances}} and {{Strategies}}},
  shorttitle = {Cross-{{Corpus Acoustic Emotion Recognition}}},
  author = {Schuller, Bj{\"o}rn and Vlasenko, Bogdan and Eyben, Florian and Wollmer, Martin and Stuhlsatz, Andre and Wendemuth, Andreas and Rigoll, Gerhard},
  year = {2010},
  journal = {IEEE Transactions on Affective Computing},
  volume = {1},
  number = {2},
  pages = {119--131},
  issn = {1949-3045},
  doi = {10.1109/T-AFFC.2010.8},
  urldate = {2019-02-10},
  abstract = {As the recognition of emotion from speech has matured to a degree where it becomes applicable in real-life settings, it is time for a realistic view on obtainable performances. Most studies tend to overestimation in this respect: acted data is often used rather than spontaneous data, results are reported on pre-selected prototypical data, and true speaker disjunctive partitioning is still less common than simple cross-validation. Even speaker disjunctive evaluation can give only little insight into the generalization ability of today's emotion recognition engines since training and test data used for system development usually tend to be similar as far as recording conditions, noise overlay, language, and types of emotions are concerned. A considerably more realistic impression can be gathered by inter-set evaluation: we therefore show results employing six standard databases in a cross-corpora evaluation experiment which could also be helpful to learn about chances to add resources for training and overcome the typical sparseness in the field. To better cope with the observed high variances, different types of normalization are investigated. 1.8 k individual evaluations in total indicate the crucial performance inferiority of inter- to intra-corpus testing.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/3ZIMY2U9/Schuller et al. - 2010 - Cross-Corpus Acoustic Emotion Recognition Varianc.pdf}
}

@article{schullerINTERSPEECH2010Paralinguistic,
  title = {The {{INTERSPEECH}} 2010 {{Paralinguistic Challenge}}},
  author = {Schuller, Bj{\"o}rn and Steidl, Stefan and Batliner, Anton and Burkhardt, Felix and Devillers, Laurence and Muller, Christian and Narayanan, Shrikanth S},
  pages = {4},
  abstract = {Most paralinguistic analysis tasks are lacking agreed-upon evaluation procedures and comparability, in contrast to more `traditional' disciplines in speech analysis. The INTERSPEECH 2010 Paralinguistic Challenge shall help overcome the usually low compatibility of results, by addressing three selected subchallenges. In the Age Sub-Challenge, the age of speakers has to be determined in four groups. In the Gender Sub-Challenge, a three-class classification task has to be solved and finally, the Affect Sub-Challenge asks for speakers' interest in ordinal representation. This paper introduces the conditions, the Challenge corpora ``aGender'' and ``TUM AVIC'' and standard feature sets that may be used. Further, baseline results are given.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/CAZUIA2H/Schuller et al. - The INTERSPEECH 2010 Paralinguistic Challenge.pdf}
}

@inproceedings{schullerInterspeech2011Speaker2011,
  title = {The Interspeech 2011 Speaker State Challenge},
  booktitle = {In {{Interspeech}}},
  author = {Schuller, Bj{\"o}rn and Steidl, Stefan and Batliner, Anton and Schiel, Florian and Krajewski, Jarek},
  year = {2011},
  abstract = {While the first open comparative challenges in the field of paralinguistics targeted more `conventional ' phenomena such as emotion, age, and gender, there still exists a multiplicity of not yet covered, but highly relevant speaker states and traits. The INTERSPEECH 2011 Speaker State Challenge thus addresses two new sub-challenges to overcome the usually low compatibility of results: In the Intoxication Sub-Challenge, alcoholisation of speakers has to be determined in two classes; in the Sleepiness Sub-Challenge, another two-class classification task has to be solved. This paper introduces the conditions, the Challenge corpora ``Alcohol Language Corpus '' and ``Sleepy Language Corpus'', and a standard feature set that may be used. Further, baseline results are given.},
  file = {/Users/timokoch/Zotero/storage/IVP9N4KY/Schuller et al. - 2011 - The interspeech 2011 speaker state challenge.pdf;/Users/timokoch/Zotero/storage/N3P55ILX/summary.html}
}

@article{schullerINTERSPEECH2012Speaker,
  title = {The {{INTERSPEECH}} 2012 {{Speaker Trait Challenge}}},
  author = {Schuller, Bj{\"o}rn and Steidl, Stefan and Batliner, Anton and Noth, Elmar and Vinciarelli, Alessandro and Burkhardt, Felix and {van Son}, Rob and Weninger, Felix and Eyben, Florian and Bocklet, Tobias and Mohammadi, Gelareh and Weiss, Benjamin},
  pages = {4},
  abstract = {The INTERSPEECH 2012 Speaker Trait Challenge provides for the first time a unified test-bed for `perceived' speaker traits: Personality in the five OCEAN personality dimensions, likability of speakers, and intelligibility of pathologic speakers. In this paper, we describe these three Sub-Challenges, Challenge conditions, baselines, and a new feature set by the openSMILE toolkit, provided to the participants.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/QM9TI5GU/Schuller et al. - The INTERSPEECH 2012 Speaker Trait Challenge.pdf}
}

@inproceedings{schullerInterspeech2012Speaker2012,
  title = {The Interspeech 2012 Speaker Trait Challenge},
  booktitle = {In {{Proc}}. {{Interspeech}} 2012},
  author = {Schuller, Bj{\"o}rn and Steidl, Stefan and Batliner, Anton and N{\"o}th, Elmar and Vinciarelli, Ro and Burkhardt, Felix and Son, Rob Van and Weninger, Felix and Eyben, Florian and Bocklet, Tobias and Mohammadi, Gelareh and Weiss, Benjamin},
  year = {2012},
  abstract = {The INTERSPEECH 2012 Speaker Trait Challenge provides for the first time a unified test-bed for `perceived ' speaker traits: Personality in the five OCEAN personality dimensions, likability of speakers, and intelligibility of pathologic speakers. In this paper, we describe these three Sub-Challenges, Challenge conditions, baselines, and a new feature set by the openSMILE toolkit, provided to the participants.},
  file = {/Users/timokoch/Zotero/storage/M4UQ79AM/Schuller et al. - 2012 - The interspeech 2012 speaker trait challenge.pdf;/Users/timokoch/Zotero/storage/FXETYZZQ/summary.html}
}

@book{schullerINTERSPEECH2016Computational2016,
  title = {The {{INTERSPEECH}} 2016 {{Computational Paralinguistics Challenge}}: {{Deception}}, {{Sincerity}} and {{Native Language}}},
  shorttitle = {The {{INTERSPEECH}} 2016 {{Computational Paralinguistics Challenge}}},
  author = {Schuller, Bj{\"o}rn and Steidl, Stefan and Batliner, Anton and Hirschberg, Julia and Burgoon, Judee and Baird, Alice and Elkins, Aaron and Zhang, Yue and Coutinho, Eduardo and Evanini, Keelan},
  year = {2016},
  month = sep,
  pages = {2005},
  doi = {10.21437/Interspeech.2016-129},
  file = {/Users/timokoch/Zotero/storage/KCYZSH2J/Schuller et al. - 2016 - The INTERSPEECH 2016 Computational Paralinguistics.pdf}
}

@inproceedings{schullerINTERSPEECH2018Computational2018,
  title = {The {{INTERSPEECH}} 2018 {{Computational Paralinguistics Challenge}}: {{Atypical}} and {{Self-Assessed Affect}}, {{Crying}} and {{Heart Beats}}},
  shorttitle = {The {{INTERSPEECH}} 2018 {{Computational Paralinguistics Challenge}}},
  booktitle = {Interspeech 2018},
  author = {Schuller, Bj{\"o}rn and Steidl, Stefan and Batliner, Anton and Marschik, Peter B. and Baumeister, Harald and Dong, Fengquan and Hantke, Simone and Pokorny, Florian B. and Rathner, Eva-Maria and {Bartl-Pokorny}, Katrin D. and Einspieler, Christa and Zhang, Dajie and Baird, Alice and Amiriparian, Shahin and Qian, Kun and Ren, Zhao and Schmitt, Maximilian and Tzirakis, Panagiotis and Zafeiriou, Stefanos},
  year = {2018},
  month = sep,
  pages = {122--126},
  publisher = {{ISCA}},
  doi = {10.21437/Interspeech.2018-51},
  urldate = {2019-02-13},
  abstract = {The INTERSPEECH 2018 Computational Paralinguistics Challenge addresses four different problems for the first time in a research competition under well-defined conditions: In the Atypical Affect Sub-Challenge, four basic emotions annotated in the speech of handicapped subjects have to be classified; in the Self-Assessed Affect Sub-Challenge, valence scores given by the speakers themselves are used for a three-class classification problem; in the Crying Sub-Challenge, three types of infant vocalisations have to be told apart; and in the Heart Beats Sub-Challenge, three different types of heart beats have to be determined. We describe the Sub-Challenges, their conditions, and baseline feature extraction and classifiers, which include data-learnt (supervised) feature representations by end-to-end learning, the `usual' ComParE and BoAW features, and deep unsupervised representation learning using the AUDEEP toolkit for the first time in the challenge series.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/CSJTHV3T/Schuller et al. - 2018 - The INTERSPEECH 2018 Computational Paralinguistics.pdf}
}

@article{schullerRecognisingRealisticEmotions2011,
  title = {Recognising Realistic Emotions and Affect in Speech: {{State}} of the Art and Lessons Learnt from the First Challenge},
  shorttitle = {Recognising Realistic Emotions and Affect in Speech},
  author = {Schuller, Bj{\"o}rn and Batliner, Anton and Steidl, Stefan and Seppi, Dino},
  year = {2011},
  month = nov,
  journal = {Speech Communication},
  series = {Sensing {{Emotion}} and {{Affect}} - {{Facing Realism}} in {{Speech Processing}}},
  volume = {53},
  number = {9},
  pages = {1062--1087},
  issn = {0167-6393},
  doi = {10.1016/j.specom.2011.01.011},
  urldate = {2021-09-17},
  abstract = {More than a decade has passed since research on automatic recognition of emotion from speech has become a new field of research in line with its `big brothers' speech and speaker recognition. This article attempts to provide a short overview on where we are today, how we got there and what this can reveal us on where to go next and how we could arrive there. In a first part, we address the basic phenomenon reflecting the last fifteen years, commenting on databases, modelling and annotation, the unit of analysis and prototypicality. We then shift to automatic processing including discussions on features, classification, robustness, evaluation, and implementation and system integration. From there we go to the first comparative challenge on emotion recognition from speech {\textendash} the INTERSPEECH 2009 Emotion Challenge, organised by (part of) the authors, including the description of the Challenge's database, Sub-Challenges, participants and their approaches, the winners, and the fusion of results to the actual learnt lessons before we finally address the ever-lasting problems and future promising attempts.},
  langid = {english},
  keywords = {Adaptation,Affect,Automatic classification,Emotion,Evaluation,Feature selection,Feature types,Noise robustness,Standardisation,Usability},
  file = {/Users/timokoch/Zotero/storage/QBQSI2TW/Schuller et al. - 2011 - Recognising realistic emotions and affect in speec.pdf;/Users/timokoch/Zotero/storage/BPNQL73V/S0167639311000185.html}
}

@article{schullerSpeechEmotionRecognition2018,
  title = {Speech Emotion Recognition: Two Decades in a Nutshell, Benchmarks, and Ongoing Trends},
  shorttitle = {Speech Emotion Recognition},
  author = {Schuller, Bj{\"o}rn},
  year = {2018},
  month = apr,
  journal = {Communications of the ACM},
  volume = {61},
  number = {5},
  pages = {90--99},
  issn = {00010782},
  doi = {10.1145/3129340},
  urldate = {2018-12-09},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/YJKGZDKD/Schuller - 2018 - Speech emotion recognition two decades in a nutsh.pdf}
}

@incollection{schullerVoiceSpeechAnalysis2011,
  title = {Voice and {{Speech Analysis}} in {{Search}} of {{States}} and {{Traits}}},
  booktitle = {Computer {{Analysis}} of {{Human Behavior}}},
  author = {Schuller, Bj{\"o}rn},
  editor = {Salah, Albert Ali and Gevers, Theo},
  year = {2011},
  pages = {227--253},
  publisher = {{Springer London}},
  address = {{London}},
  doi = {10.1007/978-0-85729-994-9_9},
  urldate = {2018-12-07},
  isbn = {978-0-85729-993-2 978-0-85729-994-9},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/5MDADVE4/Schuller - 2011 - Voice and Speech Analysis in Search of States and .pdf}
}

@article{schuwerkEnterWildAutistic2018,
  title = {Enter the {{Wild}}: {{Autistic Traits}} and {{Their Relationship}} to {{Mentalizing}} and {{Social Interaction}} in {{Everyday Life}}},
  shorttitle = {Enter the {{Wild}}},
  author = {Schuwerk, Tobias and Kaltefleiter, Larissa and Au, Quay and H{\"o}sl, Axel and Stachl, Clemens},
  year = {2018},
  doi = {10.31234/osf.io/rxatn},
  urldate = {2019-02-28},
  abstract = {Theories derived from lab-based research emphasize the importance of mentalizing for social interaction and propose a link between mentalizing, autistic traits, and social behavior. We took social cognitive research outside the lab to test these assumptions in everyday life. Via smartphone-based experience sampling and logging of smartphone usage behavior we quantified mentalizing and social interaction in our participants' natural environment. Both measures were compared with autistic traits, controlling for Big Five personality dimensions, social anxiety, and verbal intelligence. Mentalizing occurred less frequently than reasoning about actions and participants preferred to mentalize when alone. Autistic traits were negatively correlated with communication via smartphone. Yet, they were not associated with social media usage, a more indirect way of getting in touch with others. We further found no relation between autistic traits and social network size. These findings critically inform recent theories on social cognition and behavior in individuals with and without autism.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/LLESBLUR/Schuwerk et al. - Enter the Wild Autistic Traits and Their Relation.pdf}
}

@article{schwartzCharacterizingGeographicVariation,
  title = {Characterizing {{Geographic Variation}} in {{Well-Being Using Tweets}}},
  author = {Schwartz, H Andrew and Eichstaedt, Johannes C and Kern, Margaret L and Dziurzynski, Lukasz and Lucas, Richard E and Agrawal, Megha and Park, Gregory J and Lakshmikanth, Shrinidhi K and Jha, Sneha and Seligman, Martin E P and Ungar, Lyle},
  pages = {9},
  abstract = {The language used in tweets from 1,300 different US counties was found to be predictive of the subjective well-being of people living in those counties as measured by representative surveys. Topics, sets of cooccurring words derived from the tweets using LDA, improved accuracy in predicting life satisfaction over and above standard demographic and socio-economic controls (age, gender, ethnicity, income, and education). The LDA topics provide a greater behavioural and conceptual resolution into life satisfaction than the broad socio-economic and demographic variables. For example, tied in with the psychological literature, words relating to outdoor activities, spiritual meaning, exercise, and good jobs correlate with increased life satisfaction, while words signifying disengagement like 'bored' and 'tired' show a negative association.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/XHM89T7F/Schwartz et al. - Characterizing Geographic Variation in Well-Being .pdf}
}

@article{schwartzCharacterizingGeographicVariation2013,
  title = {Characterizing {{Geographic Variation}} in {{Well-Being}} Using {{Tweets}}},
  author = {Schwartz, H. A. and Eichstaedt, Johannes C. and Kern, Margaret L and Dziurzynski, Lukasz and Lucas, Richard E and Agrawal, Megha and Park, Gregory J and Lakshmikanth, Shrinidhi K and Jha, Sneha and Seligman, Martin E P and Ungar, Lyle},
  year = {2013},
  pages = {9},
  abstract = {The language used in tweets from 1,300 different US counties was found to be predictive of the subjective well-being of people living in those counties as measured by representative surveys. Topics, sets of cooccurring words derived from the tweets using LDA, improved accuracy in predicting life satisfaction over and above standard demographic and socio-economic controls (age, gender, ethnicity, income, and education). The LDA topics provide a greater behavioural and conceptual resolution into life satisfaction than the broad socio-economic and demographic variables. For example, tied in with the psychological literature, words relating to outdoor activities, spiritual meaning, exercise, and good jobs correlate with increased life satisfaction, while words signifying disengagement like 'bored' and 'tired' show a negative association.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/I57LKQBW/Schwartz et al. - Characterizing Geographic Variation in Well-Being .pdf}
}

@inproceedings{schwartzChoosingRightWords2013,
  title = {Choosing the {{Right Words}}: {{Characterizing}} and {{Reducing Error}} of the {{Word Count Approach}}},
  shorttitle = {Choosing the {{Right Words}}},
  booktitle = {Second {{Joint Conference}} on {{Lexical}} and {{Computational Semantics}} (*{{SEM}}), {{Volume}} 1: {{Proceedings}} of the {{Main Conference}} and the {{Shared Task}}: {{Semantic Textual Similarity}}},
  author = {Schwartz, H. A. and Eichstaedt, Johannes C. and Blanco, Eduardo and Dziurzynski, Lukasz and Kern, Margaret L. and Ramones, Stephanie and Seligman, Martin and Ungar, Lyle},
  year = {2013},
  month = jun,
  pages = {296--305},
  publisher = {{Association for Computational Linguistics}},
  address = {{Atlanta, Georgia, USA}},
  urldate = {2020-05-15},
  file = {/Users/timokoch/Zotero/storage/CEPTC5S3/Schwartz et al. - 2013 - Choosing the Right Words Characterizing and Reduc.pdf}
}

@inproceedings{schwartzDLATKDifferentialLanguage2017,
  title = {{{DLATK}}: {{Differential Language Analysis ToolKit}}},
  shorttitle = {{{DLATK}}},
  booktitle = {Proceedings of the 2017 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}: {{System Demonstrations}}},
  author = {Schwartz, H. A. and Giorgi, Salvatore and Sap, Maarten and Crutchley, Patrick and Ungar, Lyle and Eichstaedt, Johannes C.},
  year = {2017},
  pages = {55--60},
  publisher = {{Association for Computational Linguistics}},
  address = {{Copenhagen, Denmark}},
  doi = {10.18653/v1/D17-2010},
  urldate = {2020-05-04},
  abstract = {We present Differential Language Analysis Toolkit (DLATK), an open-source python package and command-line tool developed for conducting social-scientific language analyses. While DLATK provides standard NLP pipeline steps such as tokenization or SVM-classification, its novel strengths lie in analyses useful for psychological, health, and social science: (1) incorporation of extra-linguistic structured information, (2) specified levels and units of analysis (e.g. document, user, community), (3) statistical metrics for continuous outcomes, and (4) robust, proven, and accurate pipelines for social-scientific prediction problems. DLATK integrates multiple popular packages (SKLearn, Mallet), enables interactive usage (Jupyter Notebooks), and generally follows object oriented principles to make it easy to tie in additional libraries or storage technologies.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/UJKEBNHJ/Schwartz et al. - 2017 - DLATK Differential Language Analysis ToolKit.pdf}
}

@article{schwartzEmotionalSpeechProcessing2012,
  title = {Emotional {{Speech Processing}} at the {{Intersection}} of {{Prosody}} and {{Semantics}}},
  author = {Schwartz, Rachel and Pell, Marc D.},
  editor = {Stamatakis, Emmanuel Andreas},
  year = {2012},
  month = oct,
  journal = {PLoS ONE},
  volume = {7},
  number = {10},
  pages = {e47279},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0047279},
  urldate = {2021-06-30},
  abstract = {The ability to accurately perceive emotions is crucial for effective social interaction. Many questions remain regarding how different sources of emotional cues in speech (e.g., prosody, semantic information) are processed during emotional communication. Using a cross-modal emotional priming paradigm (Facial affect decision task), we compared the relative contributions of processing utterances with single-channel (prosody-only) versus multi-channel (prosody and semantic) cues on the perception of happy, sad, and angry emotional expressions. Our data show that emotional speech cues produce robust congruency effects on decisions about an emotionally related face target, although no processing advantage occurred when prime stimuli contained multi-channel as opposed to single-channel speech cues. Our data suggest that utterances with prosodic cues alone and utterances with combined prosody and semantic cues both activate knowledge that leads to emotional congruency (priming) effects, but that the convergence of these two information sources does not always heighten access to this knowledge during emotional speech processing.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/QYY83B3G/Schwartz und Pell - 2012 - Emotional Speech Processing at the Intersection of.pdf}
}

@article{schwartzPersonalityGenderAge2013,
  title = {Personality, Gender, and Age in the Language of Social Media: The Open-Vocabulary Approach},
  author = {Schwartz, H. A. and Eichstaedt, J. C. and Kern, M. L. and Dziurzynski, L. and Ramones, S. M. and Agrawal, M. and Shah, A. and Kosinski, Michal and Stillwell, D. and Seligman, M. E. and Ungar, L. H.},
  year = {2013},
  journal = {PLoS One},
  volume = {8},
  number = {9},
  pages = {e73791},
  issn = {1932-6203 (Electronic) 1932-6203 (Linking)},
  doi = {10.1371/journal.pone.0073791},
  abstract = {We analyzed 700 million words, phrases, and topic instances collected from the Facebook messages of 75,000 volunteers, who also took standard personality tests, and found striking variations in language with personality, gender, and age. In our open-vocabulary technique, the data itself drives a comprehensive exploration of language that distinguishes people, finding connections that are not captured with traditional closed-vocabulary word-category analyses. Our analyses shed new light on psychosocial processes yielding results that are face valid (e.g., subjects living in high elevations talk about the mountains), tie in with other research (e.g., neurotic people disproportionately use the phrase 'sick of' and the word 'depressed'), suggest new hypotheses (e.g., an active life implies emotional stability), and give detailed insights (males use the possessive 'my' when mentioning their 'wife' or 'girlfriend' more often than females use 'my' with 'husband' or 'boyfriend'). To date, this represents the largest study, by an order of magnitude, of language and personality.},
  pmcid = {PMC3783449},
  keywords = {*Age Factors,*Personality,*Sex Factors,*Social Media,*Vocabulary,Female,Humans,Language,Male},
  file = {/Users/timokoch/Zotero/storage/3YDIDAGB/journal.pone.0073791.PDF;/Users/timokoch/Zotero/storage/SQZAYJTM/Schwartz et al. - 2013 - Personality, gender, and age in the language of so.PDF}
}

@inproceedings{schwartzPersonalityInsightsLanguage2013,
  title = {Toward {{Personality Insights}} from {{Language Exploration}} in {{Social Media}}},
  booktitle = {{{AAAI Spring Symposium}}: {{Analyzing Microtext}}},
  author = {Schwartz, H. Andrew and Eichstaedt, Johannes C. and Dziurzynski, Lukasz and Kern, Margaret L. and Blanco, Eduardo and Kosinski, Michal and Stillwell, David and Seligman, Martin EP and Ungar, Lyle H.},
  year = {2013},
  pages = {72--79}
}

@incollection{schwarzMetacognitiveExperiencesIntricacies2007,
  title = {Metacognitive {{Experiences}} and the {{Intricacies}} of {{Setting People Straight}}: {{Implications}} for {{Debiasing}} and {{Public Information Campaigns}}},
  shorttitle = {Metacognitive {{Experiences}} and the {{Intricacies}} of {{Setting People Straight}}},
  booktitle = {Advances in {{Experimental Social Psychology}}},
  author = {Schwarz, Norbert and Sanna, Lawrence J. and Skurnik, Ian and Yoon, Carolyn},
  year = {2007},
  volume = {39},
  pages = {127--161},
  publisher = {{Elsevier}},
  doi = {10.1016/S0065-2601(06)39003-X},
  urldate = {2019-05-23},
  isbn = {978-0-12-015239-1},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/M3T7LCPU/Schwarz et al. - 2007 - Metacognitive Experiences and the Intricacies of S.pdf}
}

@article{seifertMobileDataCollection2018,
  title = {Mobile {{Data Collection}}: {{Smart}}, but {{Not}} ({{Yet}}) {{Smart Enough}}},
  shorttitle = {Mobile {{Data Collection}}},
  author = {Seifert, Alexander and Hofer, Matthias and Allemand, Mathias},
  year = {2018},
  journal = {Frontiers in Neuroscience},
  volume = {12},
  issn = {1662-453X},
  urldate = {2022-11-07},
  file = {/Users/timokoch/Zotero/storage/XZEWPVWK/Seifert et al. - 2018 - Mobile Data Collection Smart, but Not (Yet) Smart.pdf}
}

@inproceedings{servia-rodriguezMobileSensingService2017,
  title = {Mobile {{Sensing}} at the {{Service}} of {{Mental Well-being}}: A {{Large-scale Longitudinal Study}}},
  shorttitle = {Mobile {{Sensing}} at the {{Service}} of {{Mental Well-being}}},
  booktitle = {Proceedings of the 26th {{International Conference}} on {{World Wide Web}} - {{WWW}} '17},
  author = {{Servia-Rodr{\'i}guez}, Sandra and Rachuri, Kiran K. and Mascolo, Cecilia and Rentfrow, Peter J. and Lathia, Neal and Sandstrom, Gillian M.},
  year = {2017},
  pages = {103--112},
  publisher = {{ACM Press}},
  address = {{Perth, Australia}},
  doi = {10.1145/3038912.3052618},
  urldate = {2018-12-10},
  abstract = {Measuring mental well-being with mobile sensing has been an increasingly active research topic. Pervasiveness of smartphones combined with the convenience of mobile app distribution platforms (e.g., Google Play) provide a tremendous opportunity to reach out to millions of users. However, the studies at the confluence of mental health and mobile sensing have been longitudinally limited, controlled, or confined to a small number of participants. In this paper we report on what we believe is the largest longitudinal in-the-wild study of mood through smartphones. We describe an Android app to collect participants' self-reported moods and system triggered experience sampling data while passively measuring their physical activity, sociability, and mobility via their device's sensors. We report the results of a large-scale analysis of the data collected for about three years from {$\sim$} 18, 000 users.},
  isbn = {978-1-4503-4913-0},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/FZSJ797N/Servia-Rodríguez et al. - 2017 - Mobile Sensing at the Service of Mental Well-being.pdf}
}

@inproceedings{servia-rodriguezMobileSensingService2017a,
  title = {Mobile {{Sensing}} at the {{Service}} of {{Mental Well-being}}: A {{Large-scale Longitudinal Study}}},
  shorttitle = {Mobile {{Sensing}} at the {{Service}} of {{Mental Well-being}}},
  booktitle = {Proceedings of the 26th {{International Conference}} on {{World Wide Web}}},
  author = {{Servia-Rodr{\'i}guez}, Sandra and Rachuri, Kiran K. and Mascolo, Cecilia and Rentfrow, Peter J. and Lathia, Neal and Sandstrom, Gillian M.},
  year = {2017},
  month = apr,
  pages = {103--112},
  publisher = {{International World Wide Web Conferences Steering Committee}},
  address = {{Perth Australia}},
  doi = {10.1145/3038912.3052618},
  urldate = {2021-06-30},
  abstract = {Measuring mental well-being with mobile sensing has been an increasingly active research topic. Pervasiveness of smartphones combined with the convenience of mobile app distribution platforms (e.g., Google Play) provide a tremendous opportunity to reach out to millions of users. However, the studies at the confluence of mental health and mobile sensing have been longitudinally limited, controlled, or confined to a small number of participants. In this paper we report on what we believe is the largest longitudinal in-the-wild study of mood through smartphones. We describe an Android app to collect participants' self-reported moods and system triggered experience sampling data while passively measuring their physical activity, sociability, and mobility via their device's sensors. We report the results of a large-scale analysis of the data collected for about three years from {$\sim$} 18, 000 users.},
  isbn = {978-1-4503-4913-0},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/UVIY4KI5/Servia-Rodríguez et al. - 2017 - Mobile Sensing at the Service of Mental Well-being.pdf}
}

@inproceedings{shenAutomaticSpeechEmotion2011,
  title = {Automatic {{Speech Emotion Recognition}} Using {{Support Vector Machine}}},
  booktitle = {Proceedings of 2011 {{International Conference}} on {{Electronic}} \& {{Mechanical Engineering}} and {{Information Technology}}},
  author = {Shen, Peipei and Changjun, Zhou and Chen, Xiong},
  year = {2011},
  month = aug,
  volume = {2},
  pages = {621--625},
  doi = {10.1109/EMEIT.2011.6023178},
  abstract = {Automatic Speech Emotion Recognition (SER) is a current research topic in the field of Human Computer Interaction (HCI) with wide range of applications. The purpose of speech emotion recognition system is to automatically classify speaker's utterances into five emotional states such as disgust, boredom, sadness, neutral, and happiness. The speech samples are from Berlin emotional database and the features extracted from these utterances are energy, pitch, linear prediction cepstrum coefficients (LPCC), Mel Frequency cepstrum coefficients (MFCC), Linear Prediction coefficients and Mel cepstrum coefficients (LPCMCC). The Support Vector Machine (SVM) is used as a classifier to classify different emotional states. The system gives 66.02\% classification accuracy for only using energy and pitch features, 70.7\% for only using LPCMCC features, and 82.5\% for using both of them.},
  keywords = {Automatic Emotion Recognition,Cepstrum,Emotion recognition,Energy,Feature extraction,LPCC,LPCMCC,Mel frequency cepstral coefficient,MFCC,Pitch,Speech,Speech Emotion,Speech recognition,Support vector machines,SVM},
  file = {/Users/timokoch/Zotero/storage/MPGMN6DH/Shen et al. - 2011 - Automatic Speech Emotion Recognition using Support.pdf;/Users/timokoch/Zotero/storage/TJZEMJDW/6023178.html}
}

@article{shermanIndependentEffectsPersonality2015,
  title = {The Independent Effects of Personality and Situations on Real-Time Expressions of Behavior and Emotion.},
  author = {Sherman, Ryne A. and Rauthmann, John F. and Brown, Nicolas A. and Serfass, David G. and Jones, Ashley Bell},
  year = {2015},
  journal = {Journal of Personality and Social Psychology},
  volume = {109},
  number = {5},
  pages = {872--888},
  issn = {1939-1315, 0022-3514},
  doi = {10.1037/pspp0000036},
  urldate = {2018-12-05},
  abstract = {The joint influence of persons and situations on behavior has long been posited by personality and social psychological theory (Funder, 2006; Lewin, 1951). However, a lack of tools for realtime behavioral and situation assessment has left direct investigations of this sort immobilized. This study combines recent advances in situation assessment and experience sampling methodology to examine the simultaneous effects of personality traits and situation characteristics on real-time expressions of behavior and emotion in N = 210 participants. The results support an additive model such that both personality traits and situation characteristics independently predict real-time expressions of behavior and emotion. These results have implications for several prominent theoretical perspectives in personality, including both trait and cognitive theories.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/5JJ93FVP/Sherman et al. - 2015 - The independent effects of personality and situati.pdf}
}

@article{shresthaAlgorithmSupportedInduction2020,
  title = {Algorithm {{Supported Induction}} for {{Building Theory}}: {{How Can We Use Prediction Models}} to {{Theorize}}?},
  author = {Shrestha, Yash Raj and He, Vivianna Fang and Puranam, Phanish and {von Krogh}, Georg},
  year = {2020},
  journal = {Organization Science},
  pages = {14204},
  issn = {1047-7039},
  doi = {10.1287/orsc.2020.1382},
  urldate = {2020-12-16},
  abstract = {Across many fields of social science, machine learning (ML) algorithms are rapidly advancing research as tools to support traditional hypothesis testing research (e.g., through data reduction and automation of data coding or for improving matching on observable features of a phenomenon or constructing instrumental variables). In this paper, we argue that researchers are yet to recognize the value of ML techniques for theory building from data. This may be in part because of scholars' inherent distaste for predictions without explanations that ML algorithms are known to produce. However, precisely because of this property, we argue that ML techniques can be very useful in theory construction during a key step of inductive theorizing{\textemdash}pattern detection. ML can facilitate algorithm supported induction, yielding conclusions about patterns in data that are likely to be robustly replicable by other analysts and in other samples from the same population. These patterns can then be used as inputs to abductive reasoning for building or developing theories that explain them. We propose that algorithm-supported induction is valuable for researchers interested in using quantitative data to both develop and test theories in a transparent and reproducible manner, and we illustrate our arguments using simulations.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/JBENXLKF/Shrestha et al. - 2020 - Algorithm Supported Induction for Building Theory.pdf}
}

@article{shresthaAlgorithmSupportedInduction2021,
  title = {Algorithm {{Supported Induction}} for {{Building Theory}}: {{How Can We Use Prediction Models}} to {{Theorize}}?},
  shorttitle = {Algorithm {{Supported Induction}} for {{Building Theory}}},
  author = {Shrestha, Yash Raj and He, Vivianna Fang and Puranam, Phanish and {von Krogh}, Georg},
  year = {2021},
  month = may,
  journal = {Organization Science},
  volume = {32},
  number = {3},
  pages = {856--880},
  issn = {1047-7039, 1526-5455},
  doi = {10.1287/orsc.2020.1382},
  urldate = {2022-11-07},
  abstract = {Across many fields of social science, machine learning (ML) algorithms are rapidly advancing research as tools to support traditional hypothesis testing research (e.g., through data reduction and automation of data coding or for improving matching on observable features of a phenomenon or constructing instrumental variables). In this paper, we argue that researchers are yet to recognize the value of ML techniques for theory building from data. This may be in part because of scholars' inherent distaste for predictions without explanations that ML algorithms are known to produce. However, precisely because of this property, we argue that ML techniques can be very useful in theory construction during a key step of inductive theorizing{\textemdash}pattern detection. ML can facilitate algorithm supported induction, yielding conclusions about patterns in data that are likely to be robustly replicable by other analysts and in other samples from the same population. These patterns can then be used as inputs to abductive reasoning for building or developing theories that explain them. We propose that algorithm-supported induction is valuable for researchers interested in using quantitative data to both develop and test theories in a transparent and reproducible manner, and we illustrate our arguments using simulations.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/D6VFBV45/Shrestha et al. - 2021 - Algorithm Supported Induction for Building Theory.pdf}
}

@incollection{siebenhaarFunktionenEmojisUnd2018,
  title = {{Funktionen von Emojis und Altersabh{\"a}ngigkeit ihres Gebrauchs in der Whatsapp-Kommunikation}},
  booktitle = {{Jugendsprachen/Youth Languages}},
  author = {Siebenhaar, Beat},
  editor = {Ziegler, Arne},
  year = {2018},
  month = may,
  pages = {749--772},
  publisher = {{De Gruyter}},
  address = {{Berlin, Boston}},
  doi = {10.1515/9783110472226-034},
  urldate = {2020-09-09},
  abstract = {The article examines whether the use of emojis varies with the age of the chatters. The phenomenological insight into two corpora, a corpus of Swiss German and German data, contains the representation, commentary and illustration function of emojis, similar to the description for the `classic' ASCII smileys. However, the expanded inventory of the iconic signs widens their use on all three levels. Due to this expansion, emojis are increasingly used with a referential function. Emojis mainly take the grammatical function of nouns or simple noun phrases, but they also appear as verbs or in emoji combinations as relatively complex propositions or as a substitute for communicative actions. In addition, substitutions of letters by emojis with a similar shape are also possible. Since emojis represent a more recent phenomenon of medially written language, the expectation {\textendash} and the general prejudice {\textendash} is that emojis are used more frequently by younger people with regard to them also chatting more, and {\textendash} given their playful character {\textendash} emojis are especially favoured by young people. This trend has been confirmed for the SwissGerman data. However, the analysis of a comparable German corpus shows a different, non-age-related distribution, which questions the generalizability of this age effect on the basis of the two examined corpora. Despite the relatively large data size of 419 and 374 thousand messages from 359 and 209 people respectively, a possible distortion of the data cannot be completely dismissed. Therefore, the results should be read and interpreted with caution so as not to draw premature conclusions.},
  isbn = {978-3-11-047222-6},
  langid = {ngerman},
  file = {/Users/timokoch/Zotero/storage/7ZCHRKQG/Siebenhaar - 2018 - Funktionen von Emojis und Altersabhängigkeit ihres.pdf}
}

@article{siegelEmotionFingerprintsEmotion2018,
  title = {Emotion Fingerprints or Emotion Populations? {{A}} Meta-Analytic Investigation of Autonomic Features of Emotion Categories},
  shorttitle = {Emotion Fingerprints or Emotion Populations?},
  author = {Siegel, Erika H. and Sands, Molly K. and {Van den Noortgate}, Wim and Condon, Paul and Chang, Yale and Dy, Jennifer and Quigley, Karen S. and Barrett, Lisa Feldman},
  year = {2018},
  journal = {Psychological Bulletin},
  volume = {144},
  pages = {343--393},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1455},
  doi = {10.1037/bul0000128},
  abstract = {The classical view of emotion hypothesizes that certain emotion categories have a specific autonomic nervous system (ANS) ``fingerprint'' that is distinct from other categories. Substantial ANS variation within a category is presumed to be epiphenomenal. The theory of constructed emotion hypothesizes that an emotion category is a population of context-specific, highly variable instances that need not share an ANS fingerprint. Instead, ANS variation within a category is a meaningful part of the nature of emotion. We present a meta-analysis of 202 studies measuring ANS reactivity during lab-based inductions of emotion in nonclinical samples of adults, using a random effects, multilevel meta-analysis and multivariate pattern classification analysis to test our hypotheses. We found increases in mean effect size for 59.4\% of ANS variables across emotion categories, but the pattern of effect sizes did not clearly distinguish 1 emotion category from another. We also observed significant variation within emotion categories; heterogeneity accounted for a moderate to substantial percentage (i.e., I2 {$\geq$} 30\%) of variability in 54\% of these effect sizes. Experimental moderators epiphenomenal to emotion, such as induction type (e.g., films vs. imagery), did not explain a large portion of the variability. Correction for publication bias reduced estimated effect sizes even further, increasing heterogeneity of effect sizes for certain emotion categories. These findings, when considered in the broader empirical literature, are more consistent with population thinking and other principles from evolutionary biology found within the theory of constructed emotion, and offer insights for developing new hypotheses to understand the nature of emotion. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
  keywords = {Autonomic Nervous System,Emotions,Psychophysiology},
  file = {/Users/timokoch/Zotero/storage/CCBQ693U/Siegel et al. - 2018 - Emotion fingerprints or emotion populations A met.pdf;/Users/timokoch/Zotero/storage/8366DCZL/doiLanding.html}
}

@article{siegertDATENSETZURUNTERSUCHUNG2015,
  title = {{EIN DATENSET ZUR UNTERSUCHUNG EMOTIONALER SPRACHE IN KUNDENBINDUNGSDIALOGEN}},
  author = {Siegert, Ingo and {Philippou-Hubner}, David and Tornow, Michael and Heinemann, Ralph and Wendemuth, Andreas and Ohnemus, Kerstin and Fischer, Sarah and Schreiber, Gerald},
  year = {2015},
  pages = {9},
  langid = {ngerman},
  file = {/Users/timokoch/Zotero/storage/DBNW2YD4/Siegert et al. - 2015 - EIN DATENSET ZUR UNTERSUCHUNG EMOTIONALER SPRACHE .pdf}
}

@article{siegertNewDatasetTelephoneBased,
  title = {A New {{Dataset}} of {{Telephone-Based Human-Human Call-Center Interaction}} with {{Emotional Evaluation}}},
  author = {Siegert, Ingo and Ohnemus, Kerstin},
  pages = {7},
  abstract = {Acoustic data are an important resource for speech-based emotion recognition. To obtain optimal recognisers, it would be desirable, when the data are of high quality, include preferably long and elaborate interactions, containing non-verbal events, and having a reliable and versatile emotion annotation. Additionally, the data set should contain additional information about the speakers, such as age, sex, or personality traits.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/LH5RMVG4/Siegert und Ohnemus - A new Dataset of Telephone-Based Human-Human Call-.pdf}
}

@article{skinnerCalibratedRecordingAnalysis1935,
  title = {A Calibrated Recording and Analysis of the Pitch, Force and Quality of Vocal Tones Expressing Happiness and Sadness; and a Determination of the Pitch and Force of the Subjective Concepts of Ordinary, Soft and Loud Tones},
  author = {Skinner, E. R.},
  year = {1935},
  journal = {Speech Monographs},
  volume = {2},
  pages = {81--137},
  publisher = {{Taylor \& Francis}},
  address = {{United Kingdom}},
  issn = {0038-7169},
  doi = {10.1080/03637753509374833},
  abstract = {9males and 10 females were asked to repeat the vowel ah immediately after reading a piece of literature and listening to phonographic recordings of music judged by "experts" as indicating sadness and happiness. Oscillographic records of the vowels were made and analyzed. Results showed that the vocal responses to stimuli which evoke happiness are appreciably higher in pitch than the ordinary tones of the same subjects and higher than tones representative of sad states. This difference was found to be significant in both sexes. The average tones in response to literature or music judged as sad are practically the same as that of the subjects' ordinary tones. Differences in intensity and in tone quality were also observed for the two emotional states. Psychogalvanic readings taken during the experiment showed the presence of disturbances of an emotional nature. A second experiment to determine the subjects' conception of ordinary, soft, and loud tones showed that pitch changes with the intensity of the tones. Soft tones are lower in pitch than those designated as ordinary, and loud tones are invariably higher in pitch than either. (PsycINFO Database Record (c) 2017 APA, all rights reserved)},
  file = {/Users/timokoch/Zotero/storage/ASPWX62Y/1939-02653-001.html}
}

@misc{skowronFusingSocialMedia2016,
  title = {Fusing {{Social Media Cues}}},
  author = {Skowron, Marcin and Tkal{\v c}i{\v c}, Marko and Ferwerda, Bruce and Schedl, Markus},
  year = {2016}
}

@article{skryjomskiInfluenceMinorityClass,
  title = {Influence of Minority Class Instance Types on {{SMOTE}} Imbalanced Data Oversampling},
  author = {Skryjomski, Przemyslaw and Krawczyk, Bartosz},
  pages = {15},
  abstract = {Despite more than two decades of intense research, learning from imbalanced data still remains as one of the major difficulties posed for computational intelligence systems. Among plethora of techniques dedicated to alleviating this problem, preprocessing algorithms are considered among the most efficient ones. They aim at re-balancing the training set by either undersampling of the majority class, or oversampling of the minority one. Here, Synthetic Minority Oversampling Technique, commonly known as SMOTE, stands as the most popular solution that introduces artificial instances on the basis of minority class neighborhood distribution. However, many recent works point out to the fact that the imbalanced ratio itself is not the sole source of learning difficulties in such scenarios. One should take a deeper look into the minority class structure in order to identify which instances influence the performance of classifiers in most significant manner. In this paper, we propose to investigate the role of minority class instance types on the performance of SMOTE. To achieve this, instead of oversampling uniformly the minority class, we preprocess only selected subsets of instances, based on their individual difficulties. Experimental study proves that such a selective oversampling leads to improved classification performance.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/SAS8AAQA/Skryjomski und Krawczyk - Inﬂuence of minority class instance types on SMOTE.pdf}
}

@book{SocialMediaData2021,
  title = {Social Media Data in Affective Science},
  year = {2021},
  month = nov,
  journal = {Handbook of Computational Social Science, Volume 1},
  pages = {240--255},
  publisher = {{Routledge}},
  doi = {10.4324/9781003024583-18},
  urldate = {2022-07-12},
  abstract = {The digital traces generated by social media offer the opportunity to analyze human behavior at new scales, depths, and resolutions. The results of analyses of social media data, while sometimes difficult to generalize to a society as a whole, can give important insights on detailed actions and subjective states of individuals. This novel datasource offers a new window to tackle research questions from affective science with respect to emotion dynamics, collective emotions, and affective expression in social contexts. In this chapter, we present a balanced view of the benefits, risks, opportunities, and pitfalls of analyzing affective life through social media data. We review a variety of methods to quantify emotions and other affective states from social media data. We illustrate the application of these methods at new scales and resolutions in a series of examples from previous research. We present research gaps and open questions about the role, meaning, and functionality of affective expression in social media, pointing to emerging research trends in computational social science and social psychology. When used critically and with robust research methods, observational analyses of large-scale social media data can be complementary to traditional methodologies in psychology and cognitive science.},
  isbn = {978-1-00-302458-3},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/CQR9EH3T/social-media-data-affective-science-max-pellert-simon-schweighofer-david-garcia.html}
}

@inproceedings{songCollectingNaturalSMS2014,
  title = {Collecting {{Natural SMS}} and {{Chat Conversations}} in {{Multiple Languages}}: {{The BOLT Phase}} 2 {{Corpus}}},
  booktitle = {{{LREC}}},
  author = {Song, Zhiyi and Strassel, Stephanie and Lee, Haejoong and Walker, Kevin and Wright, Jonathan and Garland, Jennifer and Fore, Dana and Gainor, Brian and Cabe, Preston and Thomas, Thomas},
  year = {2014},
  pages = {1699--1704}
}

@inproceedings{spathisPassiveMobileSensing2019,
  title = {Passive Mobile Sensing and Psychological Traits for Large Scale Mood Prediction},
  booktitle = {Proceedings of the 13th {{EAI International Conference}} on {{Pervasive Computing Technologies}} for {{Healthcare}}},
  author = {Spathis, Dimitris and {Servia-Rodriguez}, Sandra and Farrahi, Katayoun and Mascolo, Cecilia and Rentfrow, Jason},
  year = {2019},
  month = may,
  pages = {272--281},
  publisher = {{ACM}},
  address = {{Trento Italy}},
  doi = {10.1145/3329189.3329213},
  urldate = {2021-02-01},
  abstract = {Experience sampling has long been the established method to sample people's mood in order to assess their mental state. Smartphones start to be used as experience sampling tools for mental health state as they accompany individuals during their day and can therefore gather in-the-moment data. However, the granularity of the data needs to be traded off with the level of interruption these tools introduce. As a consequence the data collected with this technique is often sparse. This has been obviated by the use of passive sensing in addition to mood reports, however, this adds additional noise.},
  isbn = {978-1-4503-6126-2},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/X2QKNTKE/Spathis et al. - 2019 - Passive mobile sensing and psychological traits fo.pdf}
}

@inproceedings{spathisPassiveMobileSensing2019a,
  title = {Passive Mobile Sensing and Psychological Traits for Large Scale Mood Prediction},
  booktitle = {Proceedings of the 13th {{EAI International Conference}} on {{Pervasive Computing Technologies}} for {{Healthcare}}},
  author = {Spathis, Dimitris and {Servia-Rodriguez}, Sandra and Farrahi, Katayoun and Mascolo, Cecilia and Rentfrow, Jason},
  year = {2019},
  month = may,
  pages = {272--281},
  publisher = {{ACM}},
  address = {{Trento Italy}},
  doi = {10.1145/3329189.3329213},
  urldate = {2020-12-30},
  abstract = {Experience sampling has long been the established method to sample people's mood in order to assess their mental state. Smartphones start to be used as experience sampling tools for mental health state as they accompany individuals during their day and can therefore gather in-the-moment data. However, the granularity of the data needs to be traded off with the level of interruption these tools introduce. As a consequence the data collected with this technique is often sparse. This has been obviated by the use of passive sensing in addition to mood reports, however, this adds additional noise.},
  isbn = {978-1-4503-6126-2},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/7SUCS7L4/Spathis et al. - 2019 - Passive mobile sensing and psychological traits fo.pdf}
}

@article{spechtStabilityChangePersonality2011,
  title = {Stability and Change of Personality across the Life Course: The Impact of Age and Major Life Events on Mean-Level and Rank-Order Stability of the {{Big Five}}},
  shorttitle = {Stability and Change of Personality across the Life Course},
  author = {Specht, Jule and Egloff, Boris and Schmukle, Stefan C.},
  year = {2011},
  month = oct,
  journal = {Journal of Personality and Social Psychology},
  volume = {101},
  number = {4},
  pages = {862--882},
  issn = {1939-1315},
  doi = {10.1037/a0024950},
  abstract = {Does personality change across the entire life course, and are those changes due to intrinsic maturation or major life experiences? This longitudinal study investigated changes in the mean levels and rank order of the Big Five personality traits in a heterogeneous sample of 14,718 Germans across all of adulthood. Latent change and latent moderated regression models provided 4 main findings: First, age had a complex curvilinear influence on mean levels of personality. Second, the rank-order stability of Emotional Stability, Extraversion, Openness, and Agreeableness all followed an inverted U-shaped function, reaching a peak between the ages of 40 and 60 and decreasing afterward, whereas Conscientiousness showed a continuously increasing rank-order stability across adulthood. Third, personality predicted the occurrence of several objective major life events (selection effects) and changed in reaction to experiencing these events (socialization effects), suggesting that personality can change due to factors other than intrinsic maturation. Fourth, when events were clustered according to their valence, as is commonly done, effects of the environment on changes in personality were either overlooked or overgeneralized. In sum, our analyses show that personality changes throughout the life span, but with more pronounced changes in young and old ages, and that this change is partly attributable to social demands and experiences.},
  langid = {english},
  pmid = {21859226},
  keywords = {Adolescent,Adult,Affect,Age Factors,Aged,{Aged, 80 and over},Aging,Emotions,Female,Germany,Humans,Internal-External Control,Interpersonal Relations,Life Change Events,Longitudinal Studies,Male,Middle Aged,Personality,Personality Development,Personality Inventory,Social Environment,Social Perception,Young Adult},
  file = {/Users/timokoch/Zotero/storage/64W2AXME/Specht et al. - 2011 - Stability and change of personality across the lif.pdf}
}

@article{sridharUnsupervisedPersonalizationEmotion2022,
  title = {Unsupervised {{Personalization}} of an {{Emotion Recognition System}}: {{The Unique Properties}} of the {{Externalization}} of {{Valence}} in {{Speech}}},
  shorttitle = {Unsupervised {{Personalization}} of an {{Emotion Recognition System}}},
  author = {Sridhar, Kusha and Busso, Carlos},
  year = {2022},
  month = oct,
  journal = {IEEE Transactions on Affective Computing},
  volume = {13},
  number = {4},
  pages = {1959--1972},
  issn = {1949-3045},
  doi = {10.1109/TAFFC.2022.3187336},
  abstract = {The prediction of valence from speech is an important, but challenging problem. The expression of valence in speech has speaker-dependent cues, which contribute to performances that are often significantly lower than the prediction of other emotional attributes such as arousal and dominance. A practical approach to improve valence prediction from speech is to adapt the models to the target speakers in the test set. Adapting a speech emotion recognition (SER) system to a particular speaker is a hard problem, especially with deep neural networks (DNNs), since it requires optimizing millions of parameters. This study proposes an unsupervised approach to address this problem by searching for speakers in the train set with similar acoustic patterns as the speaker in the test set. Speech samples from the selected speakers are used to create the adaptation set. This approach leverages transfer learning using pre-trained models, which are adapted with these speech samples. We propose three alternative adaptation strategies: unique speaker, oversampling and weighting approaches. These methods differ on the use of the adaptation set in the personalization of the valence models. The results demonstrate that a valence prediction model can be efficiently personalized with these unsupervised approaches, leading to relative improvements as high as 13.52\%.},
  keywords = {Acoustics,adaptation,Adaptation models,Data models,Emotion recognition,emotional dimensions,Predictive models,Speech emotion recognition,Speech recognition,Training,transfer learning,valence},
  file = {/Users/timokoch/Zotero/storage/Z3BYGFSQ/Sridhar und Busso - 2022 - Unsupervised Personalization of an Emotion Recogni.pdf;/Users/timokoch/Zotero/storage/2ZNIEPEH/9812504.html}
}

@article{stachlBehavioralPatternsSmartphone,
  title = {Behavioral {{Patterns}} in {{Smartphone Usage Predict Big Five Personality Traits}}},
  author = {Stachl, Clemens and Au, Quay and Schoedel, Ramona and Buschek, Daniel and V{\"o}lkel, Sarah and Schuwerk, Tobias and Oldemeier, Michelle and Ullmann, Theresa and Hussmann, Heinrich and Bischl, Bernd and B{\"u}hner, Markus},
  doi = {10.31234/osf.io/ks4vd},
  urldate = {2019-07-24},
  abstract = {The understanding, quantification and evaluation of individual differences in behavior, feelings and thoughts have always been central topics in psychological science. An enormous amount of previous work on individual differences in behavior is exclusively based on data from self-report questionnaires. To date, little is known about how individuals actually differ in their objectively quantifiable behaviors and how differences in these behaviors relate to big five personality traits. Technological advances in mobile computer and sensing technology have now created the possiblity to automatically record large amounts of data about humans' natural behavior. The collection and analysis of these records makes it possible to analyze and quantify behavioral differences at unprecedented scale and efficiency. In this study, we analyzed behavioral data obtained from 743 participants in 30 consecutive days of smartphone sensing (25,347,089 logging-events). We computed variables (15,692) about individual behavior from five semantic categories (communication \&amp; social behavior, music listening behavior, app usage behavior, mobility, and general day- \&amp; nighttime activity). Using a machine learning approach (random forest, elastic net), we show how these variables can be used to predict self-assessments of the big five personality traits at the factor and facet level. Our results reveal distinct behavioral patterns that proved to be differentially-predictive of big five personality traits. Overall, this paper shows how a combination of rich behavioral data obtained with smartphone sensing and the use of machine learning techniques can help to advance personality research and can inform both practitioners and researchers about the different behavioral patterns of personality.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/KTWYN8GI/Stachl et al. - Behavioral Patterns in Smartphone Usage Predict Bi.pdf}
}

@article{stachlPersonalityResearchAssessment2020,
  title = {Personality {{Research}} and {{Assessment}} in the {{Era}} of {{Machine Learning}}},
  author = {Stachl, Clemens and Pargent, Florian and Hilbert, Sven and Harari, Gabriella M. and Schoedel, Ramona and Vaid, Sumer and Gosling, Samuel D. and B{\"u}hner, Markus},
  year = {2020},
  journal = {European Journal of Personality},
  volume = {34},
  number = {5},
  pages = {613--631},
  issn = {1099-0984},
  doi = {10.1002/per.2257},
  urldate = {2020-10-13},
  abstract = {The increasing availability of high-dimensional, fine-grained data about human behaviour, gathered from mobile sensing studies and in the form of digital footprints, is poised to drastically alter the way personality psychologists perform research and undertake personality assessment. These new kinds and quantities of data raise important questions about how to analyse the data and interpret the results appropriately. Machine learning models are well suited to these kinds of data, allowing researchers to model highly complex relationships and to evaluate the generalizability and robustness of their results using resampling methods. The correct usage of machine learning models requires specialized methodological training that considers issues specific to this type of modelling. Here, we first provide a brief overview of past studies using machine learning in personality psychology. Second, we illustrate the main challenges that researchers face when building, interpreting, and validating machine learning models. Third, we discuss the evaluation of personality scales, derived using machine learning methods. Fourth, we highlight some key issues that arise from the use of latent variables in the modelling process. We conclude with an outlook on the future role of machine learning models in personality research and assessment.},
  copyright = {{\textcopyright} 2020 The Authors. European Journal of Personality published by John Wiley \& Sons Ltd on behalf of European Association of Personality Psychology},
  langid = {english},
  keywords = {assessment,interpretability,machine learning,overfitting,personality},
  file = {/Users/timokoch/Zotero/storage/UBD66FRH/Stachl et al. - Personality Research and Assessment in the Era of .pdf;/Users/timokoch/Zotero/storage/YXC3YF23/per.html}
}

@article{stachlPersonalityTraitsPredict2017,
  title = {Personality {{Traits Predict Smartphone Usage}}},
  author = {Stachl, Clemens and Hilbert, Sven and Au, Jiew-Quay and Buschek, Daniel and Luca, Alexander De and Bischl, Bernd and Hussmann, Heinrich and B{\"u}hner, Markus},
  year = {2017},
  month = nov,
  journal = {European Journal of Personality},
  volume = {31},
  number = {6},
  pages = {701--722},
  issn = {1099-0984},
  doi = {10.1002/per.2113},
  urldate = {2018-11-21},
  abstract = {The present study investigates to what degree individual differences can predict frequency and duration of actual behaviour, manifested in mobile application (app) usage on smartphones. In particular, this work focuses on the identification of stable associations between personality on the factor and facet level, fluid intelligence, demography and app usage in 16 distinct categories. A total of 137 subjects (87 women and 50 men), with an average age of 24 (SD = 4.72), participated in a 90-min psychometric lab session as well as in a subsequent 60-day data logging study in the field. Our data suggest that personality traits predict mobile application usage in several specific categories such as communication, photography, gaming, transportation and entertainment. Extraversion, conscientiousness and agreeableness are better predictors of mobile application usage than basic demographic variables in several distinct categories. Furthermore, predictive performance is slightly higher for single factor{\textemdash}in comparison with facet-level personality scores. Fluid intelligence and demographics additionally show stable associations with categorical app usage. In sum, this study demonstrates how individual differences can be effectively related to actual behaviour and how this can assist in understanding the behavioural underpinnings of personality. Copyright {\textcopyright} 2017 European Association of Personality Psychology},
  copyright = {Copyright {\textcopyright} 2017 European Association of Personality Psychology},
  langid = {english},
  keywords = {app usage,behaviour,Big Five,factor and facets,smartphones},
  file = {/Users/timokoch/Zotero/storage/U9A5KEBI/per.html}
}

@inproceedings{starkEthicsEmotionArtificial2021,
  title = {The {{Ethics}} of {{Emotion}} in {{Artificial Intelligence Systems}}},
  booktitle = {Proceedings of the 2021 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Stark, Luke and Hoey, Jesse},
  year = {2021},
  month = mar,
  pages = {782--793},
  publisher = {{ACM}},
  address = {{Virtual Event Canada}},
  doi = {10.1145/3442188.3445939},
  urldate = {2022-11-08},
  abstract = {In this paper, we develop a taxonomy of conceptual models and proxy data used for digital analysis of human emotional expression and outline how the combinations and permutations of these models and data impact their incorporation into artificial intelligence (AI) systems. We argue we should not take computer scientists at their word that the paradigms for human emotions they have developed internally and adapted from other disciplines can produce ground truth about human emotions; instead, we ask how different conceptualizations of what emotions are, and how they can be sensed, measured and transformed into data, shape the ethical and social implications of these AI systems.},
  isbn = {978-1-4503-8309-7},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/9L8TFF8A/Stark und Hoey - 2021 - The Ethics of Emotion in Artificial Intelligence S.pdf}
}

@misc{StatesVsTraits,
  title = {States vs Traits: Why You Aren't Defined by Your Past},
  shorttitle = {States vs Traits},
  journal = {Receptiviti},
  urldate = {2019-07-26},
  abstract = {``In words are seen the state of mind and character and disposition of the speaker.''  \rule{1em}{1pt} Plutarch  We have always known the power of words. They connect us, explain us, teach us, and define us. Our words really do reveal ourselves.  But what does that mean?  Traits  When we think about what makes peop},
  howpublished = {https://www.receptiviti.com/blog-home/states-vs-traits},
  langid = {american},
  file = {/Users/timokoch/Zotero/storage/CKBVDCEB/states-vs-traits.html}
}

@misc{statistaAgeDistributionAdult2014,
  title = {Age Distribution of Adult {{WhatsApp}} Users in the {{United States}} as of {{February}} 2014},
  author = {Statista},
  year = {2014}
}

@misc{statistaUmfrageZurNutzung2016,
  title = {Umfrage Zur {{Nutzung}} von {{Facebook-Produkten}} Nach {{Geschlecht}} in {{Deutschland}} 2016},
  author = {Statista},
  year = {2016},
  howpublished = {https://de.statista.com/statistik/daten/studie/613574/umfrage/nutzung-von-facebook-produkten-nach-geschlecht-in-deutschland/}
}

@misc{statistaWhatsAppNutzungNach2017,
  title = {{WhatsApp - Nutzung nach Altersgruppen in Deutschland 2017}},
  author = {Statista},
  year = {2017},
  journal = {Statista},
  urldate = {2020-10-02},
  abstract = {Diese Statistik zeigt das Ergebnis einer Umfrage unter Internetnutzern in Deutschland zur Nutzung von WhatsApp nach Altersgruppen im Jahr 2017.},
  howpublished = {https://de.statista.com/statistik/daten/studie/691572/umfrage/anteil-der-nutzer-von-whatsapp-nach-alter-in-deutschland/},
  langid = {ngerman},
  file = {/Users/timokoch/Zotero/storage/IIXPSGSR/anteil-der-nutzer-von-whatsapp-nach-alter-in-deutschland.html}
}

@article{stavrovaHowTellHappy2020,
  title = {How to Tell a Happy Person: {{Accuracy}} of Subjective Well-Being Perception from Texts},
  shorttitle = {How to Tell a Happy Person},
  author = {Stavrova, Olga and Haarmann, Lena},
  year = {2020},
  month = aug,
  journal = {Motivation and Emotion},
  volume = {44},
  number = {4},
  pages = {597--607},
  issn = {1573-6644},
  doi = {10.1007/s11031-019-09815-4},
  urldate = {2020-11-30},
  abstract = {Although perceptions of subjective well-being (SWB) in unacquainted others have been shown to play a major role in impression formation, little is known about how accurate such perceptions are. In two original studies and one pre-registered replication, we explored the accuracy of life satisfaction and happiness judgments from texts and its underlying mechanisms (use of linguistic cues). Participants filled in life satisfaction and happiness measures and completed a brief writing task. Another sample of participants judged the targets' life satisfaction and happiness from the obtained texts. All three studies demonstrated a small to moderate self-other agreement. A linguistic analysis showed that targets with higher (vs. lower) scores on SWB were less likely to use negation words in their texts, which allowed observers to make accurate judgment of their SWB level. Two studies pointed at negative emotion words as valid and positive emotion words as invalid (but often used) cues to happiness, yet these effects did not replicate in Study 3.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/6BI4TH5I/Stavrova und Haarmann - 2020 - How to tell a happy person Accuracy of subjective.pdf}
}

@book{steinebachDesinformationAufdeckenUnd2020,
  title = {{Desinformation aufdecken und bek{\"a}mpfen: Interdisziplin{\"a}re Ans{\"a}tze gegen Desinformationskampagnen und f{\"u}r Meinungspluralit{\"a}t}},
  shorttitle = {{Desinformation aufdecken und bek{\"a}mpfen}},
  editor = {Steinebach, Martin and Bader, Katarina and Rinsdorf, Lars and Kr{\"a}mer, Nicole and Ro{\ss}nagel, Alexander},
  year = {2020},
  publisher = {{Nomos Verlagsgesellschaft mbH \& Co. KG}},
  doi = {10.5771/9783748904816},
  urldate = {2021-05-04},
  isbn = {978-3-7489-0481-6},
  langid = {ngerman},
  file = {/Users/timokoch/Zotero/storage/AFVDK4F3/Steinebach et al. - 2020 - Desinformation aufdecken und bekämpfen Interdiszi.pdf}
}

@article{stemleProceedings5thConference,
  title = {Proceedings of the 5th {{Conference}} on {{CMC}} and {{Social Media Corpora}} for the {{Humanities}} (Cmccorpora17)},
  author = {Stemle, Egon W},
  pages = {4},
  abstract = {As a consequence of a recent curation project, the Dortmund Chat Corpus is available in CLARIN-D research infrastructures for download and querying. In a legal expertise it had been recommended that standard measures of anonymisation be applied to the corpus before its republication. This paper reports about the anonymisation campaign that was conducted for the corpus. Anonymisation has been realised as categorisation, and the taxonomy of anonymisation categories applied is introduced and the method of applying it to the TEI files is demonstrated. The results of the anonymisation campaign as well as issues of quality assessment are discussed. Finally, pseudonymisation as an alternative to categorisation as a method of the anonymisation of CMC data is discussed, as well as possibilities of an automatisation of the process.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/XFP3AR67/Stemle - Proceedings of the 5th Conference on CMC and Socia.pdf}
}

@article{stilpAcousticContextEffects2020,
  title = {Acoustic Context Effects in Speech Perception},
  author = {Stilp, Christian},
  year = {2020},
  month = jan,
  journal = {Wiley interdisciplinary reviews. Cognitive science},
  volume = {11},
  pages = {1--18},
  doi = {10.1002/wcs.1517},
  abstract = {The extreme acoustic variability of speech is well established, which makes the proficiency of human speech perception all the more impressive. Speech perception, like perception in any modality, is relative to context, and this provides a means to normalize the acoustic variability in the speech signal. Acoustic context effects in speech perception have been widely documented, but a clear understanding of how these effects relate to each other across stimuli, timescales, and acoustic domains is lacking. Here we review the influences that spectral context, temporal context, and spectrotemporal context have on speech perception. Studies are organized in terms of whether the context precedes the target (forward effects) or follows it (backward effects), and whether the context is adjacent to the target (proximal) or temporally removed from it (distal). Special cases where proximal and distal contexts have competing influences on perception are also considered. Across studies, a common theme emerges: acoustic differences between contexts and targets are perceptually magnified, producing contrast effects that facilitate perception of target sounds and words. This indicates enhanced sensitivity to changes in the acoustic environment, which maximizes the amount of potential information that can be transmitted to the perceiver. This article is categorized under: Linguistics {$>$} Language in Mind and Brain Psychology {$>$} Perception and Psychophysics Acoustic context effects in speech perception. Contexts can be temporally adjacent to the target speech sound (proximal) or temporally nonadjacent to the target (distal). Contexts that precede the target in time are forward effects; contexts that follow the target are backward effects. These combinations of context timescales and directions apply equally to spectral context effects and temporal context effects in speech perception},
  file = {/Users/timokoch/Zotero/storage/ZNUBK6Z2/Stilp - 2020 - Acoustic context effects in speech perception.pdf}
}

@article{stoneGeneralInquirerComputer1962,
  title = {The General Inquirer: {{A}} Computer System for Content Analysis and Retrieval Based on the Sentence as a Unit of Information},
  shorttitle = {The General Inquirer},
  author = {Stone, Philip J. and Bales, Robert F. and Namenwirth, J. Zvi and Ogilvie, Daniel M.},
  year = {1962},
  journal = {Behavioral Science},
  volume = {7},
  number = {4},
  pages = {484--498},
  issn = {1099-1743},
  doi = {10.1002/bs.3830070412},
  urldate = {2022-07-13},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/6N8GKDBA/bs.html}
}

@inproceedings{strakaTokenizingPOSTagging2017,
  title = {Tokenizing, {{POS Tagging}}, {{Lemmatizing}} and {{Parsing UD}} 2.0 with {{UDPipe}}},
  booktitle = {Proceedings of the {{CoNLL}} 2017 {{Shared Task}}: {{Multilingual Parsing}} from {{Raw Text}} to {{Universal Dependencies}}},
  author = {Straka, Milan and Strakov{\'a}, Jana},
  year = {2017},
  month = aug,
  pages = {88--99},
  publisher = {{Association for Computational Linguistics}},
  address = {{Vancouver, Canada}},
  doi = {10.18653/v1/K17-3009},
  urldate = {2021-04-20},
  abstract = {Many natural language processing tasks, including the most advanced ones, routinely start by several basic processing steps {\textendash} tokenization and segmentation, most likely also POS tagging and lemmatization, and commonly parsing as well. A multilingual pipeline performing these steps can be trained using the Universal Dependencies project, which contains annotations of the described tasks for 50 languages in the latest release UD 2.0. We present an update to UDPipe, a simple-to-use pipeline processing CoNLL-U version 2.0 files, which performs these tasks for multiple languages without requiring additional external data. We provide models for all 50 languages of UD 2.0, and furthermore, the pipeline can be trained easily using data in CoNLL-U format. UDPipe is a standalone application in C++, with bindings available for Python, Java, C\# and Perl. In the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies, UDPipe was the eight best system, while achieving low running times and moderately sized models.},
  file = {/Users/timokoch/Zotero/storage/WFHPAHXV/Straka und Straková - 2017 - Tokenizing, POS Tagging, Lemmatizing and Parsing U.pdf}
}

@article{stroblBiasRandomForest2007,
  title = {Bias in Random Forest Variable Importance Measures: {{Illustrations}}, Sources and a Solution},
  author = {Strobl, Carolin and Boulesteix, Anne-Laure and Zeileis, Achim and Hothorn, Torsten},
  year = {2007},
  journal = {BMC bioinformatics},
  volume = {8},
  number = {1},
  pages = {25},
  issn = {1471-2105}
}

@article{stroblConditionalVariableImportance2008,
  title = {Conditional Variable Importance for Random Forests},
  author = {Strobl, Carolin and Boulesteix, Anne-Laure and Kneib, Thomas and Augustin, Thomas and Zeileis, Achim},
  year = {2008},
  month = dec,
  journal = {BMC Bioinformatics},
  volume = {9},
  number = {1},
  pages = {307},
  issn = {1471-2105},
  doi = {10.1186/1471-2105-9-307},
  urldate = {2020-04-01},
  abstract = {Background: Random forests are becoming increasingly popular in many scientific fields because they can cope with "small n large p" problems, complex interactions and even highly correlated predictor variables. Their variable importance measures have recently been suggested as screening tools for, e.g., gene expression studies. However, these variable importance measures show a bias towards correlated predictor variables. Results: We identify two mechanisms responsible for this finding: (i) A preference for the selection of correlated predictors in the tree building process and (ii) an additional advantage for correlated predictor variables induced by the unconditional permutation scheme that is employed in the computation of the variable importance measure. Based on these considerations we develop a new, conditional permutation scheme for the computation of the variable importance measure. Conclusion: The resulting conditional variable importance reflects the true impact of each predictor variable more reliably than the original marginal approach.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/X5ZYRWU8/Strobl et al. - 2008 - Conditional variable importance for random forests.pdf}
}

@book{stullePsychologischeDiagnostikDurch2018,
  title = {{Psychologische Diagnostik durch Sprachanalyse: Validierung der PRECIRE{\textregistered}-Technologie f{\"u}r die Personalarbeit}},
  shorttitle = {{Psychologische Diagnostik durch Sprachanalyse}},
  editor = {Stulle, Klaus P.},
  year = {2018},
  publisher = {{Springer Gabler}},
  address = {{Wiesbaden}},
  isbn = {978-3-658-18770-5 978-3-658-18771-2},
  langid = {ngerman},
  annotation = {OCLC: 1015351595},
  file = {/Users/timokoch/Zotero/storage/Z7G4EH5D/Stulle - 2018 - Psychologische Diagnostik durch Sprachanalyse Val.pdf}
}

@inproceedings{suharaDeepMoodForecastingDepressed2017,
  title = {{{DeepMood}}: {{Forecasting Depressed Mood Based}} on {{Self-Reported Histories}} via {{Recurrent Neural Networks}}},
  shorttitle = {{{DeepMood}}},
  booktitle = {Proceedings of the 26th {{International Conference}} on {{World Wide Web}}},
  author = {Suhara, Yoshihiko and Xu, Yinzhan and Pentland, Alex 'Sandy'},
  year = {2017},
  month = apr,
  pages = {715--724},
  publisher = {{International World Wide Web Conferences Steering Committee}},
  address = {{Perth Australia}},
  doi = {10.1145/3038912.3052676},
  urldate = {2022-12-16},
  abstract = {Depression is a prevailing issue and is an increasing problem in many people's lives. Without observable diagnostic criteria, the signs of depression may go unnoticed, resulting in high demand for detecting depression in advance automatically. This paper tackles the challenging problem of forecasting severely depressed moods based on self-reported histories. Despite the large amount of research on understanding individual moods including depression, anxiety, and stress based on behavioral logs collected by pervasive computing devices such as smartphones, forecasting depressed moods is still an open question. This paper develops a recurrent neural network algorithm that incorporates categorical embedding layers for forecasting depression. We collected largescale records from 2,382 self-declared depressed people to conduct the experiment. Experimental results show that our method forecast the severely depressed mood of a user based on self-reported histories, with higher accuracy than SVM. The results also showed that the long-term historical information of a user improves the accuracy of forecasting depressed mood.},
  isbn = {978-1-4503-4913-0},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/QNB8RP3N/Suhara et al. - 2017 - DeepMood Forecasting Depressed Mood Based on Self.pdf}
}

@inproceedings{sumnerPredictingDarkTriad2012,
  title = {Predicting Dark Triad Personality Traits from Twitter Usage and a Linguistic Analysis of Tweets},
  booktitle = {Machine Learning and Applications (Icmla), 2012 11th International Conference On},
  author = {Sumner, Chris and Byers, Alison and Boochever, Rachel and Park, Gregory J.},
  year = {2012},
  volume = {2},
  pages = {386--393},
  publisher = {{IEEE}},
  isbn = {1-4673-4651-9}
}

@article{sunLanguageWellbeingTracking2020,
  title = {The Language of Well-Being: {{Tracking}} Fluctuations in Emotion Experience through Everyday Speech},
  shorttitle = {The Language of Well-Being},
  author = {Sun, Jessie and Schwartz, H. Andrew and Son, Youngseo and Kern, Margaret L. and Vazire, Simine},
  year = {2020},
  month = feb,
  journal = {Journal of Personality and Social Psychology},
  volume = {118},
  number = {2},
  pages = {364--387},
  issn = {1939-1315},
  doi = {10.1037/pspp0000244},
  abstract = {The words that people use have been found to reflect stable psychological traits, but less is known about the extent to which everyday fluctuations in spoken language reflect transient psychological states. We explored within-person associations between spoken words and self-reported state emotion among 185 participants who wore the Electronically Activated Recorder (EAR; an unobtrusive audio recording device) and completed experience sampling reports of their positive and negative emotions 4 times per day for 7 days (1,579 observations). We examined language using the Linguistic Inquiry and Word Count program (LIWC; theoretically created dictionaries) and open-vocabulary themes (clusters of data-driven semantically-related words). Although some studies give the impression that LIWC's positive and negative emotion dictionaries can be used as indicators of emotion experience, we found that when computed on spoken language, LIWC emotion scores were not significantly associated with self-reports of state emotion experience. Exploration of other categories of language variables suggests a number of hypotheses about substantive everyday correlates of momentary positive and negative emotion that can be tested in future studies. These findings (a) suggest that LIWC positive and negative emotion dictionaries may not capture self-reported subjective emotion experience when applied to everyday speech, (b) emphasize the importance of establishing the validity of language-based measures within one's target domain, (c) demonstrate the potential for developing new hypotheses about personality processes from the open-ended words that are used in everyday speech, and (d) extend perspectives on intraindividual variability to the domain of spoken language. (PsycINFO Database Record (c) 2020 APA, all rights reserved).},
  langid = {english},
  pmid = {30945904},
  keywords = {Adolescent,Adult,Ecological Momentary Assessment,Emotions,Female,Humans,Linguistics,Longitudinal Studies,Male,Mental Health,Semantics,Speech,Students,Vocabulary,Young Adult},
  file = {/Users/timokoch/Zotero/storage/IRQVKRTM/Sun et al. - 2020 - The language of well-being Tracking fluctuations .pdf;/Users/timokoch/Zotero/storage/N646PPR9/Sun et al. - The Language of Well-Being Tracking Fluctuations .pdf}
}

@article{sunLanguageWellbeingTracking2020a,
  title = {The Language of Well-Being: {{Tracking}} Fluctuations in Emotion Experience through Everyday Speech},
  shorttitle = {The Language of Well-Being},
  author = {Sun, Jessie and Schwartz, H. Andrew and Son, Youngseo and Kern, Margaret L. and Vazire, Simine},
  year = {2020},
  month = feb,
  journal = {Journal of Personality and Social Psychology},
  volume = {118},
  number = {2},
  pages = {364--387},
  issn = {1939-1315},
  doi = {10.1037/pspp0000244},
  abstract = {The words that people use have been found to reflect stable psychological traits, but less is known about the extent to which everyday fluctuations in spoken language reflect transient psychological states. We explored within-person associations between spoken words and self-reported state emotion among 185 participants who wore the Electronically Activated Recorder (EAR; an unobtrusive audio recording device) and completed experience sampling reports of their positive and negative emotions 4 times per day for 7 days (1,579 observations). We examined language using the Linguistic Inquiry and Word Count program (LIWC; theoretically created dictionaries) and open-vocabulary themes (clusters of data-driven semantically-related words). Although some studies give the impression that LIWC's positive and negative emotion dictionaries can be used as indicators of emotion experience, we found that when computed on spoken language, LIWC emotion scores were not significantly associated with self-reports of state emotion experience. Exploration of other categories of language variables suggests a number of hypotheses about substantive everyday correlates of momentary positive and negative emotion that can be tested in future studies. These findings (a) suggest that LIWC positive and negative emotion dictionaries may not capture self-reported subjective emotion experience when applied to everyday speech, (b) emphasize the importance of establishing the validity of language-based measures within one's target domain, (c) demonstrate the potential for developing new hypotheses about personality processes from the open-ended words that are used in everyday speech, and (d) extend perspectives on intraindividual variability to the domain of spoken language. (PsycINFO Database Record (c) 2020 APA, all rights reserved).},
  langid = {english},
  pmid = {30945904},
  keywords = {Adolescent,Adult,Ecological Momentary Assessment,Emotions,Female,Humans,Linguistics,Longitudinal Studies,Male,Mental Health,Semantics,Speech,Students,Vocabulary,Young Adult},
  file = {/Users/timokoch/Zotero/storage/GYGC64G9/Sun et al. - The Language of Well-Being Tracking Fluctuations .pdf;/Users/timokoch/Zotero/storage/SP6UWURD/sun-2020a.pdf}
}

@misc{sunPreTrainedBERTModel2022,
  title = {A {{Pre-Trained BERT Model}} for {{Android Applications}}},
  author = {Sun, Tiezhu and Allix, Kevin and Kim, Kisub and Zhou, Xin and Kim, Dongsun and Lo, David and Bissyand{\'e}, Tegawend{\'e} F. and Klein, Jacques},
  year = {2022},
  month = dec,
  number = {arXiv:2212.05976},
  eprint = {2212.05976},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-01-14},
  abstract = {The automation of an increasingly large number of software engineering tasks is becoming possible thanks to Machine Learning (ML). One foundational building block in the application of ML to software artifacts is the representation of these artifacts (e.g., source code or executable code) into a form that is suitable for learning. Many studies have leveraged representation learning, delegating to ML itself the job of automatically devising suitable representations. Yet, in the context of Android problems, existing models are either limited to coarse-grained whole-app level (e.g., apk2vec) or conducted for one specific downstream task (e.g., smali2vec). Our work is part of a new line of research that investigates effective, task-agnostic, and fine-grained universal representations of bytecode to mitigate both of these two limitations. Such representations aim to capture information relevant to various low-level downstream tasks (e.g., at the class-level). We are inspired by the field of Natural Language Processing, where the problem of universal representation was addressed by building Universal Language Models, such as BERT, whose goal is to capture abstract semantic information about sentences, in a way that is reusable for a variety of tasks. We propose DexBERT, a BERT-like Language Model dedicated to representing chunks of DEX bytecode, the main binary format used in Android applications. We empirically assess whether DexBERT is able to model the DEX language and evaluate the suitability of our model in two distinct class-level software engineering tasks: Malicious Code Localization and Defect Prediction. We also experiment with strategies to deal with the problem of catering to apps having vastly different sizes, and we demonstrate one example of using our technique to investigate what information is relevant to a given task.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Software Engineering},
  file = {/Users/timokoch/Zotero/storage/3KCTHSYT/Sun et al. - 2022 - A Pre-Trained BERT Model for Android Applications.pdf;/Users/timokoch/Zotero/storage/XJ6A5QS5/2212.html}
}

@article{swamiAnalyticThinkingReduces2014,
  title = {Analytic Thinking Reduces Belief in Conspiracy Theories},
  author = {Swami, Viren and Voracek, Martin and Stieger, Stefan and Tran, Ulrich S. and Furnham, Adrian},
  year = {2014},
  month = dec,
  journal = {Cognition},
  volume = {133},
  number = {3},
  pages = {572--585},
  issn = {00100277},
  doi = {10.1016/j.cognition.2014.08.006},
  urldate = {2019-05-23},
  abstract = {Belief in conspiracy theories has been associated with a range of negative health, civic, and social outcomes, requiring reliable methods of reducing such belief. Thinking dispositions have been highlighted as one possible factor associated with belief in conspiracy theories, but actual relationships have only been infrequently studied. In Study 1, we examined associations between belief in conspiracy theories and a range of measures of thinking dis positions in a British sample (N 990). Results indicated that a stronger belief in conspiracy theories was significantly associated with lower analytic thinking and open mindedness and greater intuitive thinking. In Studies 2 4, we examined the causational role played by analytic thinking in relation to conspiracist ideation. In Study 2 (N 112), we showed that a verbal fluency task that elicited analytic thinking reduced belief in conspiracy theo ries. In Study 3 (N 189), we found that an alternative method of eliciting analytic think ing, which related to cognitive disfluency, was effective at reducing conspiracist ideation in a student sample. In Study 4, we replicated the results of Study 3 among a general popu lation sample (N 140) in relation to generic conspiracist ideation and belief in conspiracy theories about the July 7, 2005, bombings in London. Our results highlight the potential utility of supporting attempts to promote analytic thinking as a means of countering the widespread acceptance of conspiracy theories.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/T4CT5ZDB/Swami et al. - 2014 - Analytic thinking reduces belief in conspiracy the.pdf}
}

@article{szekelyMeasuringTestingDependence2007,
  title = {Measuring and Testing Dependence by Correlation of Distances},
  author = {Sz{\'e}kely, G{\'a}bor J. and Rizzo, Maria L. and Bakirov, Nail K.},
  year = {2007},
  journal = {The annals of statistics},
  volume = {35},
  number = {6},
  pages = {2769--2794},
  issn = {0090-5364}
}

@article{tackmanDepressionNegativeEmotionality2018,
  title = {Depression, {{Negative Emotionality}}, and {{Self-Referential Language}}: {{A Multi-Lab}}, {{Multi-Measure}}, and {{Multi-Language-Task Research Synthesis}}},
  shorttitle = {Depression, {{Negative Emotionality}}, and {{Self-Referential Language}}},
  author = {Tackman, Allison and Sbarra, David and Carey, Angela and Donnellan, M. and Horn, Andrea and Holtzman, Nicholas and Edwards, To'Meisha and Pennebaker, James and Mehl, Matthias R.},
  year = {2018},
  month = mar,
  journal = {Journal of Personality and Social Psychology},
  volume = {116},
  doi = {10.1037/pspp0000187},
  abstract = {Depressive symptomatology is manifested in greater first-person singular pronoun use (i.e., I-talk), but when and for whom this effect is most apparent, and the extent to which it is specific to depression or part of a broader association between negative emotionality and I-talk, remains unclear. Using pooled data from N = 4,754 participants from 6 labs across 2 countries, we examined, in a preregistered analysis, how the depression{\textendash}I-talk effect varied by (a) first-person singular pronoun type (i.e., subjective, objective, and possessive), (b) the communication context in which language was generated (i.e., personal, momentary thought, identity-related, and impersonal), and (c) gender. Overall, there was a small but reliable positive correlation between depression and I-talk (r = .10, 95\% CI [.07, .13]). The effect was present for all first-person singular pronouns except the possessive type, in all communication contexts except the impersonal one, and for both females and males with little evidence of gender differences. Importantly, a similar pattern of results emerged for negative emotionality. Further, the depression{\textendash}I-talk effect was substantially reduced when controlled for negative emotionality but this was not the case when the negative emotionality{\textendash}I-talk effect was controlled for depression. These results suggest that the robust empirical link between depression and I-talk largely reflects a broader association between negative emotionality and I-talk. Self-referential language using first-person singular pronouns may therefore be better construed as a linguistic marker of general distress proneness or negative emotionality rather than as a specific marker of depression.},
  file = {/Users/timokoch/Zotero/storage/59ZZYIAS/Tackman et al. - 2018 - Depression, Negative Emotionality, and Self-Refere.pdf}
}

@inproceedings{tamAgeDetectionChat2009,
  title = {Age {{Detection}} in {{Chat}}},
  booktitle = {2009 {{IEEE International Conference}} on {{Semantic Computing}}},
  author = {Tam, Jenny and Martell, Craig H.},
  year = {2009},
  month = sep,
  pages = {33--39},
  publisher = {{IEEE}},
  address = {{Berkeley, CA, USA}},
  doi = {10.1109/ICSC.2009.37},
  urldate = {2019-07-29},
  abstract = {This paper presents the results of using statistical analysis and automatic text categorization to identify an author's age group based on the author's online chat posts. A Naive Bayesian Classifier and Support Vector Machine (SVM) model were used. The SVM model experiments generated an f-score measurement of 0.996 on test data distinguishing teens from adults. We also introduce an alternative method for generating ``stop words'' that chooses n-grams based on their relative distribution across the classes.},
  isbn = {978-1-4244-4962-0},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/ZV5P93WH/Tam und Martell - 2009 - Age Detection in Chat.pdf}
}

@inproceedings{tambuscioFactcheckingEffectViral2015,
  title = {Fact-Checking {{Effect}} on {{Viral Hoaxes}}: {{A Model}} of {{Misinformation Spread}} in {{Social Networks}}},
  shorttitle = {Fact-Checking {{Effect}} on {{Viral Hoaxes}}},
  booktitle = {Proceedings of the 24th {{International Conference}} on {{World Wide Web}} - {{WWW}} '15 {{Companion}}},
  author = {Tambuscio, Marcella and Ruffo, Giancarlo and Flammini, Alessandro and Menczer, Filippo},
  year = {2015},
  pages = {977--982},
  publisher = {{ACM Press}},
  address = {{Florence, Italy}},
  doi = {10.1145/2740908.2742572},
  urldate = {2019-05-23},
  abstract = {The Internet and online social networks have greatly facilitated and accelerated information diffusion processes, but at the same time they provide fertile ground for the spread of misinformation, rumors and hoaxes. The goal of this work is to introduce a simple modeling framework to study the diffusion of hoaxes and in particular how the availability of debunking information may contain their diffusion. As traditionally done in the mathematical modeling of information diffusion processes, we regard hoaxes as viruses: users can become infected if they are exposed to them, and turn into spreaders as a consequence. Upon verification, users can also turn into non-believers and spread the same attitude with a mechanism analogous to that of the hoax-spreaders. Both believers and non-believers, as time passes, can return to a susceptible state. Our model is characterized by four parameters: spreading rate, gullibility, probability to verify a hoax, and that to forget one's current belief. Simulations on homogeneous, heterogeneous, and real networks for a wide range of parameters values reveal a threshold for the factchecking probability that guarantees the complete removal of the hoax from the network. Via a mean field approximation, we establish that the threshold value does not depend on the spreading rate but only on the gullibility and forgetting probability. Our approach allows to quantitatively gauge the minimal reaction necessary to eradicate a hoax.},
  isbn = {978-1-4503-3473-0},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/6SAMMM26/Tambuscio et al. - 2015 - Fact-checking Effect on Viral Hoaxes A Model of M.pdf}
}

@article{tanhaLeiXuUniversity2016,
  title = {Lei {{Xu}}, {{University}} of {{Houston}}, {{United States Dragan Perakovic}}, {{University}} of {{Zagreb}}, {{Croatia}}},
  author = {Tanha, Ali Dehghan and Sher, Ali and Mukati, Altaf and Gradvohl, Andre Leon S and Manaf, Azizah Abd and Ahmed, Bestoun and Latino, Carl and Jak{\'o}bczak, Dariusz Jacek and Pham, Duc T},
  year = {2016},
  pages = {67},
  abstract = {This paper explores how botnets in smart devices are exacerbating identity crime. This paper places the refrigerator at the heart of this discussion of the Internet of things that has become connected through the Internet and thereby susceptible to botnets and the collection of personal identification information as an enabler for identity crime. The paper highlights the fallibility of these devices and provides some mechanism to deal with these new risks and presents discussion on the need to for this relationship to be further explored.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/8FRDP7J2/Tanha et al. - 2016 - Lei Xu, University of Houston, United States Draga.pdf}
}

@article{tausczikPsychologicalMeaningWords2009,
  title = {The {{Psychological Meaning}} of {{Words}}: {{LIWC}} and {{Computerized Text Analysis Methods}}},
  author = {Tausczik, Yla R. and Pennebaker, James W.},
  year = {2009},
  journal = {Journal of Language and Social Psychology},
  volume = {29},
  number = {1},
  pages = {24--54},
  issn = {0261-927X 1552-6526},
  doi = {10.1177/0261927x09351676},
  file = {/Users/timokoch/Zotero/storage/FD6FKMMF/Tausczik und Pennebaker - 2009 - The Psychological Meaning of Words LIWC and Compu.pdf}
}

@article{tayPsychometricValidityIssues2020,
  title = {Psychometric and {{Validity Issues}} in {{Machine Learning Approaches}} to {{Personality Assessment}}: {{A Focus}} on {{Social Media Text Mining}}},
  shorttitle = {Psychometric and {{Validity Issues}} in {{Machine Learning Approaches}} to {{Personality Assessment}}},
  author = {Tay, Louis and Woo, Sang Eun and Hickman, Louis and Saef, Rachel M.},
  editor = {Rauthmann, John},
  year = {2020},
  month = jul,
  journal = {European Journal of Personality},
  pages = {per.2290},
  issn = {0890-2070, 1099-0984},
  doi = {10.1002/per.2290},
  urldate = {2020-08-17},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/S86A9IID/Tay et al. - 2020 - Psychometric and Validity Issues in Machine Learni.pdf}
}

@misc{TextAnalysisTool,
  title = {Text Analysis as a Tool for Analyzing Conversation in Online Support Groups | {{Request PDF}}},
  journal = {ResearchGate},
  urldate = {2019-02-12},
  abstract = {ResearchGate is a network dedicated to science and research. Connect, collaborate and discover scientific publications, jobs and conferences. All for free.},
  howpublished = {https://www.researchgate.net/publication/221518011\_Text\_analysis\_as\_a\_tool\_for\_analyzing\_conversation\_in\_online\_support\_groups},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/7PLPMNKT/221518011_Text_analysis_as_a_tool_for_analyzing_conversation_in_online_support_groups.html}
}

@inproceedings{thilakaratneKnowledgedrivenApproachPredict2016,
  title = {Knowledge-Driven Approach to Predict Personality Traits by Leveraging Social Media Data},
  booktitle = {Web {{Intelligence}} ({{WI}}), 2016 {{IEEE}}/{{WIC}}/{{ACM International Conference}} On},
  author = {Thilakaratne, Menasha and Weerasinghe, Ruvan and Perera, Sujan},
  year = {2016},
  pages = {288--295},
  publisher = {{IEEE}},
  isbn = {1-5090-4470-1}
}

@article{tibshiraniRegressionShrinkageSelection1996,
  title = {Regression {{Shrinkage}} and {{Selection}} via the {{Lasso}}},
  author = {Tibshirani, Robert},
  year = {1996},
  journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
  volume = {58},
  number = {1},
  eprint = {2346178},
  eprinttype = {jstor},
  pages = {267--288},
  publisher = {{[Royal Statistical Society, Wiley]}},
  issn = {0035-9246},
  urldate = {2023-01-30},
  abstract = {We propose a new method for estimation in linear models. The `lasso' minimizes the residual sum of squares subject to the sum of the absolute value of the coefficients being less than a constant. Because of the nature of this constraint it tends to produce some coefficients that are exactly 0 and hence gives interpretable models. Our simulation studies suggest that the lasso enjoys some of the favourable properties of both subset selection and ridge regression. It produces interpretable models like subset selection and exhibits the stability of ridge regression. There is also an interesting relationship with recent work in adaptive function estimation by Donoho and Johnstone. The lasso idea is quite general and can be applied in a variety of statistical models: extensions to generalized regression models and tree-based models are briefly described.}
}

@article{tibshiraniRegressionShrinkageSelection1996a,
  title = {Regression Shrinkage and Selection via the Lasso},
  author = {Tibshirani, Robert},
  year = {1996},
  journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
  pages = {267--288},
  issn = {0035-9246},
  file = {/Users/timokoch/Zotero/storage/QZUS759M/Tibshirani - 1996 - Regression shrinkage and selection via the lasso.pdf}
}

@article{tidwellPersonalityInformationSeeking2005,
  title = {Personality and {{Information Seeking}}: {{Understanding How Traits Influence Information-Seeking Behaviors}}},
  shorttitle = {Personality and {{Information Seeking}}},
  author = {Tidwell, M.},
  year = {2005},
  month = jan,
  journal = {Journal of Business Communication},
  volume = {42},
  number = {1},
  pages = {51--77},
  issn = {0021-9436},
  doi = {10.1177/0021943604272028},
  urldate = {2019-05-27},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/B4YZ9W6X/Tidwell - 2005 - Personality and Information Seeking Understanding.pdf}
}

@article{toisoulEstimationContinuousValence2021,
  title = {Estimation of Continuous Valence and Arousal Levels from Faces in Naturalistic Conditions},
  author = {Toisoul, Antoine and Kossaifi, Jean and Bulat, Adrian and Tzimiropoulos, Georgios and Pantic, Maja},
  year = {2021},
  month = jan,
  journal = {Nature Machine Intelligence},
  volume = {3},
  number = {1},
  pages = {42--50},
  publisher = {{Nature Publishing Group}},
  issn = {2522-5839},
  doi = {10.1038/s42256-020-00280-0},
  urldate = {2021-12-20},
  abstract = {Facial affect analysis aims to create new types of human{\textendash}computer interactions by enabling computers to better understand a person's emotional state in order to provide ad hoc help and interactions. Since discrete emotional classes (such as anger, happiness, sadness and so on) are not representative of the full spectrum of emotions displayed by humans on a daily basis, psychologists typically rely on dimensional measures, namely valence (how positive the emotional display is) and arousal (how calming or exciting the emotional display looks like). However, while estimating these values from a face is natural for humans, it is extremely difficult for computer-based systems and automatic estimation of valence and arousal in naturalistic conditions is an open problem. Additionally, the subjectivity of these measures makes it hard to obtain good quality data. Here we introduce a novel deep neural network architecture to analyse facial affect in naturalistic conditions with a high level of accuracy. The proposed network integrates face alignment and jointly estimates both categorical and continuous emotions in a single pass, making it suitable for real-time applications. We test our method on three challenging datasets collected in naturalistic conditions and show that our approach outperforms all previous methods. We also discuss caveats regarding the use of this tool, and ethical aspects that must be considered in its application.},
  copyright = {2021 The Author(s), under exclusive licence to Springer Nature Limited},
  langid = {english},
  keywords = {Human behaviour,Machine learning},
  annotation = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Human behaviour;Machine learning Subject\_term\_id: human-behaviour;machine-learning},
  file = {/Users/timokoch/Zotero/storage/JE38KTHC/Toisoul et al. - 2021 - Estimation of continuous valence and arousal level.pdf;/Users/timokoch/Zotero/storage/CC2GFTE5/s42256-020-00280-0.html}
}

@article{toisoulEstimationContinuousValence2021a,
  title = {Estimation of Continuous Valence and Arousal Levels from Faces in Naturalistic Conditions},
  author = {Toisoul, Antoine and Kossaifi, Jean and Bulat, Adrian and Tzimiropoulos, Georgios and Pantic, Maja},
  year = {2021},
  month = jan,
  journal = {Nature Machine Intelligence},
  volume = {3},
  number = {1},
  pages = {42--50},
  publisher = {{Nature Publishing Group}},
  issn = {2522-5839},
  doi = {10.1038/s42256-020-00280-0},
  urldate = {2021-12-20},
  abstract = {Facial affect analysis aims to create new types of human{\textendash}computer interactions by enabling computers to better understand a person's emotional state in order to provide ad hoc help and interactions. Since discrete emotional classes (such as anger, happiness, sadness and so on) are not representative of the full spectrum of emotions displayed by humans on a daily basis, psychologists typically rely on dimensional measures, namely valence (how positive the emotional display is) and arousal (how calming or exciting the emotional display looks like). However, while estimating these values from a face is natural for humans, it is extremely difficult for computer-based systems and automatic estimation of valence and arousal in naturalistic conditions is an open problem. Additionally, the subjectivity of these measures makes it hard to obtain good quality data. Here we introduce a novel deep neural network architecture to analyse facial affect in naturalistic conditions with a high level of accuracy. The proposed network integrates face alignment and jointly estimates both categorical and continuous emotions in a single pass, making it suitable for real-time applications. We test our method on three challenging datasets collected in naturalistic conditions and show that our approach outperforms all previous methods. We also discuss caveats regarding the use of this tool, and ethical aspects that must be considered in its application.},
  copyright = {2021 The Author(s), under exclusive licence to Springer Nature Limited},
  langid = {english},
  keywords = {Human behaviour,Machine learning},
  annotation = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Human behaviour;Machine learning Subject\_term\_id: human-behaviour;machine-learning},
  file = {/Users/timokoch/Zotero/storage/NZPMDNP4/Toisoul et al. - 2021 - Estimation of continuous valence and arousal level.pdf;/Users/timokoch/Zotero/storage/FBPQFQH2/s42256-020-00280-0.html}
}

@misc{topFrauenBenutzenHaeufiger2021,
  title = {{{\guillemotleft}Frauen benutzen h{\"a}ufiger Emojis als M{\"a}nner{\guillemotright}}},
  author = {TOP},
  year = {2021},
  urldate = {2023-02-14},
  abstract = {Eine Studie der Universit{\"a}t St.Gallen hat den Sprachgebrauch in privaten Sofortnachrichten wie WhatsApp analysiert. J{\"u}ngere und {\"a}ltere Menschen schreiben anders, genauso wie Frauen und M{\"a}nner unterschiedlich kommunizieren.},
  howpublished = {https://www.toponline.ch/news/stgallen/detail/news/frauen-benutzen-eher-emojis-als-maenner-00168766/},
  langid = {ngerman},
  file = {/Users/timokoch/Zotero/storage/6ETZ2T8T/frauen-benutzen-eher-emojis-als-maenner-00168766.html}
}

@article{tossellLongitudinalStudyEmoticon2012,
  title = {A Longitudinal Study of Emoticon Use in Text Messaging from Smartphones},
  author = {Tossell, Chad C. and Kortum, Philip and Shepard, Clayton and {Barg-Walkow}, Laura H. and Rahmati, Ahmad and Zhong, Lin},
  year = {2012},
  month = mar,
  journal = {Computers in Human Behavior},
  volume = {28},
  number = {2},
  pages = {659--663},
  issn = {07475632},
  doi = {10.1016/j.chb.2011.11.012},
  urldate = {2019-07-29},
  abstract = {Our goal in the present study was to understand how emoticons are used in text messaging and, in particular, how genders differed in the frequency and variety of emoticons used via this medium. Previous research has found small and sundry differences in emotive expression online suggesting that technology has closed the gender gap. However, the data collected in these studies were public. In this study, we collected real portions of private communications data from individuals' smartphones over a 6-month period. SMS messages, in general, were not used very much overall, with only 4\% of all messages containing at least one emoticon. Still, differences between genders manifested in the amount and variety of emoticons used. Females sent more messages with emoticons; however, surprisingly, males used a more diverse range of emoticons.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/2T8P6BMU/Tossell et al. - 2012 - A longitudinal study of emoticon use in text messa.pdf}
}

@article{tovDetectingWellbeingComputerized2013,
  title = {Detecting Well-Being via Computerized Content Analysis of Brief Diary Entries.},
  author = {Tov, William and Ng, Kok Leong and Lin, Han and Qiu, Lin},
  year = {2013},
  month = dec,
  journal = {Psychological Assessment},
  volume = {25},
  number = {4},
  pages = {1069--1078},
  issn = {1939-134X, 1040-3590},
  doi = {10.1037/a0033007},
  urldate = {2020-12-02},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/4JK86IKD/Tov et al. - 2013 - Detecting well-being via computerized content anal.pdf}
}

@article{tovDetectingWellbeingComputerized2013a,
  title = {Detecting Well-Being via Computerized Content Analysis of Brief Diary Entries},
  author = {Tov, William and Ng, Kok Leong and Lin, Han and Qiu, Lin},
  year = {2013},
  month = dec,
  journal = {Psychological Assessment},
  volume = {25},
  number = {4},
  pages = {1069--1078},
  issn = {1939-134X},
  doi = {10.1037/a0033007},
  abstract = {Two studies evaluated the correspondence between self-reported well-being and codings of emotion and life content by the Linguistic Inquiry and Word Count (LIWC; Pennebaker, Booth, \& Francis, 2011). Open-ended diary responses were collected from 206 participants daily for 3 weeks (Study 1) and from 139 participants twice a week for 8 weeks (Study 2). LIWC negative emotion consistently correlated with self-reported negative emotion. LIWC positive emotion correlated with self-reported positive emotion in Study 1 but not in Study 2. No correlations were observed with global life satisfaction. Using a co-occurrence coding method to combine LIWC emotion codings with life-content codings, we estimated the frequency of positive and negative events in 6 life domains (family, friends, academics, health, leisure, and money). Domain-specific event frequencies predicted self-reported satisfaction in all domains in Study 1 but not consistently in Study 2. We suggest that the correspondence between LIWC codings and self-reported well-being is affected by the number of writing samples collected per day as well as the target period (e.g., past day vs. past week) assessed by the self-report measure. Extensions and possible implications for the analyses of similar types of open-ended data (e.g., social media messages) are discussed. (PsycINFO Database Record (c) 2013 APA, all rights reserved).},
  langid = {english},
  pmid = {23730828},
  keywords = {Anxiety,Depression,Emotions,Female,Humans,Life Change Events,Linguistics,Male,Medical Records,Natural Language Processing,Psychometrics,Quality of Life,Reproducibility of Results,Singapore,Software,Students,Writing,Young Adult}
}

@misc{triantafyllopoulosInsightsModellingPhysiological2022,
  title = {Insights on {{Modelling Physiological}}, {{Appraisal}}, and {{Affective Indicators}} of {{Stress}} Using {{Audio Features}}},
  author = {Triantafyllopoulos, Andreas and Z{\"a}nkert, Sandra and Baird, Alice and Konzok, Julian and Kudielka, Brigitte M. and Schuller, Bj{\"o}rn W.},
  year = {2022},
  month = may,
  number = {arXiv:2205.04328},
  eprint = {2205.04328},
  primaryclass = {cs, eess},
  institution = {{arXiv}},
  urldate = {2022-05-20},
  abstract = {Stress is a major threat to well-being that manifests in a variety of physiological and mental symptoms. Utilising speech samples collected while the subject is undergoing an induced stress episode has recently shown promising results for the automatic characterisation of individual stress responses. In this work, we introduce new findings that shed light onto whether speech signals are suited to model physiological biomarkers, as obtained via cortisol measurements, or self-assessed appraisal and affect measurements. Our results show that different indicators impact acoustic features in a diverse way, but that their complimentary information can nevertheless be effectively harnessed by a multi-tasking architecture to improve prediction performance for all of them.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/Users/timokoch/Zotero/storage/CUMLD5T9/Triantafyllopoulos et al. - 2022 - Insights on Modelling Physiological, Appraisal, an.pdf;/Users/timokoch/Zotero/storage/F95C4E26/2205.html}
}

@article{truongArousalValencePrediction,
  title = {Arousal and {{Valence}} Prediction in Spontaneous Emotional Speech: Felt versus Perceived Emotion},
  author = {Truong, Khiet P and {van Leeuwen}, David A and Neerincx, Mark A},
  pages = {4},
  abstract = {In this paper, we describe emotion recognition experiments carried out for spontaneous affective speech with the aim to compare the added value of annotation of felt emotion versus annotation of perceived emotion. Using speech material available in the TNO-GAMING corpus (a corpus containing audiovisual recordings of people playing videogames), speech-based affect recognizers were developed that can predict Arousal and Valence scalar values. Two types of recognizers were developed in parallel: one trained with felt emotion annotations (generated by the gamers themselves) and one trained with perceived/observed emotion annotations (generated by a group of observers). The experiments showed that, in speech, with the methods and features currently used, observed emotions are easier to predict than felt emotions. The results suggest that recognition performance strongly depends on how and by whom the emotion annotations are carried out.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/4LLSHMQY/Truong et al. - Arousal and Valence prediction in spontaneous emot.pdf}
}

@article{tutenUNDERSTANDINGDIFFERENCESWEB2001,
  title = {{{UNDERSTANDING DIFFERENCES IN WEB USAGE}}: {{THE ROLE OF NEED FOR COGNITION AND THE FIVE FACTOR MODEL OF PERSONALITY}}},
  shorttitle = {{{UNDERSTANDING DIFFERENCES IN WEB USAGE}}},
  author = {Tuten, Tracy L. and Bosnjak, Michael},
  year = {2001},
  month = jan,
  journal = {Social Behavior and Personality: an international journal},
  volume = {29},
  number = {4},
  pages = {391--398},
  issn = {03012212},
  doi = {10.2224/sbp.2001.29.4.391},
  urldate = {2019-05-27},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/LHA8ABJQ/Tuten und Bosnjak - 2001 - UNDERSTANDING DIFFERENCES IN WEB USAGE THE ROLE O.pdf}
}

@article{tzirakisEndtoendMultimodalAffect2021,
  title = {End-to-End Multimodal Affect Recognition in Real-World Environments},
  author = {Tzirakis, Panagiotis and Chen, Jiaxin and Zafeiriou, Stefanos and Schuller, Bj{\"o}rn},
  year = {2021},
  month = apr,
  journal = {Information Fusion},
  volume = {68},
  pages = {46--53},
  issn = {1566-2535},
  doi = {10.1016/j.inffus.2020.10.011},
  urldate = {2022-11-08},
  abstract = {Automatic affect recognition in real-world environments is an important task towards a natural interaction between humans and machines. The recent years, several advancements have been accomplished in determining the emotional states with the use of Deep Neural Networks (DNNs). In this paper, we propose an emotion recognition system that utilizes the raw text, audio and visual information in an end-to-end manner. To capture the emotional states of a person, robust features need to be extracted from the various modalities. To this end, we utilize Convolutional Neural Networks (CNNs) and propose a novel transformer-based architecture for the text modality that can robustly capture the semantics of sentences. We develop an audio model to process the audio channel, and adopt a variation of a high resolution network (HRNet) to process the visual modality. To fuse the modality-specific features, we propose novel attention-based methods. To capture the temporal dynamics in the signal, we utilize Long Short-Term Memory (LSTM) networks. Our model is trained on the SEWA dataset of the AVEC 2017 research sub-challenge on emotion recognition, and produces state-of-the-art results in the text, visual and multimodal domains, and comparable performance in the audio case when compared with the winning papers of the challenge that use several hand-crafted and DNN features. Code is available at: https://github.com/glam-imperial/multimodal-affect-recognition.},
  langid = {english},
  keywords = {Deep learning,Emotion recognition,Multimodal machine learning,Sentiment analysis},
  file = {/Users/timokoch/Zotero/storage/P8RP2UZ4/S1566253520303808.html}
}

@article{ueberwasserWhatSwitzerlandCorpusbased2017,
  title = {What's up, {{Switzerland}}? {{A}} Corpus-Based Research Project in a Multilingual Country},
  author = {Ueberwasser, Simone and Stark, Elisabeth},
  year = {2017},
  journal = {Linguistik online},
  volume = {84},
  number = {5},
  issn = {1615-3014},
  file = {/Users/timokoch/Zotero/storage/47PILAPT/Ueberwasser und Stark - 2017 - What’s up, Switzerland A corpus-based research pr.pdf}
}

@misc{unitednationsDefinitionYouth2013,
  title = {Definition of {{Youth}}},
  author = {United Nations},
  year = {2013}
}

@misc{UsingAdversarialTraining2019,
  title = {Using Adversarial Training to Recognize Speakers' Emotions},
  year = {2019},
  month = may,
  journal = {Amazon Science},
  urldate = {2022-12-02},
  abstract = {A person's tone of voice can tell you a lot about how they're feeling. Not surprisingly, emotion recognition is an increasingly popular conversational-AI research topic.},
  howpublished = {https://www.amazon.science/blog/using-adversarial-training-to-recognize-speakers-emotions},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/75AHXJSI/using-adversarial-training-to-recognize-speakers-emotions.html}
}

@article{vaerenberghResponseStylesSurvey2013,
  title = {Response {{Styles}} in {{Survey Research}}: {{A Literature Review}} of {{Antecedents}}, {{Consequences}}, and {{Remedies}}},
  shorttitle = {Response {{Styles}} in {{Survey Research}}},
  author = {Vaerenbergh, Yves Van and Thomas, Troy},
  year = {2013},
  month = jun,
  journal = {International Journal of Public Opinion Research},
  volume = {25},
  pages = {195--217},
  doi = {10.1093/ijpor/eds021},
  abstract = {Although the purpose of questionnaire items is to obtain a person's opinion on a certain matter, a respondent's registered opinion may not reflect his or her ``true'' opinion because of random and systematic errors. Response styles (RSs) are a respondent's tendency to respond to survey questions in certain ways regardless of the content, and they contribute to systematic error. They affect univariate and multivariate distributions of data collected by rating scales and are alternative explanations for many research results. Despite this, RS are often not controlled in research. This article provides a comprehensive summary of the types of RS, lists their potential sources, and discusses ways to diagnose and control for them. Finally, areas for further research on RS are proposed.}
}

@article{vanberkelExperienceSamplingMethod2017,
  title = {The {{Experience Sampling Method}} on {{Mobile Devices}}},
  author = {Van Berkel, Niels and Ferreira, Denzil and Kostakos, Vassilis},
  year = {2017},
  month = dec,
  journal = {ACM Computing Surveys},
  volume = {50},
  number = {6},
  pages = {1--40},
  issn = {03600300},
  doi = {10.1145/3123988},
  urldate = {2019-02-08},
  langid = {english},
  keywords = {ambulatory assessment,data collection,ecological momentary assessment,EMA,ESM,Experience sampling method,in situ,methodology,mobile devices,qualitative data,sensor,smartphone},
  file = {/Users/timokoch/Zotero/storage/8XJBL73X/Berkel et al. - 2017 - The Experience Sampling Method on Mobile Devices.pdf}
}

@article{vanberkelExperienceSamplingMethod2018,
  title = {The {{Experience Sampling Method}} on {{Mobile Devices}}},
  author = {{van Berkel}, Niels and Ferreira, Denzil and Kostakos, Vassilis},
  year = {2018},
  month = nov,
  journal = {ACM Computing Surveys},
  volume = {50},
  number = {6},
  pages = {1--40},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/3123988},
  urldate = {2022-05-10},
  abstract = {The Experience Sampling Method (ESM) is used by scientists from various disciplines to gather insights into the intra-psychic elements of human life. Researchers have used the ESM in a wide variety of studies, with the method seeing increased popularity. Mobile technologies have enabled new possibilities for the use of the ESM, while simultaneously leading to new conceptual, methodological, and technological challenges. In this survey, we provide an overview of the history of the ESM, usage of this methodology in the computer science discipline, as well as its evolution over time. Next, we identify and discuss important considerations for ESM studies on mobile devices, and analyse the particular methodological parameters scientists should consider in their study design. We reflect on the existing tools that support the ESM methodology and discuss the future development of such tools. Finally, we discuss the effect of future technological developments on the use of the ESM and identify areas requiring further investigation.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/A39FBD69/van Berkel et al. - 2018 - The Experience Sampling Method on Mobile Devices.pdf}
}

@article{vandelooTextBasedAgeGender2016,
  title = {Text-{{Based Age}} and {{Gender Prediction}} for {{Online Safety Monitoring}}},
  author = {{van de Loo}, Janneke and De Pauw, Guy and Daelemans, Walter},
  year = {2016},
  journal = {International Journal of Cyber-Security and Digital Forensics},
  volume = {5},
  number = {1},
  pages = {46--60},
  issn = {2305-0012},
  doi = {10.17781/P002012},
  urldate = {2020-03-30},
  abstract = {This paper explores the capabilities of text-based age and gender prediction geared towards the application of detecting harmful content and conduct on social media. More specifically, we focus on the use case of detecting sexual predators who try to ``groom'' children online and possibly provide false age and gender information in their user profiles. We perform age and gender classification experiments on a dataset of nearly 380,000 Dutch chat posts from a social network. We evaluate and compare binary age classifiers trained to separate younger and older authors according to different age boundaries and find that macro-averaged Fscores increase when the age boundary is raised. Furthermore, we show that use-case applicable performance levels can be achieved for the classification of minors versus adults, thereby providing a useful component in a cybersecurity monitoring tool for social network moderators.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/ZHG2XK3F/van de Loo und The Society of Digital Information and Wireless Communication - 2016 - Text-Based Age and Gender Prediction for Online Sa.pdf}
}

@article{vandergootBleachingTextAbstract2018,
  title = {Bleaching {{Text}}: {{Abstract Features}} for {{Cross-lingual Gender Prediction}}},
  shorttitle = {Bleaching {{Text}}},
  author = {{van der Goot}, Rob and Ljube{\v s}i{\'c}, Nikola and Matroos, Ian and Nissim, Malvina and Plank, Barbara},
  year = {2018},
  month = may,
  journal = {arXiv:1805.03122 [cs]},
  eprint = {1805.03122},
  primaryclass = {cs},
  urldate = {2020-03-30},
  abstract = {Gender prediction has typically focused on lexical and social network features, yielding good performance, but making systems highly language-, topic-, and platformdependent. Cross-lingual embeddings circumvent some of these limitations, but capture gender-specific style less. We propose an alternative: bleaching text, i.e., transforming lexical strings into more abstract features. This study provides evidence that such features allow for better transfer across languages. Moreover, we present a first study on the ability of humans to perform cross-lingual gender prediction. We find that human predictive power proves similar to that of our bleached models, and both perform better than lexical models.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/timokoch/Zotero/storage/G4Z6FCAT/van der Goot et al. - 2018 - Bleaching Text Abstract Features for Cross-lingua.pdf}
}

@article{vargoAgendasettingPowerFake2018,
  title = {The Agenda-Setting Power of Fake News: {{A}} Big Data Analysis of the Online Media Landscape from 2014 to 2016},
  shorttitle = {The Agenda-Setting Power of Fake News},
  author = {Vargo, Chris J and Guo, Lei and Amazeen, Michelle A},
  year = {2018},
  month = may,
  journal = {New Media \& Society},
  volume = {20},
  number = {5},
  pages = {2028--2049},
  issn = {1461-4448, 1461-7315},
  doi = {10.1177/1461444817712086},
  urldate = {2019-05-23},
  abstract = {This study examines the agenda-setting power of fake news and fact-checkers who fight them through a computational look at the online mediascape from 2014 to 2016. Although our study confirms that content from fake news websites is increasing, these sites do not exert excessive power. Instead, fake news has an intricately entwined relationship with online partisan media, both responding and setting its issue agenda. In 2016, partisan media appeared to be especially susceptible to the agendas of fake news, perhaps due to the election. Emerging news media are also responsive to the agendas of fake news, but to a lesser degree. Fake news coverage itself is diverging and becoming more autonomous topically. While fact-checkers are autonomous in their selection of issues to cover, they were not influential in determining the agenda of news media overall, and their influence appears to be declining, illustrating the difficulties factcheckers face in disseminating their corrections.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/9NSEXFB3/Vargo et al. - 2018 - The agenda-setting power of fake news A big data .pdf;/Users/timokoch/Zotero/storage/ATCQDT5D/Vargo et al. - 2018 - The agenda-setting power of fake news A big data .pdf}
}

@article{vazireKnowingMeKnowing2008,
  title = {Knowing Me, Knowing You: {{The}} Accuracy and Unique Predictive Validity of Self-Ratings and Other-Ratings of Daily Behavior},
  shorttitle = {Knowing Me, Knowing You},
  author = {Vazire, Simine and Mehl, Matthias R.},
  year = {2008},
  journal = {Journal of Personality and Social Psychology},
  volume = {95},
  number = {5},
  pages = {1202--1216},
  issn = {1939-1315(Electronic),0022-3514(Print)},
  doi = {10.1037/a0013314},
  abstract = {Many people assume that they know themselves better than anyone else knows them. Recent research on inaccuracies in self-perception, however, suggests that self-knowledge may be more limited than people typically assume. In this article, the authors examine the possibility that people may know a person as well as (or better than) that person knows himself or herself. In Study 1, the authors document the strength of laypeople's beliefs that the self is the best expert. In Study 2, the authors provide a direct test of self- and other-accuracy using an objective and representative behavioral criterion. To do this, the authors compared self- and other-ratings of daily behavior to real-life measures of act frequencies assessed unobtrusively over 4 days. Our results show that close others are as accurate as the self in predicting daily behavior. Furthermore, accuracy varies across behaviors for both the self and for others, and the two perspectives often independently predict behavior. These findings suggest that there is no single perspective from which a person is known best and that both the self and others possess unique insight into how a person typically behaves. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Behavior,Informants,Prediction,Self-Concept,Self-Perception},
  file = {/Users/timokoch/Zotero/storage/G2IYFLQY/2008-14857-013.html}
}

@incollection{verheijenCollectingFacebookPosts2016,
  title = {Collecting {{Facebook Posts}} and {{WhatsApp Chats}}},
  booktitle = {Text, {{Speech}}, and {{Dialogue}}},
  author = {Verheijen, Lieke and Stoop, Wessel},
  year = {2016},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {249--258},
  publisher = {{Springer}},
  address = {{Cham}},
  isbn = {978-3-319-45509-9 978-3-319-45510-5}
}

@incollection{verheijenWhatsAppSocialMedia2017,
  title = {{{WhatsApp}} with Social Media Slang? {{Youth}} Language Use in {{Dutch}} Written Computer-Mediated Communication},
  shorttitle = {{{WhatsApp}} with Social Media Slang?},
  author = {Verheijen, Lieke},
  year = {2017},
  month = jan,
  pages = {72--101},
  abstract = {Communication via new media or social media, i.e. computer-mediated communication (CMC), is now omnipresent. The 'CMC language' that youngsters use in such media often diverges from the 'official' spelling and grammar rules of the standard language. Many parents and teachers are thus critical of CMC language, because they view Standard Dutch as a strict norm. Yet among youths it enjoys a certain status, and is regarded as playful, informal, and cool. So an interesting power conflict exists between the overt prestige of the standard language and the covert prestige of CMC language among youngsters. To determine how Dutch youths' language use in computer-mediated messages differs from Standard Dutch, an extensive register analysis was conducted of about 400,000 tokens of digital texts, produced by youths of two age groups-adolescents (12-17 years old) and young adults (18-23 years old), in four social media-SMS text messages; instant messages, viz. MSN chats and WhatsApp messages; and microblogs, namely tweets. This corpus study focuses on various linguistic features of four writing dimensions: orthography (textisms, misspellings, typos), typo-graphy (emoticons, symbols), syntax (omissions), and lexis (borrowings, interjections). The results suggest that the variables of age and medium are of crucial importance for (Dutch) youths' online language use.},
  file = {/Users/timokoch/Zotero/storage/PFBBD6S5/Verheijen - 2017 - WhatsApp with social media slang Youth language u.pdf}
}

@article{ververidisEmotionalSpeechRecognition2006,
  title = {Emotional Speech Recognition: {{Resources}}, Features, and Methods},
  shorttitle = {Emotional Speech Recognition},
  author = {Ververidis, Dimitrios and Kotropoulos, Constantine},
  year = {2006},
  month = sep,
  journal = {Speech Communication},
  volume = {48},
  number = {9},
  pages = {1162--1181},
  issn = {01676393},
  doi = {10.1016/j.specom.2006.04.003},
  urldate = {2021-11-17},
  abstract = {In this paper we overview emotional speech recognition having in mind three goals. The first goal is to provide an up-todate record of the available emotional speech data collections. The number of emotional states, the language, the number of speakers, and the kind of speech are briefly addressed. The second goal is to present the most frequent acoustic features used for emotional speech recognition and to assess how the emotion affects them. Typical features are the pitch, the formants, the vocal tract cross-section areas, the mel-frequency cepstral coefficients, the Teager energy operator-based features, the intensity of the speech signal, and the speech rate. The third goal is to review appropriate techniques in order to classify speech into emotional states. We examine separately classification techniques that exploit timing information from which that ignore it. Classification techniques based on hidden Markov models, artificial neural networks, linear discriminant analysis, k-nearest neighbors, support vector machines are reviewed.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/Z9RSSXUF/Ververidis und Kotropoulos - 2006 - Emotional speech recognition Resources, features,.pdf}
}

@inproceedings{vganesanEmpiricalEvaluationPretrained2021,
  title = {Empirical {{Evaluation}} of {{Pre-trained Transformers}} for {{Human-Level NLP}}: {{The Role}} of {{Sample Size}} and {{Dimensionality}}},
  shorttitle = {Empirical {{Evaluation}} of {{Pre-trained Transformers}} for {{Human-Level NLP}}},
  booktitle = {Proceedings of the 2021 {{Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Human Language Technologies}}},
  author = {V Ganesan, Adithya and Matero, Matthew and Ravula, Aravind Reddy and Vu, Huy and Schwartz, H. Andrew},
  year = {2021},
  month = jun,
  pages = {4515--4532},
  publisher = {{Association for Computational Linguistics}},
  address = {{Online}},
  doi = {10.18653/v1/2021.naacl-main.357},
  urldate = {2022-08-20},
  abstract = {In human-level NLP tasks, such as predicting mental health, personality, or demographics, the number of observations is often smaller than the standard 768+ hidden state sizes of each layer within modern transformer-based language models, limiting the ability to effectively leverage transformers. Here, we provide a systematic study on the role of dimension reduction methods (principal components analysis, factorization techniques, or multi-layer auto-encoders) as well as the dimensionality of embedding vectors and sample sizes as a function of predictive performance. We first find that fine-tuning large models with a limited amount of data pose a significant difficulty which can be overcome with a pre-trained dimension reduction regime. RoBERTa consistently achieves top performance in human-level tasks, with PCA giving benefit over other reduction methods in better handling users that write longer texts. Finally, we observe that a majority of the tasks achieve results comparable to the best performance with just 1/12 of the embedding dimensions.},
  file = {/Users/timokoch/Zotero/storage/PZTLDF5W/V Ganesan et al. - 2021 - Empirical Evaluation of Pre-trained Transformers f.pdf}
}

@article{vinciarelliSurveyPersonalityComputing2014,
  title = {A {{Survey}} of {{Personality Computing}}},
  author = {Vinciarelli, Alessandro and Mohammadi, Gelareh},
  year = {2014},
  month = jul,
  journal = {IEEE Transactions on Affective Computing},
  volume = {5},
  number = {3},
  pages = {273--291},
  issn = {1949-3045},
  doi = {10.1109/TAFFC.2014.2330816},
  urldate = {2019-01-31},
  abstract = {Personality is a psychological construct aimed at explaining the wide variety of human behaviors in terms of a few, stable and measurable individual characteristics. In this respect, any technology involving understanding, prediction and synthesis of human behavior is likely to benefit from Personality Computing approaches, i.e. from technologies capable of dealing with human personality. This paper is a survey of such technologies and it aims at providing not only a solid knowledge base about the state-of-the-art, but also a conceptual model underlying the three main problems addressed in the literature, namely Automatic Personality Recognition (inference of the true personality of an individual from behavioral evidence), Automatic Personality Perception (inference of personality others attribute to an individual based on her observable behavior) and Automatic Personality Synthesis (generation of artificial personalities via embodied agents). Furthermore, the article highlights the issues still open in the field and identifies potential application areas.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/CSD7W4E6/Vinciarelli und Mohammadi - 2014 - A Survey of Personality Computing.pdf}
}

@article{vineNaturalEmotionVocabularies2020,
  title = {Natural Emotion Vocabularies as Windows on Distress and Well-Being},
  author = {Vine, Vera and Boyd, Ryan L. and Pennebaker, James W.},
  year = {2020},
  month = sep,
  journal = {Nature Communications},
  volume = {11},
  number = {1},
  pages = {4525},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-020-18349-0},
  urldate = {2020-11-20},
  abstract = {To date we know little about natural emotion word repertoires, and whether or how they are associated with emotional functioning. Principles from linguistics suggest that the richness or diversity of individuals' actively used emotion vocabularies may correspond with their typical emotion experiences. The current investigation measures active emotion vocabularies in participant-generated natural speech and examined their relationships to individual differences in mood, personality, and physical and emotional well-being. Study 1 analyzes stream-of-consciousness essays by 1,567 college students. Study 2 analyzes public blogs written by over 35,000 individuals. The studies yield consistent findings that emotion vocabulary richness corresponds broadly with experience. Larger negative emotion vocabularies correlate with more psychological distress and poorer physical health. Larger positive emotion vocabularies correlate with higher well-being and better physical health. Findings support theories linking language use and development with lived experience and may have future clinical implications pending further research.},
  copyright = {2020 The Author(s)},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/WQJJE56I/Vine et al. - 2020 - Natural emotion vocabularies as windows on distres.pdf;/Users/timokoch/Zotero/storage/FV3DC5E6/s41467-020-18349-0.html}
}

@book{vlahosTalkMeHow2019,
  title = {Talk to {{Me}}: {{How Voice Computing Will Transform}} the {{Way We Live}}, {{Work}}, and {{Think}}},
  shorttitle = {Talk to {{Me}}},
  author = {Vlahos, James},
  year = {2019},
  publisher = {{Eamon Dolan Books}},
  file = {/Users/timokoch/Zotero/storage/ZVMJBSHZ/books.html}
}

@incollection{vlasenkoInfluencePhoneticContent2008,
  title = {On the {{Influence}} of {{Phonetic Content Variation}} for {{Acoustic Emotion Recognition}}},
  booktitle = {Perception in {{Multimodal Dialogue Systems}}},
  author = {Vlasenko, Bogdan and Schuller, Bj{\"o}rn and Wendemuth, Andreas and Rigoll, Gerhard},
  editor = {Andr{\'e}, Elisabeth and Dybkj{\ae}r, Laila and Minker, Wolfgang and Neumann, Heiko and Pieraccini, Roberto and Weber, Michael},
  year = {2008},
  volume = {5078},
  pages = {217--220},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  issn = {0302-9743, 1611-3349},
  doi = {10.1007/978-3-540-69369-7_24},
  urldate = {2021-11-28},
  abstract = {Acoustic Modeling in today's emotion recognition engines employs general models independent of the spoken phonetic content. This seems to work well enough given sufficient instances to cover for a broad variety of phonetic structures and emotions at the same time. However, data is usually sparse in the field and the question arises whether unit specific models as word emotion models could outperform the typical general models. In this respect this paper tries to answer the question how strongly acoustic emotion models depend on the textual and phonetic content. We investigate the influence on the turn and word level by use of state-of-the-art techniques for frame and word modeling on the well-known public Berlin Emotional Speech and Speech Under Simulated and Actual Stress databases. In the result it is clearly shown that the phonetic structure does strongly influence the accuracy of emotion recognition.},
  isbn = {978-3-540-69368-0 978-3-540-69369-7},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/2RZDELIH/Vlasenko et al. - 2008 - On the Influence of Phonetic Content Variation for.pdf}
}

@incollection{vogtAutomaticRecognitionEmotions2008,
  title = {Automatic {{Recognition}} of {{Emotions}} from {{Speech}}: {{A Review}} of the {{Literature}} and {{Recommendations}} for {{Practical Realisation}}},
  shorttitle = {Automatic {{Recognition}} of {{Emotions}} from {{Speech}}},
  booktitle = {Affect and {{Emotion}} in {{Human-Computer Interaction}}},
  author = {Vogt, Thurid and Andr{\'e}, Elisabeth and Wagner, Johannes},
  editor = {Peter, Christian and Beale, Russell},
  year = {2008},
  volume = {4868},
  pages = {75--91},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  issn = {0302-9743, 1611-3349},
  doi = {10.1007/978-3-540-85099-1_7},
  urldate = {2021-06-30},
  abstract = {In this article we give guidelines on how to address the major technical challenges of automatic emotion recognition from speech in human-computer interfaces, which include audio segmentation to find appropriate units for emotions, extraction of emotion relevant features, classification of emotions, and training databases with emotional speech. Research so far has mostly dealt with offline evaluation of vocal emotions, and online processing has hardly been addressed. Online processing is, however, a necessary prerequisite for the realization of human-computer interfaces that analyze and respond to the user's emotions while he or she is interacting with an application. By means of a sample application, we demonstrate how the challenges arising from online processing may be solved. The overall objective of the paper is to help readers to assess the feasibility of human-computer interfaces that are sensitive to the user's emotional voice and to provide them with guidelines of how to technically realize such interfaces.},
  isbn = {978-3-540-85098-4 978-3-540-85099-1},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/SYJ5B5KF/Vogt et al. - 2008 - Automatic Recognition of Emotions from Speech A R.pdf}
}

@incollection{vogtLectureNotesComputer2008,
  title = {Lecture {{Notes}} in {{Computer Science}}},
  author = {Vogt, Thurid and Andre, Elisabeth and Wagner, Johannes},
  year = {2008},
  month = aug,
  pages = {75--91},
  doi = {10.1007/978-3-540-85099-1_7},
  abstract = {In this article we give guidelines on how to address the major technical challenges of automatic emotion recognition from speech in human-computer interfaces, which include audio segmentation to find appropriate units for emotions, extraction of emotion relevant features, classification of emotions, and training databases with emotional speech. Research so far has mostly dealt with offline evaluation of vocal emotions, and online processing has hardly been addressed. Online processing is, however, a necessary prerequisite for the realization of human-computer interfaces that analyze and respond to the user's emotions while he or she is interacting with an application. By means of a sample application, we demonstrate how the challenges arising from online processing may be solved. The overall objective of the paper is to help readers to assess the feasibility of human-computer interfaces that are sensitive to the user's emotional voice and to provide them with guidelines of how to technically realize such interfaces.},
  isbn = {978-3-540-85098-4},
  file = {/Users/timokoch/Zotero/storage/JP7V5PYW/Vogt et al. - 2008 - Lecture Notes in Computer Science.pdf}
}

@inproceedings{volkelUnderstandingEmojiInterpretation2019,
  title = {Understanding {{Emoji Interpretation}} through {{User Personality}} and {{Message Context}}},
  booktitle = {Proceedings of the 21st {{International Conference}} on {{Human-Computer Interaction}} with {{Mobile Devices}} and {{Services}}  - {{MobileHCI}} '19},
  author = {V{\"o}lkel, Sarah Theres and Buschek, Daniel and Pranjic, Jelena and Hussmann, Heinrich},
  year = {2019},
  pages = {1--12},
  publisher = {{ACM Press}},
  address = {{Taipei, Taiwan}},
  doi = {10.1145/3338286.3340114},
  urldate = {2019-10-07},
  abstract = {Emojis are commonly used as non-verbal cues in texting, yet may also lead to misunderstandings due to their often ambiguous meaning. User personality has been linked to understanding of emojis isolated from context, or via indirect personality assessment through text analysis. This paper presents the first study on the influence of personality (measured with BFI-2) on understanding of emojis, which are presented in concrete mobile messaging contexts: four recipients (parents, friend, colleague, partner) and four situations (information, arrangement, salutory, romantic). In particular, we presented short text chat scenarios in an online survey (N=646) and asked participants to add appropriate emojis. Our results show that personality factors influence the choice of emojis. In another open task participants compared emojis found as semantically similar by related work. Here, participants provided rich and varying emoji interpretations, even in defined contexts. We discuss implications for research and design of mobile texting interfaces.},
  isbn = {978-1-4503-6825-4},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/AJITVH4P/Völkel et al. - 2019 - Understanding Emoji Interpretation through User Pe.pdf}
}

@article{vragaMultiDimensionalApproachMeasuring,
  title = {A {{Multi-Dimensional Approach}} to {{Measuring News Media Literacy}}},
  author = {Vraga, Emily and Tully, Melissa and Kotcher, John E and Smithson, Anne-Bennett and {Broeckelman-Post}, Melissa},
  journal = {Journal of Media Literacy Education},
  pages = {13},
  abstract = {Measuring news media literacy is important in order for it to thrive in a variety of educational and civic contexts. This research builds on existing measures of news media literacy and two new scales are presented that measure self-perceived media literacy (SPML) and perceptions of the value of media literacy (VML). Research with a larger sample of college undergraduate students and a smaller sample of adults enabled the validation of these measures. Results confirm the value of conceptualizing news media literacy using the theoretical subcomponents of authors \& audiences, messages \& meaning, and representation \& realities. The VML scale, in particular, proved especially consequential in predicting knowledge about and attitudes towards the media.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/XFZQT7MI/Vraga et al. - A Multi-Dimensional Approach to Measuring News Med.pdf}
}

@inproceedings{waldMachinePredictionPersonality2012,
  title = {Machine Prediction of Personality from {{Facebook}} Profiles},
  booktitle = {Information {{Reuse}} and {{Integration}} ({{IRI}}), 2012 {{IEEE}} 13th {{International Conference}} On},
  author = {Wald, Randall and Khoshgoftaar, Taghi and Sumner, Chris},
  year = {2012},
  pages = {109--115},
  publisher = {{IEEE}},
  isbn = {1-4673-2284-9}
}

@inproceedings{wangAlexaCoachLeveraging2020,
  title = {Alexa as {{Coach}}: {{Leveraging Smart Speakers}} to {{Build Social Agents}} That {{Reduce Public Speaking Anxiety}}},
  shorttitle = {Alexa as {{Coach}}},
  booktitle = {Proceedings of the 2020 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Wang, Jinping and Yang, Hyun and Shao, Ruosi and Abdullah, Saeed and Sundar, S. Shyam},
  year = {2020},
  month = apr,
  pages = {1--13},
  publisher = {{ACM}},
  address = {{Honolulu HI USA}},
  doi = {10.1145/3313831.3376561},
  urldate = {2021-12-02},
  abstract = {Public speaking anxiety is one of the most common social phobias. We explore the feasibility of using a conversational agent to reduce this anxiety. We developed a public-speaking tutor on the Amazon Alexa platform that enables users to engage in cognitive reconstruction exercises. We also investigated how the sociability of the agent might affect its performance as a tutor. A user study of 53 college students with fear of public speaking showed that the interaction with the agent served to assuage pre-speech state anxiety. Agent sociability improved the sense of interpersonal closeness, which was associated with lower pre-speech anxiety. Moreover, sociability of the agent increased participants' satisfaction and their willingness to continue engagement. Our findings, thus, have implications not only for addressing public speaking anxiety in a scalable way but also for the design of future conversational agents using smart speaker platforms.},
  isbn = {978-1-4503-6708-0},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/QZCYQSW3/Wang et al. - 2020 - Alexa as Coach Leveraging Smart Speakers to Build.pdf}
}

@article{wangGenderTopicAudience,
  title = {Gender, Topic, and Audience Response: An Analysis of User-Generated Content on Facebook},
  author = {Wang, Yi-Chia and Burke, Moira and Kraut, Robert E},
  pages = {4},
  abstract = {Although both men and women communicate frequently on Facebook, we know little about what they talk about, whether their topics differ and how their network responds. Using Latent Dirichlet Allocation (LDA), we identify topics from more than half a million Facebook status updates and determine which topics are more likely to receive feedback, such as likes and comments. Women tend to share more personal topics (e.g., family matters), while men discuss more public ones (e.g., politics and sports). Generally, women receive more feedback than men, but "male" topics (those more often posted by men) receive more feedback, especially when posted by women.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/32DBDZV7/Wang et al. - Gender, topic, and audience response an analysis .pdf}
}

@article{wangReviewEmotionSensing2020,
  title = {A Review of Emotion Sensing: Categorization Models and Algorithms},
  shorttitle = {A Review of Emotion Sensing},
  author = {Wang, Zhaoxia and Ho, Seng-Beng and Cambria, Erik},
  year = {2020},
  month = dec,
  journal = {Multimedia Tools and Applications},
  volume = {79},
  number = {47},
  pages = {35553--35582},
  issn = {1573-7721},
  doi = {10.1007/s11042-019-08328-z},
  urldate = {2023-01-10},
  abstract = {Sentiment analysis consists in the identification of the sentiment polarity associated with a target object, such as a book, a movie or a phone. Sentiments reflect feelings and attitudes, while emotions provide a finer characterization of the sentiments involved. With the huge number of comments generated daily on the Internet, besides sentiment analysis, emotion identification has drawn keen interest from different researchers, businessmen and politicians for polling public opinions and attitudes. This paper reviews and discusses existing emotion categorization models for emotion analysis and proposes methods that enhance existing emotion research. We carried out emotion analysis by inviting experts from different research areas to produce comprehensive results. Moreover, a computational emotion sensing model is proposed, and future improvements are discussed in this paper.},
  langid = {english},
  keywords = {Affective computing,Emotion categorization model,Emotion definition,Sentiment analysis},
  file = {/Users/timokoch/Zotero/storage/FAJJNFRH/Wang et al. - 2020 - A review of emotion sensing categorization models.pdf}
}

@article{wangSensingBehavioralChange2018,
  title = {Sensing {{Behavioral Change}} over {{Time}}: {{Using Within-Person Variability Features}} from {{Mobile Sensing}} to {{Predict Personality Traits}}},
  shorttitle = {Sensing {{Behavioral Change}} over {{Time}}},
  author = {Wang, Weichen and Harari, Gabriella M. and Wang, Rui and M{\"u}ller, Sandrine R. and Mirjafari, Shayan and Masaba, Kizito and Campbell, Andrew T.},
  year = {2018},
  month = sep,
  journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
  volume = {2},
  number = {3},
  pages = {1--21},
  issn = {24749567},
  doi = {10.1145/3264951},
  urldate = {2019-02-11},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/WKUBVKZ5/Wang et al. - 2018 - Sensing Behavioral Change over Time Using Within-.pdf}
}

@inproceedings{wangStudentLifeAssessingMental2014,
  title = {{{StudentLife}}: Assessing Mental Health, Academic Performance and Behavioral Trends of College Students Using Smartphones},
  shorttitle = {{{StudentLife}}},
  booktitle = {Proceedings of the 2014 {{ACM International Joint Conference}} on {{Pervasive}} and {{Ubiquitous Computing}}},
  author = {Wang, Rui and Chen, Fanglin and Chen, Zhenyu and Li, Tianxing and Harari, Gabriella M. and Tignor, Stefanie and Zhou, Xia and {Ben-Zeev}, Dror and Campbell, Andrew T.},
  year = {2014},
  month = sep,
  pages = {3--14},
  publisher = {{ACM}},
  address = {{Seattle Washington}},
  doi = {10.1145/2632048.2632054},
  urldate = {2021-09-16},
  abstract = {Much of the stress and strain of student life remains hidden. The StudentLife continuous sensing app assesses the day-today and week-by-week impact of workload on stress, sleep, activity, mood, sociability, mental well-being and academic performance of a single class of 48 students across a 10 week term at Dartmouth College using Android phones. Results from the StudentLife study show a number of significant correlations between the automatic objective sensor data from smartphones and mental health and educational outcomes of the student body. We also identify a Dartmouth term lifecycle in the data that shows students start the term with high positive affect and conversation levels, low stress, and healthy sleep and daily activity patterns. As the term progresses and the workload increases, stress appreciably rises while positive affect, sleep, conversation and activity drops off. The StudentLife dataset is publicly available on the web.},
  isbn = {978-1-4503-2968-2},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/2H8PQHQ4/Wang et al. - 2014 - StudentLife assessing mental health, academic per.pdf}
}

@misc{WasVerratenInstant2022,
  title = {{Was verraten Instant Messages {\"u}ber die Nutzer}},
  year = {2022},
  month = feb,
  journal = {{$<$}IT{$>$}rockt!},
  urldate = {2023-02-14},
  abstract = {Was verraten Instant Messages {\"u}ber die Nutzer},
  chapter = {\#work!},
  langid = {nswissgerman},
  file = {/Users/timokoch/Zotero/storage/4KSFFVWM/was-verraten-instant-messages-ueber-die-nutzer.html}
}

@article{weidmanNotHearingHappiness2020,
  title = {({{Not}}) Hearing Happiness: {{Predicting}} Fluctuations in Happy Mood from Acoustic Cues Using Machine Learning},
  shorttitle = {({{Not}}) Hearing Happiness},
  author = {Weidman, Aaron C. and Sun, Jessie and Vazire, Simine and Quoidbach, Jordi and Ungar, Lyle H. and Dunn, Elizabeth W.},
  year = {2020},
  month = jun,
  journal = {Emotion (Washington, D.C.)},
  volume = {20},
  number = {4},
  pages = {642--658},
  issn = {1931-1516},
  doi = {10.1037/emo0000571},
  abstract = {Recent popular claims surrounding virtual assistants suggest that computers will soon be able to hear our emotions. Supporting this possibility, promising work has harnessed big data and emergent technologies to automatically predict stable levels of one specific emotion, happiness, at the community (e.g., counties) and trait (i.e., people) levels. Furthermore, research in affective science has shown that nonverbal vocal bursts (e.g., sighs, gasps) and specific acoustic features (e.g., pitch, energy) can differentiate between distinct emotions (e.g., anger, happiness) and that machine-learning algorithms can detect these differences. Yet, to our knowledge, no work has tested whether computers can automatically detect normal, everyday, within-person fluctuations in one emotional state from acoustic analysis. To address this issue in the context of happy mood, across 3 studies (total N = 20,197), we asked participants to repeatedly report their state happy mood and to provide audio recordings-including both direct speech and ambient sounds-from which we extracted acoustic features. Using three different machine learning algorithms (neural networks, random forests, and support vector machines) and two sets of acoustic features, we found that acoustic features yielded minimal predictive insight into happy mood above chance. Neither multilevel modeling analyses nor human coders provided additional insight into state happy mood. These findings suggest that it is not yet possible to automatically assess fluctuations in one emotional state (i.e., happy mood) from acoustic analysis, pointing to a critical future direction for affective scientists interested in acoustic analysis of emotion and automated emotion detection. (PsycInfo Database Record (c) 2020 APA, all rights reserved).},
  langid = {english},
  pmid = {30742458},
  keywords = {Adult,Cues,Emotions,Female,Happiness,Humans,Machine Learning,Male,Young Adult},
  file = {/Users/timokoch/Zotero/storage/2Y4JPLVD/Weidman-et-al.-in-press-Not-Hearing-Happiness.pdf;/Users/timokoch/Zotero/storage/PZYG6VEY/Weidman et al. - (Not) Hearing Happiness Predicting Fluctuations i.pdf;/Users/timokoch/Zotero/storage/W2RTSIML/EMO-2018-0967_Supplemental_Materials.docx}
}

@inproceedings{weiWordsPredictingUser2017,
  title = {Beyond the Words: {{Predicting}} User Personality from Heterogeneous Information},
  booktitle = {Proceedings of the Tenth {{ACM}} International Conference on Web Search and Data Mining},
  author = {Wei, Honghao and Zhang, Fuzheng and Yuan, Nicholas Jing and Cao, Chuan and Fu, Hao and Xie, Xing and Rui, Yong and Ma, Wei-Ying},
  year = {2017},
  pages = {305--314},
  publisher = {{ACM}},
  isbn = {1-4503-4675-8}
}

@article{weningerAcousticsEmotionAudio2013,
  title = {On the {{Acoustics}} of {{Emotion}} in {{Audio}}: {{What Speech}}, {{Music}}, and {{Sound}} Have in {{Common}}},
  shorttitle = {On the {{Acoustics}} of {{Emotion}} in {{Audio}}},
  author = {Weninger, Felix and Eyben, Florian and Schuller, Bj{\"o}rn W. and Mortillaro, Marcello and Scherer, Klaus R.},
  year = {2013},
  month = may,
  journal = {Frontiers in Psychology},
  volume = {4},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2013.00292},
  urldate = {2020-11-20},
  abstract = {Without doubt, there is emotional information in almost any kind of sound received by humans every day: be it the affective state of a person transmitted by means of speech; the emotion intended by a composer while writing a musical piece, or conveyed by a musician while performing it; or the affective state connected to an acoustic event occurring in the environment, in the soundtrack of a movie, or in a radio play. In the field of affective computing, there is currently some loosely connected research concerning either of these phenomena, but a holistic computational model of affect in sound is still lacking. In turn, for tomorrow's pervasive technical systems, including affective companions and robots, it is expected to be highly beneficial to understand the affective dimensions of ``the sound that something makes,'' in order to evaluate the system's auditory environment and its own audio output. This article aims at a first step toward a holistic computational model: starting from standard acoustic feature extraction schemes in the domains of speech, music, and sound analysis, we interpret the worth of individual features across these three domains, considering four audio databases with observer annotations in the arousal and valence dimensions. In the results, we find that by selection of appropriate descriptors, cross-domain arousal, and valence regression is feasible achieving significant correlations with the observer annotations of up to 0.78 for arousal (training on sound and testing on enacted speech) and 0.60 for valence (training on enacted speech and testing on music). The high degree of cross-domain consistency in encoding the two main dimensions of affect may be attributable to the co-evolution of speech and music from multimodal affect bursts, including the integration of nature sounds for expressive effects.},
  pmcid = {PMC3664314},
  pmid = {23750144},
  file = {/Users/timokoch/Zotero/storage/VPYMS6QS/Weninger et al. - 2013 - On the Acoustics of Emotion in Audio What Speech,.pdf}
}

@misc{whatsappEndtoendEncryption2018,
  title = {End-to-End Encryption},
  author = {WhatsApp},
  year = {2018}
}

@misc{whatsappTwoBillionUsers2020,
  title = {{Two Billion Users -- Connecting the World Privately}},
  author = {WhatsApp},
  year = {2020},
  journal = {WhatsApp.com},
  urldate = {2020-04-12},
  howpublished = {https://blog.whatsapp.com/two-billion-users-connecting-the-world-privately},
  langid = {ngerman}
}

@misc{wiggersNewStartupShows2022,
  title = {New Startup Shows How Emotion-Detecting {{AI}} Is Intrinsically Problematic},
  author = {Wiggers, Kyle},
  year = {2022},
  month = jan,
  journal = {VentureBeat},
  urldate = {2022-12-02},
  abstract = {Hume, a new company emerging from stealth, claims that it is 'ethically' applying emotion AI. But the science is shaky at best.},
  langid = {american},
  file = {/Users/timokoch/Zotero/storage/3LSXHVXS/new-startup-shows-how-emotion-detecting-ai-is-intrinsically-problematic.html}
}

@misc{wikipediaListEmoticons2018,
  title = {List of Emoticons},
  author = {Wikipedia},
  year = {2018},
  howpublished = {https://de.statista.com/statistik/daten/studie/613574/umfrage/nutzung-von-facebook-produkten-nach-geschlecht-in-deutschland/}
}

@article{wiltingRealVsActed,
  title = {Real vs. Acted Emotional Speech},
  author = {Wilting, Janneke and Krahmer, Emiel and Swerts, Marc},
  pages = {5},
  abstract = {Even though the use of actors is a popular method for researching the expression of emotion, little is known about the relation between acted and real emotions. To shed some light on this, we set up a novel experiment, based on the Velten mood induction procedure, during which participants have to utter pre-defined sentences with a strong emotional content. In one group of participants, real positive or negative emotions were induced, while another group was instructed to act positive or negative while uttering Velten sentences. Results of a mood questionnaire revealed that participants in the real emotion condition, indeed felt positive or negative, depending on whether they read positive or negative sentences, while participants in the acted emotion condition felt neutral afterwards. In a second, perception experiment, it was found that acted emotions (especially negative ones) were perceived more strongly than the real emotions. This suggests that actors do not feel the acted emotion, and may engage in overacting, which casts doubt on the usefulness of actors as a way to study real emotions.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/YHNZK4RM/Wilting et al. - Real vs. acted emotional speech.pdf}
}

@article{wiltingRealVsActed2006,
  title = {Real vs. Acted Emotional Speech},
  author = {Wilting, J. and Krahmer, E. J. and Swerts, M. G. J.},
  year = {2006},
  journal = {Proceedings of the International Conference on Spoken Language Processing (Interspeech 2006)},
  publisher = {{ISCA}},
  urldate = {2021-06-30},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/YMU45LBA/Wilting et al. - 2006 - Real vs. acted emotional speech.pdf;/Users/timokoch/Zotero/storage/XZRNDHG6/real-vs-acted-emotional-speech.html}
}

@article{windsorAutomatedContentAnalysis2019,
  title = {Automated Content Analysis across Six Languages},
  author = {Windsor, Leah Cathryn and Cupit, James Grayson and Windsor, Alistair James},
  year = {2019},
  month = nov,
  journal = {PLOS ONE},
  volume = {14},
  number = {11},
  pages = {e0224425},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0224425},
  urldate = {2021-02-24},
  abstract = {Corpus selection bias in international relations research presents an epistemological problem: How do we know what we know? Most social science research in the field of text analytics relies on English language corpora, biasing our ability to understand international phenomena. To address the issue of corpus selection bias, we introduce results that suggest that machine translation may be used to address non-English sources. We use human translation and machine translation (Google Translate) on a collection of aligned sentences from United Nations documents extracted from the Multi-UN corpus, analyzed with a ``bag of words'' analysis tool, Linguistic Inquiry Word Count (LIWC). Overall, the LIWC indices proved relatively stable across machine and human translated sentences. We find that while there are statistically significant differences between the original and translated documents, the effect sizes are relatively small, especially when looking at psychological processes.},
  langid = {english},
  keywords = {Cognition,Computational linguistics,Grammar,Languages,Psycholinguistics,Semantics,Social sciences,Syntax},
  file = {/Users/timokoch/Zotero/storage/ZYYW4T4H/Windsor et al. - 2019 - Automated content analysis across six languages.pdf;/Users/timokoch/Zotero/storage/6MZQ552Q/article.html}
}

@article{wolfComputergestutzteQuantitativeTextanalyse2008,
  title = {Computergest{\"u}tzte Quantitative {{Textanalyse}}},
  author = {Wolf, Markus and Horn, Andrea B. and Mehl, Matthias R. and Haug, Severin and Pennebaker, James W. and Kordy, Hans},
  year = {2008},
  journal = {Diagnostica},
  volume = {54},
  number = {2},
  pages = {85--98},
  issn = {0012-1924 2190-622X},
  doi = {10.1026/0012-1924.54.2.85}
}

@article{wolfEmotionalExpressionOnline2000,
  title = {Emotional {{Expression Online}}: {{Gender Differences}} in {{Emoticon Use}}},
  shorttitle = {Emotional {{Expression Online}}},
  author = {Wolf, Alecia},
  year = {2000},
  month = oct,
  journal = {CyberPsychology \& Behavior},
  volume = {3},
  number = {5},
  pages = {827--833},
  issn = {1094-9313, 1557-8364},
  doi = {10.1089/10949310050191809},
  urldate = {2020-04-08},
  abstract = {The analysis of emoticon (emotional icon) use in online newsgroups appears to reinforce the stereotype of the emotional female and the inexpressive male until further examination suggests otherwise. The most interesting finding of this study is illustrated by the pattern of change that develops for both genders when they move from a predominantly same gender newsgroup to a mixed-gender newsgroup. The changes that take place in emoticon use when moving from same-gender to mixed-gender newsgroups indicate that rather than the emotional expression of females being silenced or muted by male encoding of emoticons, males adopt the female standard of expressing more emotion. Furthermore, women have added dimensions including solidarity, support, assertion of positive feelings, and thanks, which were absent from the male-created definition of emoticons and their use.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/BEGDUNI5/Wolf - 2000 - Emotional Expression Online Gender Differences in.pdf}
}

@article{woongyunSelectivePostingWillingness2011,
  title = {Selective {{Posting}}: {{Willingness}} to Post a Message Online},
  author = {Woong Yun, Gi and Park, Sung-Yeon},
  year = {2011},
  journal = {Journal of Computer-Mediated Communication},
  volume = {16},
  number = {2},
  pages = {201--227},
  issn = {10836101},
  doi = {10.1111/j.1083-6101.2010.01533.x},
  file = {/Users/timokoch/Zotero/storage/ECI6B5X2/Woong Yun und Park - 2011 - Selective Posting Willingness to post a message o.pdf}
}

@article{wrightLittleInteractionsGet2016,
  title = {Do Little Interactions Get Lost in Dark Random Forests?},
  author = {Wright, Marvin N. and Ziegler, Andreas and K{\"o}nig, Inke R.},
  year = {2016},
  month = dec,
  journal = {BMC Bioinformatics},
  volume = {17},
  number = {1},
  pages = {145},
  issn = {1471-2105},
  doi = {10.1186/s12859-016-0995-8},
  urldate = {2021-06-17},
  abstract = {Background: Random forests have often been claimed to uncover interaction effects. However, if and how interaction effects can be differentiated from marginal effects remains unclear. In extensive simulation studies, we investigate whether random forest variable importance measures capture or detect gene-gene interactions. With capturing interactions, we define the ability to identify a variable that acts through an interaction with another one, while detection is the ability to identify an interaction effect as such. Results: Of the single importance measures, the Gini importance captured interaction effects in most of the simulated scenarios, however, they were masked by marginal effects in other variables. With the permutation importance, the proportion of captured interactions was lower in all cases. Pairwise importance measures performed about equal, with a slight advantage for the joint variable importance method. However, the overall fraction of detected interactions was low. In almost all scenarios the detection fraction in a model with only marginal effects was larger than in a model with an interaction effect only. Conclusions: Random forests are generally capable of capturing gene-gene interactions, but current variable importance measures are unable to detect them as interactions. In most of the cases, interactions are masked by marginal effects and interactions cannot be differentiated from marginal effects. Consequently, caution is warranted when claiming that random forests uncover interactions.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/UGWF7RQ5/Wright et al. - 2016 - Do little interactions get lost in dark random for.pdf}
}

@article{wrightRangerFastImplementation2015,
  title = {Ranger: {{A}} Fast Implementation of Random Forests for High Dimensional Data in {{C}}++ and {{R}}},
  author = {Wright, Marvin N. and Ziegler, Andreas},
  year = {2015},
  journal = {arXiv preprint arXiv:1508.04409},
  eprint = {1508.04409},
  archiveprefix = {arxiv},
  file = {/Users/timokoch/Zotero/storage/RT39BUY2/Wright und Ziegler - 2015 - ranger A fast implementation of random forests fo.pdf}
}

@article{wrightRangerFastImplementation2017,
  title = {Ranger: {{A Fast Implementation}} of {{Random Forests}} for {{High Dimensional Data}} in {{C}}++ and {{R}}},
  shorttitle = {Ranger},
  author = {Wright, Marvin N. and Ziegler, Andreas},
  year = {2017},
  month = mar,
  journal = {Journal of Statistical Software},
  volume = {77},
  number = {1},
  pages = {1--17},
  issn = {1548-7660},
  doi = {10.18637/jss.v077.i01},
  urldate = {2020-08-17},
  copyright = {Copyright (c) 2017 Marvin N. Wright, Andreas Ziegler},
  langid = {english},
  keywords = {C++,classification,machine learning,R,random forests,Rcpp,recursive partitioning,survival analysis},
  file = {/Users/timokoch/Zotero/storage/TCWRPQZH/Wright und Ziegler - 2017 - ranger A Fast Implementation of Random Forests fo.pdf;/Users/timokoch/Zotero/storage/2HLXM4H9/v077i01.html}
}

@article{wuAccuracyTraitJudgments2021,
  title = {Accuracy in Trait Judgments Based on {{WeChat}}: {{Detecting}} Who Stands on the Extreme Levels of the Big-Five Trait Continua},
  shorttitle = {Accuracy in Trait Judgments Based on {{WeChat}}},
  author = {Wu, Wenjie and Mitchell, Peter and Zheng, Jianhong and Chen, Shiyao},
  year = {2021},
  month = apr,
  journal = {Personality and Individual Differences},
  volume = {173},
  pages = {110610},
  issn = {0191-8869},
  doi = {10.1016/j.paid.2020.110610},
  urldate = {2021-02-05},
  abstract = {Trait inferences occur not only during social interaction but also in virtual environments. Previous research suggested social media owners (targets) revealed their real but not idealized personality traits online, based on which people were to some extent able to make accurate judgments of the big-five traits of the targets. In the present research, participants made inferences of different levels of targets' big-five traits (low, meddle or high) after briefly browsing scant information of the unacquainted WeChat owners. Results demonstrated that participants were not uniformly accurate in judging each level of each of the big-five traits; they were prone to be accurate when judging a target located on the extremes (low or high) of the traits, but were less accurate when judging a target located at the average level. These findings extend previous results from real-world scenarios revealing people's ability to perceive other persons based on subtle signals in the domain of social media.},
  langid = {english},
  keywords = {Accuracy,Big-five traits,Person perception,Trait judgments,WeChat},
  file = {/Users/timokoch/Zotero/storage/T8NDNKFB/S0191886920308011.html}
}

@article{wuMultimodalDataCollection2021,
  title = {Multi-Modal Data Collection for Measuring Health, Behavior, and Living Environment of Large-Scale Participant Cohorts},
  author = {Wu, C. and Fritz, H. and Bastami, S. and Maestre, J.P. and Thomaz, E. and Julien, C. and Castelli, D.M. and De Barbaro, K. and Bearman, S.K. and Harari, G.M. and Craddock, R.C. and Kinney, K.A. and Gosling, S.D. and Schnyer, D.M. and Nagy, Z.},
  year = {2021},
  journal = {GigaScience},
  volume = {10},
  number = {6},
  issn = {2047-217X},
  doi = {10.1093/gigascience/giab044},
  abstract = {Background: As mobile technologies become ever more sensor-rich, portable, and ubiquitous, data captured by smart devices are lending rich insights into users' daily lives with unprecedented comprehensiveness and ecological validity. A number of human-subject studies have been conducted to examine the use of mobile sensing to uncover individual behavioral patterns and health outcomes, yet minimal attention has been placed on measuring living environments together with other human-centered sensing data. Moreover, the participant sample size in most existing studies falls well below a few hundred, leaving questions open about the reliability of findings on the relations between mobile sensing signals and human outcomes. Results: To address these limitations, we developed a home environment sensor kit for continuous indoor air quality tracking and deployed it in conjunction with smartphones, Fitbits, and ecological momentary assessments in a cohort study of up to 1,584 college student participants per data type for 3 weeks. We propose a conceptual framework that systematically organizes human-centric data modalities by their temporal coverage and spatial freedom. Then we report our study procedure, technologies and methods deployed, and descriptive statistics of the collected data that reflect the participants' mood, sleep, behavior, and living environment. Conclusions: We were able to collect from a large participant cohort satisfactorily complete multi-modal sensing and survey data in terms of both data continuity and participant adherence. Our novel data and conceptual development provide important guidance for data collection and hypothesis generation in future human-centered sensing studies. {\textcopyright} 2021 The Author(s). Published by Oxford University Press GigaScience.},
  langid = {english},
  keywords = {BEVO Beacon,college students,ecological momentary assessment,Fitbit,health,human-centered computing,multi-modal sensing,smartphone},
  file = {/Users/timokoch/Zotero/storage/AHP8T5X5/Wu et al. - 2021 - Multi-modal data collection for measuring health, .pdf;/Users/timokoch/Zotero/storage/EIXC3D2V/display.html}
}

@article{yangBehavioralPhysiologicalSignalsBased2021,
  title = {Behavioral and {{Physiological Signals-Based Deep Multimodal Approach}} for {{Mobile Emotion Recognition}}},
  author = {Yang, Kangning and Wang, Chaofan and Gu, Yue and Sarsenbayeva, Zhanna and Tag, Benjamin and Dingler, Tilman and Wadley, Greg and Goncalves, Jorge},
  year = {2021},
  journal = {IEEE Transactions on Affective Computing},
  pages = {1--1},
  issn = {1949-3045},
  doi = {10.1109/TAFFC.2021.3100868},
  abstract = {With the rapid development of mobile and wearable devices, it is increasingly possible to access users' affective data in a more unobtrusive manner. On this basis, researchers have proposed various systems to recognize user's emotional states. However, most of these studies rely on traditional machine learning techniques and a limited number of signals, leading to systems that either do not generalize well or would frequently lack sufficient information for emotion detection in realistic scenarios. In this paper, we propose a novel attention-based LSTM system that uses a combination of sensors from a smartphone (front camera, microphone, touch panel) and a wristband (photoplethysmography, electrodermal activity, and infrared thermopile sensor) to accurately determine user's emotional states. We evaluated the proposed system by conducting a user study with 45 participants. Using collected behavioral (facial expression, speech, keystroke) and physiological (blood volume, electrodermal activity, skin temperature) affective responses induced by visual stimuli, our system was able to achieve an average accuracy of 89.2\% for binary positive and negative emotion classification under leave-one-participant-out cross-validation. Furthermore, we investigated the effectiveness of different combinations of data signals to cover different scenarios of signal availability.},
  keywords = {attention-based LSTM,behavioral signals,Biomedical monitoring,Emotion recognition,Feature extraction,mobile and wearable devices,physiological signals,Physiology,Sensors,Visualization,Wearable computers},
  file = {/Users/timokoch/Zotero/storage/L5W6QV4C/Yang et al. - 2021 - Behavioral and Physiological Signals-Based Deep Mu.pdf;/Users/timokoch/Zotero/storage/TQ6I9SKF/9502508.html}
}

@article{yangChannelMattersSelfdisclosure2019,
  title = {The {{Channel Matters}}: {{Self-disclosure}}, {{Reciprocity}} and {{Social Support}} in {{Online Cancer Support Groups}}},
  shorttitle = {The {{Channel Matters}}},
  author = {Yang, Diyi and Yao, Zheng and Seering, Joseph and Kraut, Robert},
  year = {2019},
  month = may,
  journal = {Proceedings of the SIGCHI conference on human factors in computing systems. CHI Conference},
  volume = {2019},
  doi = {10.1145/3290605.3300261},
  urldate = {2020-07-03},
  abstract = {People with health concerns go to online health support groups to obtain help and advice. To do so, they frequently disclose personal details, many times in public. Although research in non-health settings suggests that people self-disclose less in public than in private, this pattern may not apply to health support groups where people want to get relevant help. Our work examines how the use of private and public channels influences members' self-disclosure in an online cancer support group, and how channels moderate the influence of self-disclosure on reciprocity and receiving support. By automatically measuring people's self-disclosure at scale, we found that members of cancer support groups revealed more negative self-disclosure in the public channels compared to the private channels. Although one's self-disclosure leads others to self-disclose and to provide support, these effects were generally stronger in the private channel. These channel effects probably occur because the public channels are the primary venue for support exchange, while the private channels are mainly used for follow-up conversations. We discuss theoretical and practical implications of our work.},
  pmcid = {PMC6708374},
  pmid = {31448374},
  file = {/Users/timokoch/Zotero/storage/536AAIKI/Yang et al. - 2019 - The Channel Matters Self-disclosure, Reciprocity .pdf}
}

@article{yarkoniChoosingPredictionExplanation2017,
  title = {Choosing {{Prediction Over Explanation}} in {{Psychology}}: {{Lessons From Machine Learning}}},
  shorttitle = {Choosing {{Prediction Over Explanation}} in {{Psychology}}},
  author = {Yarkoni, Tal and Westfall, Jacob},
  year = {2017},
  month = nov,
  journal = {Perspectives on Psychological Science},
  volume = {12},
  number = {6},
  pages = {1100--1122},
  issn = {1745-6916, 1745-6924},
  doi = {10.1177/1745691617693393},
  urldate = {2020-06-20},
  abstract = {Psychology has historically been concerned, first and foremost, with explaining the causal mechanisms that give rise to behavior. Randomized, tightly controlled experiments are enshrined as the gold standard of psychological research, and there are endless investigations of the various mediating and moderating variables that govern various behaviors. We argue that psychology's near-total focus on explaining the causes of behavior has led much of the field to be populated by research programs that provide intricate theories of psychological mechanism but that have little (or unknown) ability to predict future behaviors with any appreciable accuracy. We propose that principles and techniques from the field of machine learning can help psychology become a more predictive science. We review some of the fundamental concepts and tools of machine learning and point out examples where these concepts have been used to conduct interesting and important psychological research that focuses on predictive research questions. We suggest that an increased focus on prediction, rather than explanation, can ultimately lead us to greater understanding of behavior.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/G2KM6QY6/Yarkoni und Westfall - 2017 - Choosing Prediction Over Explanation in Psychology.pdf}
}

@article{yarkoniPersonality1000002010,
  title = {Personality in 100,000 {{Words}}: {{A}} Large-Scale Analysis of Personality and Word Use among Bloggers},
  author = {Yarkoni, T.},
  year = {2010},
  month = jun,
  journal = {J Res Pers},
  volume = {44},
  number = {3},
  pages = {363--373},
  issn = {0092-6566 (Print) 0092-6566 (Linking)},
  doi = {10.1016/j.jrp.2010.04.001},
  abstract = {Previous studies have found systematic associations between personality and individual differences in word use. Such studies have typically focused on broad associations between major personality domains and aggregate word categories, potentially masking more specific associations. Here I report the results of a large-scale analysis of personality and word use in a large sample of blogs (N=694). The size of the dataset enabled pervasive correlations with personality to be identified for a broad range of lexical variables, including both aggregate word categories and individual English words. The results replicated category-level findings from previous offline studies, identified numerous novel associations at both a categorical and single-word level, and underscored the value of complementary approaches to the study of personality and word use.},
  pmcid = {PMC2885844}
}

@article{yeeExpressionPersonalityVirtual2011,
  title = {The Expression of Personality in Virtual Worlds},
  author = {Yee, Nick and Harris, Helen and Jabon, Maria and Bailenson, Jeremy N.},
  year = {2011},
  journal = {Social Psychological and Personality Science},
  volume = {2},
  number = {1},
  pages = {5--12}
}

@article{yuRoleAffectSelfDisclosure2015,
  title = {Role of {{Affect}} in {{Self-Disclosure}} on {{Social Network Websites}}: {{A Test}} of {{Two Competing Models}}},
  shorttitle = {Role of {{Affect}} in {{Self-Disclosure}} on {{Social Network Websites}}},
  author = {Yu, Jongtae and Hu, Paul Jen-Hwa and Cheng, Tsang-Hsiang},
  year = {2015},
  month = apr,
  journal = {Journal of Management Information Systems},
  volume = {32},
  number = {2},
  pages = {239--277},
  publisher = {{Routledge}},
  issn = {0742-1222},
  doi = {10.1080/07421222.2015.1063305},
  urldate = {2020-11-30},
  abstract = {This study examines how affect influences self-disclosure on social network (SN) websites. We test two competing models that build on direct causation theory and affect heuristic theory, respectively. In a direct effect model, affect steers self-disclosure, independent of cognitive cost{\textendash}benefit appraisals. The indirect effect model instead suggests that affect influences self-disclosure by adjusting perceptions of benefits and costs. The empirical comparison of the models relies on survey data from more than 500 university students. Overall, affect influences self-disclosure indirectly by adjusting the benefits people perceive. In particular, affect toward self-disclosure and toward SN websites relate positively to self-disclosure motivators; their perceived values appear amplified in the presence of positive affect. We also offer a plausible, alternative explanation of the observed positive relationship between privacy risk and self-disclosure according to an indirect effect model, in which self-disclosure is driven mainly by motivators, whereas the effects of inhibitors depend a posteriori on self-disclosure. These findings call for a reconsideration of any exclusive focus on the direct impacts of affect on technology use, as is common in previous research, and suggest the importance of affective factors for understanding social technology uses and managing customer relationships.},
  keywords = {affect,dual processing approach,online privacy,online self-disclosure,social network sites}
}

@article{zhangPredictingGenderBlog,
  title = {Predicting Gender from Blog Posts},
  author = {Zhang, Cathy and Zhang, Pengyu},
  pages = {10},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/KB6D42ZQ/Zhang und Zhang - Predicting gender from blog posts.pdf}
}

@inproceedings{zhangPredictingGenderBlog2010,
  title = {Predicting Gender from Blog Posts},
  author = {Zhang, Cathy and Zhang, Pengyu},
  year = {2010},
  abstract = {Blogs are informal, personal writings that people post on their own blog sites. Nowadays, blogging is an important online activity. People share blogs with their friends and family members. The topics of blog posting cover almost everything, ranging from personal life, political opinions, recipes, product reviews, or even just random rants. Although some bloggers review their biologically information on their blog site, many don't make such information public. Thereful, automatically classifying the gender or age of a blog author may have important applications in many commercial domains, such as targeted advertising and product development [8]. In blog search, this information may help people find blogs that they are interested in. From a research perspective, blog author gender classification is also an interesting problem. Blog posts are typically short and unstructured. They differ tremendously from formal texts, since they may have informal sentences, grammer errors, slang words and phrases, and wrong spellings. These characteristics of blog posts may complicate any classification or categorization attempts. The goal of our project is to identify author gender of blogs coming from a wide variety of sources. We are interested in knowing how well we can tackle this problem, what methods and features are most effective in this task.},
  file = {/Users/timokoch/Zotero/storage/YMP5VIWN/Zhang und Zhang - 2010 - Predicting gender from blog posts.pdf}
}

@misc{zhaoCurationUse2014,
  title = {Curation through Use},
  author = {Zhao, Xuan and Lindley, Si{\^a}n E.},
  year = {2014}
}

@inproceedings{zhaoCurationUseUnderstanding2014,
  title = {Curation through Use: Understanding the Personal Value of Social Media},
  shorttitle = {Curation through Use},
  booktitle = {Proceedings of the 32nd Annual {{ACM}} Conference on {{Human}} Factors in Computing Systems - {{CHI}} '14},
  author = {Zhao, Xuan and Lindley, Si{\^a}n E.},
  year = {2014},
  pages = {2431--2440},
  publisher = {{ACM Press}},
  address = {{Toronto, Ontario, Canada}},
  doi = {10.1145/2556288.2557291},
  urldate = {2020-03-18},
  abstract = {Content generation on social network sites has been considered mainly from the perspective of individuals interacting with social network contacts. Yet research has also pointed to the potential for social media to become a meaningful personal archive over time. The aim of this paper is to consider how social media, over time and across sites, forms part of the wider digital archiving space for individuals. Our findings, from a qualitative study of 14 social media users, highlight how although some sites are more associated with `keepable' social media than others, even those are not seen as archives in the usual sense of the word. We show how this perception is bound up with five contradictions, which center on social media as curated, as a reliable repository of meaningful content, as readily encountered and as having the potential to present content as a compelling narrative. We conclude by highlighting opportunities for design relating to curation through use and what this implies for personal digital archives, which are known to present difficulties in terms of curation and re-finding.},
  isbn = {978-1-4503-2473-1},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/IZLDXJI9/p2431-zhao.pdf}
}

@article{zhaoExplorationRumorCombating2016,
  title = {An Exploration of Rumor Combating Behavior on Social Media in the Context of Social Crises},
  author = {Zhao, Liming and Yin, Jianli and Song, Yao},
  year = {2016},
  month = may,
  journal = {Computers in Human Behavior},
  volume = {58},
  pages = {25--36},
  issn = {07475632},
  doi = {10.1016/j.chb.2015.11.054},
  urldate = {2019-05-23},
  abstract = {This study was conducted to provide a comprehensive understanding of the formation of social media users' rumor combating behavior during crises by merging the theory of planned behavior and the norm activation model into one theoretical framework. Based on a sample of 394 social media users, the descriptive statistical analysis showed two different kinds of gaps. ``Higher awareness but lower behavior gap'' represented gaps from higher-scoring constructs (including awareness of adverse consequences caused by rumors, ascribed responsibility of adverse consequences, sense of obligation and behavioral intention to combat rumors) to lower-scoring actual behavior, whereas ``lower attitude but higher behavior gap'' represented the gap from lower-scoring attitudes toward rumor combating to higherscoring actual behavior. The results of the structural analysis demonstrated that the proposed model had a satisfactory level of prediction power for pro-social rumor combating behavior. The findings also supported all the hypothesized relationships among the model constructs except the direct influences of subjective norms and perceived behavioral control on behavioral intention and verified the mediating roles of the model constructs. In particular, subjective norms, perceived behavioral control and awareness of adverse consequences were the three most important predictors of actual rumor combating behavior.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/27Y7MDXN/Zhao et al. - 2016 - An exploration of rumor combating behavior on soci.pdf}
}

@inproceedings{zhaoManyFacesFacebook2013,
  title = {The Many Faces of Facebook: Experiencing Social Media as Performance, Exhibition, and Personal Archive},
  shorttitle = {The Many Faces of Facebook},
  booktitle = {Proceedings of the {{SIGCHI Conference}} on {{Human Factors}} in {{Computing Systems}} - {{CHI}} '13},
  author = {Zhao, Xuan and Salehi, Niloufar and Naranjit, Sasha and Alwaalan, Sara and Voida, Stephen and Cosley, Dan},
  year = {2013},
  pages = {1},
  publisher = {{ACM Press}},
  address = {{Paris, France}},
  doi = {10.1145/2470654.2470656},
  urldate = {2020-03-18},
  abstract = {The growing use of social media means that an increasing amount of people's lives are visible online. We draw from Goffman's theatrical metaphor and Hogan's exhibition approach to explore how people manage their personal collection of social media data over time. We conducted a qualitative study of 13 participants to reveal their day-to-day decision-making about producing and curating digital traces on Facebook. Their goals and strategies showed that people experience the Facebook platform as consisting of three different functional regions: a performance region for managing recent data and impression management, an exhibition region for longer term presentation of self-image, and a personal region for archiving meaningful facets of life. Further, users' need for presenting and archiving data in these three regions is mediated by temporality. These findings trigger a discussion of how to design social media that support these dynamic and sometimes conflicting needs.},
  isbn = {978-1-4503-1899-0},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/DBFQ2Q28/Zhao et al. - 2013 - The many faces of facebook experiencing social me.pdf}
}

@misc{zhaoManyFacesFacebook2013a,
  title = {The Many Faces of Facebook},
  author = {Zhao, Xuan and Salehi, Niloufar and Naranjit, Sasha and Alwaalan, Sara and Voida, Stephen and Cosley, Dan},
  year = {2013},
  file = {/Users/timokoch/Zotero/storage/2A3TGT8P/Zhao et al. - 2013 - The many faces of facebook.pdf}
}

@misc{ZISDiedeutscheVersiondesBigFiveInventory2BFI2,
  title = {{{ZIS}}: {{Die-deutsche-Version-des-Big-Five-Inventory-2-}}({{BFI-2}})},
  urldate = {2018-11-26},
  howpublished = {https://zis.gesis.org/skala/Danner-Rammstedt-Bluemke-Treiber-Berres-Soto-John-Die-deutsche-Version-des-Big-Five-Inventory-2-(BFI-2)},
  file = {/Users/timokoch/Zotero/storage/WE4CLX7F/Danner-Rammstedt-Bluemke-Treiber-Berres-Soto-John-Die-deutsche-Version-des-Big-Five-Inventory-2.html}
}

@article{zouRegularizationVariableSelection2005,
  title = {Regularization and Variable Selection via the Elastic Net},
  author = {Zou, Hui and Hastie, Trevor},
  year = {2005},
  month = apr,
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume = {67},
  number = {2},
  pages = {301--320},
  issn = {1369-7412, 1467-9868},
  doi = {10.1111/j.1467-9868.2005.00503.x},
  urldate = {2019-09-18},
  abstract = {We propose the elastic net, a new regularization and variable selection method. Real world data and a simulation study show that the elastic net often outperforms the lasso, while enjoying a similar sparsity of representation. In addition, the elastic net encourages a grouping effect, where strongly correlated predictors tend to be in or out of the model together. The elastic net is particularly useful when the number of predictors (p) is much bigger than the number of observations (n). By contrast, the lasso is not a very satisfactory variable selection method in the p n case. An algorithm called LARS-EN is proposed for computing elastic net regularization paths efficiently, much like algorithm LARS does for the lasso.},
  langid = {english},
  file = {/Users/timokoch/Zotero/storage/KRDA2AF7/Zou und Hastie - 2005 - Regularization and variable selection via the elas.pdf}
}

@misc{zuckerbergPrivacyFocusedVisionSocial2019,
  title = {A {{Privacy-Focused Vision}} for {{Social Networking}} | {{Facebook}}},
  author = {Zuckerberg, Mark},
  year = {2019},
  urldate = {2020-08-19},
  howpublished = {https://www.facebook.com/notes/mark-zuckerberg/a-privacy-focused-vision-for-social-networking/10156700570096634/},
  file = {/Users/timokoch/Zotero/storage/B6HU892M/10156700570096634.html}
}
